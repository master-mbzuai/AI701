{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file is for training 20 child classifers and saving their dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'11': {'15': 0, '19': 1, '21': 2, '31': 3, '38': 4}, '15': {'27': 0, '29': 1, '44': 2, '78': 3, '93': 4}, '4': {'0': 0, '51': 1, '53': 2, '57': 3, '83': 4}, '14': {'2': 0, '11': 1, '35': 2, '46': 3, '98': 4}, '1': {'1': 0, '32': 1, '67': 2, '73': 3, '91': 4}, '5': {'22': 0, '39': 1, '40': 2, '86': 3, '87': 4}, '18': {'8': 0, '13': 1, '48': 2, '58': 3, '90': 4}, '3': {'9': 0, '10': 1, '16': 2, '28': 3, '61': 4}, '10': {'23': 0, '33': 1, '49': 2, '60': 3, '71': 4}, '17': {'47': 0, '52': 1, '56': 2, '59': 3, '96': 4}, '2': {'54': 0, '62': 1, '70': 2, '82': 3, '92': 4}, '9': {'12': 0, '17': 1, '37': 2, '68': 3, '76': 4}, '8': {'3': 0, '42': 1, '43': 2, '88': 3, '97': 4}, '16': {'36': 0, '50': 1, '65': 2, '74': 3, '80': 4}, '6': {'5': 0, '20': 1, '25': 2, '84': 3, '94': 4}, '12': {'34': 0, '63': 1, '64': 2, '66': 3, '75': 4}, '19': {'41': 0, '69': 1, '81': 2, '85': 3, '89': 4}, '7': {'6': 0, '7': 1, '14': 2, '18': 3, '24': 4}, '13': {'26': 0, '45': 1, '77': 2, '79': 3, '99': 4}, '0': {'4': 0, '30': 1, '55': 2, '72': 3, '95': 4}}\n"
     ]
    }
   ],
   "source": [
    "# This is mapping between fine label, ranging from 0 to 99, to labels ranging from 0 to 4\n",
    "# key: parent category -> value: dictionary {key: fine label 0-99 -> value: label 0-4}\n",
    "import json\n",
    "f = open('../parent_to_child_class_from_0_to_5.json')\n",
    "parent_to_child_class_from_0_to_5 = json.load(f)\n",
    "print(parent_to_child_class_from_0_to_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import errno\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "if sys.version_info[0] == 2:\n",
    "    import cPickle as pickle\n",
    "else:\n",
    "    import pickle\n",
    "\n",
    "import torch.utils.data as data\n",
    "from torchvision.datasets.utils import download_url, check_integrity\n",
    "import torchvision.transforms as tt\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from sklearn.metrics import *\n",
    "from torchsummary import summary\n",
    "\n",
    "class CIFAR10(data.Dataset):\n",
    "    \"\"\"`CIFAR10 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where directory\n",
    "            ``cifar-10-batches-py`` exists.\n",
    "        train (bool, optional): If True, creates dataset from training set, otherwise\n",
    "            creates from test set.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "    \"\"\"\n",
    "    base_folder = 'cifar-10-batches-py'\n",
    "    url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "    filename = \"cifar-10-python.tar.gz\"\n",
    "    tgz_md5 = 'c58f30108f718f92721af3b95e74349a'\n",
    "    train_list = [\n",
    "        ['data_batch_1', 'c99cafc152244af753f735de768cd75f'],\n",
    "        ['data_batch_2', 'd4bba439e000b95fd0a9bffe97cbabec'],\n",
    "        ['data_batch_3', '54ebc095f3ab1f0389bbae665268c751'],\n",
    "        ['data_batch_4', '634d18415352ddfa80567beed471001a'],\n",
    "        ['data_batch_5', '482c414d41f54cd18b22e5b47cb7c3cb'],\n",
    "    ]\n",
    "\n",
    "    test_list = [\n",
    "        ['test_batch', '40351d587109b95175f43aff81a1287e'],\n",
    "    ]\n",
    "\n",
    "    meta = {\n",
    "        \"filename\": \"batches.meta\",\n",
    "        \"key\": \"label_names\",\n",
    "        \"md5\": \"5ff9c542aee3614f3951f8cda6e48888\",\n",
    "    }\n",
    "\n",
    "\n",
    "    def __init__(self, root, train=True,\n",
    "                 transform=None, target_transform=None,\n",
    "                 download=False, coarse=False, coarseNumber=None):\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train = train  # training set or test set\n",
    "        self.coarse = coarse\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_integrity():\n",
    "            raise RuntimeError('Dataset not found or corrupted.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "        # now load the picked numpy arrays\n",
    "        if self.train:\n",
    "            self.train_data = []\n",
    "            self.train_labels = []\n",
    "            self.train_coarse_labels = []\n",
    "            for fentry in self.train_list:\n",
    "                f = fentry[0]\n",
    "                file = os.path.join(self.root, self.base_folder, f)\n",
    "                fo = open(file, 'rb')\n",
    "                if sys.version_info[0] == 2:\n",
    "                    entry = pickle.load(fo)\n",
    "                else:\n",
    "                    entry = pickle.load(fo, encoding='latin1')\n",
    "                self.train_data.append(entry['data'])\n",
    "                if 'labels' in entry:\n",
    "                    self.train_labels += entry['labels']\n",
    "                else:\n",
    "                    self.train_labels += entry['fine_labels']\n",
    "                    if self.coarse:\n",
    "                        self.train_coarse_labels += entry['coarse_labels']\n",
    "                fo.close()\n",
    "            new_train_coarse_labels=[]\n",
    "            new_train_fine_labels=[]\n",
    "            new_train_data=[]\n",
    "            for data, fine,coarse in zip(self.train_data[0],self.train_labels, self.train_coarse_labels):\n",
    "                if coarse==coarseNumber:\n",
    "                    new_train_data.append(data)\n",
    "                    new_train_fine_labels.append(parent_to_child_class_from_0_to_5[str(coarseNumber)][str(fine)])\n",
    "                    new_train_coarse_labels.append(coarseNumber)\n",
    "\n",
    "            self.train_data=np.array([np.array(xi) for xi in new_train_data])\n",
    "            self.train_labels=new_train_fine_labels\n",
    "            self.train_coarse_labels=new_train_coarse_labels\n",
    "\n",
    "            self.train_data = self.train_data.reshape((len(new_train_data), 3, 32, 32))\n",
    "            self.train_data = self.train_data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "        else:\n",
    "            f = self.test_list[0][0]\n",
    "            file = os.path.join(self.root, self.base_folder, f)\n",
    "            fo = open(file, 'rb')\n",
    "            if sys.version_info[0] == 2:\n",
    "                entry = pickle.load(fo)\n",
    "            else:\n",
    "                entry = pickle.load(fo, encoding='latin1')\n",
    "            self.test_data = entry['data']\n",
    "\n",
    "            if 'labels' in entry:\n",
    "                self.test_labels = entry['labels']\n",
    "            else:\n",
    "                self.test_labels = entry['fine_labels']\n",
    "                if self.coarse:\n",
    "                    self.test_coarse_labels = entry['coarse_labels']\n",
    "                new_test_coarse_labels=[]\n",
    "                new_test_fine_labels=[]\n",
    "                new_test_data=[]\n",
    "\n",
    "                for data, fine,coarse in zip(self.test_data,self.test_labels, self.test_coarse_labels):\n",
    "                    if coarse==coarseNumber:\n",
    "                        new_test_data.append(data)\n",
    "                        new_test_fine_labels.append(parent_to_child_class_from_0_to_5[str(coarseNumber)][str(fine)])\n",
    "                        new_test_coarse_labels.append(coarseNumber)\n",
    "\n",
    "                self.test_data=np.array([np.array(xi) for xi in new_test_data])\n",
    "\n",
    "                self.test_labels=new_test_fine_labels\n",
    "                self.test_coarse_labels=new_test_coarse_labels\n",
    "            fo.close()\n",
    "            self.test_data = self.test_data.reshape((len(new_test_data), 3, 32, 32))\n",
    "            self.test_data = self.test_data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        if self.train:\n",
    "            img, target = self.train_data[index], self.train_labels[index]\n",
    "            if self.coarse:\n",
    "                coarse_target = self.train_coarse_labels[index]\n",
    "        else:\n",
    "            img, target = self.test_data[index], self.test_labels[index]\n",
    "            if self.coarse:\n",
    "                coarse_target = self.test_coarse_labels[index]\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        if not self.coarse:\n",
    "            return img, target\n",
    "        else:\n",
    "            return img, target, coarse_target\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_data)\n",
    "        else:\n",
    "            return len(self.test_data)\n",
    "\n",
    "    def _check_integrity(self):\n",
    "        root = self.root\n",
    "        for fentry in (self.train_list + self.test_list):\n",
    "            filename, md5 = fentry[0], fentry[1]\n",
    "            fpath = os.path.join(root, self.base_folder, filename)\n",
    "            if not check_integrity(fpath, md5):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def download(self):\n",
    "        import tarfile\n",
    "\n",
    "        if self._check_integrity():\n",
    "            print('Files already downloaded and verified')\n",
    "            return\n",
    "\n",
    "        root = self.root\n",
    "        download_url(self.url, root, self.filename, self.tgz_md5)\n",
    "\n",
    "        # extract file\n",
    "        cwd = os.getcwd()\n",
    "        tar = tarfile.open(os.path.join(root, self.filename), \"r:gz\")\n",
    "        os.chdir(root)\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "        os.chdir(cwd)\n",
    "\n",
    "\n",
    "class CIFAR100(CIFAR10):\n",
    "    \"\"\"`CIFAR100 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
    "    This is a subclass of the `CIFAR10` Dataset.\n",
    "    \"\"\"\n",
    "    base_folder = 'cifar-100-python'\n",
    "    url = \"https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\"\n",
    "    filename = \"cifar-100-python.tar.gz\"\n",
    "    tgz_md5 = 'eb9058c3a382ffc7106e4002c42a8d85'\n",
    "    train_list = [\n",
    "        ['train', '16019d7e3df5f24257cddd939b257f8d'],\n",
    "    ]\n",
    "\n",
    "    test_list = [\n",
    "        ['test', 'f0ef6b0ae62326f3e7ffdfab6717acfc'],\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = tt.Compose([tt.RandomCrop(32, padding=4,padding_mode='reflect'), \n",
    "                         tt.RandomHorizontalFlip(), \n",
    "                         tt.ToTensor(), \n",
    "                         #tt.Normalize(mean,std,inplace=True) \n",
    "                         ]\n",
    "                         )\n",
    "transform_test = tt.Compose([tt.ToTensor(), \n",
    "                             #tt.Normalize(mean,std)\n",
    "                             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 400\n",
    "epochs = 120\n",
    "max_lr = 0.001\n",
    "grad_clip = 0.01\n",
    "weight_decay =0.001\n",
    "opt_func = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def __init__(self, fine):\n",
    "        super(ImageClassificationBase, self).__init__()\n",
    "        self.fine = fine\n",
    "        #self.parent_to_child_class={}\n",
    "        self.unique_outs=[]\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, fine, coarse = batch\n",
    "        if self.fine:\n",
    "            labels=fine\n",
    "        else:\n",
    "            labels=coarse\n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, fine, coarse = batch \n",
    "\n",
    " \n",
    "        if self.fine:\n",
    "            labels=fine\n",
    "        else:\n",
    "            labels=coarse\n",
    "        out = self(images)\n",
    "\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))\n",
    "        \n",
    "def conv_block(in_channels, out_channels, pool=False):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
    "              nn.BatchNorm2d(out_channels), \n",
    "              nn.ReLU(inplace=True)]\n",
    "    if pool: layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class ResNet9(ImageClassificationBase):\n",
    "    def __init__(self, in_channels, num_classes, fine):\n",
    "        super().__init__(fine)\n",
    "        \n",
    "        self.conv1 = conv_block(in_channels, 64)\n",
    "        self.conv2 = conv_block(64, 128, pool=True) \n",
    "        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128)) \n",
    "        \n",
    "        self.conv3 = conv_block(128, 256, pool=True)\n",
    "        self.conv4 = conv_block(256, 512, pool=True) \n",
    "        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512)) \n",
    "        self.conv5 = conv_block(512, 1028, pool=True) \n",
    "        self.res3 = nn.Sequential(conv_block(1028, 1028), conv_block(1028, 1028))  \n",
    "        \n",
    "        self.classifier_parent = nn.Sequential(nn.MaxPool2d(2), # 1028 x 1 x 1\n",
    "                                        nn.Flatten(), # 1028 \n",
    "                                        nn.Linear(1028, 20))\n",
    "        \n",
    "        self.classifier_child = nn.Sequential(self.classifier_parent,\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(20, num_classes)) # 1028 -> 100\n",
    "        \n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.conv1(xb)\n",
    "        out = self.conv2(out)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.conv5(out)\n",
    "        out = self.res3(out) + out\n",
    "        out = self.classifier_child(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in test_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def fit_one_cycle(epochs, max_lr, model, train_loader, test_loader, \n",
    "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
    "    torch.cuda.empty_cache()\n",
    "    history = []\n",
    "    \n",
    "    # Set up cutom optimizer with weight decay\n",
    "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
    "    # Set up one-cycle learning rate scheduler\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n",
    "                                                steps_per_epoch=len(train_loader))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        lrs = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            if grad_clip: \n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Record & update learning rate\n",
    "            lrs.append(get_lr(optimizer))\n",
    "            sched.step()\n",
    "        \n",
    "        # Validation phase\n",
    "        result = evaluate(model, test_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        result['lrs'] = lrs\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate testing accuracy, predicted label, confusion matrix, and table for classification report\n",
    "def test_label_predictions(model, device, test_loader, fine):\n",
    "    model.eval()\n",
    "    actuals = []\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        if fine:\n",
    "            for data, target, _ in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                prediction = output.argmax(dim=1, keepdim=True)\n",
    "                print(\"predicted \", prediction, \" actual: \", target)\n",
    "                actuals.extend(target.view_as(prediction))\n",
    "                predictions.extend(prediction)\n",
    "        else:\n",
    "            for data, _, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                prediction = output.argmax(dim=1, keepdim=True)\n",
    "                print(\"predicted \", prediction, \" actual: \", target)\n",
    "                actuals.extend(target.view_as(prediction))\n",
    "                predictions.extend(prediction)\n",
    "\n",
    "    return [i.item() for i in actuals], [i.item() for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[{'val_loss': 7.941000938415527, 'val_acc': 0.21400000154972076}]\n",
      "Epoch [0], last_lr: 0.00016, train_loss: 6.8697, val_loss: 6.8457, val_acc: 0.2220\n",
      "Epoch [1], last_lr: 0.00017, train_loss: 6.5565, val_loss: 6.4581, val_acc: 0.2200\n",
      "Epoch [2], last_lr: 0.00019, train_loss: 6.2289, val_loss: 6.1874, val_acc: 0.2020\n",
      "Epoch [3], last_lr: 0.00021, train_loss: 5.8583, val_loss: 5.9268, val_acc: 0.1940\n",
      "Epoch [4], last_lr: 0.00024, train_loss: 5.6384, val_loss: 5.6602, val_acc: 0.1760\n",
      "Epoch [5], last_lr: 0.00027, train_loss: 5.2631, val_loss: 5.3901, val_acc: 0.1840\n",
      "Epoch [6], last_lr: 0.00031, train_loss: 5.0340, val_loss: 5.1360, val_acc: 0.1940\n",
      "Epoch [7], last_lr: 0.00036, train_loss: 4.8465, val_loss: 4.8897, val_acc: 0.2000\n",
      "Epoch [8], last_lr: 0.00041, train_loss: 4.6506, val_loss: 4.6378, val_acc: 0.1940\n",
      "Epoch [9], last_lr: 0.00047, train_loss: 4.4105, val_loss: 4.4053, val_acc: 0.1960\n",
      "Epoch [10], last_lr: 0.00053, train_loss: 4.0750, val_loss: 4.2363, val_acc: 0.2140\n",
      "Epoch [11], last_lr: 0.00060, train_loss: 3.9263, val_loss: 4.1637, val_acc: 0.2040\n",
      "Epoch [12], last_lr: 0.00068, train_loss: 3.8253, val_loss: 4.1335, val_acc: 0.2120\n",
      "Epoch [13], last_lr: 0.00075, train_loss: 3.7220, val_loss: 4.0068, val_acc: 0.2180\n",
      "Epoch [14], last_lr: 0.00084, train_loss: 3.6028, val_loss: 3.7829, val_acc: 0.2400\n",
      "Epoch [15], last_lr: 0.00092, train_loss: 3.4134, val_loss: 3.5704, val_acc: 0.2560\n",
      "Epoch [16], last_lr: 0.00102, train_loss: 3.1895, val_loss: 3.3739, val_acc: 0.2580\n",
      "Epoch [17], last_lr: 0.00111, train_loss: 2.9841, val_loss: 3.1829, val_acc: 0.2620\n",
      "Epoch [18], last_lr: 0.00121, train_loss: 2.7495, val_loss: 2.9992, val_acc: 0.2800\n",
      "Epoch [19], last_lr: 0.00131, train_loss: 2.5332, val_loss: 2.7645, val_acc: 0.2980\n",
      "Epoch [20], last_lr: 0.00141, train_loss: 2.3358, val_loss: 2.5489, val_acc: 0.3320\n",
      "Epoch [21], last_lr: 0.00152, train_loss: 2.1218, val_loss: 2.3739, val_acc: 0.3680\n",
      "Epoch [22], last_lr: 0.00163, train_loss: 1.8649, val_loss: 2.1935, val_acc: 0.3940\n",
      "Epoch [23], last_lr: 0.00174, train_loss: 1.7372, val_loss: 2.0413, val_acc: 0.4180\n",
      "Epoch [24], last_lr: 0.00185, train_loss: 1.5427, val_loss: 1.9292, val_acc: 0.4420\n",
      "Epoch [25], last_lr: 0.00196, train_loss: 1.4224, val_loss: 1.8165, val_acc: 0.4580\n",
      "Epoch [26], last_lr: 0.00207, train_loss: 1.3022, val_loss: 1.7306, val_acc: 0.4680\n",
      "Epoch [27], last_lr: 0.00218, train_loss: 1.2141, val_loss: 1.6454, val_acc: 0.4880\n",
      "Epoch [28], last_lr: 0.00230, train_loss: 1.1141, val_loss: 1.5748, val_acc: 0.4780\n",
      "Epoch [29], last_lr: 0.00241, train_loss: 1.0274, val_loss: 1.5206, val_acc: 0.4960\n",
      "Epoch [30], last_lr: 0.00252, train_loss: 0.9806, val_loss: 1.4722, val_acc: 0.5060\n",
      "Epoch [31], last_lr: 0.00262, train_loss: 0.9293, val_loss: 1.4117, val_acc: 0.5140\n",
      "Epoch [32], last_lr: 0.00273, train_loss: 0.8864, val_loss: 1.3736, val_acc: 0.5300\n",
      "Epoch [33], last_lr: 0.00284, train_loss: 0.8647, val_loss: 1.3307, val_acc: 0.5380\n",
      "Epoch [34], last_lr: 0.00294, train_loss: 0.8302, val_loss: 1.3044, val_acc: 0.5380\n",
      "Epoch [35], last_lr: 0.00304, train_loss: 0.8011, val_loss: 1.2710, val_acc: 0.5540\n",
      "Epoch [36], last_lr: 0.00313, train_loss: 0.7743, val_loss: 1.2537, val_acc: 0.5580\n",
      "Epoch [37], last_lr: 0.00322, train_loss: 0.7941, val_loss: 1.2423, val_acc: 0.5620\n",
      "Epoch [38], last_lr: 0.00331, train_loss: 0.7545, val_loss: 1.2167, val_acc: 0.5540\n",
      "Epoch [39], last_lr: 0.00339, train_loss: 0.7600, val_loss: 1.2190, val_acc: 0.5440\n",
      "Epoch [40], last_lr: 0.00347, train_loss: 0.7311, val_loss: 1.1950, val_acc: 0.5540\n",
      "Epoch [41], last_lr: 0.00355, train_loss: 0.7375, val_loss: 1.1903, val_acc: 0.5600\n",
      "Epoch [42], last_lr: 0.00362, train_loss: 0.7207, val_loss: 1.1791, val_acc: 0.5600\n",
      "Epoch [43], last_lr: 0.00368, train_loss: 0.7248, val_loss: 1.1985, val_acc: 0.5600\n",
      "Epoch [44], last_lr: 0.00374, train_loss: 0.7264, val_loss: 1.1658, val_acc: 0.5660\n",
      "Epoch [45], last_lr: 0.00379, train_loss: 0.7289, val_loss: 1.1701, val_acc: 0.5500\n",
      "Epoch [46], last_lr: 0.00384, train_loss: 0.7103, val_loss: 1.1535, val_acc: 0.5660\n",
      "Epoch [47], last_lr: 0.00388, train_loss: 0.7098, val_loss: 1.1555, val_acc: 0.5660\n",
      "Epoch [48], last_lr: 0.00392, train_loss: 0.6863, val_loss: 1.1602, val_acc: 0.5620\n",
      "Epoch [49], last_lr: 0.00395, train_loss: 0.6951, val_loss: 1.1462, val_acc: 0.5680\n",
      "Epoch [50], last_lr: 0.00397, train_loss: 0.6888, val_loss: 1.1515, val_acc: 0.5740\n",
      "Epoch [51], last_lr: 0.00399, train_loss: 0.6988, val_loss: 1.1706, val_acc: 0.5680\n",
      "Epoch [52], last_lr: 0.00400, train_loss: 0.7000, val_loss: 1.1497, val_acc: 0.5660\n",
      "Epoch [53], last_lr: 0.00400, train_loss: 0.6876, val_loss: 1.1380, val_acc: 0.5760\n",
      "Epoch [54], last_lr: 0.00400, train_loss: 0.6978, val_loss: 1.1441, val_acc: 0.5780\n",
      "Epoch [55], last_lr: 0.00400, train_loss: 0.6789, val_loss: 1.1496, val_acc: 0.5720\n",
      "Epoch [56], last_lr: 0.00399, train_loss: 0.7004, val_loss: 1.1478, val_acc: 0.5800\n",
      "Epoch [57], last_lr: 0.00399, train_loss: 0.6907, val_loss: 1.1413, val_acc: 0.5720\n",
      "Epoch [58], last_lr: 0.00398, train_loss: 0.6950, val_loss: 1.1243, val_acc: 0.5660\n",
      "Epoch [59], last_lr: 0.00398, train_loss: 0.6860, val_loss: 1.1460, val_acc: 0.5860\n",
      "Epoch [60], last_lr: 0.00397, train_loss: 0.6979, val_loss: 1.1411, val_acc: 0.5720\n",
      "Epoch [61], last_lr: 0.00396, train_loss: 0.6727, val_loss: 1.1475, val_acc: 0.5780\n",
      "Epoch [62], last_lr: 0.00395, train_loss: 0.6622, val_loss: 1.1178, val_acc: 0.5800\n",
      "Epoch [63], last_lr: 0.00394, train_loss: 0.6973, val_loss: 1.1231, val_acc: 0.5600\n",
      "Epoch [64], last_lr: 0.00393, train_loss: 0.6763, val_loss: 1.1459, val_acc: 0.5860\n",
      "Epoch [65], last_lr: 0.00391, train_loss: 0.6625, val_loss: 1.1287, val_acc: 0.5720\n",
      "Epoch [66], last_lr: 0.00390, train_loss: 0.6755, val_loss: 1.1293, val_acc: 0.5720\n",
      "Epoch [67], last_lr: 0.00388, train_loss: 0.6674, val_loss: 1.1589, val_acc: 0.5800\n",
      "Epoch [68], last_lr: 0.00386, train_loss: 0.6697, val_loss: 1.1367, val_acc: 0.5680\n",
      "Epoch [69], last_lr: 0.00384, train_loss: 0.6577, val_loss: 1.1444, val_acc: 0.5600\n",
      "Epoch [70], last_lr: 0.00382, train_loss: 0.6737, val_loss: 1.1593, val_acc: 0.5780\n",
      "Epoch [71], last_lr: 0.00380, train_loss: 0.6602, val_loss: 1.1327, val_acc: 0.5720\n",
      "Epoch [72], last_lr: 0.00378, train_loss: 0.6482, val_loss: 1.1285, val_acc: 0.5700\n",
      "Epoch [73], last_lr: 0.00376, train_loss: 0.6520, val_loss: 1.1219, val_acc: 0.5820\n",
      "Epoch [74], last_lr: 0.00373, train_loss: 0.6584, val_loss: 1.1371, val_acc: 0.5780\n",
      "Epoch [75], last_lr: 0.00371, train_loss: 0.6457, val_loss: 1.1406, val_acc: 0.5820\n",
      "Epoch [76], last_lr: 0.00368, train_loss: 0.6680, val_loss: 1.1384, val_acc: 0.5640\n",
      "Epoch [77], last_lr: 0.00365, train_loss: 0.6611, val_loss: 1.1230, val_acc: 0.5840\n",
      "Epoch [78], last_lr: 0.00362, train_loss: 0.6569, val_loss: 1.1432, val_acc: 0.5900\n",
      "Epoch [79], last_lr: 0.00359, train_loss: 0.6497, val_loss: 1.1253, val_acc: 0.5760\n",
      "Epoch [80], last_lr: 0.00356, train_loss: 0.6708, val_loss: 1.1280, val_acc: 0.5700\n",
      "Epoch [81], last_lr: 0.00353, train_loss: 0.6870, val_loss: 1.1253, val_acc: 0.5860\n",
      "Epoch [82], last_lr: 0.00350, train_loss: 0.6693, val_loss: 1.1271, val_acc: 0.5780\n",
      "Epoch [83], last_lr: 0.00347, train_loss: 0.6616, val_loss: 1.1293, val_acc: 0.5800\n",
      "Epoch [84], last_lr: 0.00343, train_loss: 0.6510, val_loss: 1.1325, val_acc: 0.5880\n",
      "Epoch [85], last_lr: 0.00340, train_loss: 0.6534, val_loss: 1.1397, val_acc: 0.5780\n",
      "Epoch [86], last_lr: 0.00336, train_loss: 0.6607, val_loss: 1.1468, val_acc: 0.5740\n",
      "Epoch [87], last_lr: 0.00332, train_loss: 0.6568, val_loss: 1.1260, val_acc: 0.5820\n",
      "Epoch [88], last_lr: 0.00329, train_loss: 0.6563, val_loss: 1.1237, val_acc: 0.5760\n",
      "Epoch [89], last_lr: 0.00325, train_loss: 0.6464, val_loss: 1.1226, val_acc: 0.5740\n",
      "Epoch [90], last_lr: 0.00321, train_loss: 0.6577, val_loss: 1.1262, val_acc: 0.5780\n",
      "Epoch [91], last_lr: 0.00317, train_loss: 0.6451, val_loss: 1.1244, val_acc: 0.5700\n",
      "Epoch [92], last_lr: 0.00313, train_loss: 0.6698, val_loss: 1.1302, val_acc: 0.5640\n",
      "Epoch [93], last_lr: 0.00309, train_loss: 0.6381, val_loss: 1.1353, val_acc: 0.5680\n",
      "Epoch [94], last_lr: 0.00304, train_loss: 0.6429, val_loss: 1.1406, val_acc: 0.5800\n",
      "Epoch [95], last_lr: 0.00300, train_loss: 0.6637, val_loss: 1.1299, val_acc: 0.5720\n",
      "Epoch [96], last_lr: 0.00296, train_loss: 0.6572, val_loss: 1.1463, val_acc: 0.5720\n",
      "Epoch [97], last_lr: 0.00291, train_loss: 0.6516, val_loss: 1.1378, val_acc: 0.5740\n",
      "Epoch [98], last_lr: 0.00287, train_loss: 0.6520, val_loss: 1.1368, val_acc: 0.5780\n",
      "Epoch [99], last_lr: 0.00282, train_loss: 0.6284, val_loss: 1.1277, val_acc: 0.5740\n",
      "Epoch [100], last_lr: 0.00278, train_loss: 0.6591, val_loss: 1.1231, val_acc: 0.5680\n",
      "Epoch [101], last_lr: 0.00273, train_loss: 0.6343, val_loss: 1.1376, val_acc: 0.5720\n",
      "Epoch [102], last_lr: 0.00268, train_loss: 0.6343, val_loss: 1.1356, val_acc: 0.5680\n",
      "Epoch [103], last_lr: 0.00264, train_loss: 0.6581, val_loss: 1.1314, val_acc: 0.5760\n",
      "Epoch [104], last_lr: 0.00259, train_loss: 0.6630, val_loss: 1.1401, val_acc: 0.5740\n",
      "Epoch [105], last_lr: 0.00254, train_loss: 0.6434, val_loss: 1.1293, val_acc: 0.5780\n",
      "Epoch [106], last_lr: 0.00249, train_loss: 0.6322, val_loss: 1.1289, val_acc: 0.5780\n",
      "Epoch [107], last_lr: 0.00245, train_loss: 0.6470, val_loss: 1.1252, val_acc: 0.5740\n",
      "Epoch [108], last_lr: 0.00240, train_loss: 0.6639, val_loss: 1.1267, val_acc: 0.5800\n",
      "Epoch [109], last_lr: 0.00235, train_loss: 0.6557, val_loss: 1.1249, val_acc: 0.5720\n",
      "Epoch [110], last_lr: 0.00230, train_loss: 0.6373, val_loss: 1.1284, val_acc: 0.5820\n",
      "Epoch [111], last_lr: 0.00225, train_loss: 0.6381, val_loss: 1.1254, val_acc: 0.5740\n",
      "Epoch [112], last_lr: 0.00220, train_loss: 0.6299, val_loss: 1.1242, val_acc: 0.5760\n",
      "Epoch [113], last_lr: 0.00215, train_loss: 0.6554, val_loss: 1.1224, val_acc: 0.5780\n",
      "Epoch [114], last_lr: 0.00210, train_loss: 0.6454, val_loss: 1.1265, val_acc: 0.5840\n",
      "Epoch [115], last_lr: 0.00205, train_loss: 0.6382, val_loss: 1.1271, val_acc: 0.5800\n",
      "Epoch [116], last_lr: 0.00200, train_loss: 0.6548, val_loss: 1.1401, val_acc: 0.5760\n",
      "Epoch [117], last_lr: 0.00195, train_loss: 0.6465, val_loss: 1.1391, val_acc: 0.5800\n",
      "Epoch [118], last_lr: 0.00190, train_loss: 0.6551, val_loss: 1.1380, val_acc: 0.5640\n",
      "Epoch [119], last_lr: 0.00185, train_loss: 0.6528, val_loss: 1.1252, val_acc: 0.5660\n",
      "Epoch [120], last_lr: 0.00180, train_loss: 0.6379, val_loss: 1.1264, val_acc: 0.5740\n",
      "Epoch [121], last_lr: 0.00175, train_loss: 0.6527, val_loss: 1.1200, val_acc: 0.5800\n",
      "Epoch [122], last_lr: 0.00170, train_loss: 0.6577, val_loss: 1.1226, val_acc: 0.5720\n",
      "Epoch [123], last_lr: 0.00165, train_loss: 0.6423, val_loss: 1.1193, val_acc: 0.5780\n",
      "Epoch [124], last_lr: 0.00160, train_loss: 0.6736, val_loss: 1.1186, val_acc: 0.5680\n",
      "Epoch [125], last_lr: 0.00155, train_loss: 0.6451, val_loss: 1.1170, val_acc: 0.5800\n",
      "Epoch [126], last_lr: 0.00151, train_loss: 0.6292, val_loss: 1.1165, val_acc: 0.5760\n",
      "Epoch [127], last_lr: 0.00146, train_loss: 0.6389, val_loss: 1.1142, val_acc: 0.5720\n",
      "Epoch [128], last_lr: 0.00141, train_loss: 0.6558, val_loss: 1.1140, val_acc: 0.5740\n",
      "Epoch [129], last_lr: 0.00136, train_loss: 0.6488, val_loss: 1.1160, val_acc: 0.5700\n",
      "Epoch [130], last_lr: 0.00132, train_loss: 0.6612, val_loss: 1.1161, val_acc: 0.5800\n",
      "Epoch [131], last_lr: 0.00127, train_loss: 0.6482, val_loss: 1.1148, val_acc: 0.5700\n",
      "Epoch [132], last_lr: 0.00122, train_loss: 0.6458, val_loss: 1.1149, val_acc: 0.5760\n",
      "Epoch [133], last_lr: 0.00118, train_loss: 0.6292, val_loss: 1.1141, val_acc: 0.5720\n",
      "Epoch [134], last_lr: 0.00113, train_loss: 0.6456, val_loss: 1.1168, val_acc: 0.5760\n",
      "Epoch [135], last_lr: 0.00109, train_loss: 0.6374, val_loss: 1.1155, val_acc: 0.5720\n",
      "Epoch [136], last_lr: 0.00104, train_loss: 0.6371, val_loss: 1.1172, val_acc: 0.5720\n",
      "Epoch [137], last_lr: 0.00100, train_loss: 0.6245, val_loss: 1.1172, val_acc: 0.5740\n",
      "Epoch [138], last_lr: 0.00096, train_loss: 0.6327, val_loss: 1.1179, val_acc: 0.5760\n",
      "Epoch [139], last_lr: 0.00091, train_loss: 0.6338, val_loss: 1.1200, val_acc: 0.5780\n",
      "Epoch [140], last_lr: 0.00087, train_loss: 0.6395, val_loss: 1.1199, val_acc: 0.5740\n",
      "Epoch [141], last_lr: 0.00083, train_loss: 0.6394, val_loss: 1.1221, val_acc: 0.5780\n",
      "Epoch [142], last_lr: 0.00079, train_loss: 0.6351, val_loss: 1.1246, val_acc: 0.5740\n",
      "Epoch [143], last_lr: 0.00075, train_loss: 0.6371, val_loss: 1.1258, val_acc: 0.5800\n",
      "Epoch [144], last_lr: 0.00071, train_loss: 0.6401, val_loss: 1.1259, val_acc: 0.5780\n",
      "Epoch [145], last_lr: 0.00068, train_loss: 0.6593, val_loss: 1.1251, val_acc: 0.5720\n",
      "Epoch [146], last_lr: 0.00064, train_loss: 0.6296, val_loss: 1.1244, val_acc: 0.5680\n",
      "Epoch [147], last_lr: 0.00060, train_loss: 0.6473, val_loss: 1.1281, val_acc: 0.5780\n",
      "Epoch [148], last_lr: 0.00057, train_loss: 0.6481, val_loss: 1.1258, val_acc: 0.5800\n",
      "Epoch [149], last_lr: 0.00053, train_loss: 0.6553, val_loss: 1.1271, val_acc: 0.5740\n",
      "Epoch [150], last_lr: 0.00050, train_loss: 0.6388, val_loss: 1.1273, val_acc: 0.5740\n",
      "Epoch [151], last_lr: 0.00047, train_loss: 0.6515, val_loss: 1.1271, val_acc: 0.5780\n",
      "Epoch [152], last_lr: 0.00044, train_loss: 0.6310, val_loss: 1.1286, val_acc: 0.5780\n",
      "Epoch [153], last_lr: 0.00041, train_loss: 0.6438, val_loss: 1.1275, val_acc: 0.5800\n",
      "Epoch [154], last_lr: 0.00038, train_loss: 0.6304, val_loss: 1.1260, val_acc: 0.5800\n",
      "Epoch [155], last_lr: 0.00035, train_loss: 0.6321, val_loss: 1.1248, val_acc: 0.5820\n",
      "Epoch [156], last_lr: 0.00032, train_loss: 0.6457, val_loss: 1.1263, val_acc: 0.5780\n",
      "Epoch [157], last_lr: 0.00029, train_loss: 0.6258, val_loss: 1.1256, val_acc: 0.5780\n",
      "Epoch [158], last_lr: 0.00027, train_loss: 0.6418, val_loss: 1.1260, val_acc: 0.5800\n",
      "Epoch [159], last_lr: 0.00024, train_loss: 0.6409, val_loss: 1.1260, val_acc: 0.5780\n",
      "Epoch [160], last_lr: 0.00022, train_loss: 0.6182, val_loss: 1.1265, val_acc: 0.5800\n",
      "Epoch [161], last_lr: 0.00020, train_loss: 0.6377, val_loss: 1.1276, val_acc: 0.5800\n",
      "Epoch [162], last_lr: 0.00018, train_loss: 0.6470, val_loss: 1.1275, val_acc: 0.5760\n",
      "Epoch [163], last_lr: 0.00016, train_loss: 0.6335, val_loss: 1.1253, val_acc: 0.5780\n",
      "Epoch [164], last_lr: 0.00014, train_loss: 0.6471, val_loss: 1.1270, val_acc: 0.5780\n",
      "Epoch [165], last_lr: 0.00012, train_loss: 0.6263, val_loss: 1.1279, val_acc: 0.5800\n",
      "Epoch [166], last_lr: 0.00010, train_loss: 0.6394, val_loss: 1.1272, val_acc: 0.5840\n",
      "Epoch [167], last_lr: 0.00009, train_loss: 0.6422, val_loss: 1.1265, val_acc: 0.5760\n",
      "Epoch [168], last_lr: 0.00007, train_loss: 0.6456, val_loss: 1.1253, val_acc: 0.5760\n",
      "Epoch [169], last_lr: 0.00006, train_loss: 0.6386, val_loss: 1.1257, val_acc: 0.5740\n",
      "Epoch [170], last_lr: 0.00005, train_loss: 0.6446, val_loss: 1.1253, val_acc: 0.5760\n",
      "Epoch [171], last_lr: 0.00004, train_loss: 0.6497, val_loss: 1.1266, val_acc: 0.5780\n",
      "Epoch [172], last_lr: 0.00003, train_loss: 0.6371, val_loss: 1.1269, val_acc: 0.5760\n",
      "Epoch [173], last_lr: 0.00002, train_loss: 0.6320, val_loss: 1.1266, val_acc: 0.5780\n",
      "Epoch [174], last_lr: 0.00002, train_loss: 0.6477, val_loss: 1.1265, val_acc: 0.5780\n",
      "Epoch [175], last_lr: 0.00001, train_loss: 0.6247, val_loss: 1.1267, val_acc: 0.5780\n",
      "Epoch [176], last_lr: 0.00001, train_loss: 0.6404, val_loss: 1.1267, val_acc: 0.5820\n",
      "Epoch [177], last_lr: 0.00000, train_loss: 0.6315, val_loss: 1.1260, val_acc: 0.5820\n",
      "Epoch [178], last_lr: 0.00000, train_loss: 0.6326, val_loss: 1.1258, val_acc: 0.5780\n",
      "Epoch [179], last_lr: 0.00000, train_loss: 0.6347, val_loss: 1.1270, val_acc: 0.5780\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[{'val_loss': 6.7617926597595215, 'val_acc': 0.09399999678134918}]\n",
      "Epoch [0], last_lr: 0.00016, train_loss: 6.8378, val_loss: 6.2708, val_acc: 0.1140\n",
      "Epoch [1], last_lr: 0.00017, train_loss: 6.4935, val_loss: 6.0003, val_acc: 0.1240\n",
      "Epoch [2], last_lr: 0.00019, train_loss: 6.1593, val_loss: 5.7340, val_acc: 0.1280\n",
      "Epoch [3], last_lr: 0.00021, train_loss: 5.8136, val_loss: 5.4142, val_acc: 0.1260\n",
      "Epoch [4], last_lr: 0.00024, train_loss: 5.4392, val_loss: 5.0631, val_acc: 0.1300\n",
      "Epoch [5], last_lr: 0.00027, train_loss: 5.0247, val_loss: 4.7000, val_acc: 0.1440\n",
      "Epoch [6], last_lr: 0.00031, train_loss: 4.6755, val_loss: 4.3707, val_acc: 0.1500\n",
      "Epoch [7], last_lr: 0.00036, train_loss: 4.4506, val_loss: 4.0904, val_acc: 0.1460\n",
      "Epoch [8], last_lr: 0.00041, train_loss: 4.2627, val_loss: 3.9066, val_acc: 0.1660\n",
      "Epoch [9], last_lr: 0.00047, train_loss: 3.9949, val_loss: 3.7976, val_acc: 0.1880\n",
      "Epoch [10], last_lr: 0.00053, train_loss: 3.8090, val_loss: 3.7016, val_acc: 0.2000\n",
      "Epoch [11], last_lr: 0.00060, train_loss: 3.7083, val_loss: 3.6229, val_acc: 0.2040\n",
      "Epoch [12], last_lr: 0.00068, train_loss: 3.6218, val_loss: 3.5469, val_acc: 0.2020\n",
      "Epoch [13], last_lr: 0.00075, train_loss: 3.4541, val_loss: 3.4105, val_acc: 0.2080\n",
      "Epoch [14], last_lr: 0.00084, train_loss: 3.3070, val_loss: 3.2279, val_acc: 0.2260\n",
      "Epoch [15], last_lr: 0.00092, train_loss: 3.1635, val_loss: 3.0659, val_acc: 0.2440\n",
      "Epoch [16], last_lr: 0.00102, train_loss: 2.9837, val_loss: 2.8954, val_acc: 0.2660\n",
      "Epoch [17], last_lr: 0.00111, train_loss: 2.7391, val_loss: 2.7052, val_acc: 0.2780\n",
      "Epoch [18], last_lr: 0.00121, train_loss: 2.5100, val_loss: 2.4992, val_acc: 0.3120\n",
      "Epoch [19], last_lr: 0.00131, train_loss: 2.2781, val_loss: 2.2871, val_acc: 0.3480\n",
      "Epoch [20], last_lr: 0.00141, train_loss: 2.0700, val_loss: 2.0884, val_acc: 0.3780\n",
      "Epoch [21], last_lr: 0.00152, train_loss: 1.8476, val_loss: 1.9154, val_acc: 0.4160\n",
      "Epoch [22], last_lr: 0.00163, train_loss: 1.6793, val_loss: 1.7561, val_acc: 0.4540\n",
      "Epoch [23], last_lr: 0.00174, train_loss: 1.4710, val_loss: 1.6001, val_acc: 0.4940\n",
      "Epoch [24], last_lr: 0.00185, train_loss: 1.2538, val_loss: 1.4931, val_acc: 0.5120\n",
      "Epoch [25], last_lr: 0.00196, train_loss: 1.1399, val_loss: 1.3916, val_acc: 0.5440\n",
      "Epoch [26], last_lr: 0.00207, train_loss: 1.0647, val_loss: 1.3112, val_acc: 0.5680\n",
      "Epoch [27], last_lr: 0.00218, train_loss: 0.9415, val_loss: 1.2379, val_acc: 0.5740\n",
      "Epoch [28], last_lr: 0.00230, train_loss: 0.8686, val_loss: 1.1894, val_acc: 0.5900\n",
      "Epoch [29], last_lr: 0.00241, train_loss: 0.7842, val_loss: 1.1284, val_acc: 0.5900\n",
      "Epoch [30], last_lr: 0.00252, train_loss: 0.7287, val_loss: 1.1098, val_acc: 0.6160\n",
      "Epoch [31], last_lr: 0.00262, train_loss: 0.7251, val_loss: 1.0572, val_acc: 0.6120\n",
      "Epoch [32], last_lr: 0.00273, train_loss: 0.6565, val_loss: 1.0476, val_acc: 0.6400\n",
      "Epoch [33], last_lr: 0.00284, train_loss: 0.6067, val_loss: 1.0057, val_acc: 0.6300\n",
      "Epoch [34], last_lr: 0.00294, train_loss: 0.5537, val_loss: 1.0166, val_acc: 0.6400\n",
      "Epoch [35], last_lr: 0.00304, train_loss: 0.5618, val_loss: 0.9785, val_acc: 0.6500\n",
      "Epoch [36], last_lr: 0.00313, train_loss: 0.5338, val_loss: 1.0029, val_acc: 0.6600\n",
      "Epoch [37], last_lr: 0.00322, train_loss: 0.5477, val_loss: 0.9798, val_acc: 0.6480\n",
      "Epoch [38], last_lr: 0.00331, train_loss: 0.5020, val_loss: 0.9801, val_acc: 0.6580\n",
      "Epoch [39], last_lr: 0.00339, train_loss: 0.5052, val_loss: 0.9416, val_acc: 0.6660\n",
      "Epoch [40], last_lr: 0.00347, train_loss: 0.5094, val_loss: 0.9696, val_acc: 0.6680\n",
      "Epoch [41], last_lr: 0.00355, train_loss: 0.4975, val_loss: 0.9371, val_acc: 0.6720\n",
      "Epoch [42], last_lr: 0.00362, train_loss: 0.4647, val_loss: 0.9406, val_acc: 0.6640\n",
      "Epoch [43], last_lr: 0.00368, train_loss: 0.4587, val_loss: 0.9307, val_acc: 0.6720\n",
      "Epoch [44], last_lr: 0.00374, train_loss: 0.4592, val_loss: 0.9242, val_acc: 0.6820\n",
      "Epoch [45], last_lr: 0.00379, train_loss: 0.4557, val_loss: 0.9230, val_acc: 0.6600\n",
      "Epoch [46], last_lr: 0.00384, train_loss: 0.4711, val_loss: 0.9379, val_acc: 0.6720\n",
      "Epoch [47], last_lr: 0.00388, train_loss: 0.4452, val_loss: 0.9307, val_acc: 0.6740\n",
      "Epoch [48], last_lr: 0.00392, train_loss: 0.4461, val_loss: 0.9286, val_acc: 0.6740\n",
      "Epoch [49], last_lr: 0.00395, train_loss: 0.4448, val_loss: 0.9376, val_acc: 0.6680\n",
      "Epoch [50], last_lr: 0.00397, train_loss: 0.4238, val_loss: 0.9280, val_acc: 0.6740\n",
      "Epoch [51], last_lr: 0.00399, train_loss: 0.4460, val_loss: 0.9405, val_acc: 0.6680\n",
      "Epoch [52], last_lr: 0.00400, train_loss: 0.4322, val_loss: 0.9311, val_acc: 0.6740\n",
      "Epoch [53], last_lr: 0.00400, train_loss: 0.4402, val_loss: 0.9211, val_acc: 0.6720\n",
      "Epoch [54], last_lr: 0.00400, train_loss: 0.4352, val_loss: 0.9215, val_acc: 0.6800\n",
      "Epoch [55], last_lr: 0.00400, train_loss: 0.4233, val_loss: 0.9504, val_acc: 0.6600\n",
      "Epoch [56], last_lr: 0.00399, train_loss: 0.4539, val_loss: 0.9771, val_acc: 0.6700\n",
      "Epoch [57], last_lr: 0.00399, train_loss: 0.4306, val_loss: 0.9491, val_acc: 0.6680\n",
      "Epoch [58], last_lr: 0.00398, train_loss: 0.4293, val_loss: 0.9270, val_acc: 0.6760\n",
      "Epoch [59], last_lr: 0.00398, train_loss: 0.4127, val_loss: 0.9198, val_acc: 0.6740\n",
      "Epoch [60], last_lr: 0.00397, train_loss: 0.4090, val_loss: 0.9256, val_acc: 0.6720\n",
      "Epoch [61], last_lr: 0.00396, train_loss: 0.4187, val_loss: 0.9088, val_acc: 0.6800\n",
      "Epoch [62], last_lr: 0.00395, train_loss: 0.3991, val_loss: 0.9088, val_acc: 0.6800\n",
      "Epoch [63], last_lr: 0.00394, train_loss: 0.4230, val_loss: 0.9057, val_acc: 0.6840\n",
      "Epoch [64], last_lr: 0.00393, train_loss: 0.3991, val_loss: 0.8986, val_acc: 0.6780\n",
      "Epoch [65], last_lr: 0.00391, train_loss: 0.4006, val_loss: 0.9095, val_acc: 0.6820\n",
      "Epoch [66], last_lr: 0.00390, train_loss: 0.4227, val_loss: 0.9097, val_acc: 0.6740\n",
      "Epoch [67], last_lr: 0.00388, train_loss: 0.3924, val_loss: 0.9108, val_acc: 0.6720\n",
      "Epoch [68], last_lr: 0.00386, train_loss: 0.4076, val_loss: 0.9417, val_acc: 0.6880\n",
      "Epoch [69], last_lr: 0.00384, train_loss: 0.3992, val_loss: 0.9141, val_acc: 0.6740\n",
      "Epoch [70], last_lr: 0.00382, train_loss: 0.3933, val_loss: 0.9414, val_acc: 0.6620\n",
      "Epoch [71], last_lr: 0.00380, train_loss: 0.4294, val_loss: 0.9359, val_acc: 0.6800\n",
      "Epoch [72], last_lr: 0.00378, train_loss: 0.4005, val_loss: 0.9091, val_acc: 0.6820\n",
      "Epoch [73], last_lr: 0.00376, train_loss: 0.4035, val_loss: 0.9058, val_acc: 0.6780\n",
      "Epoch [74], last_lr: 0.00373, train_loss: 0.3913, val_loss: 0.9076, val_acc: 0.6900\n",
      "Epoch [75], last_lr: 0.00371, train_loss: 0.3947, val_loss: 0.9083, val_acc: 0.6800\n",
      "Epoch [76], last_lr: 0.00368, train_loss: 0.3869, val_loss: 0.9078, val_acc: 0.6800\n",
      "Epoch [77], last_lr: 0.00365, train_loss: 0.3921, val_loss: 0.9265, val_acc: 0.6740\n",
      "Epoch [78], last_lr: 0.00362, train_loss: 0.3973, val_loss: 0.9153, val_acc: 0.6780\n",
      "Epoch [79], last_lr: 0.00359, train_loss: 0.3972, val_loss: 0.9227, val_acc: 0.6780\n",
      "Epoch [80], last_lr: 0.00356, train_loss: 0.3997, val_loss: 0.9117, val_acc: 0.6840\n",
      "Epoch [81], last_lr: 0.00353, train_loss: 0.3979, val_loss: 0.9109, val_acc: 0.6860\n",
      "Epoch [82], last_lr: 0.00350, train_loss: 0.3864, val_loss: 0.9060, val_acc: 0.6720\n",
      "Epoch [83], last_lr: 0.00347, train_loss: 0.3977, val_loss: 0.9402, val_acc: 0.6760\n",
      "Epoch [84], last_lr: 0.00343, train_loss: 0.4014, val_loss: 0.9060, val_acc: 0.6740\n",
      "Epoch [85], last_lr: 0.00340, train_loss: 0.3965, val_loss: 0.9212, val_acc: 0.6840\n",
      "Epoch [86], last_lr: 0.00336, train_loss: 0.3771, val_loss: 0.9149, val_acc: 0.6720\n",
      "Epoch [87], last_lr: 0.00332, train_loss: 0.3898, val_loss: 0.9225, val_acc: 0.6700\n",
      "Epoch [88], last_lr: 0.00329, train_loss: 0.4062, val_loss: 0.9435, val_acc: 0.6820\n",
      "Epoch [89], last_lr: 0.00325, train_loss: 0.4117, val_loss: 0.9412, val_acc: 0.6720\n",
      "Epoch [90], last_lr: 0.00321, train_loss: 0.4100, val_loss: 0.9351, val_acc: 0.6840\n",
      "Epoch [91], last_lr: 0.00317, train_loss: 0.3995, val_loss: 0.9164, val_acc: 0.6740\n",
      "Epoch [92], last_lr: 0.00313, train_loss: 0.3868, val_loss: 0.9307, val_acc: 0.6820\n",
      "Epoch [93], last_lr: 0.00309, train_loss: 0.3925, val_loss: 0.9247, val_acc: 0.6740\n",
      "Epoch [94], last_lr: 0.00304, train_loss: 0.3839, val_loss: 0.9358, val_acc: 0.6740\n",
      "Epoch [95], last_lr: 0.00300, train_loss: 0.4135, val_loss: 0.9293, val_acc: 0.6760\n",
      "Epoch [96], last_lr: 0.00296, train_loss: 0.3902, val_loss: 0.9164, val_acc: 0.6720\n",
      "Epoch [97], last_lr: 0.00291, train_loss: 0.3840, val_loss: 0.9273, val_acc: 0.6820\n",
      "Epoch [98], last_lr: 0.00287, train_loss: 0.3891, val_loss: 0.9162, val_acc: 0.6760\n",
      "Epoch [99], last_lr: 0.00282, train_loss: 0.3953, val_loss: 0.9369, val_acc: 0.6860\n",
      "Epoch [100], last_lr: 0.00278, train_loss: 0.3932, val_loss: 0.9260, val_acc: 0.6840\n",
      "Epoch [101], last_lr: 0.00273, train_loss: 0.3945, val_loss: 0.9263, val_acc: 0.6820\n",
      "Epoch [102], last_lr: 0.00268, train_loss: 0.3984, val_loss: 0.9259, val_acc: 0.6780\n",
      "Epoch [103], last_lr: 0.00264, train_loss: 0.3793, val_loss: 0.9197, val_acc: 0.6780\n",
      "Epoch [104], last_lr: 0.00259, train_loss: 0.3653, val_loss: 0.9183, val_acc: 0.6780\n",
      "Epoch [105], last_lr: 0.00254, train_loss: 0.3812, val_loss: 0.9176, val_acc: 0.6760\n",
      "Epoch [106], last_lr: 0.00249, train_loss: 0.3767, val_loss: 0.9147, val_acc: 0.6760\n",
      "Epoch [107], last_lr: 0.00245, train_loss: 0.3761, val_loss: 0.9414, val_acc: 0.6720\n",
      "Epoch [108], last_lr: 0.00240, train_loss: 0.3912, val_loss: 0.9217, val_acc: 0.6700\n",
      "Epoch [109], last_lr: 0.00235, train_loss: 0.3887, val_loss: 0.9341, val_acc: 0.6780\n",
      "Epoch [110], last_lr: 0.00230, train_loss: 0.3994, val_loss: 0.9117, val_acc: 0.6700\n",
      "Epoch [111], last_lr: 0.00225, train_loss: 0.3840, val_loss: 0.9311, val_acc: 0.6760\n",
      "Epoch [112], last_lr: 0.00220, train_loss: 0.3844, val_loss: 0.9109, val_acc: 0.6720\n",
      "Epoch [113], last_lr: 0.00215, train_loss: 0.3777, val_loss: 0.9229, val_acc: 0.6720\n",
      "Epoch [114], last_lr: 0.00210, train_loss: 0.3848, val_loss: 0.9087, val_acc: 0.6780\n",
      "Epoch [115], last_lr: 0.00205, train_loss: 0.3750, val_loss: 0.9139, val_acc: 0.6780\n",
      "Epoch [116], last_lr: 0.00200, train_loss: 0.3602, val_loss: 0.9161, val_acc: 0.6760\n",
      "Epoch [117], last_lr: 0.00195, train_loss: 0.3999, val_loss: 0.9170, val_acc: 0.6760\n",
      "Epoch [118], last_lr: 0.00190, train_loss: 0.3650, val_loss: 0.9189, val_acc: 0.6780\n",
      "Epoch [119], last_lr: 0.00185, train_loss: 0.3893, val_loss: 0.9184, val_acc: 0.6700\n",
      "Epoch [120], last_lr: 0.00180, train_loss: 0.3638, val_loss: 0.9171, val_acc: 0.6720\n",
      "Epoch [121], last_lr: 0.00175, train_loss: 0.3797, val_loss: 0.9147, val_acc: 0.6740\n",
      "Epoch [122], last_lr: 0.00170, train_loss: 0.3746, val_loss: 0.9096, val_acc: 0.6760\n",
      "Epoch [123], last_lr: 0.00165, train_loss: 0.3693, val_loss: 0.9240, val_acc: 0.6780\n",
      "Epoch [124], last_lr: 0.00160, train_loss: 0.3799, val_loss: 0.9162, val_acc: 0.6780\n",
      "Epoch [125], last_lr: 0.00155, train_loss: 0.3815, val_loss: 0.9178, val_acc: 0.6680\n",
      "Epoch [126], last_lr: 0.00151, train_loss: 0.3651, val_loss: 0.9167, val_acc: 0.6800\n",
      "Epoch [127], last_lr: 0.00146, train_loss: 0.3723, val_loss: 0.9141, val_acc: 0.6780\n",
      "Epoch [128], last_lr: 0.00141, train_loss: 0.3696, val_loss: 0.9189, val_acc: 0.6720\n",
      "Epoch [129], last_lr: 0.00136, train_loss: 0.3891, val_loss: 0.9147, val_acc: 0.6860\n",
      "Epoch [130], last_lr: 0.00132, train_loss: 0.3577, val_loss: 0.9219, val_acc: 0.6740\n",
      "Epoch [131], last_lr: 0.00127, train_loss: 0.3659, val_loss: 0.9117, val_acc: 0.6740\n",
      "Epoch [132], last_lr: 0.00122, train_loss: 0.3823, val_loss: 0.9122, val_acc: 0.6780\n",
      "Epoch [133], last_lr: 0.00118, train_loss: 0.3637, val_loss: 0.9106, val_acc: 0.6780\n",
      "Epoch [134], last_lr: 0.00113, train_loss: 0.3632, val_loss: 0.9150, val_acc: 0.6760\n",
      "Epoch [135], last_lr: 0.00109, train_loss: 0.3734, val_loss: 0.9155, val_acc: 0.6740\n",
      "Epoch [136], last_lr: 0.00104, train_loss: 0.3696, val_loss: 0.9149, val_acc: 0.6720\n",
      "Epoch [137], last_lr: 0.00100, train_loss: 0.3907, val_loss: 0.9184, val_acc: 0.6760\n",
      "Epoch [138], last_lr: 0.00096, train_loss: 0.3667, val_loss: 0.9189, val_acc: 0.6720\n",
      "Epoch [139], last_lr: 0.00091, train_loss: 0.3832, val_loss: 0.9124, val_acc: 0.6740\n",
      "Epoch [140], last_lr: 0.00087, train_loss: 0.3654, val_loss: 0.9155, val_acc: 0.6740\n",
      "Epoch [141], last_lr: 0.00083, train_loss: 0.3782, val_loss: 0.9189, val_acc: 0.6780\n",
      "Epoch [142], last_lr: 0.00079, train_loss: 0.3569, val_loss: 0.9200, val_acc: 0.6820\n",
      "Epoch [143], last_lr: 0.00075, train_loss: 0.3612, val_loss: 0.9179, val_acc: 0.6780\n",
      "Epoch [144], last_lr: 0.00071, train_loss: 0.3618, val_loss: 0.9211, val_acc: 0.6720\n",
      "Epoch [145], last_lr: 0.00068, train_loss: 0.3712, val_loss: 0.9201, val_acc: 0.6780\n",
      "Epoch [146], last_lr: 0.00064, train_loss: 0.3737, val_loss: 0.9210, val_acc: 0.6780\n",
      "Epoch [147], last_lr: 0.00060, train_loss: 0.3868, val_loss: 0.9172, val_acc: 0.6780\n",
      "Epoch [148], last_lr: 0.00057, train_loss: 0.3686, val_loss: 0.9183, val_acc: 0.6780\n",
      "Epoch [149], last_lr: 0.00053, train_loss: 0.3840, val_loss: 0.9183, val_acc: 0.6760\n",
      "Epoch [150], last_lr: 0.00050, train_loss: 0.3657, val_loss: 0.9184, val_acc: 0.6780\n",
      "Epoch [151], last_lr: 0.00047, train_loss: 0.3673, val_loss: 0.9178, val_acc: 0.6780\n",
      "Epoch [152], last_lr: 0.00044, train_loss: 0.3657, val_loss: 0.9185, val_acc: 0.6760\n",
      "Epoch [153], last_lr: 0.00041, train_loss: 0.3977, val_loss: 0.9194, val_acc: 0.6780\n",
      "Epoch [154], last_lr: 0.00038, train_loss: 0.3689, val_loss: 0.9163, val_acc: 0.6760\n",
      "Epoch [155], last_lr: 0.00035, train_loss: 0.3545, val_loss: 0.9176, val_acc: 0.6780\n",
      "Epoch [156], last_lr: 0.00032, train_loss: 0.3737, val_loss: 0.9213, val_acc: 0.6760\n",
      "Epoch [157], last_lr: 0.00029, train_loss: 0.3671, val_loss: 0.9238, val_acc: 0.6740\n",
      "Epoch [158], last_lr: 0.00027, train_loss: 0.3736, val_loss: 0.9219, val_acc: 0.6760\n",
      "Epoch [159], last_lr: 0.00024, train_loss: 0.3796, val_loss: 0.9203, val_acc: 0.6780\n",
      "Epoch [160], last_lr: 0.00022, train_loss: 0.3644, val_loss: 0.9195, val_acc: 0.6780\n",
      "Epoch [161], last_lr: 0.00020, train_loss: 0.3723, val_loss: 0.9201, val_acc: 0.6780\n",
      "Epoch [162], last_lr: 0.00018, train_loss: 0.3783, val_loss: 0.9218, val_acc: 0.6780\n",
      "Epoch [163], last_lr: 0.00016, train_loss: 0.3673, val_loss: 0.9228, val_acc: 0.6760\n",
      "Epoch [164], last_lr: 0.00014, train_loss: 0.3741, val_loss: 0.9197, val_acc: 0.6760\n",
      "Epoch [165], last_lr: 0.00012, train_loss: 0.3699, val_loss: 0.9221, val_acc: 0.6760\n",
      "Epoch [166], last_lr: 0.00010, train_loss: 0.3718, val_loss: 0.9215, val_acc: 0.6780\n",
      "Epoch [167], last_lr: 0.00009, train_loss: 0.3697, val_loss: 0.9216, val_acc: 0.6780\n",
      "Epoch [168], last_lr: 0.00007, train_loss: 0.3630, val_loss: 0.9220, val_acc: 0.6780\n",
      "Epoch [169], last_lr: 0.00006, train_loss: 0.3664, val_loss: 0.9205, val_acc: 0.6780\n",
      "Epoch [170], last_lr: 0.00005, train_loss: 0.3582, val_loss: 0.9203, val_acc: 0.6780\n",
      "Epoch [171], last_lr: 0.00004, train_loss: 0.3639, val_loss: 0.9209, val_acc: 0.6760\n",
      "Epoch [172], last_lr: 0.00003, train_loss: 0.3795, val_loss: 0.9200, val_acc: 0.6780\n",
      "Epoch [173], last_lr: 0.00002, train_loss: 0.3570, val_loss: 0.9206, val_acc: 0.6780\n",
      "Epoch [174], last_lr: 0.00002, train_loss: 0.3675, val_loss: 0.9200, val_acc: 0.6760\n",
      "Epoch [175], last_lr: 0.00001, train_loss: 0.3469, val_loss: 0.9199, val_acc: 0.6780\n",
      "Epoch [176], last_lr: 0.00001, train_loss: 0.3675, val_loss: 0.9206, val_acc: 0.6780\n",
      "Epoch [177], last_lr: 0.00000, train_loss: 0.3739, val_loss: 0.9214, val_acc: 0.6780\n",
      "Epoch [178], last_lr: 0.00000, train_loss: 0.3700, val_loss: 0.9202, val_acc: 0.6780\n",
      "Epoch [179], last_lr: 0.00000, train_loss: 0.3589, val_loss: 0.9197, val_acc: 0.6780\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[{'val_loss': 18.498266220092773, 'val_acc': 0.20000000298023224}]\n",
      "Epoch [0], last_lr: 0.00016, train_loss: 18.1762, val_loss: 17.9857, val_acc: 0.2000\n",
      "Epoch [1], last_lr: 0.00017, train_loss: 17.7095, val_loss: 17.6697, val_acc: 0.2000\n",
      "Epoch [2], last_lr: 0.00019, train_loss: 17.2117, val_loss: 17.2542, val_acc: 0.2000\n",
      "Epoch [3], last_lr: 0.00021, train_loss: 16.5766, val_loss: 16.7430, val_acc: 0.2020\n",
      "Epoch [4], last_lr: 0.00024, train_loss: 15.9508, val_loss: 16.0902, val_acc: 0.2040\n",
      "Epoch [5], last_lr: 0.00027, train_loss: 15.2357, val_loss: 15.3473, val_acc: 0.2040\n",
      "Epoch [6], last_lr: 0.00031, train_loss: 14.4116, val_loss: 14.3811, val_acc: 0.2020\n",
      "Epoch [7], last_lr: 0.00036, train_loss: 13.4721, val_loss: 13.3743, val_acc: 0.1980\n",
      "Epoch [8], last_lr: 0.00041, train_loss: 12.3710, val_loss: 12.1682, val_acc: 0.2000\n",
      "Epoch [9], last_lr: 0.00047, train_loss: 11.2100, val_loss: 10.8731, val_acc: 0.2060\n",
      "Epoch [10], last_lr: 0.00053, train_loss: 9.9129, val_loss: 9.5028, val_acc: 0.2220\n",
      "Epoch [11], last_lr: 0.00060, train_loss: 8.6232, val_loss: 8.1412, val_acc: 0.2260\n",
      "Epoch [12], last_lr: 0.00068, train_loss: 7.3232, val_loss: 6.7426, val_acc: 0.2260\n",
      "Epoch [13], last_lr: 0.00075, train_loss: 6.0581, val_loss: 5.4410, val_acc: 0.2340\n",
      "Epoch [14], last_lr: 0.00084, train_loss: 4.9036, val_loss: 4.5915, val_acc: 0.2560\n",
      "Epoch [15], last_lr: 0.00092, train_loss: 4.4357, val_loss: 4.2933, val_acc: 0.2540\n",
      "Epoch [16], last_lr: 0.00102, train_loss: 4.0869, val_loss: 3.8782, val_acc: 0.2500\n",
      "Epoch [17], last_lr: 0.00111, train_loss: 3.5883, val_loss: 3.4409, val_acc: 0.2320\n",
      "Epoch [18], last_lr: 0.00121, train_loss: 3.3378, val_loss: 3.3973, val_acc: 0.2420\n",
      "Epoch [19], last_lr: 0.00131, train_loss: 3.2810, val_loss: 3.2166, val_acc: 0.2500\n",
      "Epoch [20], last_lr: 0.00141, train_loss: 3.0388, val_loss: 3.0346, val_acc: 0.2880\n",
      "Epoch [21], last_lr: 0.00152, train_loss: 2.9106, val_loss: 2.8734, val_acc: 0.3000\n",
      "Epoch [22], last_lr: 0.00163, train_loss: 2.7159, val_loss: 2.6740, val_acc: 0.3100\n",
      "Epoch [23], last_lr: 0.00174, train_loss: 2.4822, val_loss: 2.4357, val_acc: 0.3520\n",
      "Epoch [24], last_lr: 0.00185, train_loss: 2.2502, val_loss: 2.2273, val_acc: 0.3720\n",
      "Epoch [25], last_lr: 0.00196, train_loss: 1.9890, val_loss: 2.0415, val_acc: 0.3960\n",
      "Epoch [26], last_lr: 0.00207, train_loss: 1.7636, val_loss: 1.8550, val_acc: 0.4320\n",
      "Epoch [27], last_lr: 0.00218, train_loss: 1.5632, val_loss: 1.6930, val_acc: 0.4560\n",
      "Epoch [28], last_lr: 0.00230, train_loss: 1.4176, val_loss: 1.5438, val_acc: 0.4960\n",
      "Epoch [29], last_lr: 0.00241, train_loss: 1.2684, val_loss: 1.4239, val_acc: 0.5080\n",
      "Epoch [30], last_lr: 0.00252, train_loss: 1.1553, val_loss: 1.3135, val_acc: 0.5300\n",
      "Epoch [31], last_lr: 0.00262, train_loss: 1.0556, val_loss: 1.2506, val_acc: 0.5280\n",
      "Epoch [32], last_lr: 0.00273, train_loss: 0.9894, val_loss: 1.1640, val_acc: 0.5660\n",
      "Epoch [33], last_lr: 0.00284, train_loss: 0.8918, val_loss: 1.1170, val_acc: 0.5740\n",
      "Epoch [34], last_lr: 0.00294, train_loss: 0.8648, val_loss: 1.0796, val_acc: 0.5980\n",
      "Epoch [35], last_lr: 0.00304, train_loss: 0.8322, val_loss: 1.0491, val_acc: 0.6020\n",
      "Epoch [36], last_lr: 0.00313, train_loss: 0.7898, val_loss: 1.0245, val_acc: 0.6160\n",
      "Epoch [37], last_lr: 0.00322, train_loss: 0.7673, val_loss: 1.0199, val_acc: 0.6220\n",
      "Epoch [38], last_lr: 0.00331, train_loss: 0.7606, val_loss: 0.9933, val_acc: 0.6220\n",
      "Epoch [39], last_lr: 0.00339, train_loss: 0.7412, val_loss: 0.9838, val_acc: 0.6100\n",
      "Epoch [40], last_lr: 0.00347, train_loss: 0.7101, val_loss: 0.9800, val_acc: 0.6300\n",
      "Epoch [41], last_lr: 0.00355, train_loss: 0.7047, val_loss: 0.9793, val_acc: 0.6240\n",
      "Epoch [42], last_lr: 0.00362, train_loss: 0.6893, val_loss: 0.9574, val_acc: 0.6300\n",
      "Epoch [43], last_lr: 0.00368, train_loss: 0.6979, val_loss: 0.9592, val_acc: 0.6380\n",
      "Epoch [44], last_lr: 0.00374, train_loss: 0.6769, val_loss: 0.9612, val_acc: 0.6340\n",
      "Epoch [45], last_lr: 0.00379, train_loss: 0.6871, val_loss: 0.9466, val_acc: 0.6360\n",
      "Epoch [46], last_lr: 0.00384, train_loss: 0.6742, val_loss: 0.9463, val_acc: 0.6400\n",
      "Epoch [47], last_lr: 0.00388, train_loss: 0.6850, val_loss: 0.9703, val_acc: 0.6340\n",
      "Epoch [48], last_lr: 0.00392, train_loss: 0.6897, val_loss: 0.9514, val_acc: 0.6380\n",
      "Epoch [49], last_lr: 0.00395, train_loss: 0.6667, val_loss: 0.9489, val_acc: 0.6460\n",
      "Epoch [50], last_lr: 0.00397, train_loss: 0.6630, val_loss: 0.9389, val_acc: 0.6540\n",
      "Epoch [51], last_lr: 0.00399, train_loss: 0.6612, val_loss: 0.9492, val_acc: 0.6540\n",
      "Epoch [52], last_lr: 0.00400, train_loss: 0.6480, val_loss: 0.9526, val_acc: 0.6600\n",
      "Epoch [53], last_lr: 0.00400, train_loss: 0.6648, val_loss: 0.9445, val_acc: 0.6560\n",
      "Epoch [54], last_lr: 0.00400, train_loss: 0.6721, val_loss: 0.9401, val_acc: 0.6500\n",
      "Epoch [55], last_lr: 0.00400, train_loss: 0.6378, val_loss: 0.9384, val_acc: 0.6580\n",
      "Epoch [56], last_lr: 0.00399, train_loss: 0.6581, val_loss: 0.9369, val_acc: 0.6540\n",
      "Epoch [57], last_lr: 0.00399, train_loss: 0.6412, val_loss: 0.9341, val_acc: 0.6620\n",
      "Epoch [58], last_lr: 0.00398, train_loss: 0.6517, val_loss: 0.9365, val_acc: 0.6560\n",
      "Epoch [59], last_lr: 0.00398, train_loss: 0.6522, val_loss: 0.9482, val_acc: 0.6620\n",
      "Epoch [60], last_lr: 0.00397, train_loss: 0.6293, val_loss: 0.9325, val_acc: 0.6580\n",
      "Epoch [61], last_lr: 0.00396, train_loss: 0.6506, val_loss: 0.9400, val_acc: 0.6520\n",
      "Epoch [62], last_lr: 0.00395, train_loss: 0.6505, val_loss: 0.9418, val_acc: 0.6680\n",
      "Epoch [63], last_lr: 0.00394, train_loss: 0.6351, val_loss: 0.9278, val_acc: 0.6700\n",
      "Epoch [64], last_lr: 0.00393, train_loss: 0.6406, val_loss: 0.9297, val_acc: 0.6600\n",
      "Epoch [65], last_lr: 0.00391, train_loss: 0.6553, val_loss: 0.9740, val_acc: 0.6440\n",
      "Epoch [66], last_lr: 0.00390, train_loss: 0.6440, val_loss: 0.9375, val_acc: 0.6640\n",
      "Epoch [67], last_lr: 0.00388, train_loss: 0.6359, val_loss: 0.9343, val_acc: 0.6740\n",
      "Epoch [68], last_lr: 0.00386, train_loss: 0.6343, val_loss: 0.9217, val_acc: 0.6660\n",
      "Epoch [69], last_lr: 0.00384, train_loss: 0.6302, val_loss: 0.9314, val_acc: 0.6640\n",
      "Epoch [70], last_lr: 0.00382, train_loss: 0.6381, val_loss: 0.9170, val_acc: 0.6600\n",
      "Epoch [71], last_lr: 0.00380, train_loss: 0.6324, val_loss: 0.9226, val_acc: 0.6580\n",
      "Epoch [72], last_lr: 0.00378, train_loss: 0.6284, val_loss: 0.9180, val_acc: 0.6720\n",
      "Epoch [73], last_lr: 0.00376, train_loss: 0.6390, val_loss: 0.9249, val_acc: 0.6620\n",
      "Epoch [74], last_lr: 0.00373, train_loss: 0.6159, val_loss: 0.9426, val_acc: 0.6680\n",
      "Epoch [75], last_lr: 0.00371, train_loss: 0.6495, val_loss: 0.9381, val_acc: 0.6800\n",
      "Epoch [76], last_lr: 0.00368, train_loss: 0.6444, val_loss: 0.9114, val_acc: 0.6700\n",
      "Epoch [77], last_lr: 0.00365, train_loss: 0.6226, val_loss: 0.9123, val_acc: 0.6840\n",
      "Epoch [78], last_lr: 0.00362, train_loss: 0.6179, val_loss: 0.9111, val_acc: 0.6740\n",
      "Epoch [79], last_lr: 0.00359, train_loss: 0.6054, val_loss: 0.9055, val_acc: 0.6780\n",
      "Epoch [80], last_lr: 0.00356, train_loss: 0.6225, val_loss: 0.9143, val_acc: 0.6760\n",
      "Epoch [81], last_lr: 0.00353, train_loss: 0.6201, val_loss: 0.9104, val_acc: 0.6780\n",
      "Epoch [82], last_lr: 0.00350, train_loss: 0.6405, val_loss: 0.9285, val_acc: 0.6740\n",
      "Epoch [83], last_lr: 0.00347, train_loss: 0.6262, val_loss: 0.9146, val_acc: 0.6660\n",
      "Epoch [84], last_lr: 0.00343, train_loss: 0.6134, val_loss: 0.9182, val_acc: 0.6740\n",
      "Epoch [85], last_lr: 0.00340, train_loss: 0.6389, val_loss: 0.9247, val_acc: 0.6640\n",
      "Epoch [86], last_lr: 0.00336, train_loss: 0.6308, val_loss: 0.9534, val_acc: 0.6700\n",
      "Epoch [87], last_lr: 0.00332, train_loss: 0.6226, val_loss: 0.9214, val_acc: 0.6780\n",
      "Epoch [88], last_lr: 0.00329, train_loss: 0.6273, val_loss: 0.9253, val_acc: 0.6700\n",
      "Epoch [89], last_lr: 0.00325, train_loss: 0.6201, val_loss: 0.9405, val_acc: 0.6760\n",
      "Epoch [90], last_lr: 0.00321, train_loss: 0.6219, val_loss: 0.9243, val_acc: 0.6780\n",
      "Epoch [91], last_lr: 0.00317, train_loss: 0.6253, val_loss: 0.9230, val_acc: 0.6720\n",
      "Epoch [92], last_lr: 0.00313, train_loss: 0.6309, val_loss: 0.9397, val_acc: 0.6660\n",
      "Epoch [93], last_lr: 0.00309, train_loss: 0.6059, val_loss: 0.9253, val_acc: 0.6780\n",
      "Epoch [94], last_lr: 0.00304, train_loss: 0.6189, val_loss: 0.9165, val_acc: 0.6680\n",
      "Epoch [95], last_lr: 0.00300, train_loss: 0.6132, val_loss: 0.9240, val_acc: 0.6740\n",
      "Epoch [96], last_lr: 0.00296, train_loss: 0.6104, val_loss: 0.9257, val_acc: 0.6720\n",
      "Epoch [97], last_lr: 0.00291, train_loss: 0.6197, val_loss: 0.9328, val_acc: 0.6700\n",
      "Epoch [98], last_lr: 0.00287, train_loss: 0.6106, val_loss: 0.9201, val_acc: 0.6600\n",
      "Epoch [99], last_lr: 0.00282, train_loss: 0.6171, val_loss: 0.9229, val_acc: 0.6680\n",
      "Epoch [100], last_lr: 0.00278, train_loss: 0.6230, val_loss: 0.9309, val_acc: 0.6700\n",
      "Epoch [101], last_lr: 0.00273, train_loss: 0.6239, val_loss: 0.9182, val_acc: 0.6760\n",
      "Epoch [102], last_lr: 0.00268, train_loss: 0.6107, val_loss: 0.9167, val_acc: 0.6740\n",
      "Epoch [103], last_lr: 0.00264, train_loss: 0.6112, val_loss: 0.9153, val_acc: 0.6760\n",
      "Epoch [104], last_lr: 0.00259, train_loss: 0.6183, val_loss: 0.9138, val_acc: 0.6600\n",
      "Epoch [105], last_lr: 0.00254, train_loss: 0.6304, val_loss: 0.9226, val_acc: 0.6720\n",
      "Epoch [106], last_lr: 0.00249, train_loss: 0.6084, val_loss: 0.9141, val_acc: 0.6840\n",
      "Epoch [107], last_lr: 0.00245, train_loss: 0.6302, val_loss: 0.9140, val_acc: 0.6720\n",
      "Epoch [108], last_lr: 0.00240, train_loss: 0.6297, val_loss: 0.9215, val_acc: 0.6800\n",
      "Epoch [109], last_lr: 0.00235, train_loss: 0.6314, val_loss: 0.9136, val_acc: 0.6760\n",
      "Epoch [110], last_lr: 0.00230, train_loss: 0.6156, val_loss: 0.9108, val_acc: 0.6740\n",
      "Epoch [111], last_lr: 0.00225, train_loss: 0.6285, val_loss: 0.9204, val_acc: 0.6760\n",
      "Epoch [112], last_lr: 0.00220, train_loss: 0.6051, val_loss: 0.9137, val_acc: 0.6740\n",
      "Epoch [113], last_lr: 0.00215, train_loss: 0.6175, val_loss: 0.9227, val_acc: 0.6720\n",
      "Epoch [114], last_lr: 0.00210, train_loss: 0.6224, val_loss: 0.9119, val_acc: 0.6740\n",
      "Epoch [115], last_lr: 0.00205, train_loss: 0.6192, val_loss: 0.9179, val_acc: 0.6760\n",
      "Epoch [116], last_lr: 0.00200, train_loss: 0.6212, val_loss: 0.9165, val_acc: 0.6780\n",
      "Epoch [117], last_lr: 0.00195, train_loss: 0.6012, val_loss: 0.9224, val_acc: 0.6800\n",
      "Epoch [118], last_lr: 0.00190, train_loss: 0.6236, val_loss: 0.9129, val_acc: 0.6700\n",
      "Epoch [119], last_lr: 0.00185, train_loss: 0.5860, val_loss: 0.9326, val_acc: 0.6800\n",
      "Epoch [120], last_lr: 0.00180, train_loss: 0.6230, val_loss: 0.9142, val_acc: 0.6800\n",
      "Epoch [121], last_lr: 0.00175, train_loss: 0.6341, val_loss: 0.9415, val_acc: 0.6640\n",
      "Epoch [122], last_lr: 0.00170, train_loss: 0.6076, val_loss: 0.9221, val_acc: 0.6760\n",
      "Epoch [123], last_lr: 0.00165, train_loss: 0.6147, val_loss: 0.9248, val_acc: 0.6760\n",
      "Epoch [124], last_lr: 0.00160, train_loss: 0.6529, val_loss: 0.9144, val_acc: 0.6760\n",
      "Epoch [125], last_lr: 0.00155, train_loss: 0.6117, val_loss: 0.9217, val_acc: 0.6800\n",
      "Epoch [126], last_lr: 0.00151, train_loss: 0.5966, val_loss: 0.9218, val_acc: 0.6720\n",
      "Epoch [127], last_lr: 0.00146, train_loss: 0.6076, val_loss: 0.9147, val_acc: 0.6840\n",
      "Epoch [128], last_lr: 0.00141, train_loss: 0.6355, val_loss: 0.9170, val_acc: 0.6800\n",
      "Epoch [129], last_lr: 0.00136, train_loss: 0.6228, val_loss: 0.9165, val_acc: 0.6820\n",
      "Epoch [130], last_lr: 0.00132, train_loss: 0.6306, val_loss: 0.9212, val_acc: 0.6820\n",
      "Epoch [131], last_lr: 0.00127, train_loss: 0.6012, val_loss: 0.9170, val_acc: 0.6780\n",
      "Epoch [132], last_lr: 0.00122, train_loss: 0.6328, val_loss: 0.9240, val_acc: 0.6780\n",
      "Epoch [133], last_lr: 0.00118, train_loss: 0.6040, val_loss: 0.9116, val_acc: 0.6740\n",
      "Epoch [134], last_lr: 0.00113, train_loss: 0.6124, val_loss: 0.9095, val_acc: 0.6700\n",
      "Epoch [135], last_lr: 0.00109, train_loss: 0.6187, val_loss: 0.9173, val_acc: 0.6820\n",
      "Epoch [136], last_lr: 0.00104, train_loss: 0.6161, val_loss: 0.9146, val_acc: 0.6700\n",
      "Epoch [137], last_lr: 0.00100, train_loss: 0.6149, val_loss: 0.9090, val_acc: 0.6760\n",
      "Epoch [138], last_lr: 0.00096, train_loss: 0.5893, val_loss: 0.9110, val_acc: 0.6840\n",
      "Epoch [139], last_lr: 0.00091, train_loss: 0.6165, val_loss: 0.9109, val_acc: 0.6800\n",
      "Epoch [140], last_lr: 0.00087, train_loss: 0.6110, val_loss: 0.9108, val_acc: 0.6820\n",
      "Epoch [141], last_lr: 0.00083, train_loss: 0.6269, val_loss: 0.9087, val_acc: 0.6840\n",
      "Epoch [142], last_lr: 0.00079, train_loss: 0.6063, val_loss: 0.9155, val_acc: 0.6760\n",
      "Epoch [143], last_lr: 0.00075, train_loss: 0.5979, val_loss: 0.9122, val_acc: 0.6820\n",
      "Epoch [144], last_lr: 0.00071, train_loss: 0.6136, val_loss: 0.9115, val_acc: 0.6820\n",
      "Epoch [145], last_lr: 0.00068, train_loss: 0.6248, val_loss: 0.9149, val_acc: 0.6820\n",
      "Epoch [146], last_lr: 0.00064, train_loss: 0.5916, val_loss: 0.9181, val_acc: 0.6740\n",
      "Epoch [147], last_lr: 0.00060, train_loss: 0.6016, val_loss: 0.9133, val_acc: 0.6820\n",
      "Epoch [148], last_lr: 0.00057, train_loss: 0.6202, val_loss: 0.9137, val_acc: 0.6840\n",
      "Epoch [149], last_lr: 0.00053, train_loss: 0.6127, val_loss: 0.9179, val_acc: 0.6780\n",
      "Epoch [150], last_lr: 0.00050, train_loss: 0.6210, val_loss: 0.9196, val_acc: 0.6720\n",
      "Epoch [151], last_lr: 0.00047, train_loss: 0.5971, val_loss: 0.9173, val_acc: 0.6840\n",
      "Epoch [152], last_lr: 0.00044, train_loss: 0.6052, val_loss: 0.9194, val_acc: 0.6820\n",
      "Epoch [153], last_lr: 0.00041, train_loss: 0.6048, val_loss: 0.9178, val_acc: 0.6760\n",
      "Epoch [154], last_lr: 0.00038, train_loss: 0.6047, val_loss: 0.9171, val_acc: 0.6800\n",
      "Epoch [155], last_lr: 0.00035, train_loss: 0.6169, val_loss: 0.9182, val_acc: 0.6800\n",
      "Epoch [156], last_lr: 0.00032, train_loss: 0.5981, val_loss: 0.9199, val_acc: 0.6760\n",
      "Epoch [157], last_lr: 0.00029, train_loss: 0.6059, val_loss: 0.9190, val_acc: 0.6780\n",
      "Epoch [158], last_lr: 0.00027, train_loss: 0.6052, val_loss: 0.9178, val_acc: 0.6820\n",
      "Epoch [159], last_lr: 0.00024, train_loss: 0.6139, val_loss: 0.9168, val_acc: 0.6780\n",
      "Epoch [160], last_lr: 0.00022, train_loss: 0.6146, val_loss: 0.9181, val_acc: 0.6780\n",
      "Epoch [161], last_lr: 0.00020, train_loss: 0.6086, val_loss: 0.9169, val_acc: 0.6780\n",
      "Epoch [162], last_lr: 0.00018, train_loss: 0.6116, val_loss: 0.9171, val_acc: 0.6780\n",
      "Epoch [163], last_lr: 0.00016, train_loss: 0.5960, val_loss: 0.9168, val_acc: 0.6780\n",
      "Epoch [164], last_lr: 0.00014, train_loss: 0.6345, val_loss: 0.9176, val_acc: 0.6780\n",
      "Epoch [165], last_lr: 0.00012, train_loss: 0.6070, val_loss: 0.9167, val_acc: 0.6780\n",
      "Epoch [166], last_lr: 0.00010, train_loss: 0.6110, val_loss: 0.9193, val_acc: 0.6780\n",
      "Epoch [167], last_lr: 0.00009, train_loss: 0.6109, val_loss: 0.9194, val_acc: 0.6760\n",
      "Epoch [168], last_lr: 0.00007, train_loss: 0.6163, val_loss: 0.9182, val_acc: 0.6760\n",
      "Epoch [169], last_lr: 0.00006, train_loss: 0.5996, val_loss: 0.9178, val_acc: 0.6740\n",
      "Epoch [170], last_lr: 0.00005, train_loss: 0.6217, val_loss: 0.9186, val_acc: 0.6740\n",
      "Epoch [171], last_lr: 0.00004, train_loss: 0.5715, val_loss: 0.9180, val_acc: 0.6780\n",
      "Epoch [172], last_lr: 0.00003, train_loss: 0.6225, val_loss: 0.9173, val_acc: 0.6780\n",
      "Epoch [173], last_lr: 0.00002, train_loss: 0.6138, val_loss: 0.9162, val_acc: 0.6800\n",
      "Epoch [174], last_lr: 0.00002, train_loss: 0.6004, val_loss: 0.9166, val_acc: 0.6760\n",
      "Epoch [175], last_lr: 0.00001, train_loss: 0.6070, val_loss: 0.9176, val_acc: 0.6780\n",
      "Epoch [176], last_lr: 0.00001, train_loss: 0.5922, val_loss: 0.9176, val_acc: 0.6760\n",
      "Epoch [177], last_lr: 0.00000, train_loss: 0.6244, val_loss: 0.9182, val_acc: 0.6780\n",
      "Epoch [178], last_lr: 0.00000, train_loss: 0.6012, val_loss: 0.9178, val_acc: 0.6800\n",
      "Epoch [179], last_lr: 0.00000, train_loss: 0.5961, val_loss: 0.9168, val_acc: 0.6800\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[{'val_loss': 16.425880432128906, 'val_acc': 0.20600000023841858}]\n",
      "Epoch [0], last_lr: 0.00016, train_loss: 12.7518, val_loss: 13.9190, val_acc: 0.2240\n",
      "Epoch [1], last_lr: 0.00017, train_loss: 12.3789, val_loss: 12.7621, val_acc: 0.2160\n",
      "Epoch [2], last_lr: 0.00019, train_loss: 11.9426, val_loss: 12.0996, val_acc: 0.2160\n",
      "Epoch [3], last_lr: 0.00021, train_loss: 11.5493, val_loss: 11.5426, val_acc: 0.2220\n",
      "Epoch [4], last_lr: 0.00024, train_loss: 10.9917, val_loss: 10.9662, val_acc: 0.2200\n",
      "Epoch [5], last_lr: 0.00027, train_loss: 10.4653, val_loss: 10.3371, val_acc: 0.2220\n",
      "Epoch [6], last_lr: 0.00031, train_loss: 9.8372, val_loss: 9.6133, val_acc: 0.2200\n",
      "Epoch [7], last_lr: 0.00036, train_loss: 9.1439, val_loss: 8.7890, val_acc: 0.2240\n",
      "Epoch [8], last_lr: 0.00041, train_loss: 8.2997, val_loss: 7.8670, val_acc: 0.2220\n",
      "Epoch [9], last_lr: 0.00047, train_loss: 7.3751, val_loss: 6.8470, val_acc: 0.2120\n",
      "Epoch [10], last_lr: 0.00053, train_loss: 6.3487, val_loss: 5.7342, val_acc: 0.2020\n",
      "Epoch [11], last_lr: 0.00060, train_loss: 5.3307, val_loss: 4.6607, val_acc: 0.1680\n",
      "Epoch [12], last_lr: 0.00068, train_loss: 4.3477, val_loss: 3.8950, val_acc: 0.1640\n",
      "Epoch [13], last_lr: 0.00075, train_loss: 3.7528, val_loss: 3.6806, val_acc: 0.2180\n",
      "Epoch [14], last_lr: 0.00084, train_loss: 3.5603, val_loss: 3.7495, val_acc: 0.2520\n",
      "Epoch [15], last_lr: 0.00092, train_loss: 3.5960, val_loss: 3.6919, val_acc: 0.2640\n",
      "Epoch [16], last_lr: 0.00102, train_loss: 3.4404, val_loss: 3.4807, val_acc: 0.2440\n",
      "Epoch [17], last_lr: 0.00111, train_loss: 3.2450, val_loss: 3.2506, val_acc: 0.2240\n",
      "Epoch [18], last_lr: 0.00121, train_loss: 3.0207, val_loss: 3.0543, val_acc: 0.2400\n",
      "Epoch [19], last_lr: 0.00131, train_loss: 2.7865, val_loss: 2.8535, val_acc: 0.2780\n",
      "Epoch [20], last_lr: 0.00141, train_loss: 2.5226, val_loss: 2.6489, val_acc: 0.2960\n",
      "Epoch [21], last_lr: 0.00152, train_loss: 2.2962, val_loss: 2.3958, val_acc: 0.3200\n",
      "Epoch [22], last_lr: 0.00163, train_loss: 2.0448, val_loss: 2.1797, val_acc: 0.3620\n",
      "Epoch [23], last_lr: 0.00174, train_loss: 1.7939, val_loss: 1.9781, val_acc: 0.4160\n",
      "Epoch [24], last_lr: 0.00185, train_loss: 1.5880, val_loss: 1.7953, val_acc: 0.4500\n",
      "Epoch [25], last_lr: 0.00196, train_loss: 1.3757, val_loss: 1.6405, val_acc: 0.5040\n",
      "Epoch [26], last_lr: 0.00207, train_loss: 1.1991, val_loss: 1.5157, val_acc: 0.5320\n",
      "Epoch [27], last_lr: 0.00218, train_loss: 1.0621, val_loss: 1.4115, val_acc: 0.5640\n",
      "Epoch [28], last_lr: 0.00230, train_loss: 0.9605, val_loss: 1.3333, val_acc: 0.5720\n",
      "Epoch [29], last_lr: 0.00241, train_loss: 0.8763, val_loss: 1.2571, val_acc: 0.5920\n",
      "Epoch [30], last_lr: 0.00252, train_loss: 0.7973, val_loss: 1.1909, val_acc: 0.6160\n",
      "Epoch [31], last_lr: 0.00262, train_loss: 0.7178, val_loss: 1.1325, val_acc: 0.6300\n",
      "Epoch [32], last_lr: 0.00273, train_loss: 0.6881, val_loss: 1.0937, val_acc: 0.6400\n",
      "Epoch [33], last_lr: 0.00284, train_loss: 0.6598, val_loss: 1.0546, val_acc: 0.6520\n",
      "Epoch [34], last_lr: 0.00294, train_loss: 0.6052, val_loss: 1.0247, val_acc: 0.6540\n",
      "Epoch [35], last_lr: 0.00304, train_loss: 0.5818, val_loss: 1.0001, val_acc: 0.6580\n",
      "Epoch [36], last_lr: 0.00313, train_loss: 0.5660, val_loss: 0.9814, val_acc: 0.6640\n",
      "Epoch [37], last_lr: 0.00322, train_loss: 0.5320, val_loss: 0.9554, val_acc: 0.6700\n",
      "Epoch [38], last_lr: 0.00331, train_loss: 0.5152, val_loss: 0.9413, val_acc: 0.6760\n",
      "Epoch [39], last_lr: 0.00339, train_loss: 0.5048, val_loss: 0.9322, val_acc: 0.6680\n",
      "Epoch [40], last_lr: 0.00347, train_loss: 0.4724, val_loss: 0.9179, val_acc: 0.6760\n",
      "Epoch [41], last_lr: 0.00355, train_loss: 0.4773, val_loss: 0.9097, val_acc: 0.6800\n",
      "Epoch [42], last_lr: 0.00362, train_loss: 0.4724, val_loss: 0.9143, val_acc: 0.6700\n",
      "Epoch [43], last_lr: 0.00368, train_loss: 0.4651, val_loss: 0.9031, val_acc: 0.6800\n",
      "Epoch [44], last_lr: 0.00374, train_loss: 0.4635, val_loss: 0.8903, val_acc: 0.6920\n",
      "Epoch [45], last_lr: 0.00379, train_loss: 0.4417, val_loss: 0.8965, val_acc: 0.6900\n",
      "Epoch [46], last_lr: 0.00384, train_loss: 0.4469, val_loss: 0.8966, val_acc: 0.6820\n",
      "Epoch [47], last_lr: 0.00388, train_loss: 0.4428, val_loss: 0.8984, val_acc: 0.6760\n",
      "Epoch [48], last_lr: 0.00392, train_loss: 0.4454, val_loss: 0.8857, val_acc: 0.6860\n",
      "Epoch [49], last_lr: 0.00395, train_loss: 0.4473, val_loss: 0.8951, val_acc: 0.6780\n",
      "Epoch [50], last_lr: 0.00397, train_loss: 0.4282, val_loss: 0.8735, val_acc: 0.6900\n",
      "Epoch [51], last_lr: 0.00399, train_loss: 0.4129, val_loss: 0.8978, val_acc: 0.7040\n",
      "Epoch [52], last_lr: 0.00400, train_loss: 0.4547, val_loss: 0.8797, val_acc: 0.6880\n",
      "Epoch [53], last_lr: 0.00400, train_loss: 0.4250, val_loss: 0.8726, val_acc: 0.6920\n",
      "Epoch [54], last_lr: 0.00400, train_loss: 0.4204, val_loss: 0.8901, val_acc: 0.6860\n",
      "Epoch [55], last_lr: 0.00400, train_loss: 0.4135, val_loss: 0.9100, val_acc: 0.6960\n",
      "Epoch [56], last_lr: 0.00399, train_loss: 0.4373, val_loss: 0.8771, val_acc: 0.6900\n",
      "Epoch [57], last_lr: 0.00399, train_loss: 0.4248, val_loss: 0.8728, val_acc: 0.6980\n",
      "Epoch [58], last_lr: 0.00398, train_loss: 0.4195, val_loss: 0.8646, val_acc: 0.6920\n",
      "Epoch [59], last_lr: 0.00398, train_loss: 0.4211, val_loss: 0.8762, val_acc: 0.6840\n",
      "Epoch [60], last_lr: 0.00397, train_loss: 0.4029, val_loss: 0.8532, val_acc: 0.6980\n",
      "Epoch [61], last_lr: 0.00396, train_loss: 0.3981, val_loss: 0.8874, val_acc: 0.6980\n",
      "Epoch [62], last_lr: 0.00395, train_loss: 0.4453, val_loss: 0.8877, val_acc: 0.6860\n",
      "Epoch [63], last_lr: 0.00394, train_loss: 0.4049, val_loss: 0.8477, val_acc: 0.7040\n",
      "Epoch [64], last_lr: 0.00393, train_loss: 0.4010, val_loss: 0.8564, val_acc: 0.6900\n",
      "Epoch [65], last_lr: 0.00391, train_loss: 0.4093, val_loss: 0.8742, val_acc: 0.6840\n",
      "Epoch [66], last_lr: 0.00390, train_loss: 0.4139, val_loss: 0.8554, val_acc: 0.7080\n",
      "Epoch [67], last_lr: 0.00388, train_loss: 0.4126, val_loss: 0.8630, val_acc: 0.6820\n",
      "Epoch [68], last_lr: 0.00386, train_loss: 0.3839, val_loss: 0.8525, val_acc: 0.6980\n",
      "Epoch [69], last_lr: 0.00384, train_loss: 0.3793, val_loss: 0.9270, val_acc: 0.6840\n",
      "Epoch [70], last_lr: 0.00382, train_loss: 0.4259, val_loss: 0.8857, val_acc: 0.6720\n",
      "Epoch [71], last_lr: 0.00380, train_loss: 0.3944, val_loss: 0.8662, val_acc: 0.6940\n",
      "Epoch [72], last_lr: 0.00378, train_loss: 0.4000, val_loss: 0.8756, val_acc: 0.7000\n",
      "Epoch [73], last_lr: 0.00376, train_loss: 0.4027, val_loss: 0.8595, val_acc: 0.6960\n",
      "Epoch [74], last_lr: 0.00373, train_loss: 0.3824, val_loss: 0.8553, val_acc: 0.6940\n",
      "Epoch [75], last_lr: 0.00371, train_loss: 0.3896, val_loss: 0.8500, val_acc: 0.7000\n",
      "Epoch [76], last_lr: 0.00368, train_loss: 0.3782, val_loss: 0.8569, val_acc: 0.6900\n",
      "Epoch [77], last_lr: 0.00365, train_loss: 0.3929, val_loss: 0.8488, val_acc: 0.7000\n",
      "Epoch [78], last_lr: 0.00362, train_loss: 0.3944, val_loss: 0.8724, val_acc: 0.6900\n",
      "Epoch [79], last_lr: 0.00359, train_loss: 0.4007, val_loss: 0.8428, val_acc: 0.7060\n",
      "Epoch [80], last_lr: 0.00356, train_loss: 0.3785, val_loss: 0.8420, val_acc: 0.7060\n",
      "Epoch [81], last_lr: 0.00353, train_loss: 0.3777, val_loss: 0.8692, val_acc: 0.6920\n",
      "Epoch [82], last_lr: 0.00350, train_loss: 0.3685, val_loss: 0.8354, val_acc: 0.7040\n",
      "Epoch [83], last_lr: 0.00347, train_loss: 0.4005, val_loss: 0.8490, val_acc: 0.6920\n",
      "Epoch [84], last_lr: 0.00343, train_loss: 0.3683, val_loss: 0.8419, val_acc: 0.7020\n",
      "Epoch [85], last_lr: 0.00340, train_loss: 0.3673, val_loss: 0.8604, val_acc: 0.6900\n",
      "Epoch [86], last_lr: 0.00336, train_loss: 0.3807, val_loss: 0.8445, val_acc: 0.6940\n",
      "Epoch [87], last_lr: 0.00332, train_loss: 0.3932, val_loss: 0.8556, val_acc: 0.6840\n",
      "Epoch [88], last_lr: 0.00329, train_loss: 0.3727, val_loss: 0.8389, val_acc: 0.7000\n",
      "Epoch [89], last_lr: 0.00325, train_loss: 0.3852, val_loss: 0.8443, val_acc: 0.6880\n",
      "Epoch [90], last_lr: 0.00321, train_loss: 0.3743, val_loss: 0.8411, val_acc: 0.6980\n",
      "Epoch [91], last_lr: 0.00317, train_loss: 0.3780, val_loss: 0.8381, val_acc: 0.7040\n",
      "Epoch [92], last_lr: 0.00313, train_loss: 0.3858, val_loss: 0.8453, val_acc: 0.6820\n",
      "Epoch [93], last_lr: 0.00309, train_loss: 0.3755, val_loss: 0.8382, val_acc: 0.6940\n",
      "Epoch [94], last_lr: 0.00304, train_loss: 0.3720, val_loss: 0.8341, val_acc: 0.7040\n",
      "Epoch [95], last_lr: 0.00300, train_loss: 0.3764, val_loss: 0.8775, val_acc: 0.6780\n",
      "Epoch [96], last_lr: 0.00296, train_loss: 0.3729, val_loss: 0.8501, val_acc: 0.7080\n",
      "Epoch [97], last_lr: 0.00291, train_loss: 0.3703, val_loss: 0.8689, val_acc: 0.6900\n",
      "Epoch [98], last_lr: 0.00287, train_loss: 0.3883, val_loss: 0.8378, val_acc: 0.7020\n",
      "Epoch [99], last_lr: 0.00282, train_loss: 0.3629, val_loss: 0.8412, val_acc: 0.6880\n",
      "Epoch [100], last_lr: 0.00278, train_loss: 0.3691, val_loss: 0.8393, val_acc: 0.7020\n",
      "Epoch [101], last_lr: 0.00273, train_loss: 0.3732, val_loss: 0.8359, val_acc: 0.7080\n",
      "Epoch [102], last_lr: 0.00268, train_loss: 0.3645, val_loss: 0.8592, val_acc: 0.6880\n",
      "Epoch [103], last_lr: 0.00264, train_loss: 0.3568, val_loss: 0.8372, val_acc: 0.7040\n",
      "Epoch [104], last_lr: 0.00259, train_loss: 0.3820, val_loss: 0.8495, val_acc: 0.6940\n",
      "Epoch [105], last_lr: 0.00254, train_loss: 0.3710, val_loss: 0.8351, val_acc: 0.7140\n",
      "Epoch [106], last_lr: 0.00249, train_loss: 0.3735, val_loss: 0.8461, val_acc: 0.6900\n",
      "Epoch [107], last_lr: 0.00245, train_loss: 0.3533, val_loss: 0.8316, val_acc: 0.7120\n",
      "Epoch [108], last_lr: 0.00240, train_loss: 0.3678, val_loss: 0.8498, val_acc: 0.6880\n",
      "Epoch [109], last_lr: 0.00235, train_loss: 0.3421, val_loss: 0.8415, val_acc: 0.7060\n",
      "Epoch [110], last_lr: 0.00230, train_loss: 0.3683, val_loss: 0.8370, val_acc: 0.7120\n",
      "Epoch [111], last_lr: 0.00225, train_loss: 0.3710, val_loss: 0.8441, val_acc: 0.6980\n",
      "Epoch [112], last_lr: 0.00220, train_loss: 0.3699, val_loss: 0.8471, val_acc: 0.6940\n",
      "Epoch [113], last_lr: 0.00215, train_loss: 0.3671, val_loss: 0.8539, val_acc: 0.7020\n",
      "Epoch [114], last_lr: 0.00210, train_loss: 0.3648, val_loss: 0.8430, val_acc: 0.7120\n",
      "Epoch [115], last_lr: 0.00205, train_loss: 0.3513, val_loss: 0.8517, val_acc: 0.6820\n",
      "Epoch [116], last_lr: 0.00200, train_loss: 0.3612, val_loss: 0.8432, val_acc: 0.7060\n",
      "Epoch [117], last_lr: 0.00195, train_loss: 0.3752, val_loss: 0.8466, val_acc: 0.6840\n",
      "Epoch [118], last_lr: 0.00190, train_loss: 0.3629, val_loss: 0.8430, val_acc: 0.7080\n",
      "Epoch [119], last_lr: 0.00185, train_loss: 0.3571, val_loss: 0.8429, val_acc: 0.7020\n",
      "Epoch [120], last_lr: 0.00180, train_loss: 0.3672, val_loss: 0.8460, val_acc: 0.6920\n",
      "Epoch [121], last_lr: 0.00175, train_loss: 0.3625, val_loss: 0.8392, val_acc: 0.7100\n",
      "Epoch [122], last_lr: 0.00170, train_loss: 0.3601, val_loss: 0.8456, val_acc: 0.7000\n",
      "Epoch [123], last_lr: 0.00165, train_loss: 0.3657, val_loss: 0.8438, val_acc: 0.7060\n",
      "Epoch [124], last_lr: 0.00160, train_loss: 0.3656, val_loss: 0.8454, val_acc: 0.7060\n",
      "Epoch [125], last_lr: 0.00155, train_loss: 0.3597, val_loss: 0.8502, val_acc: 0.6980\n",
      "Epoch [126], last_lr: 0.00151, train_loss: 0.3657, val_loss: 0.8413, val_acc: 0.7080\n",
      "Epoch [127], last_lr: 0.00146, train_loss: 0.3508, val_loss: 0.8417, val_acc: 0.7080\n",
      "Epoch [128], last_lr: 0.00141, train_loss: 0.3444, val_loss: 0.8527, val_acc: 0.7000\n",
      "Epoch [129], last_lr: 0.00136, train_loss: 0.3514, val_loss: 0.8436, val_acc: 0.7080\n",
      "Epoch [130], last_lr: 0.00132, train_loss: 0.3688, val_loss: 0.8460, val_acc: 0.7040\n",
      "Epoch [131], last_lr: 0.00127, train_loss: 0.3501, val_loss: 0.8431, val_acc: 0.6980\n",
      "Epoch [132], last_lr: 0.00122, train_loss: 0.3410, val_loss: 0.8456, val_acc: 0.6960\n",
      "Epoch [133], last_lr: 0.00118, train_loss: 0.3425, val_loss: 0.8445, val_acc: 0.7020\n",
      "Epoch [134], last_lr: 0.00113, train_loss: 0.3618, val_loss: 0.8473, val_acc: 0.6980\n",
      "Epoch [135], last_lr: 0.00109, train_loss: 0.3481, val_loss: 0.8494, val_acc: 0.6980\n",
      "Epoch [136], last_lr: 0.00104, train_loss: 0.3602, val_loss: 0.8474, val_acc: 0.6960\n",
      "Epoch [137], last_lr: 0.00100, train_loss: 0.3468, val_loss: 0.8468, val_acc: 0.7020\n",
      "Epoch [138], last_lr: 0.00096, train_loss: 0.3543, val_loss: 0.8463, val_acc: 0.7060\n",
      "Epoch [139], last_lr: 0.00091, train_loss: 0.3522, val_loss: 0.8458, val_acc: 0.7120\n",
      "Epoch [140], last_lr: 0.00087, train_loss: 0.3514, val_loss: 0.8484, val_acc: 0.6980\n",
      "Epoch [141], last_lr: 0.00083, train_loss: 0.3606, val_loss: 0.8474, val_acc: 0.7000\n",
      "Epoch [142], last_lr: 0.00079, train_loss: 0.3574, val_loss: 0.8433, val_acc: 0.7100\n",
      "Epoch [143], last_lr: 0.00075, train_loss: 0.3719, val_loss: 0.8462, val_acc: 0.7080\n",
      "Epoch [144], last_lr: 0.00071, train_loss: 0.3499, val_loss: 0.8502, val_acc: 0.7060\n",
      "Epoch [145], last_lr: 0.00068, train_loss: 0.3355, val_loss: 0.8464, val_acc: 0.7020\n",
      "Epoch [146], last_lr: 0.00064, train_loss: 0.3452, val_loss: 0.8480, val_acc: 0.7060\n",
      "Epoch [147], last_lr: 0.00060, train_loss: 0.3532, val_loss: 0.8498, val_acc: 0.7020\n",
      "Epoch [148], last_lr: 0.00057, train_loss: 0.3497, val_loss: 0.8464, val_acc: 0.7060\n",
      "Epoch [149], last_lr: 0.00053, train_loss: 0.3558, val_loss: 0.8452, val_acc: 0.7080\n",
      "Epoch [150], last_lr: 0.00050, train_loss: 0.3279, val_loss: 0.8490, val_acc: 0.6980\n",
      "Epoch [151], last_lr: 0.00047, train_loss: 0.3572, val_loss: 0.8501, val_acc: 0.6980\n",
      "Epoch [152], last_lr: 0.00044, train_loss: 0.3467, val_loss: 0.8475, val_acc: 0.7000\n",
      "Epoch [153], last_lr: 0.00041, train_loss: 0.3437, val_loss: 0.8469, val_acc: 0.7000\n",
      "Epoch [154], last_lr: 0.00038, train_loss: 0.3538, val_loss: 0.8474, val_acc: 0.7000\n",
      "Epoch [155], last_lr: 0.00035, train_loss: 0.3376, val_loss: 0.8483, val_acc: 0.7040\n",
      "Epoch [156], last_lr: 0.00032, train_loss: 0.3586, val_loss: 0.8489, val_acc: 0.7060\n",
      "Epoch [157], last_lr: 0.00029, train_loss: 0.3463, val_loss: 0.8490, val_acc: 0.7020\n",
      "Epoch [158], last_lr: 0.00027, train_loss: 0.3484, val_loss: 0.8491, val_acc: 0.7020\n",
      "Epoch [159], last_lr: 0.00024, train_loss: 0.3437, val_loss: 0.8506, val_acc: 0.7020\n",
      "Epoch [160], last_lr: 0.00022, train_loss: 0.3472, val_loss: 0.8493, val_acc: 0.7020\n",
      "Epoch [161], last_lr: 0.00020, train_loss: 0.3518, val_loss: 0.8493, val_acc: 0.7040\n",
      "Epoch [162], last_lr: 0.00018, train_loss: 0.3571, val_loss: 0.8487, val_acc: 0.7040\n",
      "Epoch [163], last_lr: 0.00016, train_loss: 0.3403, val_loss: 0.8486, val_acc: 0.7040\n",
      "Epoch [164], last_lr: 0.00014, train_loss: 0.3585, val_loss: 0.8491, val_acc: 0.7040\n",
      "Epoch [165], last_lr: 0.00012, train_loss: 0.3534, val_loss: 0.8480, val_acc: 0.7040\n",
      "Epoch [166], last_lr: 0.00010, train_loss: 0.3681, val_loss: 0.8474, val_acc: 0.7020\n",
      "Epoch [167], last_lr: 0.00009, train_loss: 0.3408, val_loss: 0.8498, val_acc: 0.7020\n",
      "Epoch [168], last_lr: 0.00007, train_loss: 0.3626, val_loss: 0.8480, val_acc: 0.7020\n",
      "Epoch [169], last_lr: 0.00006, train_loss: 0.3563, val_loss: 0.8490, val_acc: 0.7000\n",
      "Epoch [170], last_lr: 0.00005, train_loss: 0.3607, val_loss: 0.8488, val_acc: 0.7020\n",
      "Epoch [171], last_lr: 0.00004, train_loss: 0.3492, val_loss: 0.8481, val_acc: 0.7020\n",
      "Epoch [172], last_lr: 0.00003, train_loss: 0.3406, val_loss: 0.8475, val_acc: 0.7020\n",
      "Epoch [173], last_lr: 0.00002, train_loss: 0.3554, val_loss: 0.8478, val_acc: 0.7020\n",
      "Epoch [174], last_lr: 0.00002, train_loss: 0.3601, val_loss: 0.8491, val_acc: 0.7020\n",
      "Epoch [175], last_lr: 0.00001, train_loss: 0.3453, val_loss: 0.8493, val_acc: 0.7020\n",
      "Epoch [176], last_lr: 0.00001, train_loss: 0.3526, val_loss: 0.8491, val_acc: 0.7020\n",
      "Epoch [177], last_lr: 0.00000, train_loss: 0.3487, val_loss: 0.8483, val_acc: 0.7020\n",
      "Epoch [178], last_lr: 0.00000, train_loss: 0.3578, val_loss: 0.8496, val_acc: 0.7020\n",
      "Epoch [179], last_lr: 0.00000, train_loss: 0.3430, val_loss: 0.8505, val_acc: 0.7020\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[{'val_loss': 4.3917107582092285, 'val_acc': 0.2840000092983246}]\n",
      "Epoch [0], last_lr: 0.00016, train_loss: 6.0407, val_loss: 4.6709, val_acc: 0.2740\n",
      "Epoch [1], last_lr: 0.00017, train_loss: 5.7016, val_loss: 4.8694, val_acc: 0.2540\n",
      "Epoch [2], last_lr: 0.00019, train_loss: 5.3584, val_loss: 4.8681, val_acc: 0.2480\n",
      "Epoch [3], last_lr: 0.00021, train_loss: 5.0699, val_loss: 4.7146, val_acc: 0.2500\n",
      "Epoch [4], last_lr: 0.00024, train_loss: 4.6691, val_loss: 4.4690, val_acc: 0.2540\n",
      "Epoch [5], last_lr: 0.00027, train_loss: 4.3634, val_loss: 4.1918, val_acc: 0.2480\n",
      "Epoch [6], last_lr: 0.00031, train_loss: 4.0184, val_loss: 3.9040, val_acc: 0.2460\n",
      "Epoch [7], last_lr: 0.00036, train_loss: 3.7212, val_loss: 3.6500, val_acc: 0.2460\n",
      "Epoch [8], last_lr: 0.00041, train_loss: 3.4720, val_loss: 3.4703, val_acc: 0.2360\n",
      "Epoch [9], last_lr: 0.00047, train_loss: 3.3214, val_loss: 3.3882, val_acc: 0.2600\n",
      "Epoch [10], last_lr: 0.00053, train_loss: 3.2733, val_loss: 3.3319, val_acc: 0.2860\n",
      "Epoch [11], last_lr: 0.00060, train_loss: 3.1705, val_loss: 3.2064, val_acc: 0.2960\n",
      "Epoch [12], last_lr: 0.00068, train_loss: 3.0457, val_loss: 3.0565, val_acc: 0.2960\n",
      "Epoch [13], last_lr: 0.00075, train_loss: 2.8972, val_loss: 2.8994, val_acc: 0.3020\n",
      "Epoch [14], last_lr: 0.00084, train_loss: 2.7111, val_loss: 2.7340, val_acc: 0.3240\n",
      "Epoch [15], last_lr: 0.00092, train_loss: 2.5699, val_loss: 2.5566, val_acc: 0.3560\n",
      "Epoch [16], last_lr: 0.00102, train_loss: 2.3618, val_loss: 2.3707, val_acc: 0.3720\n",
      "Epoch [17], last_lr: 0.00111, train_loss: 2.1411, val_loss: 2.1829, val_acc: 0.4200\n",
      "Epoch [18], last_lr: 0.00121, train_loss: 1.9915, val_loss: 1.9922, val_acc: 0.4500\n",
      "Epoch [19], last_lr: 0.00131, train_loss: 1.8005, val_loss: 1.8155, val_acc: 0.4880\n",
      "Epoch [20], last_lr: 0.00141, train_loss: 1.5893, val_loss: 1.6570, val_acc: 0.5200\n",
      "Epoch [21], last_lr: 0.00152, train_loss: 1.3931, val_loss: 1.5159, val_acc: 0.5440\n",
      "Epoch [22], last_lr: 0.00163, train_loss: 1.2803, val_loss: 1.3862, val_acc: 0.5800\n",
      "Epoch [23], last_lr: 0.00174, train_loss: 1.1884, val_loss: 1.2901, val_acc: 0.6000\n",
      "Epoch [24], last_lr: 0.00185, train_loss: 1.0546, val_loss: 1.1998, val_acc: 0.6100\n",
      "Epoch [25], last_lr: 0.00196, train_loss: 0.9647, val_loss: 1.1375, val_acc: 0.6380\n",
      "Epoch [26], last_lr: 0.00207, train_loss: 0.8764, val_loss: 1.0752, val_acc: 0.6340\n",
      "Epoch [27], last_lr: 0.00218, train_loss: 0.8054, val_loss: 1.0417, val_acc: 0.6560\n",
      "Epoch [28], last_lr: 0.00230, train_loss: 0.7663, val_loss: 0.9944, val_acc: 0.6680\n",
      "Epoch [29], last_lr: 0.00241, train_loss: 0.7447, val_loss: 0.9786, val_acc: 0.6760\n",
      "Epoch [30], last_lr: 0.00252, train_loss: 0.6949, val_loss: 0.9469, val_acc: 0.6880\n",
      "Epoch [31], last_lr: 0.00262, train_loss: 0.6826, val_loss: 0.9398, val_acc: 0.6840\n",
      "Epoch [32], last_lr: 0.00273, train_loss: 0.6788, val_loss: 0.9154, val_acc: 0.7000\n",
      "Epoch [33], last_lr: 0.00284, train_loss: 0.6365, val_loss: 0.9079, val_acc: 0.6740\n",
      "Epoch [34], last_lr: 0.00294, train_loss: 0.6120, val_loss: 0.8973, val_acc: 0.6940\n",
      "Epoch [35], last_lr: 0.00304, train_loss: 0.6046, val_loss: 0.8981, val_acc: 0.7000\n",
      "Epoch [36], last_lr: 0.00313, train_loss: 0.5893, val_loss: 0.8739, val_acc: 0.6960\n",
      "Epoch [37], last_lr: 0.00322, train_loss: 0.5698, val_loss: 0.8697, val_acc: 0.6980\n",
      "Epoch [38], last_lr: 0.00331, train_loss: 0.5731, val_loss: 0.8706, val_acc: 0.6980\n",
      "Epoch [39], last_lr: 0.00339, train_loss: 0.5570, val_loss: 0.8579, val_acc: 0.7000\n",
      "Epoch [40], last_lr: 0.00347, train_loss: 0.5440, val_loss: 0.8695, val_acc: 0.6960\n",
      "Epoch [41], last_lr: 0.00355, train_loss: 0.5495, val_loss: 0.8658, val_acc: 0.7080\n",
      "Epoch [42], last_lr: 0.00362, train_loss: 0.5356, val_loss: 0.8564, val_acc: 0.7000\n",
      "Epoch [43], last_lr: 0.00368, train_loss: 0.5343, val_loss: 0.8609, val_acc: 0.7040\n",
      "Epoch [44], last_lr: 0.00374, train_loss: 0.5280, val_loss: 0.8472, val_acc: 0.7040\n",
      "Epoch [45], last_lr: 0.00379, train_loss: 0.5375, val_loss: 0.8423, val_acc: 0.6980\n",
      "Epoch [46], last_lr: 0.00384, train_loss: 0.5264, val_loss: 0.8489, val_acc: 0.7000\n",
      "Epoch [47], last_lr: 0.00388, train_loss: 0.5145, val_loss: 0.8686, val_acc: 0.6960\n",
      "Epoch [48], last_lr: 0.00392, train_loss: 0.5173, val_loss: 0.8431, val_acc: 0.7060\n",
      "Epoch [49], last_lr: 0.00395, train_loss: 0.5200, val_loss: 0.8506, val_acc: 0.6980\n",
      "Epoch [50], last_lr: 0.00397, train_loss: 0.5277, val_loss: 0.8515, val_acc: 0.7060\n",
      "Epoch [51], last_lr: 0.00399, train_loss: 0.5002, val_loss: 0.8441, val_acc: 0.7140\n",
      "Epoch [52], last_lr: 0.00400, train_loss: 0.5090, val_loss: 0.8546, val_acc: 0.7100\n",
      "Epoch [53], last_lr: 0.00400, train_loss: 0.5167, val_loss: 0.8435, val_acc: 0.7140\n",
      "Epoch [54], last_lr: 0.00400, train_loss: 0.5042, val_loss: 0.8499, val_acc: 0.7100\n",
      "Epoch [55], last_lr: 0.00400, train_loss: 0.5221, val_loss: 0.8514, val_acc: 0.7120\n",
      "Epoch [56], last_lr: 0.00399, train_loss: 0.5179, val_loss: 0.8353, val_acc: 0.7120\n",
      "Epoch [57], last_lr: 0.00399, train_loss: 0.5011, val_loss: 0.8504, val_acc: 0.7080\n",
      "Epoch [58], last_lr: 0.00398, train_loss: 0.5063, val_loss: 0.8255, val_acc: 0.7160\n",
      "Epoch [59], last_lr: 0.00398, train_loss: 0.4944, val_loss: 0.8387, val_acc: 0.7100\n",
      "Epoch [60], last_lr: 0.00397, train_loss: 0.5019, val_loss: 0.8200, val_acc: 0.7080\n",
      "Epoch [61], last_lr: 0.00396, train_loss: 0.4954, val_loss: 0.8206, val_acc: 0.7200\n",
      "Epoch [62], last_lr: 0.00395, train_loss: 0.4969, val_loss: 0.8193, val_acc: 0.7080\n",
      "Epoch [63], last_lr: 0.00394, train_loss: 0.4892, val_loss: 0.8213, val_acc: 0.7160\n",
      "Epoch [64], last_lr: 0.00393, train_loss: 0.4956, val_loss: 0.8303, val_acc: 0.7100\n",
      "Epoch [65], last_lr: 0.00391, train_loss: 0.4848, val_loss: 0.8196, val_acc: 0.7240\n",
      "Epoch [66], last_lr: 0.00390, train_loss: 0.4919, val_loss: 0.8171, val_acc: 0.7220\n",
      "Epoch [67], last_lr: 0.00388, train_loss: 0.4991, val_loss: 0.8415, val_acc: 0.7060\n",
      "Epoch [68], last_lr: 0.00386, train_loss: 0.5029, val_loss: 0.8165, val_acc: 0.7180\n",
      "Epoch [69], last_lr: 0.00384, train_loss: 0.4856, val_loss: 0.8510, val_acc: 0.7060\n",
      "Epoch [70], last_lr: 0.00382, train_loss: 0.4902, val_loss: 0.8264, val_acc: 0.7180\n",
      "Epoch [71], last_lr: 0.00380, train_loss: 0.4685, val_loss: 0.8345, val_acc: 0.7040\n",
      "Epoch [72], last_lr: 0.00378, train_loss: 0.4869, val_loss: 0.8308, val_acc: 0.7100\n",
      "Epoch [73], last_lr: 0.00376, train_loss: 0.4978, val_loss: 0.8326, val_acc: 0.7060\n",
      "Epoch [74], last_lr: 0.00373, train_loss: 0.4861, val_loss: 0.8197, val_acc: 0.7240\n",
      "Epoch [75], last_lr: 0.00371, train_loss: 0.4790, val_loss: 0.8351, val_acc: 0.7100\n",
      "Epoch [76], last_lr: 0.00368, train_loss: 0.4920, val_loss: 0.8205, val_acc: 0.7220\n",
      "Epoch [77], last_lr: 0.00365, train_loss: 0.4873, val_loss: 0.8279, val_acc: 0.7220\n",
      "Epoch [78], last_lr: 0.00362, train_loss: 0.5035, val_loss: 0.8230, val_acc: 0.7240\n",
      "Epoch [79], last_lr: 0.00359, train_loss: 0.4842, val_loss: 0.8494, val_acc: 0.7120\n",
      "Epoch [80], last_lr: 0.00356, train_loss: 0.4858, val_loss: 0.8219, val_acc: 0.7140\n",
      "Epoch [81], last_lr: 0.00353, train_loss: 0.4948, val_loss: 0.8421, val_acc: 0.7200\n",
      "Epoch [82], last_lr: 0.00350, train_loss: 0.4882, val_loss: 0.8124, val_acc: 0.7300\n",
      "Epoch [83], last_lr: 0.00347, train_loss: 0.4855, val_loss: 0.8156, val_acc: 0.7240\n",
      "Epoch [84], last_lr: 0.00343, train_loss: 0.4822, val_loss: 0.8115, val_acc: 0.7260\n",
      "Epoch [85], last_lr: 0.00340, train_loss: 0.4873, val_loss: 0.8156, val_acc: 0.7220\n",
      "Epoch [86], last_lr: 0.00336, train_loss: 0.4793, val_loss: 0.8098, val_acc: 0.7220\n",
      "Epoch [87], last_lr: 0.00332, train_loss: 0.4772, val_loss: 0.8205, val_acc: 0.7100\n",
      "Epoch [88], last_lr: 0.00329, train_loss: 0.4711, val_loss: 0.8128, val_acc: 0.7240\n",
      "Epoch [89], last_lr: 0.00325, train_loss: 0.4811, val_loss: 0.8123, val_acc: 0.7140\n",
      "Epoch [90], last_lr: 0.00321, train_loss: 0.4724, val_loss: 0.8105, val_acc: 0.7260\n",
      "Epoch [91], last_lr: 0.00317, train_loss: 0.4734, val_loss: 0.8050, val_acc: 0.7240\n",
      "Epoch [92], last_lr: 0.00313, train_loss: 0.4655, val_loss: 0.8016, val_acc: 0.7220\n",
      "Epoch [93], last_lr: 0.00309, train_loss: 0.4723, val_loss: 0.8016, val_acc: 0.7300\n",
      "Epoch [94], last_lr: 0.00304, train_loss: 0.4779, val_loss: 0.7979, val_acc: 0.7340\n",
      "Epoch [95], last_lr: 0.00300, train_loss: 0.4830, val_loss: 0.8063, val_acc: 0.7300\n",
      "Epoch [96], last_lr: 0.00296, train_loss: 0.4792, val_loss: 0.8058, val_acc: 0.7300\n",
      "Epoch [97], last_lr: 0.00291, train_loss: 0.4796, val_loss: 0.8011, val_acc: 0.7320\n",
      "Epoch [98], last_lr: 0.00287, train_loss: 0.4800, val_loss: 0.8092, val_acc: 0.7260\n",
      "Epoch [99], last_lr: 0.00282, train_loss: 0.4587, val_loss: 0.7996, val_acc: 0.7300\n",
      "Epoch [100], last_lr: 0.00278, train_loss: 0.4761, val_loss: 0.8088, val_acc: 0.7260\n",
      "Epoch [101], last_lr: 0.00273, train_loss: 0.4694, val_loss: 0.8011, val_acc: 0.7300\n",
      "Epoch [102], last_lr: 0.00268, train_loss: 0.4672, val_loss: 0.8050, val_acc: 0.7240\n",
      "Epoch [103], last_lr: 0.00264, train_loss: 0.4728, val_loss: 0.8073, val_acc: 0.7220\n",
      "Epoch [104], last_lr: 0.00259, train_loss: 0.4649, val_loss: 0.8111, val_acc: 0.7180\n",
      "Epoch [105], last_lr: 0.00254, train_loss: 0.4584, val_loss: 0.8098, val_acc: 0.7260\n",
      "Epoch [106], last_lr: 0.00249, train_loss: 0.4659, val_loss: 0.8130, val_acc: 0.7220\n",
      "Epoch [107], last_lr: 0.00245, train_loss: 0.4673, val_loss: 0.8157, val_acc: 0.7280\n",
      "Epoch [108], last_lr: 0.00240, train_loss: 0.4723, val_loss: 0.8167, val_acc: 0.7200\n",
      "Epoch [109], last_lr: 0.00235, train_loss: 0.4868, val_loss: 0.8043, val_acc: 0.7340\n",
      "Epoch [110], last_lr: 0.00230, train_loss: 0.4702, val_loss: 0.8147, val_acc: 0.7220\n",
      "Epoch [111], last_lr: 0.00225, train_loss: 0.4777, val_loss: 0.7991, val_acc: 0.7400\n",
      "Epoch [112], last_lr: 0.00220, train_loss: 0.4692, val_loss: 0.8079, val_acc: 0.7180\n",
      "Epoch [113], last_lr: 0.00215, train_loss: 0.4738, val_loss: 0.8003, val_acc: 0.7400\n",
      "Epoch [114], last_lr: 0.00210, train_loss: 0.4702, val_loss: 0.8157, val_acc: 0.7180\n",
      "Epoch [115], last_lr: 0.00205, train_loss: 0.4789, val_loss: 0.8000, val_acc: 0.7360\n",
      "Epoch [116], last_lr: 0.00200, train_loss: 0.4630, val_loss: 0.8116, val_acc: 0.7200\n",
      "Epoch [117], last_lr: 0.00195, train_loss: 0.4667, val_loss: 0.8054, val_acc: 0.7280\n",
      "Epoch [118], last_lr: 0.00190, train_loss: 0.4669, val_loss: 0.8181, val_acc: 0.7240\n",
      "Epoch [119], last_lr: 0.00185, train_loss: 0.4628, val_loss: 0.8120, val_acc: 0.7200\n",
      "Epoch [120], last_lr: 0.00180, train_loss: 0.4568, val_loss: 0.8149, val_acc: 0.7220\n",
      "Epoch [121], last_lr: 0.00175, train_loss: 0.4680, val_loss: 0.8089, val_acc: 0.7180\n",
      "Epoch [122], last_lr: 0.00170, train_loss: 0.4793, val_loss: 0.8180, val_acc: 0.7160\n",
      "Epoch [123], last_lr: 0.00165, train_loss: 0.4595, val_loss: 0.8089, val_acc: 0.7220\n",
      "Epoch [124], last_lr: 0.00160, train_loss: 0.4713, val_loss: 0.8130, val_acc: 0.7180\n",
      "Epoch [125], last_lr: 0.00155, train_loss: 0.4832, val_loss: 0.8056, val_acc: 0.7200\n",
      "Epoch [126], last_lr: 0.00151, train_loss: 0.4534, val_loss: 0.8101, val_acc: 0.7220\n",
      "Epoch [127], last_lr: 0.00146, train_loss: 0.4681, val_loss: 0.8043, val_acc: 0.7200\n",
      "Epoch [128], last_lr: 0.00141, train_loss: 0.4594, val_loss: 0.8052, val_acc: 0.7360\n",
      "Epoch [129], last_lr: 0.00136, train_loss: 0.4744, val_loss: 0.8110, val_acc: 0.7200\n",
      "Epoch [130], last_lr: 0.00132, train_loss: 0.4691, val_loss: 0.8051, val_acc: 0.7280\n",
      "Epoch [131], last_lr: 0.00127, train_loss: 0.4538, val_loss: 0.8033, val_acc: 0.7360\n",
      "Epoch [132], last_lr: 0.00122, train_loss: 0.4602, val_loss: 0.8200, val_acc: 0.7060\n",
      "Epoch [133], last_lr: 0.00118, train_loss: 0.4705, val_loss: 0.8063, val_acc: 0.7260\n",
      "Epoch [134], last_lr: 0.00113, train_loss: 0.4655, val_loss: 0.8067, val_acc: 0.7420\n",
      "Epoch [135], last_lr: 0.00109, train_loss: 0.4577, val_loss: 0.8045, val_acc: 0.7220\n",
      "Epoch [136], last_lr: 0.00104, train_loss: 0.4703, val_loss: 0.8028, val_acc: 0.7320\n",
      "Epoch [137], last_lr: 0.00100, train_loss: 0.4534, val_loss: 0.8033, val_acc: 0.7440\n",
      "Epoch [138], last_lr: 0.00096, train_loss: 0.4710, val_loss: 0.8050, val_acc: 0.7260\n",
      "Epoch [139], last_lr: 0.00091, train_loss: 0.4539, val_loss: 0.8066, val_acc: 0.7240\n",
      "Epoch [140], last_lr: 0.00087, train_loss: 0.4610, val_loss: 0.8024, val_acc: 0.7300\n",
      "Epoch [141], last_lr: 0.00083, train_loss: 0.4480, val_loss: 0.8027, val_acc: 0.7260\n",
      "Epoch [142], last_lr: 0.00079, train_loss: 0.4598, val_loss: 0.8048, val_acc: 0.7340\n",
      "Epoch [143], last_lr: 0.00075, train_loss: 0.4658, val_loss: 0.8047, val_acc: 0.7280\n",
      "Epoch [144], last_lr: 0.00071, train_loss: 0.4591, val_loss: 0.8024, val_acc: 0.7280\n",
      "Epoch [145], last_lr: 0.00068, train_loss: 0.4628, val_loss: 0.8032, val_acc: 0.7220\n",
      "Epoch [146], last_lr: 0.00064, train_loss: 0.4517, val_loss: 0.8014, val_acc: 0.7340\n",
      "Epoch [147], last_lr: 0.00060, train_loss: 0.4515, val_loss: 0.8028, val_acc: 0.7380\n",
      "Epoch [148], last_lr: 0.00057, train_loss: 0.4601, val_loss: 0.8031, val_acc: 0.7340\n",
      "Epoch [149], last_lr: 0.00053, train_loss: 0.4525, val_loss: 0.8051, val_acc: 0.7320\n",
      "Epoch [150], last_lr: 0.00050, train_loss: 0.4653, val_loss: 0.8038, val_acc: 0.7320\n",
      "Epoch [151], last_lr: 0.00047, train_loss: 0.4586, val_loss: 0.8026, val_acc: 0.7380\n",
      "Epoch [152], last_lr: 0.00044, train_loss: 0.4552, val_loss: 0.8040, val_acc: 0.7320\n",
      "Epoch [153], last_lr: 0.00041, train_loss: 0.4506, val_loss: 0.8056, val_acc: 0.7280\n",
      "Epoch [154], last_lr: 0.00038, train_loss: 0.4568, val_loss: 0.8067, val_acc: 0.7280\n",
      "Epoch [155], last_lr: 0.00035, train_loss: 0.4606, val_loss: 0.8039, val_acc: 0.7340\n",
      "Epoch [156], last_lr: 0.00032, train_loss: 0.4530, val_loss: 0.8032, val_acc: 0.7260\n",
      "Epoch [157], last_lr: 0.00029, train_loss: 0.4589, val_loss: 0.8036, val_acc: 0.7260\n",
      "Epoch [158], last_lr: 0.00027, train_loss: 0.4852, val_loss: 0.8028, val_acc: 0.7320\n",
      "Epoch [159], last_lr: 0.00024, train_loss: 0.4449, val_loss: 0.8058, val_acc: 0.7320\n",
      "Epoch [160], last_lr: 0.00022, train_loss: 0.4592, val_loss: 0.8059, val_acc: 0.7320\n",
      "Epoch [161], last_lr: 0.00020, train_loss: 0.4684, val_loss: 0.8056, val_acc: 0.7320\n",
      "Epoch [162], last_lr: 0.00018, train_loss: 0.4577, val_loss: 0.8053, val_acc: 0.7320\n",
      "Epoch [163], last_lr: 0.00016, train_loss: 0.4606, val_loss: 0.8066, val_acc: 0.7300\n",
      "Epoch [164], last_lr: 0.00014, train_loss: 0.4406, val_loss: 0.8059, val_acc: 0.7300\n",
      "Epoch [165], last_lr: 0.00012, train_loss: 0.4519, val_loss: 0.8056, val_acc: 0.7320\n",
      "Epoch [166], last_lr: 0.00010, train_loss: 0.4769, val_loss: 0.8045, val_acc: 0.7320\n",
      "Epoch [167], last_lr: 0.00009, train_loss: 0.4566, val_loss: 0.8059, val_acc: 0.7320\n",
      "Epoch [168], last_lr: 0.00007, train_loss: 0.4542, val_loss: 0.8047, val_acc: 0.7300\n",
      "Epoch [169], last_lr: 0.00006, train_loss: 0.4672, val_loss: 0.8033, val_acc: 0.7320\n",
      "Epoch [170], last_lr: 0.00005, train_loss: 0.4655, val_loss: 0.8037, val_acc: 0.7320\n",
      "Epoch [171], last_lr: 0.00004, train_loss: 0.4726, val_loss: 0.8050, val_acc: 0.7300\n",
      "Epoch [172], last_lr: 0.00003, train_loss: 0.4593, val_loss: 0.8060, val_acc: 0.7300\n",
      "Epoch [173], last_lr: 0.00002, train_loss: 0.4588, val_loss: 0.8045, val_acc: 0.7320\n",
      "Epoch [174], last_lr: 0.00002, train_loss: 0.4668, val_loss: 0.8055, val_acc: 0.7300\n",
      "Epoch [175], last_lr: 0.00001, train_loss: 0.4428, val_loss: 0.8053, val_acc: 0.7340\n",
      "Epoch [176], last_lr: 0.00001, train_loss: 0.4727, val_loss: 0.8042, val_acc: 0.7300\n",
      "Epoch [177], last_lr: 0.00000, train_loss: 0.4444, val_loss: 0.8057, val_acc: 0.7300\n",
      "Epoch [178], last_lr: 0.00000, train_loss: 0.4575, val_loss: 0.8048, val_acc: 0.7320\n",
      "Epoch [179], last_lr: 0.00000, train_loss: 0.4622, val_loss: 0.8046, val_acc: 0.7320\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[{'val_loss': 7.388917922973633, 'val_acc': 0.1379999965429306}]\n",
      "Epoch [0], last_lr: 0.00016, train_loss: 6.9612, val_loss: 7.0428, val_acc: 0.1500\n",
      "Epoch [1], last_lr: 0.00017, train_loss: 6.6621, val_loss: 6.9609, val_acc: 0.1560\n",
      "Epoch [2], last_lr: 0.00019, train_loss: 6.4213, val_loss: 6.8767, val_acc: 0.1600\n",
      "Epoch [3], last_lr: 0.00021, train_loss: 6.1778, val_loss: 6.7375, val_acc: 0.1600\n",
      "Epoch [4], last_lr: 0.00024, train_loss: 5.9982, val_loss: 6.5770, val_acc: 0.1660\n",
      "Epoch [5], last_lr: 0.00027, train_loss: 5.7884, val_loss: 6.4004, val_acc: 0.1600\n",
      "Epoch [6], last_lr: 0.00031, train_loss: 5.5618, val_loss: 6.1883, val_acc: 0.1600\n",
      "Epoch [7], last_lr: 0.00036, train_loss: 5.2502, val_loss: 5.9648, val_acc: 0.1700\n",
      "Epoch [8], last_lr: 0.00041, train_loss: 5.0372, val_loss: 5.6658, val_acc: 0.1720\n",
      "Epoch [9], last_lr: 0.00047, train_loss: 4.7033, val_loss: 5.3098, val_acc: 0.1720\n",
      "Epoch [10], last_lr: 0.00053, train_loss: 4.2948, val_loss: 4.9015, val_acc: 0.1700\n",
      "Epoch [11], last_lr: 0.00060, train_loss: 3.8865, val_loss: 4.4493, val_acc: 0.1840\n",
      "Epoch [12], last_lr: 0.00068, train_loss: 3.4244, val_loss: 3.9987, val_acc: 0.1960\n",
      "Epoch [13], last_lr: 0.00075, train_loss: 3.0114, val_loss: 3.6660, val_acc: 0.2460\n",
      "Epoch [14], last_lr: 0.00084, train_loss: 2.9102, val_loss: 3.5362, val_acc: 0.2620\n",
      "Epoch [15], last_lr: 0.00092, train_loss: 2.8086, val_loss: 3.3847, val_acc: 0.2680\n",
      "Epoch [16], last_lr: 0.00102, train_loss: 2.6449, val_loss: 3.2160, val_acc: 0.2880\n",
      "Epoch [17], last_lr: 0.00111, train_loss: 2.3903, val_loss: 3.1088, val_acc: 0.3100\n",
      "Epoch [18], last_lr: 0.00121, train_loss: 2.2488, val_loss: 2.9180, val_acc: 0.3300\n",
      "Epoch [19], last_lr: 0.00131, train_loss: 2.0586, val_loss: 2.6540, val_acc: 0.3480\n",
      "Epoch [20], last_lr: 0.00141, train_loss: 1.8080, val_loss: 2.4371, val_acc: 0.3800\n",
      "Epoch [21], last_lr: 0.00152, train_loss: 1.6241, val_loss: 2.2571, val_acc: 0.4140\n",
      "Epoch [22], last_lr: 0.00163, train_loss: 1.4654, val_loss: 2.0626, val_acc: 0.4600\n",
      "Epoch [23], last_lr: 0.00174, train_loss: 1.2745, val_loss: 1.8629, val_acc: 0.4900\n",
      "Epoch [24], last_lr: 0.00185, train_loss: 1.0977, val_loss: 1.6960, val_acc: 0.5140\n",
      "Epoch [25], last_lr: 0.00196, train_loss: 1.0072, val_loss: 1.5616, val_acc: 0.5540\n",
      "Epoch [26], last_lr: 0.00207, train_loss: 0.8729, val_loss: 1.4302, val_acc: 0.5980\n",
      "Epoch [27], last_lr: 0.00218, train_loss: 0.7560, val_loss: 1.3370, val_acc: 0.6220\n",
      "Epoch [28], last_lr: 0.00230, train_loss: 0.7471, val_loss: 1.2571, val_acc: 0.6440\n",
      "Epoch [29], last_lr: 0.00241, train_loss: 0.6621, val_loss: 1.1811, val_acc: 0.6600\n",
      "Epoch [30], last_lr: 0.00252, train_loss: 0.5999, val_loss: 1.1282, val_acc: 0.6740\n",
      "Epoch [31], last_lr: 0.00262, train_loss: 0.5751, val_loss: 1.0779, val_acc: 0.6920\n",
      "Epoch [32], last_lr: 0.00273, train_loss: 0.5437, val_loss: 1.0658, val_acc: 0.6800\n",
      "Epoch [33], last_lr: 0.00284, train_loss: 0.5107, val_loss: 1.0119, val_acc: 0.7000\n",
      "Epoch [34], last_lr: 0.00294, train_loss: 0.5033, val_loss: 1.0129, val_acc: 0.6860\n",
      "Epoch [35], last_lr: 0.00304, train_loss: 0.4715, val_loss: 0.9716, val_acc: 0.6980\n",
      "Epoch [36], last_lr: 0.00313, train_loss: 0.4779, val_loss: 0.9693, val_acc: 0.7000\n",
      "Epoch [37], last_lr: 0.00322, train_loss: 0.4454, val_loss: 0.9551, val_acc: 0.7160\n",
      "Epoch [38], last_lr: 0.00331, train_loss: 0.4231, val_loss: 0.9361, val_acc: 0.7080\n",
      "Epoch [39], last_lr: 0.00339, train_loss: 0.4589, val_loss: 0.9380, val_acc: 0.7160\n",
      "Epoch [40], last_lr: 0.00347, train_loss: 0.4111, val_loss: 0.9194, val_acc: 0.7080\n",
      "Epoch [41], last_lr: 0.00355, train_loss: 0.4260, val_loss: 0.9190, val_acc: 0.7080\n",
      "Epoch [42], last_lr: 0.00362, train_loss: 0.4042, val_loss: 0.9307, val_acc: 0.7080\n",
      "Epoch [43], last_lr: 0.00368, train_loss: 0.4126, val_loss: 0.8980, val_acc: 0.7220\n",
      "Epoch [44], last_lr: 0.00374, train_loss: 0.3989, val_loss: 0.9293, val_acc: 0.7020\n",
      "Epoch [45], last_lr: 0.00379, train_loss: 0.4215, val_loss: 0.9103, val_acc: 0.7100\n",
      "Epoch [46], last_lr: 0.00384, train_loss: 0.3770, val_loss: 0.8899, val_acc: 0.7180\n",
      "Epoch [47], last_lr: 0.00388, train_loss: 0.4088, val_loss: 0.8902, val_acc: 0.7240\n",
      "Epoch [48], last_lr: 0.00392, train_loss: 0.3875, val_loss: 0.8837, val_acc: 0.7260\n",
      "Epoch [49], last_lr: 0.00395, train_loss: 0.3977, val_loss: 0.8976, val_acc: 0.7220\n",
      "Epoch [50], last_lr: 0.00397, train_loss: 0.3779, val_loss: 0.8988, val_acc: 0.7220\n",
      "Epoch [51], last_lr: 0.00399, train_loss: 0.3620, val_loss: 0.9114, val_acc: 0.7220\n",
      "Epoch [52], last_lr: 0.00400, train_loss: 0.3708, val_loss: 0.8885, val_acc: 0.7300\n",
      "Epoch [53], last_lr: 0.00400, train_loss: 0.3675, val_loss: 0.8844, val_acc: 0.7140\n",
      "Epoch [54], last_lr: 0.00400, train_loss: 0.3692, val_loss: 0.9040, val_acc: 0.7140\n",
      "Epoch [55], last_lr: 0.00400, train_loss: 0.3837, val_loss: 0.8799, val_acc: 0.7240\n",
      "Epoch [56], last_lr: 0.00399, train_loss: 0.3648, val_loss: 0.9169, val_acc: 0.7200\n",
      "Epoch [57], last_lr: 0.00399, train_loss: 0.3822, val_loss: 0.8665, val_acc: 0.7220\n",
      "Epoch [58], last_lr: 0.00398, train_loss: 0.3508, val_loss: 0.9066, val_acc: 0.7180\n",
      "Epoch [59], last_lr: 0.00398, train_loss: 0.3732, val_loss: 0.9062, val_acc: 0.7180\n",
      "Epoch [60], last_lr: 0.00397, train_loss: 0.3492, val_loss: 0.8963, val_acc: 0.7140\n",
      "Epoch [61], last_lr: 0.00396, train_loss: 0.3557, val_loss: 0.9057, val_acc: 0.7240\n",
      "Epoch [62], last_lr: 0.00395, train_loss: 0.3735, val_loss: 0.8923, val_acc: 0.7160\n",
      "Epoch [63], last_lr: 0.00394, train_loss: 0.3657, val_loss: 0.8960, val_acc: 0.7140\n",
      "Epoch [64], last_lr: 0.00393, train_loss: 0.3540, val_loss: 0.8688, val_acc: 0.7340\n",
      "Epoch [65], last_lr: 0.00391, train_loss: 0.3610, val_loss: 0.8962, val_acc: 0.7160\n",
      "Epoch [66], last_lr: 0.00390, train_loss: 0.3510, val_loss: 0.9091, val_acc: 0.7260\n",
      "Epoch [67], last_lr: 0.00388, train_loss: 0.3573, val_loss: 0.8855, val_acc: 0.7280\n",
      "Epoch [68], last_lr: 0.00386, train_loss: 0.3429, val_loss: 0.9003, val_acc: 0.7240\n",
      "Epoch [69], last_lr: 0.00384, train_loss: 0.3485, val_loss: 0.8752, val_acc: 0.7260\n",
      "Epoch [70], last_lr: 0.00382, train_loss: 0.3557, val_loss: 0.9128, val_acc: 0.7080\n",
      "Epoch [71], last_lr: 0.00380, train_loss: 0.3393, val_loss: 0.8820, val_acc: 0.7240\n",
      "Epoch [72], last_lr: 0.00378, train_loss: 0.3490, val_loss: 0.8924, val_acc: 0.7140\n",
      "Epoch [73], last_lr: 0.00376, train_loss: 0.3360, val_loss: 0.9176, val_acc: 0.7180\n",
      "Epoch [74], last_lr: 0.00373, train_loss: 0.3693, val_loss: 0.8708, val_acc: 0.7180\n",
      "Epoch [75], last_lr: 0.00371, train_loss: 0.3382, val_loss: 0.9070, val_acc: 0.7200\n",
      "Epoch [76], last_lr: 0.00368, train_loss: 0.3541, val_loss: 0.8837, val_acc: 0.7160\n",
      "Epoch [77], last_lr: 0.00365, train_loss: 0.3374, val_loss: 0.8977, val_acc: 0.7240\n",
      "Epoch [78], last_lr: 0.00362, train_loss: 0.3740, val_loss: 0.8674, val_acc: 0.7260\n",
      "Epoch [79], last_lr: 0.00359, train_loss: 0.3310, val_loss: 0.8819, val_acc: 0.7240\n",
      "Epoch [80], last_lr: 0.00356, train_loss: 0.3365, val_loss: 0.8867, val_acc: 0.7300\n",
      "Epoch [81], last_lr: 0.00353, train_loss: 0.3390, val_loss: 0.8865, val_acc: 0.7280\n",
      "Epoch [82], last_lr: 0.00350, train_loss: 0.3436, val_loss: 0.8689, val_acc: 0.7340\n",
      "Epoch [83], last_lr: 0.00347, train_loss: 0.3428, val_loss: 0.9406, val_acc: 0.7160\n",
      "Epoch [84], last_lr: 0.00343, train_loss: 0.3435, val_loss: 0.8797, val_acc: 0.7200\n",
      "Epoch [85], last_lr: 0.00340, train_loss: 0.3536, val_loss: 0.8908, val_acc: 0.7320\n",
      "Epoch [86], last_lr: 0.00336, train_loss: 0.3498, val_loss: 0.8946, val_acc: 0.7060\n",
      "Epoch [87], last_lr: 0.00332, train_loss: 0.3249, val_loss: 0.9105, val_acc: 0.7160\n",
      "Epoch [88], last_lr: 0.00329, train_loss: 0.3281, val_loss: 0.8734, val_acc: 0.7140\n",
      "Epoch [89], last_lr: 0.00325, train_loss: 0.3481, val_loss: 0.9009, val_acc: 0.7180\n",
      "Epoch [90], last_lr: 0.00321, train_loss: 0.3320, val_loss: 0.8786, val_acc: 0.7200\n",
      "Epoch [91], last_lr: 0.00317, train_loss: 0.3456, val_loss: 0.8850, val_acc: 0.7260\n",
      "Epoch [92], last_lr: 0.00313, train_loss: 0.3379, val_loss: 0.8789, val_acc: 0.7220\n",
      "Epoch [93], last_lr: 0.00309, train_loss: 0.3566, val_loss: 0.8704, val_acc: 0.7220\n",
      "Epoch [94], last_lr: 0.00304, train_loss: 0.3297, val_loss: 0.8862, val_acc: 0.7120\n",
      "Epoch [95], last_lr: 0.00300, train_loss: 0.3395, val_loss: 0.8922, val_acc: 0.7260\n",
      "Epoch [96], last_lr: 0.00296, train_loss: 0.3368, val_loss: 0.8877, val_acc: 0.7160\n",
      "Epoch [97], last_lr: 0.00291, train_loss: 0.3538, val_loss: 0.9042, val_acc: 0.7180\n",
      "Epoch [98], last_lr: 0.00287, train_loss: 0.3637, val_loss: 0.8668, val_acc: 0.7200\n",
      "Epoch [99], last_lr: 0.00282, train_loss: 0.3427, val_loss: 0.8973, val_acc: 0.7120\n",
      "Epoch [100], last_lr: 0.00278, train_loss: 0.3337, val_loss: 0.8665, val_acc: 0.7180\n",
      "Epoch [101], last_lr: 0.00273, train_loss: 0.3325, val_loss: 0.8944, val_acc: 0.7100\n",
      "Epoch [102], last_lr: 0.00268, train_loss: 0.3401, val_loss: 0.8611, val_acc: 0.7220\n",
      "Epoch [103], last_lr: 0.00264, train_loss: 0.3579, val_loss: 0.8826, val_acc: 0.7180\n",
      "Epoch [104], last_lr: 0.00259, train_loss: 0.3390, val_loss: 0.8678, val_acc: 0.7300\n",
      "Epoch [105], last_lr: 0.00254, train_loss: 0.3324, val_loss: 0.8891, val_acc: 0.7160\n",
      "Epoch [106], last_lr: 0.00249, train_loss: 0.3419, val_loss: 0.8726, val_acc: 0.7300\n",
      "Epoch [107], last_lr: 0.00245, train_loss: 0.3330, val_loss: 0.8928, val_acc: 0.7260\n",
      "Epoch [108], last_lr: 0.00240, train_loss: 0.3327, val_loss: 0.8803, val_acc: 0.7260\n",
      "Epoch [109], last_lr: 0.00235, train_loss: 0.3234, val_loss: 0.8785, val_acc: 0.7240\n",
      "Epoch [110], last_lr: 0.00230, train_loss: 0.3282, val_loss: 0.8810, val_acc: 0.7280\n",
      "Epoch [111], last_lr: 0.00225, train_loss: 0.3370, val_loss: 0.8790, val_acc: 0.7260\n",
      "Epoch [112], last_lr: 0.00220, train_loss: 0.3251, val_loss: 0.8625, val_acc: 0.7320\n",
      "Epoch [113], last_lr: 0.00215, train_loss: 0.3167, val_loss: 0.8733, val_acc: 0.7300\n",
      "Epoch [114], last_lr: 0.00210, train_loss: 0.3230, val_loss: 0.8882, val_acc: 0.7180\n",
      "Epoch [115], last_lr: 0.00205, train_loss: 0.3261, val_loss: 0.8814, val_acc: 0.7260\n",
      "Epoch [116], last_lr: 0.00200, train_loss: 0.3270, val_loss: 0.8821, val_acc: 0.7180\n",
      "Epoch [117], last_lr: 0.00195, train_loss: 0.3292, val_loss: 0.8761, val_acc: 0.7160\n",
      "Epoch [118], last_lr: 0.00190, train_loss: 0.3148, val_loss: 0.8626, val_acc: 0.7300\n",
      "Epoch [119], last_lr: 0.00185, train_loss: 0.3340, val_loss: 0.8828, val_acc: 0.7220\n",
      "Epoch [120], last_lr: 0.00180, train_loss: 0.3191, val_loss: 0.8558, val_acc: 0.7240\n",
      "Epoch [121], last_lr: 0.00175, train_loss: 0.3161, val_loss: 0.8674, val_acc: 0.7220\n",
      "Epoch [122], last_lr: 0.00170, train_loss: 0.3328, val_loss: 0.8928, val_acc: 0.7200\n",
      "Epoch [123], last_lr: 0.00165, train_loss: 0.3083, val_loss: 0.8672, val_acc: 0.7260\n",
      "Epoch [124], last_lr: 0.00160, train_loss: 0.3311, val_loss: 0.8854, val_acc: 0.7240\n",
      "Epoch [125], last_lr: 0.00155, train_loss: 0.3312, val_loss: 0.8678, val_acc: 0.7300\n",
      "Epoch [126], last_lr: 0.00151, train_loss: 0.3249, val_loss: 0.8698, val_acc: 0.7240\n",
      "Epoch [127], last_lr: 0.00146, train_loss: 0.3403, val_loss: 0.8909, val_acc: 0.7200\n",
      "Epoch [128], last_lr: 0.00141, train_loss: 0.3307, val_loss: 0.8778, val_acc: 0.7220\n",
      "Epoch [129], last_lr: 0.00136, train_loss: 0.3179, val_loss: 0.8709, val_acc: 0.7280\n",
      "Epoch [130], last_lr: 0.00132, train_loss: 0.3132, val_loss: 0.8766, val_acc: 0.7260\n",
      "Epoch [131], last_lr: 0.00127, train_loss: 0.3257, val_loss: 0.8731, val_acc: 0.7340\n",
      "Epoch [132], last_lr: 0.00122, train_loss: 0.3175, val_loss: 0.8771, val_acc: 0.7280\n",
      "Epoch [133], last_lr: 0.00118, train_loss: 0.3225, val_loss: 0.8829, val_acc: 0.7240\n",
      "Epoch [134], last_lr: 0.00113, train_loss: 0.3210, val_loss: 0.8893, val_acc: 0.7220\n",
      "Epoch [135], last_lr: 0.00109, train_loss: 0.3175, val_loss: 0.8803, val_acc: 0.7260\n",
      "Epoch [136], last_lr: 0.00104, train_loss: 0.3212, val_loss: 0.8783, val_acc: 0.7260\n",
      "Epoch [137], last_lr: 0.00100, train_loss: 0.3417, val_loss: 0.8866, val_acc: 0.7220\n",
      "Epoch [138], last_lr: 0.00096, train_loss: 0.3088, val_loss: 0.8920, val_acc: 0.7220\n",
      "Epoch [139], last_lr: 0.00091, train_loss: 0.3287, val_loss: 0.8923, val_acc: 0.7240\n",
      "Epoch [140], last_lr: 0.00087, train_loss: 0.3328, val_loss: 0.8838, val_acc: 0.7300\n",
      "Epoch [141], last_lr: 0.00083, train_loss: 0.3273, val_loss: 0.8882, val_acc: 0.7200\n",
      "Epoch [142], last_lr: 0.00079, train_loss: 0.3206, val_loss: 0.8924, val_acc: 0.7220\n",
      "Epoch [143], last_lr: 0.00075, train_loss: 0.3110, val_loss: 0.8948, val_acc: 0.7260\n",
      "Epoch [144], last_lr: 0.00071, train_loss: 0.3280, val_loss: 0.8886, val_acc: 0.7260\n",
      "Epoch [145], last_lr: 0.00068, train_loss: 0.3133, val_loss: 0.8934, val_acc: 0.7200\n",
      "Epoch [146], last_lr: 0.00064, train_loss: 0.3303, val_loss: 0.8882, val_acc: 0.7220\n",
      "Epoch [147], last_lr: 0.00060, train_loss: 0.3339, val_loss: 0.8909, val_acc: 0.7260\n",
      "Epoch [148], last_lr: 0.00057, train_loss: 0.3306, val_loss: 0.9009, val_acc: 0.7200\n",
      "Epoch [149], last_lr: 0.00053, train_loss: 0.3174, val_loss: 0.9037, val_acc: 0.7200\n",
      "Epoch [150], last_lr: 0.00050, train_loss: 0.3140, val_loss: 0.8987, val_acc: 0.7260\n",
      "Epoch [151], last_lr: 0.00047, train_loss: 0.3283, val_loss: 0.8913, val_acc: 0.7220\n",
      "Epoch [152], last_lr: 0.00044, train_loss: 0.3213, val_loss: 0.8933, val_acc: 0.7220\n",
      "Epoch [153], last_lr: 0.00041, train_loss: 0.3284, val_loss: 0.8974, val_acc: 0.7240\n",
      "Epoch [154], last_lr: 0.00038, train_loss: 0.3383, val_loss: 0.8982, val_acc: 0.7220\n",
      "Epoch [155], last_lr: 0.00035, train_loss: 0.3062, val_loss: 0.8947, val_acc: 0.7280\n",
      "Epoch [156], last_lr: 0.00032, train_loss: 0.3438, val_loss: 0.8916, val_acc: 0.7280\n",
      "Epoch [157], last_lr: 0.00029, train_loss: 0.3200, val_loss: 0.8895, val_acc: 0.7220\n",
      "Epoch [158], last_lr: 0.00027, train_loss: 0.3177, val_loss: 0.8877, val_acc: 0.7240\n",
      "Epoch [159], last_lr: 0.00024, train_loss: 0.3281, val_loss: 0.8876, val_acc: 0.7240\n",
      "Epoch [160], last_lr: 0.00022, train_loss: 0.3313, val_loss: 0.8911, val_acc: 0.7260\n",
      "Epoch [161], last_lr: 0.00020, train_loss: 0.3267, val_loss: 0.8919, val_acc: 0.7220\n",
      "Epoch [162], last_lr: 0.00018, train_loss: 0.3299, val_loss: 0.8920, val_acc: 0.7240\n",
      "Epoch [163], last_lr: 0.00016, train_loss: 0.3373, val_loss: 0.8937, val_acc: 0.7220\n",
      "Epoch [164], last_lr: 0.00014, train_loss: 0.3158, val_loss: 0.8917, val_acc: 0.7220\n",
      "Epoch [165], last_lr: 0.00012, train_loss: 0.3223, val_loss: 0.8931, val_acc: 0.7240\n",
      "Epoch [166], last_lr: 0.00010, train_loss: 0.3379, val_loss: 0.8932, val_acc: 0.7240\n",
      "Epoch [167], last_lr: 0.00009, train_loss: 0.3256, val_loss: 0.8947, val_acc: 0.7260\n",
      "Epoch [168], last_lr: 0.00007, train_loss: 0.3182, val_loss: 0.8920, val_acc: 0.7260\n",
      "Epoch [169], last_lr: 0.00006, train_loss: 0.3292, val_loss: 0.8925, val_acc: 0.7260\n",
      "Epoch [170], last_lr: 0.00005, train_loss: 0.3301, val_loss: 0.8941, val_acc: 0.7240\n",
      "Epoch [171], last_lr: 0.00004, train_loss: 0.3201, val_loss: 0.8944, val_acc: 0.7260\n",
      "Epoch [172], last_lr: 0.00003, train_loss: 0.3085, val_loss: 0.8950, val_acc: 0.7260\n",
      "Epoch [173], last_lr: 0.00002, train_loss: 0.3269, val_loss: 0.8944, val_acc: 0.7280\n",
      "Epoch [174], last_lr: 0.00002, train_loss: 0.3165, val_loss: 0.8934, val_acc: 0.7240\n",
      "Epoch [175], last_lr: 0.00001, train_loss: 0.3310, val_loss: 0.8942, val_acc: 0.7260\n",
      "Epoch [176], last_lr: 0.00001, train_loss: 0.3095, val_loss: 0.8970, val_acc: 0.7260\n",
      "Epoch [177], last_lr: 0.00000, train_loss: 0.3302, val_loss: 0.8956, val_acc: 0.7220\n",
      "Epoch [178], last_lr: 0.00000, train_loss: 0.3315, val_loss: 0.8941, val_acc: 0.7240\n",
      "Epoch [179], last_lr: 0.00000, train_loss: 0.3316, val_loss: 0.8933, val_acc: 0.7220\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[{'val_loss': 18.885231018066406, 'val_acc': 0.20000000298023224}]\n",
      "Epoch [0], last_lr: 0.00016, train_loss: 14.3784, val_loss: 16.2944, val_acc: 0.1960\n",
      "Epoch [1], last_lr: 0.00017, train_loss: 13.9061, val_loss: 14.6669, val_acc: 0.1940\n",
      "Epoch [2], last_lr: 0.00019, train_loss: 13.3870, val_loss: 13.6164, val_acc: 0.1880\n",
      "Epoch [3], last_lr: 0.00021, train_loss: 12.8498, val_loss: 12.8298, val_acc: 0.1860\n",
      "Epoch [4], last_lr: 0.00024, train_loss: 12.2909, val_loss: 12.0875, val_acc: 0.1800\n",
      "Epoch [5], last_lr: 0.00027, train_loss: 11.6150, val_loss: 11.3474, val_acc: 0.1760\n",
      "Epoch [6], last_lr: 0.00031, train_loss: 10.9406, val_loss: 10.5193, val_acc: 0.1780\n",
      "Epoch [7], last_lr: 0.00036, train_loss: 10.1077, val_loss: 9.6792, val_acc: 0.1760\n",
      "Epoch [8], last_lr: 0.00041, train_loss: 9.3751, val_loss: 8.7682, val_acc: 0.1780\n",
      "Epoch [9], last_lr: 0.00047, train_loss: 8.5382, val_loss: 7.8022, val_acc: 0.1860\n",
      "Epoch [10], last_lr: 0.00053, train_loss: 7.5179, val_loss: 6.7411, val_acc: 0.1980\n",
      "Epoch [11], last_lr: 0.00060, train_loss: 6.4681, val_loss: 5.6257, val_acc: 0.2040\n",
      "Epoch [12], last_lr: 0.00068, train_loss: 5.4284, val_loss: 4.7381, val_acc: 0.2180\n",
      "Epoch [13], last_lr: 0.00075, train_loss: 4.7246, val_loss: 4.3070, val_acc: 0.2160\n",
      "Epoch [14], last_lr: 0.00084, train_loss: 4.4113, val_loss: 4.2793, val_acc: 0.1840\n",
      "Epoch [15], last_lr: 0.00092, train_loss: 4.3785, val_loss: 4.3037, val_acc: 0.1820\n",
      "Epoch [16], last_lr: 0.00102, train_loss: 4.2595, val_loss: 4.1101, val_acc: 0.1860\n",
      "Epoch [17], last_lr: 0.00111, train_loss: 4.1151, val_loss: 3.9008, val_acc: 0.2060\n",
      "Epoch [18], last_lr: 0.00121, train_loss: 4.0081, val_loss: 3.7747, val_acc: 0.2080\n",
      "Epoch [19], last_lr: 0.00131, train_loss: 3.8313, val_loss: 3.5986, val_acc: 0.1960\n",
      "Epoch [20], last_lr: 0.00141, train_loss: 3.6132, val_loss: 3.4302, val_acc: 0.2080\n",
      "Epoch [21], last_lr: 0.00152, train_loss: 3.3637, val_loss: 3.1503, val_acc: 0.2360\n",
      "Epoch [22], last_lr: 0.00163, train_loss: 3.0916, val_loss: 2.8700, val_acc: 0.2280\n",
      "Epoch [23], last_lr: 0.00174, train_loss: 2.8123, val_loss: 2.6024, val_acc: 0.2540\n",
      "Epoch [24], last_lr: 0.00185, train_loss: 2.5216, val_loss: 2.3264, val_acc: 0.2860\n",
      "Epoch [25], last_lr: 0.00196, train_loss: 2.2429, val_loss: 2.0693, val_acc: 0.3200\n",
      "Epoch [26], last_lr: 0.00207, train_loss: 1.9696, val_loss: 1.8407, val_acc: 0.3640\n",
      "Epoch [27], last_lr: 0.00218, train_loss: 1.6806, val_loss: 1.6332, val_acc: 0.4240\n",
      "Epoch [28], last_lr: 0.00230, train_loss: 1.4753, val_loss: 1.4756, val_acc: 0.4720\n",
      "Epoch [29], last_lr: 0.00241, train_loss: 1.3073, val_loss: 1.3371, val_acc: 0.5080\n",
      "Epoch [30], last_lr: 0.00252, train_loss: 1.1580, val_loss: 1.2606, val_acc: 0.5400\n",
      "Epoch [31], last_lr: 0.00262, train_loss: 1.0512, val_loss: 1.1823, val_acc: 0.5680\n",
      "Epoch [32], last_lr: 0.00273, train_loss: 0.9916, val_loss: 1.1420, val_acc: 0.5800\n",
      "Epoch [33], last_lr: 0.00284, train_loss: 0.8913, val_loss: 1.1153, val_acc: 0.5880\n",
      "Epoch [34], last_lr: 0.00294, train_loss: 0.8909, val_loss: 1.0768, val_acc: 0.5860\n",
      "Epoch [35], last_lr: 0.00304, train_loss: 0.8417, val_loss: 1.0617, val_acc: 0.6120\n",
      "Epoch [36], last_lr: 0.00313, train_loss: 0.8140, val_loss: 1.0599, val_acc: 0.6220\n",
      "Epoch [37], last_lr: 0.00322, train_loss: 0.7903, val_loss: 1.0568, val_acc: 0.6180\n",
      "Epoch [38], last_lr: 0.00331, train_loss: 0.7742, val_loss: 1.0432, val_acc: 0.6220\n",
      "Epoch [39], last_lr: 0.00339, train_loss: 0.7732, val_loss: 1.0335, val_acc: 0.6460\n",
      "Epoch [40], last_lr: 0.00347, train_loss: 0.7519, val_loss: 1.0318, val_acc: 0.6400\n",
      "Epoch [41], last_lr: 0.00355, train_loss: 0.7323, val_loss: 1.0492, val_acc: 0.6240\n",
      "Epoch [42], last_lr: 0.00362, train_loss: 0.7224, val_loss: 1.0354, val_acc: 0.6320\n",
      "Epoch [43], last_lr: 0.00368, train_loss: 0.7383, val_loss: 1.0226, val_acc: 0.6420\n",
      "Epoch [44], last_lr: 0.00374, train_loss: 0.7148, val_loss: 1.0281, val_acc: 0.6400\n",
      "Epoch [45], last_lr: 0.00379, train_loss: 0.7171, val_loss: 1.0151, val_acc: 0.6340\n",
      "Epoch [46], last_lr: 0.00384, train_loss: 0.7133, val_loss: 1.0320, val_acc: 0.6260\n",
      "Epoch [47], last_lr: 0.00388, train_loss: 0.6931, val_loss: 1.0456, val_acc: 0.6340\n",
      "Epoch [48], last_lr: 0.00392, train_loss: 0.6925, val_loss: 1.0038, val_acc: 0.6480\n",
      "Epoch [49], last_lr: 0.00395, train_loss: 0.6738, val_loss: 1.0099, val_acc: 0.6500\n",
      "Epoch [50], last_lr: 0.00397, train_loss: 0.6948, val_loss: 1.0079, val_acc: 0.6340\n",
      "Epoch [51], last_lr: 0.00399, train_loss: 0.6929, val_loss: 1.0176, val_acc: 0.6420\n",
      "Epoch [52], last_lr: 0.00400, train_loss: 0.6769, val_loss: 1.0287, val_acc: 0.6420\n",
      "Epoch [53], last_lr: 0.00400, train_loss: 0.6831, val_loss: 0.9971, val_acc: 0.6620\n",
      "Epoch [54], last_lr: 0.00400, train_loss: 0.6699, val_loss: 0.9938, val_acc: 0.6500\n",
      "Epoch [55], last_lr: 0.00400, train_loss: 0.6836, val_loss: 1.0016, val_acc: 0.6440\n",
      "Epoch [56], last_lr: 0.00399, train_loss: 0.6715, val_loss: 1.0037, val_acc: 0.6440\n",
      "Epoch [57], last_lr: 0.00399, train_loss: 0.6752, val_loss: 1.0180, val_acc: 0.6380\n",
      "Epoch [58], last_lr: 0.00398, train_loss: 0.6815, val_loss: 1.0143, val_acc: 0.6380\n",
      "Epoch [59], last_lr: 0.00398, train_loss: 0.6745, val_loss: 1.0356, val_acc: 0.6420\n",
      "Epoch [60], last_lr: 0.00397, train_loss: 0.6721, val_loss: 1.0090, val_acc: 0.6420\n",
      "Epoch [61], last_lr: 0.00396, train_loss: 0.6560, val_loss: 1.0026, val_acc: 0.6540\n",
      "Epoch [62], last_lr: 0.00395, train_loss: 0.6461, val_loss: 1.0075, val_acc: 0.6520\n",
      "Epoch [63], last_lr: 0.00394, train_loss: 0.6420, val_loss: 1.0434, val_acc: 0.6300\n",
      "Epoch [64], last_lr: 0.00393, train_loss: 0.6931, val_loss: 1.0014, val_acc: 0.6440\n",
      "Epoch [65], last_lr: 0.00391, train_loss: 0.6644, val_loss: 1.0011, val_acc: 0.6580\n",
      "Epoch [66], last_lr: 0.00390, train_loss: 0.6633, val_loss: 1.0209, val_acc: 0.6360\n",
      "Epoch [67], last_lr: 0.00388, train_loss: 0.6596, val_loss: 1.0189, val_acc: 0.6440\n",
      "Epoch [68], last_lr: 0.00386, train_loss: 0.6433, val_loss: 1.0180, val_acc: 0.6500\n",
      "Epoch [69], last_lr: 0.00384, train_loss: 0.6393, val_loss: 1.0255, val_acc: 0.6500\n",
      "Epoch [70], last_lr: 0.00382, train_loss: 0.6444, val_loss: 1.0249, val_acc: 0.6560\n",
      "Epoch [71], last_lr: 0.00380, train_loss: 0.6433, val_loss: 1.0150, val_acc: 0.6460\n",
      "Epoch [72], last_lr: 0.00378, train_loss: 0.6294, val_loss: 1.0187, val_acc: 0.6480\n",
      "Epoch [73], last_lr: 0.00376, train_loss: 0.6408, val_loss: 1.0117, val_acc: 0.6460\n",
      "Epoch [74], last_lr: 0.00373, train_loss: 0.6231, val_loss: 1.0206, val_acc: 0.6580\n",
      "Epoch [75], last_lr: 0.00371, train_loss: 0.6404, val_loss: 1.0164, val_acc: 0.6480\n",
      "Epoch [76], last_lr: 0.00368, train_loss: 0.6384, val_loss: 1.0168, val_acc: 0.6500\n",
      "Epoch [77], last_lr: 0.00365, train_loss: 0.6271, val_loss: 1.0266, val_acc: 0.6520\n",
      "Epoch [78], last_lr: 0.00362, train_loss: 0.6444, val_loss: 1.0221, val_acc: 0.6700\n",
      "Epoch [79], last_lr: 0.00359, train_loss: 0.6293, val_loss: 1.0236, val_acc: 0.6560\n",
      "Epoch [80], last_lr: 0.00356, train_loss: 0.6413, val_loss: 1.0113, val_acc: 0.6540\n",
      "Epoch [81], last_lr: 0.00353, train_loss: 0.6313, val_loss: 1.0259, val_acc: 0.6580\n",
      "Epoch [82], last_lr: 0.00350, train_loss: 0.6294, val_loss: 1.0250, val_acc: 0.6480\n",
      "Epoch [83], last_lr: 0.00347, train_loss: 0.6309, val_loss: 1.0420, val_acc: 0.6520\n",
      "Epoch [84], last_lr: 0.00343, train_loss: 0.6202, val_loss: 1.0330, val_acc: 0.6460\n",
      "Epoch [85], last_lr: 0.00340, train_loss: 0.6145, val_loss: 1.0307, val_acc: 0.6600\n",
      "Epoch [86], last_lr: 0.00336, train_loss: 0.6184, val_loss: 1.0449, val_acc: 0.6500\n",
      "Epoch [87], last_lr: 0.00332, train_loss: 0.6444, val_loss: 1.0435, val_acc: 0.6420\n",
      "Epoch [88], last_lr: 0.00329, train_loss: 0.6097, val_loss: 1.0334, val_acc: 0.6640\n",
      "Epoch [89], last_lr: 0.00325, train_loss: 0.6437, val_loss: 1.0387, val_acc: 0.6600\n",
      "Epoch [90], last_lr: 0.00321, train_loss: 0.6109, val_loss: 1.0377, val_acc: 0.6540\n",
      "Epoch [91], last_lr: 0.00317, train_loss: 0.6352, val_loss: 1.0343, val_acc: 0.6440\n",
      "Epoch [92], last_lr: 0.00313, train_loss: 0.6063, val_loss: 1.0290, val_acc: 0.6500\n",
      "Epoch [93], last_lr: 0.00309, train_loss: 0.6087, val_loss: 1.0342, val_acc: 0.6480\n",
      "Epoch [94], last_lr: 0.00304, train_loss: 0.6127, val_loss: 1.0164, val_acc: 0.6660\n",
      "Epoch [95], last_lr: 0.00300, train_loss: 0.6047, val_loss: 1.0155, val_acc: 0.6660\n",
      "Epoch [96], last_lr: 0.00296, train_loss: 0.5817, val_loss: 1.0238, val_acc: 0.6560\n",
      "Epoch [97], last_lr: 0.00291, train_loss: 0.6228, val_loss: 1.0231, val_acc: 0.6500\n",
      "Epoch [98], last_lr: 0.00287, train_loss: 0.6373, val_loss: 1.0289, val_acc: 0.6520\n",
      "Epoch [99], last_lr: 0.00282, train_loss: 0.6229, val_loss: 1.0317, val_acc: 0.6480\n",
      "Epoch [100], last_lr: 0.00278, train_loss: 0.6148, val_loss: 1.0303, val_acc: 0.6520\n",
      "Epoch [101], last_lr: 0.00273, train_loss: 0.6186, val_loss: 1.0326, val_acc: 0.6520\n",
      "Epoch [102], last_lr: 0.00268, train_loss: 0.6319, val_loss: 1.0350, val_acc: 0.6480\n",
      "Epoch [103], last_lr: 0.00264, train_loss: 0.6200, val_loss: 1.0361, val_acc: 0.6560\n",
      "Epoch [104], last_lr: 0.00259, train_loss: 0.6258, val_loss: 1.0258, val_acc: 0.6580\n",
      "Epoch [105], last_lr: 0.00254, train_loss: 0.6064, val_loss: 1.0265, val_acc: 0.6620\n",
      "Epoch [106], last_lr: 0.00249, train_loss: 0.6144, val_loss: 1.0310, val_acc: 0.6520\n",
      "Epoch [107], last_lr: 0.00245, train_loss: 0.6090, val_loss: 1.0225, val_acc: 0.6620\n",
      "Epoch [108], last_lr: 0.00240, train_loss: 0.6033, val_loss: 1.0359, val_acc: 0.6520\n",
      "Epoch [109], last_lr: 0.00235, train_loss: 0.6257, val_loss: 1.0257, val_acc: 0.6520\n",
      "Epoch [110], last_lr: 0.00230, train_loss: 0.6135, val_loss: 1.0277, val_acc: 0.6560\n",
      "Epoch [111], last_lr: 0.00225, train_loss: 0.6006, val_loss: 1.0253, val_acc: 0.6520\n",
      "Epoch [112], last_lr: 0.00220, train_loss: 0.5985, val_loss: 1.0262, val_acc: 0.6540\n",
      "Epoch [113], last_lr: 0.00215, train_loss: 0.6120, val_loss: 1.0277, val_acc: 0.6540\n",
      "Epoch [114], last_lr: 0.00210, train_loss: 0.6281, val_loss: 1.0331, val_acc: 0.6600\n",
      "Epoch [115], last_lr: 0.00205, train_loss: 0.6169, val_loss: 1.0326, val_acc: 0.6580\n",
      "Epoch [116], last_lr: 0.00200, train_loss: 0.6007, val_loss: 1.0377, val_acc: 0.6560\n",
      "Epoch [117], last_lr: 0.00195, train_loss: 0.6200, val_loss: 1.0265, val_acc: 0.6600\n",
      "Epoch [118], last_lr: 0.00190, train_loss: 0.6328, val_loss: 1.0323, val_acc: 0.6560\n",
      "Epoch [119], last_lr: 0.00185, train_loss: 0.6017, val_loss: 1.0292, val_acc: 0.6540\n",
      "Epoch [120], last_lr: 0.00180, train_loss: 0.6006, val_loss: 1.0211, val_acc: 0.6640\n",
      "Epoch [121], last_lr: 0.00175, train_loss: 0.6008, val_loss: 1.0244, val_acc: 0.6500\n",
      "Epoch [122], last_lr: 0.00170, train_loss: 0.6463, val_loss: 1.0270, val_acc: 0.6540\n",
      "Epoch [123], last_lr: 0.00165, train_loss: 0.6055, val_loss: 1.0244, val_acc: 0.6500\n",
      "Epoch [124], last_lr: 0.00160, train_loss: 0.5971, val_loss: 1.0300, val_acc: 0.6540\n",
      "Epoch [125], last_lr: 0.00155, train_loss: 0.6152, val_loss: 1.0240, val_acc: 0.6620\n",
      "Epoch [126], last_lr: 0.00151, train_loss: 0.6044, val_loss: 1.0324, val_acc: 0.6540\n",
      "Epoch [127], last_lr: 0.00146, train_loss: 0.6029, val_loss: 1.0210, val_acc: 0.6640\n",
      "Epoch [128], last_lr: 0.00141, train_loss: 0.5855, val_loss: 1.0252, val_acc: 0.6620\n",
      "Epoch [129], last_lr: 0.00136, train_loss: 0.6025, val_loss: 1.0290, val_acc: 0.6480\n",
      "Epoch [130], last_lr: 0.00132, train_loss: 0.6073, val_loss: 1.0190, val_acc: 0.6700\n",
      "Epoch [131], last_lr: 0.00127, train_loss: 0.6180, val_loss: 1.0274, val_acc: 0.6560\n",
      "Epoch [132], last_lr: 0.00122, train_loss: 0.6204, val_loss: 1.0187, val_acc: 0.6680\n",
      "Epoch [133], last_lr: 0.00118, train_loss: 0.6022, val_loss: 1.0178, val_acc: 0.6560\n",
      "Epoch [134], last_lr: 0.00113, train_loss: 0.6131, val_loss: 1.0223, val_acc: 0.6480\n",
      "Epoch [135], last_lr: 0.00109, train_loss: 0.6148, val_loss: 1.0231, val_acc: 0.6560\n",
      "Epoch [136], last_lr: 0.00104, train_loss: 0.6127, val_loss: 1.0298, val_acc: 0.6540\n",
      "Epoch [137], last_lr: 0.00100, train_loss: 0.5986, val_loss: 1.0256, val_acc: 0.6520\n",
      "Epoch [138], last_lr: 0.00096, train_loss: 0.5935, val_loss: 1.0222, val_acc: 0.6600\n",
      "Epoch [139], last_lr: 0.00091, train_loss: 0.5991, val_loss: 1.0290, val_acc: 0.6520\n",
      "Epoch [140], last_lr: 0.00087, train_loss: 0.6053, val_loss: 1.0247, val_acc: 0.6640\n",
      "Epoch [141], last_lr: 0.00083, train_loss: 0.6128, val_loss: 1.0247, val_acc: 0.6600\n",
      "Epoch [142], last_lr: 0.00079, train_loss: 0.6022, val_loss: 1.0266, val_acc: 0.6580\n",
      "Epoch [143], last_lr: 0.00075, train_loss: 0.6127, val_loss: 1.0229, val_acc: 0.6640\n",
      "Epoch [144], last_lr: 0.00071, train_loss: 0.5954, val_loss: 1.0237, val_acc: 0.6600\n",
      "Epoch [145], last_lr: 0.00068, train_loss: 0.6110, val_loss: 1.0268, val_acc: 0.6560\n",
      "Epoch [146], last_lr: 0.00064, train_loss: 0.6076, val_loss: 1.0279, val_acc: 0.6520\n",
      "Epoch [147], last_lr: 0.00060, train_loss: 0.5817, val_loss: 1.0210, val_acc: 0.6640\n",
      "Epoch [148], last_lr: 0.00057, train_loss: 0.5898, val_loss: 1.0220, val_acc: 0.6620\n",
      "Epoch [149], last_lr: 0.00053, train_loss: 0.6019, val_loss: 1.0312, val_acc: 0.6520\n",
      "Epoch [150], last_lr: 0.00050, train_loss: 0.6045, val_loss: 1.0251, val_acc: 0.6580\n",
      "Epoch [151], last_lr: 0.00047, train_loss: 0.5893, val_loss: 1.0201, val_acc: 0.6680\n",
      "Epoch [152], last_lr: 0.00044, train_loss: 0.5975, val_loss: 1.0208, val_acc: 0.6640\n",
      "Epoch [153], last_lr: 0.00041, train_loss: 0.5972, val_loss: 1.0232, val_acc: 0.6560\n",
      "Epoch [154], last_lr: 0.00038, train_loss: 0.5992, val_loss: 1.0247, val_acc: 0.6540\n",
      "Epoch [155], last_lr: 0.00035, train_loss: 0.6089, val_loss: 1.0238, val_acc: 0.6580\n",
      "Epoch [156], last_lr: 0.00032, train_loss: 0.6082, val_loss: 1.0231, val_acc: 0.6580\n",
      "Epoch [157], last_lr: 0.00029, train_loss: 0.6123, val_loss: 1.0232, val_acc: 0.6620\n",
      "Epoch [158], last_lr: 0.00027, train_loss: 0.6000, val_loss: 1.0248, val_acc: 0.6560\n",
      "Epoch [159], last_lr: 0.00024, train_loss: 0.6240, val_loss: 1.0253, val_acc: 0.6540\n",
      "Epoch [160], last_lr: 0.00022, train_loss: 0.5949, val_loss: 1.0250, val_acc: 0.6540\n",
      "Epoch [161], last_lr: 0.00020, train_loss: 0.5954, val_loss: 1.0255, val_acc: 0.6580\n",
      "Epoch [162], last_lr: 0.00018, train_loss: 0.5949, val_loss: 1.0271, val_acc: 0.6580\n",
      "Epoch [163], last_lr: 0.00016, train_loss: 0.6021, val_loss: 1.0267, val_acc: 0.6620\n",
      "Epoch [164], last_lr: 0.00014, train_loss: 0.6011, val_loss: 1.0267, val_acc: 0.6580\n",
      "Epoch [165], last_lr: 0.00012, train_loss: 0.6146, val_loss: 1.0250, val_acc: 0.6560\n",
      "Epoch [166], last_lr: 0.00010, train_loss: 0.6027, val_loss: 1.0266, val_acc: 0.6540\n",
      "Epoch [167], last_lr: 0.00009, train_loss: 0.5994, val_loss: 1.0267, val_acc: 0.6560\n",
      "Epoch [168], last_lr: 0.00007, train_loss: 0.6028, val_loss: 1.0254, val_acc: 0.6580\n",
      "Epoch [169], last_lr: 0.00006, train_loss: 0.5817, val_loss: 1.0241, val_acc: 0.6580\n",
      "Epoch [170], last_lr: 0.00005, train_loss: 0.6074, val_loss: 1.0230, val_acc: 0.6600\n",
      "Epoch [171], last_lr: 0.00004, train_loss: 0.5989, val_loss: 1.0244, val_acc: 0.6600\n",
      "Epoch [172], last_lr: 0.00003, train_loss: 0.6232, val_loss: 1.0249, val_acc: 0.6580\n",
      "Epoch [173], last_lr: 0.00002, train_loss: 0.6159, val_loss: 1.0250, val_acc: 0.6540\n",
      "Epoch [174], last_lr: 0.00002, train_loss: 0.6253, val_loss: 1.0262, val_acc: 0.6560\n",
      "Epoch [175], last_lr: 0.00001, train_loss: 0.5890, val_loss: 1.0269, val_acc: 0.6560\n",
      "Epoch [176], last_lr: 0.00001, train_loss: 0.6057, val_loss: 1.0244, val_acc: 0.6580\n",
      "Epoch [177], last_lr: 0.00000, train_loss: 0.6007, val_loss: 1.0251, val_acc: 0.6580\n",
      "Epoch [178], last_lr: 0.00000, train_loss: 0.5901, val_loss: 1.0259, val_acc: 0.6560\n",
      "Epoch [179], last_lr: 0.00000, train_loss: 0.5946, val_loss: 1.0236, val_acc: 0.6560\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[{'val_loss': 5.873149394989014, 'val_acc': 0.20800000429153442}]\n",
      "Epoch [0], last_lr: 0.00016, train_loss: 6.7321, val_loss: 6.0325, val_acc: 0.2400\n",
      "Epoch [1], last_lr: 0.00017, train_loss: 6.4263, val_loss: 6.1142, val_acc: 0.2480\n",
      "Epoch [2], last_lr: 0.00019, train_loss: 6.2680, val_loss: 6.0449, val_acc: 0.2460\n",
      "Epoch [3], last_lr: 0.00021, train_loss: 6.1078, val_loss: 5.8912, val_acc: 0.2440\n",
      "Epoch [4], last_lr: 0.00024, train_loss: 5.8672, val_loss: 5.7028, val_acc: 0.2460\n",
      "Epoch [5], last_lr: 0.00027, train_loss: 5.6798, val_loss: 5.4721, val_acc: 0.2400\n",
      "Epoch [6], last_lr: 0.00031, train_loss: 5.4643, val_loss: 5.2340, val_acc: 0.2360\n",
      "Epoch [7], last_lr: 0.00036, train_loss: 5.1815, val_loss: 4.9491, val_acc: 0.2400\n",
      "Epoch [8], last_lr: 0.00041, train_loss: 4.8863, val_loss: 4.6574, val_acc: 0.2360\n",
      "Epoch [9], last_lr: 0.00047, train_loss: 4.6626, val_loss: 4.3692, val_acc: 0.2360\n",
      "Epoch [10], last_lr: 0.00053, train_loss: 4.3282, val_loss: 4.1377, val_acc: 0.2240\n",
      "Epoch [11], last_lr: 0.00060, train_loss: 4.0891, val_loss: 3.9883, val_acc: 0.2260\n",
      "Epoch [12], last_lr: 0.00068, train_loss: 3.8730, val_loss: 3.9235, val_acc: 0.2380\n",
      "Epoch [13], last_lr: 0.00075, train_loss: 3.8645, val_loss: 3.8165, val_acc: 0.2600\n",
      "Epoch [14], last_lr: 0.00084, train_loss: 3.7061, val_loss: 3.6351, val_acc: 0.2700\n",
      "Epoch [15], last_lr: 0.00092, train_loss: 3.4774, val_loss: 3.4303, val_acc: 0.2780\n",
      "Epoch [16], last_lr: 0.00102, train_loss: 3.2654, val_loss: 3.2434, val_acc: 0.2860\n",
      "Epoch [17], last_lr: 0.00111, train_loss: 3.1390, val_loss: 3.0328, val_acc: 0.3060\n",
      "Epoch [18], last_lr: 0.00121, train_loss: 2.7720, val_loss: 2.8260, val_acc: 0.3220\n",
      "Epoch [19], last_lr: 0.00131, train_loss: 2.5639, val_loss: 2.6025, val_acc: 0.3440\n",
      "Epoch [20], last_lr: 0.00141, train_loss: 2.2994, val_loss: 2.3639, val_acc: 0.3820\n",
      "Epoch [21], last_lr: 0.00152, train_loss: 2.0280, val_loss: 2.1633, val_acc: 0.4120\n",
      "Epoch [22], last_lr: 0.00163, train_loss: 1.7801, val_loss: 1.9455, val_acc: 0.4460\n",
      "Epoch [23], last_lr: 0.00174, train_loss: 1.5667, val_loss: 1.7501, val_acc: 0.4860\n",
      "Epoch [24], last_lr: 0.00185, train_loss: 1.3062, val_loss: 1.6057, val_acc: 0.5220\n",
      "Epoch [25], last_lr: 0.00196, train_loss: 1.1380, val_loss: 1.4578, val_acc: 0.5420\n",
      "Epoch [26], last_lr: 0.00207, train_loss: 1.0412, val_loss: 1.3581, val_acc: 0.5660\n",
      "Epoch [27], last_lr: 0.00218, train_loss: 0.8774, val_loss: 1.2671, val_acc: 0.5820\n",
      "Epoch [28], last_lr: 0.00230, train_loss: 0.7861, val_loss: 1.1947, val_acc: 0.5960\n",
      "Epoch [29], last_lr: 0.00241, train_loss: 0.7188, val_loss: 1.1556, val_acc: 0.6000\n",
      "Epoch [30], last_lr: 0.00252, train_loss: 0.6782, val_loss: 1.0949, val_acc: 0.6040\n",
      "Epoch [31], last_lr: 0.00262, train_loss: 0.6193, val_loss: 1.0762, val_acc: 0.6220\n",
      "Epoch [32], last_lr: 0.00273, train_loss: 0.5724, val_loss: 1.0422, val_acc: 0.6220\n",
      "Epoch [33], last_lr: 0.00284, train_loss: 0.5426, val_loss: 1.0372, val_acc: 0.6440\n",
      "Epoch [34], last_lr: 0.00294, train_loss: 0.5322, val_loss: 1.0255, val_acc: 0.6400\n",
      "Epoch [35], last_lr: 0.00304, train_loss: 0.5217, val_loss: 1.0017, val_acc: 0.6500\n",
      "Epoch [36], last_lr: 0.00313, train_loss: 0.5031, val_loss: 0.9871, val_acc: 0.6560\n",
      "Epoch [37], last_lr: 0.00322, train_loss: 0.4834, val_loss: 0.9724, val_acc: 0.6540\n",
      "Epoch [38], last_lr: 0.00331, train_loss: 0.4735, val_loss: 0.9924, val_acc: 0.6600\n",
      "Epoch [39], last_lr: 0.00339, train_loss: 0.4922, val_loss: 0.9781, val_acc: 0.6640\n",
      "Epoch [40], last_lr: 0.00347, train_loss: 0.4510, val_loss: 0.9849, val_acc: 0.6540\n",
      "Epoch [41], last_lr: 0.00355, train_loss: 0.4755, val_loss: 0.9676, val_acc: 0.6700\n",
      "Epoch [42], last_lr: 0.00362, train_loss: 0.4362, val_loss: 0.9718, val_acc: 0.6520\n",
      "Epoch [43], last_lr: 0.00368, train_loss: 0.4611, val_loss: 0.9518, val_acc: 0.6840\n",
      "Epoch [44], last_lr: 0.00374, train_loss: 0.4299, val_loss: 0.9570, val_acc: 0.6560\n",
      "Epoch [45], last_lr: 0.00379, train_loss: 0.4395, val_loss: 0.9721, val_acc: 0.6640\n",
      "Epoch [46], last_lr: 0.00384, train_loss: 0.4451, val_loss: 0.9377, val_acc: 0.6840\n",
      "Epoch [47], last_lr: 0.00388, train_loss: 0.4231, val_loss: 0.9574, val_acc: 0.6860\n",
      "Epoch [48], last_lr: 0.00392, train_loss: 0.4082, val_loss: 0.9511, val_acc: 0.6660\n",
      "Epoch [49], last_lr: 0.00395, train_loss: 0.4449, val_loss: 0.9243, val_acc: 0.6900\n",
      "Epoch [50], last_lr: 0.00397, train_loss: 0.3997, val_loss: 0.9603, val_acc: 0.6720\n",
      "Epoch [51], last_lr: 0.00399, train_loss: 0.4538, val_loss: 0.9269, val_acc: 0.7020\n",
      "Epoch [52], last_lr: 0.00400, train_loss: 0.4075, val_loss: 0.9097, val_acc: 0.6960\n",
      "Epoch [53], last_lr: 0.00400, train_loss: 0.3952, val_loss: 0.9148, val_acc: 0.7000\n",
      "Epoch [54], last_lr: 0.00400, train_loss: 0.4154, val_loss: 0.9390, val_acc: 0.6800\n",
      "Epoch [55], last_lr: 0.00400, train_loss: 0.4289, val_loss: 0.9299, val_acc: 0.6980\n",
      "Epoch [56], last_lr: 0.00399, train_loss: 0.3988, val_loss: 0.9197, val_acc: 0.6800\n",
      "Epoch [57], last_lr: 0.00399, train_loss: 0.4112, val_loss: 0.9311, val_acc: 0.6900\n",
      "Epoch [58], last_lr: 0.00398, train_loss: 0.4134, val_loss: 0.9031, val_acc: 0.6920\n",
      "Epoch [59], last_lr: 0.00398, train_loss: 0.3862, val_loss: 0.9346, val_acc: 0.6920\n",
      "Epoch [60], last_lr: 0.00397, train_loss: 0.4145, val_loss: 0.9097, val_acc: 0.6820\n",
      "Epoch [61], last_lr: 0.00396, train_loss: 0.3933, val_loss: 0.8931, val_acc: 0.6980\n",
      "Epoch [62], last_lr: 0.00395, train_loss: 0.3810, val_loss: 0.9215, val_acc: 0.6980\n",
      "Epoch [63], last_lr: 0.00394, train_loss: 0.4002, val_loss: 0.8909, val_acc: 0.6920\n",
      "Epoch [64], last_lr: 0.00393, train_loss: 0.3852, val_loss: 0.8937, val_acc: 0.6920\n",
      "Epoch [65], last_lr: 0.00391, train_loss: 0.3943, val_loss: 0.9033, val_acc: 0.7040\n",
      "Epoch [66], last_lr: 0.00390, train_loss: 0.3994, val_loss: 0.8936, val_acc: 0.6980\n",
      "Epoch [67], last_lr: 0.00388, train_loss: 0.3889, val_loss: 0.9103, val_acc: 0.7000\n",
      "Epoch [68], last_lr: 0.00386, train_loss: 0.3805, val_loss: 0.8972, val_acc: 0.6940\n",
      "Epoch [69], last_lr: 0.00384, train_loss: 0.4027, val_loss: 0.8989, val_acc: 0.7000\n",
      "Epoch [70], last_lr: 0.00382, train_loss: 0.3992, val_loss: 0.8904, val_acc: 0.7040\n",
      "Epoch [71], last_lr: 0.00380, train_loss: 0.3914, val_loss: 0.9035, val_acc: 0.7000\n",
      "Epoch [72], last_lr: 0.00378, train_loss: 0.3943, val_loss: 0.9137, val_acc: 0.7080\n",
      "Epoch [73], last_lr: 0.00376, train_loss: 0.4003, val_loss: 0.9104, val_acc: 0.6900\n",
      "Epoch [74], last_lr: 0.00373, train_loss: 0.3860, val_loss: 0.8906, val_acc: 0.6900\n",
      "Epoch [75], last_lr: 0.00371, train_loss: 0.3815, val_loss: 0.9024, val_acc: 0.6980\n",
      "Epoch [76], last_lr: 0.00368, train_loss: 0.4020, val_loss: 0.8720, val_acc: 0.7140\n",
      "Epoch [77], last_lr: 0.00365, train_loss: 0.4067, val_loss: 0.8909, val_acc: 0.7060\n",
      "Epoch [78], last_lr: 0.00362, train_loss: 0.4000, val_loss: 0.8719, val_acc: 0.7040\n",
      "Epoch [79], last_lr: 0.00359, train_loss: 0.3880, val_loss: 0.8911, val_acc: 0.7200\n",
      "Epoch [80], last_lr: 0.00356, train_loss: 0.3799, val_loss: 0.8969, val_acc: 0.6980\n",
      "Epoch [81], last_lr: 0.00353, train_loss: 0.3973, val_loss: 0.8800, val_acc: 0.7080\n",
      "Epoch [82], last_lr: 0.00350, train_loss: 0.3813, val_loss: 0.8977, val_acc: 0.6980\n",
      "Epoch [83], last_lr: 0.00347, train_loss: 0.4149, val_loss: 0.8918, val_acc: 0.7140\n",
      "Epoch [84], last_lr: 0.00343, train_loss: 0.3770, val_loss: 0.8947, val_acc: 0.6880\n",
      "Epoch [85], last_lr: 0.00340, train_loss: 0.3926, val_loss: 0.8940, val_acc: 0.6980\n",
      "Epoch [86], last_lr: 0.00336, train_loss: 0.3591, val_loss: 0.8879, val_acc: 0.7140\n",
      "Epoch [87], last_lr: 0.00332, train_loss: 0.3797, val_loss: 0.9036, val_acc: 0.6920\n",
      "Epoch [88], last_lr: 0.00329, train_loss: 0.3962, val_loss: 0.8854, val_acc: 0.7120\n",
      "Epoch [89], last_lr: 0.00325, train_loss: 0.3696, val_loss: 0.9123, val_acc: 0.6920\n",
      "Epoch [90], last_lr: 0.00321, train_loss: 0.3778, val_loss: 0.8882, val_acc: 0.7080\n",
      "Epoch [91], last_lr: 0.00317, train_loss: 0.3795, val_loss: 0.8976, val_acc: 0.7040\n",
      "Epoch [92], last_lr: 0.00313, train_loss: 0.3802, val_loss: 0.8931, val_acc: 0.7040\n",
      "Epoch [93], last_lr: 0.00309, train_loss: 0.3639, val_loss: 0.8887, val_acc: 0.6980\n",
      "Epoch [94], last_lr: 0.00304, train_loss: 0.3865, val_loss: 0.9008, val_acc: 0.7020\n",
      "Epoch [95], last_lr: 0.00300, train_loss: 0.3686, val_loss: 0.8885, val_acc: 0.6980\n",
      "Epoch [96], last_lr: 0.00296, train_loss: 0.3857, val_loss: 0.8939, val_acc: 0.7100\n",
      "Epoch [97], last_lr: 0.00291, train_loss: 0.3967, val_loss: 0.8904, val_acc: 0.7080\n",
      "Epoch [98], last_lr: 0.00287, train_loss: 0.3524, val_loss: 0.9001, val_acc: 0.7040\n",
      "Epoch [99], last_lr: 0.00282, train_loss: 0.3751, val_loss: 0.8818, val_acc: 0.6960\n",
      "Epoch [100], last_lr: 0.00278, train_loss: 0.3506, val_loss: 0.9104, val_acc: 0.7020\n",
      "Epoch [101], last_lr: 0.00273, train_loss: 0.3764, val_loss: 0.8794, val_acc: 0.7080\n",
      "Epoch [102], last_lr: 0.00268, train_loss: 0.3745, val_loss: 0.8930, val_acc: 0.7040\n",
      "Epoch [103], last_lr: 0.00264, train_loss: 0.3577, val_loss: 0.8751, val_acc: 0.7080\n",
      "Epoch [104], last_lr: 0.00259, train_loss: 0.3644, val_loss: 0.8791, val_acc: 0.7080\n",
      "Epoch [105], last_lr: 0.00254, train_loss: 0.3613, val_loss: 0.8717, val_acc: 0.7040\n",
      "Epoch [106], last_lr: 0.00249, train_loss: 0.3541, val_loss: 0.8865, val_acc: 0.7020\n",
      "Epoch [107], last_lr: 0.00245, train_loss: 0.3755, val_loss: 0.8731, val_acc: 0.7020\n",
      "Epoch [108], last_lr: 0.00240, train_loss: 0.3656, val_loss: 0.8785, val_acc: 0.7060\n",
      "Epoch [109], last_lr: 0.00235, train_loss: 0.3580, val_loss: 0.8752, val_acc: 0.7020\n",
      "Epoch [110], last_lr: 0.00230, train_loss: 0.3552, val_loss: 0.8833, val_acc: 0.7000\n",
      "Epoch [111], last_lr: 0.00225, train_loss: 0.3796, val_loss: 0.8759, val_acc: 0.7060\n",
      "Epoch [112], last_lr: 0.00220, train_loss: 0.3600, val_loss: 0.8833, val_acc: 0.7060\n",
      "Epoch [113], last_lr: 0.00215, train_loss: 0.3669, val_loss: 0.8770, val_acc: 0.7060\n",
      "Epoch [114], last_lr: 0.00210, train_loss: 0.3520, val_loss: 0.8731, val_acc: 0.7080\n",
      "Epoch [115], last_lr: 0.00205, train_loss: 0.3516, val_loss: 0.8792, val_acc: 0.7080\n",
      "Epoch [116], last_lr: 0.00200, train_loss: 0.3937, val_loss: 0.8725, val_acc: 0.6960\n",
      "Epoch [117], last_lr: 0.00195, train_loss: 0.3669, val_loss: 0.8755, val_acc: 0.7020\n",
      "Epoch [118], last_lr: 0.00190, train_loss: 0.3469, val_loss: 0.8766, val_acc: 0.7080\n",
      "Epoch [119], last_lr: 0.00185, train_loss: 0.3562, val_loss: 0.8737, val_acc: 0.6960\n",
      "Epoch [120], last_lr: 0.00180, train_loss: 0.3633, val_loss: 0.8783, val_acc: 0.7000\n",
      "Epoch [121], last_lr: 0.00175, train_loss: 0.3464, val_loss: 0.8824, val_acc: 0.7040\n",
      "Epoch [122], last_lr: 0.00170, train_loss: 0.3610, val_loss: 0.8749, val_acc: 0.7020\n",
      "Epoch [123], last_lr: 0.00165, train_loss: 0.3449, val_loss: 0.8772, val_acc: 0.7020\n",
      "Epoch [124], last_lr: 0.00160, train_loss: 0.3508, val_loss: 0.8854, val_acc: 0.7020\n",
      "Epoch [125], last_lr: 0.00155, train_loss: 0.3518, val_loss: 0.8778, val_acc: 0.7040\n",
      "Epoch [126], last_lr: 0.00151, train_loss: 0.3576, val_loss: 0.8751, val_acc: 0.7040\n",
      "Epoch [127], last_lr: 0.00146, train_loss: 0.3648, val_loss: 0.8733, val_acc: 0.7040\n",
      "Epoch [128], last_lr: 0.00141, train_loss: 0.3659, val_loss: 0.8777, val_acc: 0.7120\n",
      "Epoch [129], last_lr: 0.00136, train_loss: 0.3762, val_loss: 0.8742, val_acc: 0.7060\n",
      "Epoch [130], last_lr: 0.00132, train_loss: 0.3597, val_loss: 0.8703, val_acc: 0.7120\n",
      "Epoch [131], last_lr: 0.00127, train_loss: 0.3672, val_loss: 0.8744, val_acc: 0.7040\n",
      "Epoch [132], last_lr: 0.00122, train_loss: 0.3661, val_loss: 0.8776, val_acc: 0.7160\n",
      "Epoch [133], last_lr: 0.00118, train_loss: 0.3677, val_loss: 0.8751, val_acc: 0.7060\n",
      "Epoch [134], last_lr: 0.00113, train_loss: 0.3569, val_loss: 0.8711, val_acc: 0.7080\n",
      "Epoch [135], last_lr: 0.00109, train_loss: 0.3543, val_loss: 0.8726, val_acc: 0.7040\n",
      "Epoch [136], last_lr: 0.00104, train_loss: 0.3691, val_loss: 0.8752, val_acc: 0.7080\n",
      "Epoch [137], last_lr: 0.00100, train_loss: 0.3566, val_loss: 0.8733, val_acc: 0.7080\n",
      "Epoch [138], last_lr: 0.00096, train_loss: 0.3586, val_loss: 0.8766, val_acc: 0.7060\n",
      "Epoch [139], last_lr: 0.00091, train_loss: 0.3649, val_loss: 0.8745, val_acc: 0.7100\n",
      "Epoch [140], last_lr: 0.00087, train_loss: 0.3588, val_loss: 0.8723, val_acc: 0.7080\n",
      "Epoch [141], last_lr: 0.00083, train_loss: 0.3526, val_loss: 0.8724, val_acc: 0.7060\n",
      "Epoch [142], last_lr: 0.00079, train_loss: 0.3694, val_loss: 0.8738, val_acc: 0.7020\n",
      "Epoch [143], last_lr: 0.00075, train_loss: 0.3477, val_loss: 0.8745, val_acc: 0.7040\n",
      "Epoch [144], last_lr: 0.00071, train_loss: 0.3456, val_loss: 0.8740, val_acc: 0.7080\n",
      "Epoch [145], last_lr: 0.00068, train_loss: 0.3389, val_loss: 0.8748, val_acc: 0.7020\n",
      "Epoch [146], last_lr: 0.00064, train_loss: 0.3503, val_loss: 0.8751, val_acc: 0.7020\n",
      "Epoch [147], last_lr: 0.00060, train_loss: 0.3461, val_loss: 0.8755, val_acc: 0.7040\n",
      "Epoch [148], last_lr: 0.00057, train_loss: 0.3470, val_loss: 0.8743, val_acc: 0.7060\n",
      "Epoch [149], last_lr: 0.00053, train_loss: 0.3475, val_loss: 0.8735, val_acc: 0.7040\n",
      "Epoch [150], last_lr: 0.00050, train_loss: 0.3728, val_loss: 0.8721, val_acc: 0.7040\n",
      "Epoch [151], last_lr: 0.00047, train_loss: 0.3487, val_loss: 0.8738, val_acc: 0.6980\n",
      "Epoch [152], last_lr: 0.00044, train_loss: 0.3677, val_loss: 0.8742, val_acc: 0.6980\n",
      "Epoch [153], last_lr: 0.00041, train_loss: 0.3477, val_loss: 0.8746, val_acc: 0.7000\n",
      "Epoch [154], last_lr: 0.00038, train_loss: 0.3453, val_loss: 0.8752, val_acc: 0.7040\n",
      "Epoch [155], last_lr: 0.00035, train_loss: 0.3438, val_loss: 0.8750, val_acc: 0.7020\n",
      "Epoch [156], last_lr: 0.00032, train_loss: 0.3516, val_loss: 0.8753, val_acc: 0.7040\n",
      "Epoch [157], last_lr: 0.00029, train_loss: 0.3561, val_loss: 0.8739, val_acc: 0.7020\n",
      "Epoch [158], last_lr: 0.00027, train_loss: 0.3450, val_loss: 0.8729, val_acc: 0.7060\n",
      "Epoch [159], last_lr: 0.00024, train_loss: 0.3463, val_loss: 0.8722, val_acc: 0.7060\n",
      "Epoch [160], last_lr: 0.00022, train_loss: 0.3594, val_loss: 0.8735, val_acc: 0.7060\n",
      "Epoch [161], last_lr: 0.00020, train_loss: 0.3594, val_loss: 0.8737, val_acc: 0.7060\n",
      "Epoch [162], last_lr: 0.00018, train_loss: 0.3554, val_loss: 0.8744, val_acc: 0.7060\n",
      "Epoch [163], last_lr: 0.00016, train_loss: 0.3704, val_loss: 0.8718, val_acc: 0.7080\n",
      "Epoch [164], last_lr: 0.00014, train_loss: 0.3537, val_loss: 0.8737, val_acc: 0.7040\n",
      "Epoch [165], last_lr: 0.00012, train_loss: 0.3594, val_loss: 0.8735, val_acc: 0.7080\n",
      "Epoch [166], last_lr: 0.00010, train_loss: 0.3419, val_loss: 0.8733, val_acc: 0.7080\n",
      "Epoch [167], last_lr: 0.00009, train_loss: 0.3291, val_loss: 0.8743, val_acc: 0.7080\n",
      "Epoch [168], last_lr: 0.00007, train_loss: 0.3739, val_loss: 0.8750, val_acc: 0.7080\n",
      "Epoch [169], last_lr: 0.00006, train_loss: 0.3630, val_loss: 0.8735, val_acc: 0.7060\n",
      "Epoch [170], last_lr: 0.00005, train_loss: 0.3562, val_loss: 0.8753, val_acc: 0.7020\n",
      "Epoch [171], last_lr: 0.00004, train_loss: 0.3647, val_loss: 0.8724, val_acc: 0.7000\n",
      "Epoch [172], last_lr: 0.00003, train_loss: 0.3408, val_loss: 0.8719, val_acc: 0.7000\n",
      "Epoch [173], last_lr: 0.00002, train_loss: 0.3633, val_loss: 0.8703, val_acc: 0.7040\n",
      "Epoch [174], last_lr: 0.00002, train_loss: 0.3747, val_loss: 0.8716, val_acc: 0.7060\n",
      "Epoch [175], last_lr: 0.00001, train_loss: 0.3658, val_loss: 0.8708, val_acc: 0.7060\n",
      "Epoch [176], last_lr: 0.00001, train_loss: 0.3656, val_loss: 0.8738, val_acc: 0.7060\n",
      "Epoch [177], last_lr: 0.00000, train_loss: 0.3484, val_loss: 0.8723, val_acc: 0.7080\n",
      "Epoch [178], last_lr: 0.00000, train_loss: 0.3483, val_loss: 0.8743, val_acc: 0.7060\n",
      "Epoch [179], last_lr: 0.00000, train_loss: 0.3679, val_loss: 0.8744, val_acc: 0.7080\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[{'val_loss': 8.297754287719727, 'val_acc': 0.21400000154972076}]\n",
      "Epoch [0], last_lr: 0.00016, train_loss: 4.7662, val_loss: 6.1279, val_acc: 0.2280\n",
      "Epoch [1], last_lr: 0.00017, train_loss: 4.5304, val_loss: 5.2773, val_acc: 0.2380\n",
      "Epoch [2], last_lr: 0.00019, train_loss: 4.3352, val_loss: 4.8625, val_acc: 0.2260\n",
      "Epoch [3], last_lr: 0.00021, train_loss: 4.1393, val_loss: 4.5753, val_acc: 0.2340\n",
      "Epoch [4], last_lr: 0.00024, train_loss: 3.8324, val_loss: 4.3168, val_acc: 0.2280\n",
      "Epoch [5], last_lr: 0.00027, train_loss: 3.5516, val_loss: 4.0712, val_acc: 0.2320\n",
      "Epoch [6], last_lr: 0.00031, train_loss: 3.4148, val_loss: 3.8462, val_acc: 0.2300\n",
      "Epoch [7], last_lr: 0.00036, train_loss: 3.2578, val_loss: 3.7167, val_acc: 0.2280\n",
      "Epoch [8], last_lr: 0.00041, train_loss: 3.1398, val_loss: 3.6375, val_acc: 0.2300\n",
      "Epoch [9], last_lr: 0.00047, train_loss: 3.1629, val_loss: 3.5749, val_acc: 0.2240\n",
      "Epoch [10], last_lr: 0.00053, train_loss: 3.0467, val_loss: 3.4868, val_acc: 0.2380\n",
      "Epoch [11], last_lr: 0.00060, train_loss: 2.8685, val_loss: 3.3701, val_acc: 0.2440\n",
      "Epoch [12], last_lr: 0.00068, train_loss: 2.7853, val_loss: 3.2497, val_acc: 0.2640\n",
      "Epoch [13], last_lr: 0.00075, train_loss: 2.6154, val_loss: 3.0992, val_acc: 0.2760\n",
      "Epoch [14], last_lr: 0.00084, train_loss: 2.4905, val_loss: 2.9126, val_acc: 0.2900\n",
      "Epoch [15], last_lr: 0.00092, train_loss: 2.2738, val_loss: 2.7259, val_acc: 0.3120\n",
      "Epoch [16], last_lr: 0.00102, train_loss: 2.1433, val_loss: 2.5564, val_acc: 0.3380\n",
      "Epoch [17], last_lr: 0.00111, train_loss: 1.9777, val_loss: 2.3745, val_acc: 0.3600\n",
      "Epoch [18], last_lr: 0.00121, train_loss: 1.7971, val_loss: 2.1797, val_acc: 0.3860\n",
      "Epoch [19], last_lr: 0.00131, train_loss: 1.5874, val_loss: 2.0126, val_acc: 0.4180\n",
      "Epoch [20], last_lr: 0.00141, train_loss: 1.4559, val_loss: 1.8676, val_acc: 0.4600\n",
      "Epoch [21], last_lr: 0.00152, train_loss: 1.2684, val_loss: 1.7351, val_acc: 0.4800\n",
      "Epoch [22], last_lr: 0.00163, train_loss: 1.1916, val_loss: 1.6133, val_acc: 0.5060\n",
      "Epoch [23], last_lr: 0.00174, train_loss: 1.0864, val_loss: 1.5163, val_acc: 0.5260\n",
      "Epoch [24], last_lr: 0.00185, train_loss: 1.0096, val_loss: 1.4272, val_acc: 0.5440\n",
      "Epoch [25], last_lr: 0.00196, train_loss: 0.9034, val_loss: 1.3519, val_acc: 0.5700\n",
      "Epoch [26], last_lr: 0.00207, train_loss: 0.8345, val_loss: 1.3002, val_acc: 0.5860\n",
      "Epoch [27], last_lr: 0.00218, train_loss: 0.7762, val_loss: 1.2450, val_acc: 0.6060\n",
      "Epoch [28], last_lr: 0.00230, train_loss: 0.7413, val_loss: 1.1959, val_acc: 0.6200\n",
      "Epoch [29], last_lr: 0.00241, train_loss: 0.7329, val_loss: 1.1797, val_acc: 0.6340\n",
      "Epoch [30], last_lr: 0.00252, train_loss: 0.6705, val_loss: 1.1297, val_acc: 0.6500\n",
      "Epoch [31], last_lr: 0.00262, train_loss: 0.6643, val_loss: 1.1316, val_acc: 0.6340\n",
      "Epoch [32], last_lr: 0.00273, train_loss: 0.6190, val_loss: 1.0792, val_acc: 0.6580\n",
      "Epoch [33], last_lr: 0.00284, train_loss: 0.6296, val_loss: 1.0522, val_acc: 0.6600\n",
      "Epoch [34], last_lr: 0.00294, train_loss: 0.5783, val_loss: 1.0322, val_acc: 0.6600\n",
      "Epoch [35], last_lr: 0.00304, train_loss: 0.5587, val_loss: 1.0372, val_acc: 0.6720\n",
      "Epoch [36], last_lr: 0.00313, train_loss: 0.5562, val_loss: 1.0013, val_acc: 0.6680\n",
      "Epoch [37], last_lr: 0.00322, train_loss: 0.5570, val_loss: 1.0086, val_acc: 0.6840\n",
      "Epoch [38], last_lr: 0.00331, train_loss: 0.5662, val_loss: 0.9722, val_acc: 0.6800\n",
      "Epoch [39], last_lr: 0.00339, train_loss: 0.5404, val_loss: 0.9627, val_acc: 0.6920\n",
      "Epoch [40], last_lr: 0.00347, train_loss: 0.5139, val_loss: 0.9514, val_acc: 0.6880\n",
      "Epoch [41], last_lr: 0.00355, train_loss: 0.4920, val_loss: 0.9546, val_acc: 0.6920\n",
      "Epoch [42], last_lr: 0.00362, train_loss: 0.4926, val_loss: 0.9232, val_acc: 0.6900\n",
      "Epoch [43], last_lr: 0.00368, train_loss: 0.5079, val_loss: 0.9272, val_acc: 0.6940\n",
      "Epoch [44], last_lr: 0.00374, train_loss: 0.4593, val_loss: 0.9052, val_acc: 0.7040\n",
      "Epoch [45], last_lr: 0.00379, train_loss: 0.4578, val_loss: 0.8882, val_acc: 0.7000\n",
      "Epoch [46], last_lr: 0.00384, train_loss: 0.4592, val_loss: 0.9018, val_acc: 0.6980\n",
      "Epoch [47], last_lr: 0.00388, train_loss: 0.4605, val_loss: 0.8927, val_acc: 0.6980\n",
      "Epoch [48], last_lr: 0.00392, train_loss: 0.4730, val_loss: 0.8965, val_acc: 0.6960\n",
      "Epoch [49], last_lr: 0.00395, train_loss: 0.4452, val_loss: 0.8794, val_acc: 0.7040\n",
      "Epoch [50], last_lr: 0.00397, train_loss: 0.4519, val_loss: 0.8795, val_acc: 0.6980\n",
      "Epoch [51], last_lr: 0.00399, train_loss: 0.4242, val_loss: 0.8861, val_acc: 0.6920\n",
      "Epoch [52], last_lr: 0.00400, train_loss: 0.4341, val_loss: 0.8769, val_acc: 0.7040\n",
      "Epoch [53], last_lr: 0.00400, train_loss: 0.4403, val_loss: 0.8870, val_acc: 0.6940\n",
      "Epoch [54], last_lr: 0.00400, train_loss: 0.4245, val_loss: 0.8997, val_acc: 0.7000\n",
      "Epoch [55], last_lr: 0.00400, train_loss: 0.4133, val_loss: 0.8773, val_acc: 0.6920\n",
      "Epoch [56], last_lr: 0.00399, train_loss: 0.4384, val_loss: 0.8934, val_acc: 0.6980\n",
      "Epoch [57], last_lr: 0.00399, train_loss: 0.4250, val_loss: 0.8846, val_acc: 0.6900\n",
      "Epoch [58], last_lr: 0.00398, train_loss: 0.4264, val_loss: 0.8703, val_acc: 0.6980\n",
      "Epoch [59], last_lr: 0.00398, train_loss: 0.4147, val_loss: 0.8651, val_acc: 0.6960\n",
      "Epoch [60], last_lr: 0.00397, train_loss: 0.4316, val_loss: 0.8708, val_acc: 0.7100\n",
      "Epoch [61], last_lr: 0.00396, train_loss: 0.4000, val_loss: 0.8628, val_acc: 0.7000\n",
      "Epoch [62], last_lr: 0.00395, train_loss: 0.4187, val_loss: 0.9298, val_acc: 0.6880\n",
      "Epoch [63], last_lr: 0.00394, train_loss: 0.4138, val_loss: 0.8682, val_acc: 0.6820\n",
      "Epoch [64], last_lr: 0.00393, train_loss: 0.4073, val_loss: 0.8711, val_acc: 0.7080\n",
      "Epoch [65], last_lr: 0.00391, train_loss: 0.4202, val_loss: 0.8735, val_acc: 0.7020\n",
      "Epoch [66], last_lr: 0.00390, train_loss: 0.4320, val_loss: 0.9140, val_acc: 0.6880\n",
      "Epoch [67], last_lr: 0.00388, train_loss: 0.3917, val_loss: 0.8440, val_acc: 0.7040\n",
      "Epoch [68], last_lr: 0.00386, train_loss: 0.4088, val_loss: 0.8738, val_acc: 0.7140\n",
      "Epoch [69], last_lr: 0.00384, train_loss: 0.4040, val_loss: 0.8543, val_acc: 0.7100\n",
      "Epoch [70], last_lr: 0.00382, train_loss: 0.4329, val_loss: 0.9151, val_acc: 0.6920\n",
      "Epoch [71], last_lr: 0.00380, train_loss: 0.4022, val_loss: 0.8454, val_acc: 0.7040\n",
      "Epoch [72], last_lr: 0.00378, train_loss: 0.4032, val_loss: 0.8760, val_acc: 0.7020\n",
      "Epoch [73], last_lr: 0.00376, train_loss: 0.3963, val_loss: 0.8642, val_acc: 0.7040\n",
      "Epoch [74], last_lr: 0.00373, train_loss: 0.4009, val_loss: 0.8886, val_acc: 0.6860\n",
      "Epoch [75], last_lr: 0.00371, train_loss: 0.3895, val_loss: 0.8640, val_acc: 0.7000\n",
      "Epoch [76], last_lr: 0.00368, train_loss: 0.3846, val_loss: 0.8746, val_acc: 0.7040\n",
      "Epoch [77], last_lr: 0.00365, train_loss: 0.3925, val_loss: 0.8581, val_acc: 0.6980\n",
      "Epoch [78], last_lr: 0.00362, train_loss: 0.3814, val_loss: 0.8623, val_acc: 0.6900\n",
      "Epoch [79], last_lr: 0.00359, train_loss: 0.4135, val_loss: 0.8545, val_acc: 0.7020\n",
      "Epoch [80], last_lr: 0.00356, train_loss: 0.4064, val_loss: 0.8804, val_acc: 0.6980\n",
      "Epoch [81], last_lr: 0.00353, train_loss: 0.4003, val_loss: 0.8782, val_acc: 0.6960\n",
      "Epoch [82], last_lr: 0.00350, train_loss: 0.4042, val_loss: 0.8711, val_acc: 0.6860\n",
      "Epoch [83], last_lr: 0.00347, train_loss: 0.3938, val_loss: 0.8638, val_acc: 0.6940\n",
      "Epoch [84], last_lr: 0.00343, train_loss: 0.3710, val_loss: 0.8445, val_acc: 0.6960\n",
      "Epoch [85], last_lr: 0.00340, train_loss: 0.4005, val_loss: 0.8487, val_acc: 0.6960\n",
      "Epoch [86], last_lr: 0.00336, train_loss: 0.3929, val_loss: 0.8760, val_acc: 0.6980\n",
      "Epoch [87], last_lr: 0.00332, train_loss: 0.3777, val_loss: 0.8397, val_acc: 0.7060\n",
      "Epoch [88], last_lr: 0.00329, train_loss: 0.4124, val_loss: 0.8577, val_acc: 0.6980\n",
      "Epoch [89], last_lr: 0.00325, train_loss: 0.4061, val_loss: 0.8490, val_acc: 0.6960\n",
      "Epoch [90], last_lr: 0.00321, train_loss: 0.4170, val_loss: 0.8681, val_acc: 0.6920\n",
      "Epoch [91], last_lr: 0.00317, train_loss: 0.4025, val_loss: 0.8328, val_acc: 0.7080\n",
      "Epoch [92], last_lr: 0.00313, train_loss: 0.3779, val_loss: 0.8411, val_acc: 0.6980\n",
      "Epoch [93], last_lr: 0.00309, train_loss: 0.4053, val_loss: 0.8581, val_acc: 0.7100\n",
      "Epoch [94], last_lr: 0.00304, train_loss: 0.3984, val_loss: 0.8844, val_acc: 0.6880\n",
      "Epoch [95], last_lr: 0.00300, train_loss: 0.3893, val_loss: 0.8381, val_acc: 0.7160\n",
      "Epoch [96], last_lr: 0.00296, train_loss: 0.3914, val_loss: 0.8430, val_acc: 0.7060\n",
      "Epoch [97], last_lr: 0.00291, train_loss: 0.4030, val_loss: 0.8542, val_acc: 0.7020\n",
      "Epoch [98], last_lr: 0.00287, train_loss: 0.3854, val_loss: 0.8821, val_acc: 0.7060\n",
      "Epoch [99], last_lr: 0.00282, train_loss: 0.3869, val_loss: 0.8374, val_acc: 0.7060\n",
      "Epoch [100], last_lr: 0.00278, train_loss: 0.3781, val_loss: 0.8382, val_acc: 0.7040\n",
      "Epoch [101], last_lr: 0.00273, train_loss: 0.3825, val_loss: 0.8288, val_acc: 0.7040\n",
      "Epoch [102], last_lr: 0.00268, train_loss: 0.3855, val_loss: 0.8429, val_acc: 0.7100\n",
      "Epoch [103], last_lr: 0.00264, train_loss: 0.3744, val_loss: 0.8227, val_acc: 0.7060\n",
      "Epoch [104], last_lr: 0.00259, train_loss: 0.3893, val_loss: 0.8362, val_acc: 0.7040\n",
      "Epoch [105], last_lr: 0.00254, train_loss: 0.3602, val_loss: 0.8157, val_acc: 0.7180\n",
      "Epoch [106], last_lr: 0.00249, train_loss: 0.3907, val_loss: 0.8371, val_acc: 0.7040\n",
      "Epoch [107], last_lr: 0.00245, train_loss: 0.3770, val_loss: 0.8268, val_acc: 0.7120\n",
      "Epoch [108], last_lr: 0.00240, train_loss: 0.3942, val_loss: 0.8425, val_acc: 0.7020\n",
      "Epoch [109], last_lr: 0.00235, train_loss: 0.3821, val_loss: 0.8327, val_acc: 0.7120\n",
      "Epoch [110], last_lr: 0.00230, train_loss: 0.3764, val_loss: 0.8414, val_acc: 0.7000\n",
      "Epoch [111], last_lr: 0.00225, train_loss: 0.3748, val_loss: 0.8273, val_acc: 0.7120\n",
      "Epoch [112], last_lr: 0.00220, train_loss: 0.3935, val_loss: 0.8569, val_acc: 0.6960\n",
      "Epoch [113], last_lr: 0.00215, train_loss: 0.3854, val_loss: 0.8268, val_acc: 0.7140\n",
      "Epoch [114], last_lr: 0.00210, train_loss: 0.3712, val_loss: 0.8332, val_acc: 0.7120\n",
      "Epoch [115], last_lr: 0.00205, train_loss: 0.3712, val_loss: 0.8436, val_acc: 0.7020\n",
      "Epoch [116], last_lr: 0.00200, train_loss: 0.3722, val_loss: 0.8401, val_acc: 0.7120\n",
      "Epoch [117], last_lr: 0.00195, train_loss: 0.3719, val_loss: 0.8560, val_acc: 0.7040\n",
      "Epoch [118], last_lr: 0.00190, train_loss: 0.3798, val_loss: 0.8291, val_acc: 0.7140\n",
      "Epoch [119], last_lr: 0.00185, train_loss: 0.3772, val_loss: 0.8472, val_acc: 0.7020\n",
      "Epoch [120], last_lr: 0.00180, train_loss: 0.3720, val_loss: 0.8311, val_acc: 0.7120\n",
      "Epoch [121], last_lr: 0.00175, train_loss: 0.3707, val_loss: 0.8413, val_acc: 0.7060\n",
      "Epoch [122], last_lr: 0.00170, train_loss: 0.3518, val_loss: 0.8393, val_acc: 0.7040\n",
      "Epoch [123], last_lr: 0.00165, train_loss: 0.3702, val_loss: 0.8505, val_acc: 0.7020\n",
      "Epoch [124], last_lr: 0.00160, train_loss: 0.3681, val_loss: 0.8295, val_acc: 0.7040\n",
      "Epoch [125], last_lr: 0.00155, train_loss: 0.3665, val_loss: 0.8324, val_acc: 0.6980\n",
      "Epoch [126], last_lr: 0.00151, train_loss: 0.3650, val_loss: 0.8467, val_acc: 0.7100\n",
      "Epoch [127], last_lr: 0.00146, train_loss: 0.3643, val_loss: 0.8334, val_acc: 0.7180\n",
      "Epoch [128], last_lr: 0.00141, train_loss: 0.3606, val_loss: 0.8334, val_acc: 0.7160\n",
      "Epoch [129], last_lr: 0.00136, train_loss: 0.3688, val_loss: 0.8466, val_acc: 0.7040\n",
      "Epoch [130], last_lr: 0.00132, train_loss: 0.3692, val_loss: 0.8315, val_acc: 0.7180\n",
      "Epoch [131], last_lr: 0.00127, train_loss: 0.3602, val_loss: 0.8311, val_acc: 0.7180\n",
      "Epoch [132], last_lr: 0.00122, train_loss: 0.3912, val_loss: 0.8465, val_acc: 0.7020\n",
      "Epoch [133], last_lr: 0.00118, train_loss: 0.3724, val_loss: 0.8226, val_acc: 0.7160\n",
      "Epoch [134], last_lr: 0.00113, train_loss: 0.3700, val_loss: 0.8270, val_acc: 0.7200\n",
      "Epoch [135], last_lr: 0.00109, train_loss: 0.3639, val_loss: 0.8439, val_acc: 0.7060\n",
      "Epoch [136], last_lr: 0.00104, train_loss: 0.3797, val_loss: 0.8344, val_acc: 0.7080\n",
      "Epoch [137], last_lr: 0.00100, train_loss: 0.3666, val_loss: 0.8327, val_acc: 0.7120\n",
      "Epoch [138], last_lr: 0.00096, train_loss: 0.3592, val_loss: 0.8438, val_acc: 0.7080\n",
      "Epoch [139], last_lr: 0.00091, train_loss: 0.3801, val_loss: 0.8254, val_acc: 0.7140\n",
      "Epoch [140], last_lr: 0.00087, train_loss: 0.3649, val_loss: 0.8336, val_acc: 0.7100\n",
      "Epoch [141], last_lr: 0.00083, train_loss: 0.3688, val_loss: 0.8403, val_acc: 0.7080\n",
      "Epoch [142], last_lr: 0.00079, train_loss: 0.3576, val_loss: 0.8343, val_acc: 0.7080\n",
      "Epoch [143], last_lr: 0.00075, train_loss: 0.3694, val_loss: 0.8305, val_acc: 0.7140\n",
      "Epoch [144], last_lr: 0.00071, train_loss: 0.3617, val_loss: 0.8339, val_acc: 0.7180\n",
      "Epoch [145], last_lr: 0.00068, train_loss: 0.3736, val_loss: 0.8359, val_acc: 0.7120\n",
      "Epoch [146], last_lr: 0.00064, train_loss: 0.3627, val_loss: 0.8394, val_acc: 0.7060\n",
      "Epoch [147], last_lr: 0.00060, train_loss: 0.3530, val_loss: 0.8347, val_acc: 0.7100\n",
      "Epoch [148], last_lr: 0.00057, train_loss: 0.3865, val_loss: 0.8331, val_acc: 0.7060\n",
      "Epoch [149], last_lr: 0.00053, train_loss: 0.3651, val_loss: 0.8364, val_acc: 0.7100\n",
      "Epoch [150], last_lr: 0.00050, train_loss: 0.3702, val_loss: 0.8356, val_acc: 0.7120\n",
      "Epoch [151], last_lr: 0.00047, train_loss: 0.3761, val_loss: 0.8360, val_acc: 0.7080\n",
      "Epoch [152], last_lr: 0.00044, train_loss: 0.3743, val_loss: 0.8386, val_acc: 0.7060\n",
      "Epoch [153], last_lr: 0.00041, train_loss: 0.3723, val_loss: 0.8402, val_acc: 0.7120\n",
      "Epoch [154], last_lr: 0.00038, train_loss: 0.3753, val_loss: 0.8374, val_acc: 0.7100\n",
      "Epoch [155], last_lr: 0.00035, train_loss: 0.3829, val_loss: 0.8357, val_acc: 0.7060\n",
      "Epoch [156], last_lr: 0.00032, train_loss: 0.3614, val_loss: 0.8348, val_acc: 0.7060\n",
      "Epoch [157], last_lr: 0.00029, train_loss: 0.3670, val_loss: 0.8370, val_acc: 0.7120\n",
      "Epoch [158], last_lr: 0.00027, train_loss: 0.3605, val_loss: 0.8319, val_acc: 0.7140\n",
      "Epoch [159], last_lr: 0.00024, train_loss: 0.3596, val_loss: 0.8313, val_acc: 0.7080\n",
      "Epoch [160], last_lr: 0.00022, train_loss: 0.3663, val_loss: 0.8352, val_acc: 0.7020\n",
      "Epoch [161], last_lr: 0.00020, train_loss: 0.3600, val_loss: 0.8355, val_acc: 0.7040\n",
      "Epoch [162], last_lr: 0.00018, train_loss: 0.3738, val_loss: 0.8370, val_acc: 0.7080\n",
      "Epoch [163], last_lr: 0.00016, train_loss: 0.3562, val_loss: 0.8362, val_acc: 0.7080\n",
      "Epoch [164], last_lr: 0.00014, train_loss: 0.3453, val_loss: 0.8382, val_acc: 0.7100\n",
      "Epoch [165], last_lr: 0.00012, train_loss: 0.3694, val_loss: 0.8391, val_acc: 0.7080\n",
      "Epoch [166], last_lr: 0.00010, train_loss: 0.3637, val_loss: 0.8397, val_acc: 0.7080\n",
      "Epoch [167], last_lr: 0.00009, train_loss: 0.3488, val_loss: 0.8376, val_acc: 0.7060\n",
      "Epoch [168], last_lr: 0.00007, train_loss: 0.3674, val_loss: 0.8373, val_acc: 0.7060\n",
      "Epoch [169], last_lr: 0.00006, train_loss: 0.3727, val_loss: 0.8376, val_acc: 0.7020\n",
      "Epoch [170], last_lr: 0.00005, train_loss: 0.3553, val_loss: 0.8367, val_acc: 0.7060\n",
      "Epoch [171], last_lr: 0.00004, train_loss: 0.3773, val_loss: 0.8368, val_acc: 0.7080\n",
      "Epoch [172], last_lr: 0.00003, train_loss: 0.3654, val_loss: 0.8357, val_acc: 0.7040\n",
      "Epoch [173], last_lr: 0.00002, train_loss: 0.3544, val_loss: 0.8320, val_acc: 0.7120\n",
      "Epoch [174], last_lr: 0.00002, train_loss: 0.3483, val_loss: 0.8342, val_acc: 0.7080\n",
      "Epoch [175], last_lr: 0.00001, train_loss: 0.3571, val_loss: 0.8337, val_acc: 0.7060\n",
      "Epoch [176], last_lr: 0.00001, train_loss: 0.3652, val_loss: 0.8334, val_acc: 0.7060\n",
      "Epoch [177], last_lr: 0.00000, train_loss: 0.3529, val_loss: 0.8367, val_acc: 0.7080\n",
      "Epoch [178], last_lr: 0.00000, train_loss: 0.3600, val_loss: 0.8346, val_acc: 0.7080\n",
      "Epoch [179], last_lr: 0.00000, train_loss: 0.3770, val_loss: 0.8349, val_acc: 0.7100\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[{'val_loss': 9.49824047088623, 'val_acc': 0.32600000500679016}]\n",
      "Epoch [0], last_lr: 0.00016, train_loss: 11.8647, val_loss: 10.0384, val_acc: 0.2580\n",
      "Epoch [1], last_lr: 0.00017, train_loss: 11.4042, val_loss: 10.5588, val_acc: 0.2340\n",
      "Epoch [2], last_lr: 0.00019, train_loss: 10.9444, val_loss: 10.6484, val_acc: 0.2260\n",
      "Epoch [3], last_lr: 0.00021, train_loss: 10.4295, val_loss: 10.4261, val_acc: 0.2280\n",
      "Epoch [4], last_lr: 0.00024, train_loss: 9.8359, val_loss: 9.9944, val_acc: 0.2320\n",
      "Epoch [5], last_lr: 0.00027, train_loss: 9.2626, val_loss: 9.4476, val_acc: 0.2380\n",
      "Epoch [6], last_lr: 0.00031, train_loss: 8.6131, val_loss: 8.8062, val_acc: 0.2560\n",
      "Epoch [7], last_lr: 0.00036, train_loss: 8.0007, val_loss: 8.2160, val_acc: 0.2560\n",
      "Epoch [8], last_lr: 0.00041, train_loss: 7.4086, val_loss: 7.6050, val_acc: 0.2800\n",
      "Epoch [9], last_lr: 0.00047, train_loss: 6.8181, val_loss: 6.9975, val_acc: 0.2820\n",
      "Epoch [10], last_lr: 0.00053, train_loss: 6.2192, val_loss: 6.3782, val_acc: 0.2720\n",
      "Epoch [11], last_lr: 0.00060, train_loss: 5.5374, val_loss: 5.7201, val_acc: 0.2740\n",
      "Epoch [12], last_lr: 0.00068, train_loss: 4.9477, val_loss: 5.1210, val_acc: 0.2400\n",
      "Epoch [13], last_lr: 0.00075, train_loss: 4.3939, val_loss: 4.6694, val_acc: 0.2200\n",
      "Epoch [14], last_lr: 0.00084, train_loss: 4.0312, val_loss: 4.2437, val_acc: 0.2220\n",
      "Epoch [15], last_lr: 0.00092, train_loss: 3.7118, val_loss: 3.8880, val_acc: 0.2360\n",
      "Epoch [16], last_lr: 0.00102, train_loss: 3.4788, val_loss: 3.7643, val_acc: 0.2460\n",
      "Epoch [17], last_lr: 0.00111, train_loss: 3.3378, val_loss: 3.6748, val_acc: 0.2640\n",
      "Epoch [18], last_lr: 0.00121, train_loss: 3.1697, val_loss: 3.5484, val_acc: 0.2860\n",
      "Epoch [19], last_lr: 0.00131, train_loss: 2.9763, val_loss: 3.3088, val_acc: 0.2940\n",
      "Epoch [20], last_lr: 0.00141, train_loss: 2.7864, val_loss: 3.0493, val_acc: 0.2780\n",
      "Epoch [21], last_lr: 0.00152, train_loss: 2.5388, val_loss: 2.8033, val_acc: 0.3200\n",
      "Epoch [22], last_lr: 0.00163, train_loss: 2.3024, val_loss: 2.5405, val_acc: 0.3620\n",
      "Epoch [23], last_lr: 0.00174, train_loss: 1.9981, val_loss: 2.2364, val_acc: 0.3800\n",
      "Epoch [24], last_lr: 0.00185, train_loss: 1.7251, val_loss: 1.9703, val_acc: 0.4180\n",
      "Epoch [25], last_lr: 0.00196, train_loss: 1.4905, val_loss: 1.7226, val_acc: 0.4660\n",
      "Epoch [26], last_lr: 0.00207, train_loss: 1.2703, val_loss: 1.5167, val_acc: 0.5260\n",
      "Epoch [27], last_lr: 0.00218, train_loss: 1.0760, val_loss: 1.3586, val_acc: 0.5680\n",
      "Epoch [28], last_lr: 0.00230, train_loss: 0.9484, val_loss: 1.2402, val_acc: 0.5900\n",
      "Epoch [29], last_lr: 0.00241, train_loss: 0.8732, val_loss: 1.1385, val_acc: 0.6260\n",
      "Epoch [30], last_lr: 0.00252, train_loss: 0.8082, val_loss: 1.0685, val_acc: 0.6460\n",
      "Epoch [31], last_lr: 0.00262, train_loss: 0.7433, val_loss: 1.0124, val_acc: 0.6680\n",
      "Epoch [32], last_lr: 0.00273, train_loss: 0.6889, val_loss: 0.9727, val_acc: 0.6700\n",
      "Epoch [33], last_lr: 0.00284, train_loss: 0.6584, val_loss: 0.9396, val_acc: 0.6780\n",
      "Epoch [34], last_lr: 0.00294, train_loss: 0.6163, val_loss: 0.9130, val_acc: 0.6860\n",
      "Epoch [35], last_lr: 0.00304, train_loss: 0.5921, val_loss: 0.9030, val_acc: 0.6960\n",
      "Epoch [36], last_lr: 0.00313, train_loss: 0.5893, val_loss: 0.8751, val_acc: 0.6920\n",
      "Epoch [37], last_lr: 0.00322, train_loss: 0.5566, val_loss: 0.8609, val_acc: 0.7040\n",
      "Epoch [38], last_lr: 0.00331, train_loss: 0.5378, val_loss: 0.8439, val_acc: 0.7000\n",
      "Epoch [39], last_lr: 0.00339, train_loss: 0.5485, val_loss: 0.8339, val_acc: 0.7100\n",
      "Epoch [40], last_lr: 0.00347, train_loss: 0.5406, val_loss: 0.8318, val_acc: 0.7160\n",
      "Epoch [41], last_lr: 0.00355, train_loss: 0.5172, val_loss: 0.8182, val_acc: 0.7120\n",
      "Epoch [42], last_lr: 0.00362, train_loss: 0.4919, val_loss: 0.8211, val_acc: 0.7220\n",
      "Epoch [43], last_lr: 0.00368, train_loss: 0.4977, val_loss: 0.8069, val_acc: 0.7080\n",
      "Epoch [44], last_lr: 0.00374, train_loss: 0.5162, val_loss: 0.8123, val_acc: 0.7300\n",
      "Epoch [45], last_lr: 0.00379, train_loss: 0.4958, val_loss: 0.7904, val_acc: 0.7220\n",
      "Epoch [46], last_lr: 0.00384, train_loss: 0.5062, val_loss: 0.7994, val_acc: 0.7260\n",
      "Epoch [47], last_lr: 0.00388, train_loss: 0.4815, val_loss: 0.8043, val_acc: 0.7180\n",
      "Epoch [48], last_lr: 0.00392, train_loss: 0.5036, val_loss: 0.7885, val_acc: 0.7320\n",
      "Epoch [49], last_lr: 0.00395, train_loss: 0.4676, val_loss: 0.7895, val_acc: 0.7260\n",
      "Epoch [50], last_lr: 0.00397, train_loss: 0.4992, val_loss: 0.7979, val_acc: 0.6980\n",
      "Epoch [51], last_lr: 0.00399, train_loss: 0.4903, val_loss: 0.8119, val_acc: 0.7220\n",
      "Epoch [52], last_lr: 0.00400, train_loss: 0.4689, val_loss: 0.7899, val_acc: 0.7200\n",
      "Epoch [53], last_lr: 0.00400, train_loss: 0.4904, val_loss: 0.7928, val_acc: 0.7360\n",
      "Epoch [54], last_lr: 0.00400, train_loss: 0.4935, val_loss: 0.7970, val_acc: 0.7200\n",
      "Epoch [55], last_lr: 0.00400, train_loss: 0.4791, val_loss: 0.8021, val_acc: 0.7280\n",
      "Epoch [56], last_lr: 0.00399, train_loss: 0.4759, val_loss: 0.8044, val_acc: 0.7200\n",
      "Epoch [57], last_lr: 0.00399, train_loss: 0.4999, val_loss: 0.7778, val_acc: 0.7320\n",
      "Epoch [58], last_lr: 0.00398, train_loss: 0.4767, val_loss: 0.7734, val_acc: 0.7160\n",
      "Epoch [59], last_lr: 0.00398, train_loss: 0.4557, val_loss: 0.7715, val_acc: 0.7400\n",
      "Epoch [60], last_lr: 0.00397, train_loss: 0.4647, val_loss: 0.7677, val_acc: 0.7300\n",
      "Epoch [61], last_lr: 0.00396, train_loss: 0.4931, val_loss: 0.7910, val_acc: 0.7160\n",
      "Epoch [62], last_lr: 0.00395, train_loss: 0.4809, val_loss: 0.7717, val_acc: 0.7360\n",
      "Epoch [63], last_lr: 0.00394, train_loss: 0.4560, val_loss: 0.7612, val_acc: 0.7300\n",
      "Epoch [64], last_lr: 0.00393, train_loss: 0.4609, val_loss: 0.7789, val_acc: 0.7340\n",
      "Epoch [65], last_lr: 0.00391, train_loss: 0.4616, val_loss: 0.7584, val_acc: 0.7340\n",
      "Epoch [66], last_lr: 0.00390, train_loss: 0.4524, val_loss: 0.7767, val_acc: 0.7180\n",
      "Epoch [67], last_lr: 0.00388, train_loss: 0.4817, val_loss: 0.7568, val_acc: 0.7320\n",
      "Epoch [68], last_lr: 0.00386, train_loss: 0.4613, val_loss: 0.7611, val_acc: 0.7360\n",
      "Epoch [69], last_lr: 0.00384, train_loss: 0.4532, val_loss: 0.7617, val_acc: 0.7380\n",
      "Epoch [70], last_lr: 0.00382, train_loss: 0.4578, val_loss: 0.7789, val_acc: 0.7100\n",
      "Epoch [71], last_lr: 0.00380, train_loss: 0.4937, val_loss: 0.7708, val_acc: 0.7280\n",
      "Epoch [72], last_lr: 0.00378, train_loss: 0.4684, val_loss: 0.7618, val_acc: 0.7240\n",
      "Epoch [73], last_lr: 0.00376, train_loss: 0.4778, val_loss: 0.7906, val_acc: 0.7240\n",
      "Epoch [74], last_lr: 0.00373, train_loss: 0.4623, val_loss: 0.7661, val_acc: 0.7220\n",
      "Epoch [75], last_lr: 0.00371, train_loss: 0.4418, val_loss: 0.7593, val_acc: 0.7300\n",
      "Epoch [76], last_lr: 0.00368, train_loss: 0.4630, val_loss: 0.7610, val_acc: 0.7260\n",
      "Epoch [77], last_lr: 0.00365, train_loss: 0.4524, val_loss: 0.7502, val_acc: 0.7180\n",
      "Epoch [78], last_lr: 0.00362, train_loss: 0.4487, val_loss: 0.7519, val_acc: 0.7340\n",
      "Epoch [79], last_lr: 0.00359, train_loss: 0.4579, val_loss: 0.7618, val_acc: 0.7260\n",
      "Epoch [80], last_lr: 0.00356, train_loss: 0.4531, val_loss: 0.7651, val_acc: 0.7400\n",
      "Epoch [81], last_lr: 0.00353, train_loss: 0.4496, val_loss: 0.7512, val_acc: 0.7260\n",
      "Epoch [82], last_lr: 0.00350, train_loss: 0.4516, val_loss: 0.7494, val_acc: 0.7340\n",
      "Epoch [83], last_lr: 0.00347, train_loss: 0.4507, val_loss: 0.7598, val_acc: 0.7300\n",
      "Epoch [84], last_lr: 0.00343, train_loss: 0.4771, val_loss: 0.7590, val_acc: 0.7300\n",
      "Epoch [85], last_lr: 0.00340, train_loss: 0.4443, val_loss: 0.7503, val_acc: 0.7360\n",
      "Epoch [86], last_lr: 0.00336, train_loss: 0.4527, val_loss: 0.7493, val_acc: 0.7300\n",
      "Epoch [87], last_lr: 0.00332, train_loss: 0.4814, val_loss: 0.7564, val_acc: 0.7400\n",
      "Epoch [88], last_lr: 0.00329, train_loss: 0.4483, val_loss: 0.7550, val_acc: 0.7400\n",
      "Epoch [89], last_lr: 0.00325, train_loss: 0.4501, val_loss: 0.7530, val_acc: 0.7320\n",
      "Epoch [90], last_lr: 0.00321, train_loss: 0.4561, val_loss: 0.7662, val_acc: 0.7420\n",
      "Epoch [91], last_lr: 0.00317, train_loss: 0.4418, val_loss: 0.7522, val_acc: 0.7240\n",
      "Epoch [92], last_lr: 0.00313, train_loss: 0.4402, val_loss: 0.7474, val_acc: 0.7440\n",
      "Epoch [93], last_lr: 0.00309, train_loss: 0.4482, val_loss: 0.7529, val_acc: 0.7360\n",
      "Epoch [94], last_lr: 0.00304, train_loss: 0.4453, val_loss: 0.7492, val_acc: 0.7380\n",
      "Epoch [95], last_lr: 0.00300, train_loss: 0.4545, val_loss: 0.7480, val_acc: 0.7300\n",
      "Epoch [96], last_lr: 0.00296, train_loss: 0.4405, val_loss: 0.7457, val_acc: 0.7320\n",
      "Epoch [97], last_lr: 0.00291, train_loss: 0.4486, val_loss: 0.7435, val_acc: 0.7420\n",
      "Epoch [98], last_lr: 0.00287, train_loss: 0.4432, val_loss: 0.7421, val_acc: 0.7360\n",
      "Epoch [99], last_lr: 0.00282, train_loss: 0.4415, val_loss: 0.7473, val_acc: 0.7400\n",
      "Epoch [100], last_lr: 0.00278, train_loss: 0.4476, val_loss: 0.7423, val_acc: 0.7340\n",
      "Epoch [101], last_lr: 0.00273, train_loss: 0.4314, val_loss: 0.7545, val_acc: 0.7380\n",
      "Epoch [102], last_lr: 0.00268, train_loss: 0.4535, val_loss: 0.7513, val_acc: 0.7220\n",
      "Epoch [103], last_lr: 0.00264, train_loss: 0.4417, val_loss: 0.7506, val_acc: 0.7380\n",
      "Epoch [104], last_lr: 0.00259, train_loss: 0.4576, val_loss: 0.7454, val_acc: 0.7320\n",
      "Epoch [105], last_lr: 0.00254, train_loss: 0.4402, val_loss: 0.7447, val_acc: 0.7320\n",
      "Epoch [106], last_lr: 0.00249, train_loss: 0.4474, val_loss: 0.7534, val_acc: 0.7500\n",
      "Epoch [107], last_lr: 0.00245, train_loss: 0.4432, val_loss: 0.7484, val_acc: 0.7260\n",
      "Epoch [108], last_lr: 0.00240, train_loss: 0.4520, val_loss: 0.7553, val_acc: 0.7440\n",
      "Epoch [109], last_lr: 0.00235, train_loss: 0.4481, val_loss: 0.7537, val_acc: 0.7200\n",
      "Epoch [110], last_lr: 0.00230, train_loss: 0.4403, val_loss: 0.7526, val_acc: 0.7400\n",
      "Epoch [111], last_lr: 0.00225, train_loss: 0.4286, val_loss: 0.7533, val_acc: 0.7320\n",
      "Epoch [112], last_lr: 0.00220, train_loss: 0.4461, val_loss: 0.7536, val_acc: 0.7340\n",
      "Epoch [113], last_lr: 0.00215, train_loss: 0.4458, val_loss: 0.7459, val_acc: 0.7360\n",
      "Epoch [114], last_lr: 0.00210, train_loss: 0.4556, val_loss: 0.7461, val_acc: 0.7360\n",
      "Epoch [115], last_lr: 0.00205, train_loss: 0.4679, val_loss: 0.7425, val_acc: 0.7340\n",
      "Epoch [116], last_lr: 0.00200, train_loss: 0.4417, val_loss: 0.7416, val_acc: 0.7280\n",
      "Epoch [117], last_lr: 0.00195, train_loss: 0.4311, val_loss: 0.7460, val_acc: 0.7400\n",
      "Epoch [118], last_lr: 0.00190, train_loss: 0.4226, val_loss: 0.7442, val_acc: 0.7360\n",
      "Epoch [119], last_lr: 0.00185, train_loss: 0.4415, val_loss: 0.7546, val_acc: 0.7340\n",
      "Epoch [120], last_lr: 0.00180, train_loss: 0.4262, val_loss: 0.7512, val_acc: 0.7300\n",
      "Epoch [121], last_lr: 0.00175, train_loss: 0.4379, val_loss: 0.7461, val_acc: 0.7300\n",
      "Epoch [122], last_lr: 0.00170, train_loss: 0.4348, val_loss: 0.7468, val_acc: 0.7420\n",
      "Epoch [123], last_lr: 0.00165, train_loss: 0.4191, val_loss: 0.7420, val_acc: 0.7380\n",
      "Epoch [124], last_lr: 0.00160, train_loss: 0.4313, val_loss: 0.7437, val_acc: 0.7440\n",
      "Epoch [125], last_lr: 0.00155, train_loss: 0.4329, val_loss: 0.7452, val_acc: 0.7400\n",
      "Epoch [126], last_lr: 0.00151, train_loss: 0.4400, val_loss: 0.7439, val_acc: 0.7340\n",
      "Epoch [127], last_lr: 0.00146, train_loss: 0.4568, val_loss: 0.7390, val_acc: 0.7440\n",
      "Epoch [128], last_lr: 0.00141, train_loss: 0.4450, val_loss: 0.7441, val_acc: 0.7380\n",
      "Epoch [129], last_lr: 0.00136, train_loss: 0.4431, val_loss: 0.7426, val_acc: 0.7380\n",
      "Epoch [130], last_lr: 0.00132, train_loss: 0.4320, val_loss: 0.7413, val_acc: 0.7320\n",
      "Epoch [131], last_lr: 0.00127, train_loss: 0.4375, val_loss: 0.7407, val_acc: 0.7340\n",
      "Epoch [132], last_lr: 0.00122, train_loss: 0.4258, val_loss: 0.7426, val_acc: 0.7360\n",
      "Epoch [133], last_lr: 0.00118, train_loss: 0.4390, val_loss: 0.7426, val_acc: 0.7320\n",
      "Epoch [134], last_lr: 0.00113, train_loss: 0.4364, val_loss: 0.7435, val_acc: 0.7320\n",
      "Epoch [135], last_lr: 0.00109, train_loss: 0.4503, val_loss: 0.7451, val_acc: 0.7340\n",
      "Epoch [136], last_lr: 0.00104, train_loss: 0.4166, val_loss: 0.7439, val_acc: 0.7460\n",
      "Epoch [137], last_lr: 0.00100, train_loss: 0.4525, val_loss: 0.7457, val_acc: 0.7320\n",
      "Epoch [138], last_lr: 0.00096, train_loss: 0.4402, val_loss: 0.7441, val_acc: 0.7380\n",
      "Epoch [139], last_lr: 0.00091, train_loss: 0.4459, val_loss: 0.7474, val_acc: 0.7380\n",
      "Epoch [140], last_lr: 0.00087, train_loss: 0.4229, val_loss: 0.7424, val_acc: 0.7320\n",
      "Epoch [141], last_lr: 0.00083, train_loss: 0.4233, val_loss: 0.7451, val_acc: 0.7360\n",
      "Epoch [142], last_lr: 0.00079, train_loss: 0.4341, val_loss: 0.7474, val_acc: 0.7440\n",
      "Epoch [143], last_lr: 0.00075, train_loss: 0.4399, val_loss: 0.7481, val_acc: 0.7340\n",
      "Epoch [144], last_lr: 0.00071, train_loss: 0.4309, val_loss: 0.7431, val_acc: 0.7380\n",
      "Epoch [145], last_lr: 0.00068, train_loss: 0.4229, val_loss: 0.7420, val_acc: 0.7340\n",
      "Epoch [146], last_lr: 0.00064, train_loss: 0.4211, val_loss: 0.7447, val_acc: 0.7380\n",
      "Epoch [147], last_lr: 0.00060, train_loss: 0.4255, val_loss: 0.7438, val_acc: 0.7420\n",
      "Epoch [148], last_lr: 0.00057, train_loss: 0.4450, val_loss: 0.7417, val_acc: 0.7380\n",
      "Epoch [149], last_lr: 0.00053, train_loss: 0.4279, val_loss: 0.7425, val_acc: 0.7380\n",
      "Epoch [150], last_lr: 0.00050, train_loss: 0.4166, val_loss: 0.7418, val_acc: 0.7400\n",
      "Epoch [151], last_lr: 0.00047, train_loss: 0.4447, val_loss: 0.7399, val_acc: 0.7360\n",
      "Epoch [152], last_lr: 0.00044, train_loss: 0.4184, val_loss: 0.7403, val_acc: 0.7400\n",
      "Epoch [153], last_lr: 0.00041, train_loss: 0.4238, val_loss: 0.7396, val_acc: 0.7420\n",
      "Epoch [154], last_lr: 0.00038, train_loss: 0.4334, val_loss: 0.7391, val_acc: 0.7420\n",
      "Epoch [155], last_lr: 0.00035, train_loss: 0.4356, val_loss: 0.7402, val_acc: 0.7420\n",
      "Epoch [156], last_lr: 0.00032, train_loss: 0.4463, val_loss: 0.7412, val_acc: 0.7420\n",
      "Epoch [157], last_lr: 0.00029, train_loss: 0.4166, val_loss: 0.7401, val_acc: 0.7420\n",
      "Epoch [158], last_lr: 0.00027, train_loss: 0.4258, val_loss: 0.7404, val_acc: 0.7420\n",
      "Epoch [159], last_lr: 0.00024, train_loss: 0.4486, val_loss: 0.7413, val_acc: 0.7420\n",
      "Epoch [160], last_lr: 0.00022, train_loss: 0.4399, val_loss: 0.7395, val_acc: 0.7380\n",
      "Epoch [161], last_lr: 0.00020, train_loss: 0.4311, val_loss: 0.7391, val_acc: 0.7400\n",
      "Epoch [162], last_lr: 0.00018, train_loss: 0.4156, val_loss: 0.7390, val_acc: 0.7420\n",
      "Epoch [163], last_lr: 0.00016, train_loss: 0.4313, val_loss: 0.7392, val_acc: 0.7380\n",
      "Epoch [164], last_lr: 0.00014, train_loss: 0.4249, val_loss: 0.7381, val_acc: 0.7400\n",
      "Epoch [165], last_lr: 0.00012, train_loss: 0.4122, val_loss: 0.7408, val_acc: 0.7400\n",
      "Epoch [166], last_lr: 0.00010, train_loss: 0.4396, val_loss: 0.7413, val_acc: 0.7380\n",
      "Epoch [167], last_lr: 0.00009, train_loss: 0.4455, val_loss: 0.7416, val_acc: 0.7360\n",
      "Epoch [168], last_lr: 0.00007, train_loss: 0.4040, val_loss: 0.7422, val_acc: 0.7380\n",
      "Epoch [169], last_lr: 0.00006, train_loss: 0.4184, val_loss: 0.7416, val_acc: 0.7360\n",
      "Epoch [170], last_lr: 0.00005, train_loss: 0.4214, val_loss: 0.7405, val_acc: 0.7380\n",
      "Epoch [171], last_lr: 0.00004, train_loss: 0.4287, val_loss: 0.7393, val_acc: 0.7420\n",
      "Epoch [172], last_lr: 0.00003, train_loss: 0.4474, val_loss: 0.7384, val_acc: 0.7440\n",
      "Epoch [173], last_lr: 0.00002, train_loss: 0.4400, val_loss: 0.7388, val_acc: 0.7460\n",
      "Epoch [174], last_lr: 0.00002, train_loss: 0.4410, val_loss: 0.7407, val_acc: 0.7420\n",
      "Epoch [175], last_lr: 0.00001, train_loss: 0.4217, val_loss: 0.7414, val_acc: 0.7400\n",
      "Epoch [176], last_lr: 0.00001, train_loss: 0.4355, val_loss: 0.7412, val_acc: 0.7380\n",
      "Epoch [177], last_lr: 0.00000, train_loss: 0.4489, val_loss: 0.7404, val_acc: 0.7380\n",
      "Epoch [178], last_lr: 0.00000, train_loss: 0.4259, val_loss: 0.7387, val_acc: 0.7420\n",
      "Epoch [179], last_lr: 0.00000, train_loss: 0.4320, val_loss: 0.7388, val_acc: 0.7400\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[{'val_loss': 15.47873592376709, 'val_acc': 0.13600000739097595}]\n",
      "Epoch [0], last_lr: 0.00016, train_loss: 15.2801, val_loss: 14.8505, val_acc: 0.1540\n",
      "Epoch [1], last_lr: 0.00017, train_loss: 14.7940, val_loss: 14.1982, val_acc: 0.1580\n",
      "Epoch [2], last_lr: 0.00019, train_loss: 14.3884, val_loss: 13.6209, val_acc: 0.1640\n",
      "Epoch [3], last_lr: 0.00021, train_loss: 13.8220, val_loss: 13.1267, val_acc: 0.1660\n",
      "Epoch [4], last_lr: 0.00024, train_loss: 13.2768, val_loss: 12.5599, val_acc: 0.1580\n",
      "Epoch [5], last_lr: 0.00027, train_loss: 12.7470, val_loss: 11.9806, val_acc: 0.1420\n",
      "Epoch [6], last_lr: 0.00031, train_loss: 12.1558, val_loss: 11.3605, val_acc: 0.1240\n",
      "Epoch [7], last_lr: 0.00036, train_loss: 11.5132, val_loss: 10.6971, val_acc: 0.1140\n",
      "Epoch [8], last_lr: 0.00041, train_loss: 10.7784, val_loss: 9.9567, val_acc: 0.1080\n",
      "Epoch [9], last_lr: 0.00047, train_loss: 10.0707, val_loss: 9.1897, val_acc: 0.1060\n",
      "Epoch [10], last_lr: 0.00053, train_loss: 9.2057, val_loss: 8.3779, val_acc: 0.1100\n",
      "Epoch [11], last_lr: 0.00060, train_loss: 8.4858, val_loss: 7.7191, val_acc: 0.1040\n",
      "Epoch [12], last_lr: 0.00068, train_loss: 7.7987, val_loss: 7.2414, val_acc: 0.1260\n",
      "Epoch [13], last_lr: 0.00075, train_loss: 7.3062, val_loss: 6.8351, val_acc: 0.1380\n",
      "Epoch [14], last_lr: 0.00084, train_loss: 6.9279, val_loss: 6.4179, val_acc: 0.1400\n",
      "Epoch [15], last_lr: 0.00092, train_loss: 6.4048, val_loss: 5.8673, val_acc: 0.1260\n",
      "Epoch [16], last_lr: 0.00102, train_loss: 5.8743, val_loss: 5.2335, val_acc: 0.1260\n",
      "Epoch [17], last_lr: 0.00111, train_loss: 5.2094, val_loss: 4.5909, val_acc: 0.1340\n",
      "Epoch [18], last_lr: 0.00121, train_loss: 4.6732, val_loss: 4.1772, val_acc: 0.1560\n",
      "Epoch [19], last_lr: 0.00131, train_loss: 4.3870, val_loss: 4.1223, val_acc: 0.1860\n",
      "Epoch [20], last_lr: 0.00141, train_loss: 4.2400, val_loss: 3.8381, val_acc: 0.1820\n",
      "Epoch [21], last_lr: 0.00152, train_loss: 3.8949, val_loss: 3.5897, val_acc: 0.1720\n",
      "Epoch [22], last_lr: 0.00163, train_loss: 3.6863, val_loss: 3.3282, val_acc: 0.1880\n",
      "Epoch [23], last_lr: 0.00174, train_loss: 3.3204, val_loss: 3.0222, val_acc: 0.2100\n",
      "Epoch [24], last_lr: 0.00185, train_loss: 3.0403, val_loss: 2.7466, val_acc: 0.2380\n",
      "Epoch [25], last_lr: 0.00196, train_loss: 2.7075, val_loss: 2.4882, val_acc: 0.2780\n",
      "Epoch [26], last_lr: 0.00207, train_loss: 2.4510, val_loss: 2.2177, val_acc: 0.3160\n",
      "Epoch [27], last_lr: 0.00218, train_loss: 2.1267, val_loss: 1.9950, val_acc: 0.3580\n",
      "Epoch [28], last_lr: 0.00230, train_loss: 1.8913, val_loss: 1.8110, val_acc: 0.3900\n",
      "Epoch [29], last_lr: 0.00241, train_loss: 1.6598, val_loss: 1.6461, val_acc: 0.4320\n",
      "Epoch [30], last_lr: 0.00252, train_loss: 1.5183, val_loss: 1.5172, val_acc: 0.4500\n",
      "Epoch [31], last_lr: 0.00262, train_loss: 1.3434, val_loss: 1.3949, val_acc: 0.4920\n",
      "Epoch [32], last_lr: 0.00273, train_loss: 1.2436, val_loss: 1.3040, val_acc: 0.5180\n",
      "Epoch [33], last_lr: 0.00284, train_loss: 1.1382, val_loss: 1.2347, val_acc: 0.5540\n",
      "Epoch [34], last_lr: 0.00294, train_loss: 1.0386, val_loss: 1.1828, val_acc: 0.5560\n",
      "Epoch [35], last_lr: 0.00304, train_loss: 0.9705, val_loss: 1.1471, val_acc: 0.5720\n",
      "Epoch [36], last_lr: 0.00313, train_loss: 0.9587, val_loss: 1.1140, val_acc: 0.5940\n",
      "Epoch [37], last_lr: 0.00322, train_loss: 0.9123, val_loss: 1.0789, val_acc: 0.5900\n",
      "Epoch [38], last_lr: 0.00331, train_loss: 0.8643, val_loss: 1.0691, val_acc: 0.6200\n",
      "Epoch [39], last_lr: 0.00339, train_loss: 0.8480, val_loss: 1.0393, val_acc: 0.6080\n",
      "Epoch [40], last_lr: 0.00347, train_loss: 0.8356, val_loss: 1.0422, val_acc: 0.6080\n",
      "Epoch [41], last_lr: 0.00355, train_loss: 0.8098, val_loss: 1.0141, val_acc: 0.6140\n",
      "Epoch [42], last_lr: 0.00362, train_loss: 0.8223, val_loss: 1.0167, val_acc: 0.6260\n",
      "Epoch [43], last_lr: 0.00368, train_loss: 0.7707, val_loss: 1.0088, val_acc: 0.6300\n",
      "Epoch [44], last_lr: 0.00374, train_loss: 0.7865, val_loss: 1.0108, val_acc: 0.6260\n",
      "Epoch [45], last_lr: 0.00379, train_loss: 0.7696, val_loss: 1.0008, val_acc: 0.6220\n",
      "Epoch [46], last_lr: 0.00384, train_loss: 0.7692, val_loss: 0.9974, val_acc: 0.6340\n",
      "Epoch [47], last_lr: 0.00388, train_loss: 0.7628, val_loss: 0.9839, val_acc: 0.6360\n",
      "Epoch [48], last_lr: 0.00392, train_loss: 0.7721, val_loss: 0.9717, val_acc: 0.6360\n",
      "Epoch [49], last_lr: 0.00395, train_loss: 0.7483, val_loss: 0.9970, val_acc: 0.6380\n",
      "Epoch [50], last_lr: 0.00397, train_loss: 0.7485, val_loss: 0.9625, val_acc: 0.6440\n",
      "Epoch [51], last_lr: 0.00399, train_loss: 0.7396, val_loss: 0.9791, val_acc: 0.6220\n",
      "Epoch [52], last_lr: 0.00400, train_loss: 0.7484, val_loss: 0.9624, val_acc: 0.6440\n",
      "Epoch [53], last_lr: 0.00400, train_loss: 0.7492, val_loss: 0.9895, val_acc: 0.6360\n",
      "Epoch [54], last_lr: 0.00400, train_loss: 0.7269, val_loss: 0.9551, val_acc: 0.6620\n",
      "Epoch [55], last_lr: 0.00400, train_loss: 0.7258, val_loss: 0.9519, val_acc: 0.6520\n",
      "Epoch [56], last_lr: 0.00399, train_loss: 0.7190, val_loss: 0.9478, val_acc: 0.6560\n",
      "Epoch [57], last_lr: 0.00399, train_loss: 0.7038, val_loss: 0.9805, val_acc: 0.6440\n",
      "Epoch [58], last_lr: 0.00398, train_loss: 0.7204, val_loss: 0.9630, val_acc: 0.6360\n",
      "Epoch [59], last_lr: 0.00398, train_loss: 0.7099, val_loss: 0.9446, val_acc: 0.6540\n",
      "Epoch [60], last_lr: 0.00397, train_loss: 0.7183, val_loss: 0.9674, val_acc: 0.6360\n",
      "Epoch [61], last_lr: 0.00396, train_loss: 0.7123, val_loss: 0.9520, val_acc: 0.6340\n",
      "Epoch [62], last_lr: 0.00395, train_loss: 0.7171, val_loss: 0.9604, val_acc: 0.6480\n",
      "Epoch [63], last_lr: 0.00394, train_loss: 0.7294, val_loss: 0.9992, val_acc: 0.6280\n",
      "Epoch [64], last_lr: 0.00393, train_loss: 0.7012, val_loss: 0.9675, val_acc: 0.6380\n",
      "Epoch [65], last_lr: 0.00391, train_loss: 0.7024, val_loss: 0.9475, val_acc: 0.6620\n",
      "Epoch [66], last_lr: 0.00390, train_loss: 0.7173, val_loss: 0.9779, val_acc: 0.6420\n",
      "Epoch [67], last_lr: 0.00388, train_loss: 0.6921, val_loss: 0.9422, val_acc: 0.6620\n",
      "Epoch [68], last_lr: 0.00386, train_loss: 0.6974, val_loss: 0.9435, val_acc: 0.6580\n",
      "Epoch [69], last_lr: 0.00384, train_loss: 0.7213, val_loss: 1.0023, val_acc: 0.6260\n",
      "Epoch [70], last_lr: 0.00382, train_loss: 0.6962, val_loss: 0.9448, val_acc: 0.6460\n",
      "Epoch [71], last_lr: 0.00380, train_loss: 0.6765, val_loss: 0.9473, val_acc: 0.6460\n",
      "Epoch [72], last_lr: 0.00378, train_loss: 0.6928, val_loss: 0.9744, val_acc: 0.6340\n",
      "Epoch [73], last_lr: 0.00376, train_loss: 0.6914, val_loss: 0.9406, val_acc: 0.6420\n",
      "Epoch [74], last_lr: 0.00373, train_loss: 0.7009, val_loss: 0.9690, val_acc: 0.6300\n",
      "Epoch [75], last_lr: 0.00371, train_loss: 0.6849, val_loss: 0.9430, val_acc: 0.6320\n",
      "Epoch [76], last_lr: 0.00368, train_loss: 0.6931, val_loss: 0.9476, val_acc: 0.6420\n",
      "Epoch [77], last_lr: 0.00365, train_loss: 0.6882, val_loss: 0.9758, val_acc: 0.6380\n",
      "Epoch [78], last_lr: 0.00362, train_loss: 0.7013, val_loss: 0.9466, val_acc: 0.6400\n",
      "Epoch [79], last_lr: 0.00359, train_loss: 0.7006, val_loss: 0.9368, val_acc: 0.6520\n",
      "Epoch [80], last_lr: 0.00356, train_loss: 0.6848, val_loss: 0.9788, val_acc: 0.6420\n",
      "Epoch [81], last_lr: 0.00353, train_loss: 0.6956, val_loss: 0.9387, val_acc: 0.6460\n",
      "Epoch [82], last_lr: 0.00350, train_loss: 0.6892, val_loss: 0.9399, val_acc: 0.6440\n",
      "Epoch [83], last_lr: 0.00347, train_loss: 0.6730, val_loss: 0.9445, val_acc: 0.6520\n",
      "Epoch [84], last_lr: 0.00343, train_loss: 0.6659, val_loss: 0.9552, val_acc: 0.6440\n",
      "Epoch [85], last_lr: 0.00340, train_loss: 0.6691, val_loss: 0.9669, val_acc: 0.6260\n",
      "Epoch [86], last_lr: 0.00336, train_loss: 0.6842, val_loss: 0.9618, val_acc: 0.6440\n",
      "Epoch [87], last_lr: 0.00332, train_loss: 0.6750, val_loss: 0.9637, val_acc: 0.6220\n",
      "Epoch [88], last_lr: 0.00329, train_loss: 0.6764, val_loss: 0.9493, val_acc: 0.6360\n",
      "Epoch [89], last_lr: 0.00325, train_loss: 0.6731, val_loss: 0.9595, val_acc: 0.6460\n",
      "Epoch [90], last_lr: 0.00321, train_loss: 0.6948, val_loss: 0.9383, val_acc: 0.6540\n",
      "Epoch [91], last_lr: 0.00317, train_loss: 0.6765, val_loss: 0.9400, val_acc: 0.6540\n",
      "Epoch [92], last_lr: 0.00313, train_loss: 0.6725, val_loss: 0.9384, val_acc: 0.6640\n",
      "Epoch [93], last_lr: 0.00309, train_loss: 0.6783, val_loss: 0.9593, val_acc: 0.6520\n",
      "Epoch [94], last_lr: 0.00304, train_loss: 0.6954, val_loss: 0.9513, val_acc: 0.6580\n",
      "Epoch [95], last_lr: 0.00300, train_loss: 0.6786, val_loss: 0.9606, val_acc: 0.6580\n",
      "Epoch [96], last_lr: 0.00296, train_loss: 0.6745, val_loss: 0.9470, val_acc: 0.6540\n",
      "Epoch [97], last_lr: 0.00291, train_loss: 0.6905, val_loss: 0.9817, val_acc: 0.6340\n",
      "Epoch [98], last_lr: 0.00287, train_loss: 0.6761, val_loss: 0.9491, val_acc: 0.6520\n",
      "Epoch [99], last_lr: 0.00282, train_loss: 0.6905, val_loss: 0.9596, val_acc: 0.6520\n",
      "Epoch [100], last_lr: 0.00278, train_loss: 0.6703, val_loss: 0.9467, val_acc: 0.6560\n",
      "Epoch [101], last_lr: 0.00273, train_loss: 0.6717, val_loss: 0.9523, val_acc: 0.6580\n",
      "Epoch [102], last_lr: 0.00268, train_loss: 0.6732, val_loss: 0.9457, val_acc: 0.6560\n",
      "Epoch [103], last_lr: 0.00264, train_loss: 0.6593, val_loss: 0.9489, val_acc: 0.6520\n",
      "Epoch [104], last_lr: 0.00259, train_loss: 0.6762, val_loss: 0.9520, val_acc: 0.6540\n",
      "Epoch [105], last_lr: 0.00254, train_loss: 0.6669, val_loss: 0.9489, val_acc: 0.6540\n",
      "Epoch [106], last_lr: 0.00249, train_loss: 0.6604, val_loss: 0.9739, val_acc: 0.6400\n",
      "Epoch [107], last_lr: 0.00245, train_loss: 0.6790, val_loss: 0.9633, val_acc: 0.6480\n",
      "Epoch [108], last_lr: 0.00240, train_loss: 0.6791, val_loss: 0.9641, val_acc: 0.6420\n",
      "Epoch [109], last_lr: 0.00235, train_loss: 0.6863, val_loss: 0.9801, val_acc: 0.6420\n",
      "Epoch [110], last_lr: 0.00230, train_loss: 0.6935, val_loss: 0.9642, val_acc: 0.6520\n",
      "Epoch [111], last_lr: 0.00225, train_loss: 0.6866, val_loss: 0.9628, val_acc: 0.6540\n",
      "Epoch [112], last_lr: 0.00220, train_loss: 0.6549, val_loss: 0.9533, val_acc: 0.6500\n",
      "Epoch [113], last_lr: 0.00215, train_loss: 0.7012, val_loss: 0.9747, val_acc: 0.6400\n",
      "Epoch [114], last_lr: 0.00210, train_loss: 0.6740, val_loss: 0.9471, val_acc: 0.6520\n",
      "Epoch [115], last_lr: 0.00205, train_loss: 0.6984, val_loss: 0.9515, val_acc: 0.6560\n",
      "Epoch [116], last_lr: 0.00200, train_loss: 0.6809, val_loss: 0.9529, val_acc: 0.6520\n",
      "Epoch [117], last_lr: 0.00195, train_loss: 0.6665, val_loss: 0.9458, val_acc: 0.6640\n",
      "Epoch [118], last_lr: 0.00190, train_loss: 0.6714, val_loss: 0.9544, val_acc: 0.6540\n",
      "Epoch [119], last_lr: 0.00185, train_loss: 0.6634, val_loss: 0.9510, val_acc: 0.6500\n",
      "Epoch [120], last_lr: 0.00180, train_loss: 0.6746, val_loss: 0.9525, val_acc: 0.6480\n",
      "Epoch [121], last_lr: 0.00175, train_loss: 0.6568, val_loss: 0.9478, val_acc: 0.6600\n",
      "Epoch [122], last_lr: 0.00170, train_loss: 0.6805, val_loss: 0.9469, val_acc: 0.6660\n",
      "Epoch [123], last_lr: 0.00165, train_loss: 0.6777, val_loss: 0.9493, val_acc: 0.6560\n",
      "Epoch [124], last_lr: 0.00160, train_loss: 0.6718, val_loss: 0.9431, val_acc: 0.6600\n",
      "Epoch [125], last_lr: 0.00155, train_loss: 0.6782, val_loss: 0.9521, val_acc: 0.6560\n",
      "Epoch [126], last_lr: 0.00151, train_loss: 0.6766, val_loss: 0.9394, val_acc: 0.6620\n",
      "Epoch [127], last_lr: 0.00146, train_loss: 0.6720, val_loss: 0.9482, val_acc: 0.6620\n",
      "Epoch [128], last_lr: 0.00141, train_loss: 0.6566, val_loss: 0.9440, val_acc: 0.6540\n",
      "Epoch [129], last_lr: 0.00136, train_loss: 0.6705, val_loss: 0.9402, val_acc: 0.6560\n",
      "Epoch [130], last_lr: 0.00132, train_loss: 0.6581, val_loss: 0.9497, val_acc: 0.6560\n",
      "Epoch [131], last_lr: 0.00127, train_loss: 0.6838, val_loss: 0.9426, val_acc: 0.6620\n",
      "Epoch [132], last_lr: 0.00122, train_loss: 0.6819, val_loss: 0.9451, val_acc: 0.6580\n",
      "Epoch [133], last_lr: 0.00118, train_loss: 0.6548, val_loss: 0.9524, val_acc: 0.6540\n",
      "Epoch [134], last_lr: 0.00113, train_loss: 0.6641, val_loss: 0.9499, val_acc: 0.6600\n",
      "Epoch [135], last_lr: 0.00109, train_loss: 0.6623, val_loss: 0.9542, val_acc: 0.6560\n",
      "Epoch [136], last_lr: 0.00104, train_loss: 0.6614, val_loss: 0.9440, val_acc: 0.6580\n",
      "Epoch [137], last_lr: 0.00100, train_loss: 0.6702, val_loss: 0.9465, val_acc: 0.6540\n",
      "Epoch [138], last_lr: 0.00096, train_loss: 0.6777, val_loss: 0.9603, val_acc: 0.6540\n",
      "Epoch [139], last_lr: 0.00091, train_loss: 0.6681, val_loss: 0.9491, val_acc: 0.6600\n",
      "Epoch [140], last_lr: 0.00087, train_loss: 0.6607, val_loss: 0.9499, val_acc: 0.6480\n",
      "Epoch [141], last_lr: 0.00083, train_loss: 0.6610, val_loss: 0.9555, val_acc: 0.6480\n",
      "Epoch [142], last_lr: 0.00079, train_loss: 0.6751, val_loss: 0.9519, val_acc: 0.6560\n",
      "Epoch [143], last_lr: 0.00075, train_loss: 0.6613, val_loss: 0.9492, val_acc: 0.6540\n",
      "Epoch [144], last_lr: 0.00071, train_loss: 0.6586, val_loss: 0.9513, val_acc: 0.6480\n",
      "Epoch [145], last_lr: 0.00068, train_loss: 0.6542, val_loss: 0.9567, val_acc: 0.6480\n",
      "Epoch [146], last_lr: 0.00064, train_loss: 0.6688, val_loss: 0.9535, val_acc: 0.6560\n",
      "Epoch [147], last_lr: 0.00060, train_loss: 0.6739, val_loss: 0.9537, val_acc: 0.6560\n",
      "Epoch [148], last_lr: 0.00057, train_loss: 0.6587, val_loss: 0.9544, val_acc: 0.6540\n",
      "Epoch [149], last_lr: 0.00053, train_loss: 0.6618, val_loss: 0.9568, val_acc: 0.6500\n",
      "Epoch [150], last_lr: 0.00050, train_loss: 0.6621, val_loss: 0.9573, val_acc: 0.6560\n",
      "Epoch [151], last_lr: 0.00047, train_loss: 0.6511, val_loss: 0.9542, val_acc: 0.6560\n",
      "Epoch [152], last_lr: 0.00044, train_loss: 0.6665, val_loss: 0.9524, val_acc: 0.6540\n",
      "Epoch [153], last_lr: 0.00041, train_loss: 0.6714, val_loss: 0.9543, val_acc: 0.6540\n",
      "Epoch [154], last_lr: 0.00038, train_loss: 0.6645, val_loss: 0.9545, val_acc: 0.6580\n",
      "Epoch [155], last_lr: 0.00035, train_loss: 0.6627, val_loss: 0.9560, val_acc: 0.6500\n",
      "Epoch [156], last_lr: 0.00032, train_loss: 0.6621, val_loss: 0.9568, val_acc: 0.6520\n",
      "Epoch [157], last_lr: 0.00029, train_loss: 0.6623, val_loss: 0.9558, val_acc: 0.6560\n",
      "Epoch [158], last_lr: 0.00027, train_loss: 0.6713, val_loss: 0.9558, val_acc: 0.6500\n",
      "Epoch [159], last_lr: 0.00024, train_loss: 0.6784, val_loss: 0.9559, val_acc: 0.6520\n",
      "Epoch [160], last_lr: 0.00022, train_loss: 0.6634, val_loss: 0.9555, val_acc: 0.6540\n",
      "Epoch [161], last_lr: 0.00020, train_loss: 0.6672, val_loss: 0.9540, val_acc: 0.6560\n",
      "Epoch [162], last_lr: 0.00018, train_loss: 0.6755, val_loss: 0.9520, val_acc: 0.6560\n",
      "Epoch [163], last_lr: 0.00016, train_loss: 0.6660, val_loss: 0.9530, val_acc: 0.6540\n",
      "Epoch [164], last_lr: 0.00014, train_loss: 0.6758, val_loss: 0.9527, val_acc: 0.6540\n",
      "Epoch [165], last_lr: 0.00012, train_loss: 0.6814, val_loss: 0.9516, val_acc: 0.6540\n",
      "Epoch [166], last_lr: 0.00010, train_loss: 0.6649, val_loss: 0.9525, val_acc: 0.6540\n",
      "Epoch [167], last_lr: 0.00009, train_loss: 0.6574, val_loss: 0.9546, val_acc: 0.6540\n",
      "Epoch [168], last_lr: 0.00007, train_loss: 0.6509, val_loss: 0.9547, val_acc: 0.6540\n",
      "Epoch [169], last_lr: 0.00006, train_loss: 0.6522, val_loss: 0.9545, val_acc: 0.6540\n",
      "Epoch [170], last_lr: 0.00005, train_loss: 0.6507, val_loss: 0.9524, val_acc: 0.6540\n",
      "Epoch [171], last_lr: 0.00004, train_loss: 0.6573, val_loss: 0.9528, val_acc: 0.6520\n",
      "Epoch [172], last_lr: 0.00003, train_loss: 0.6523, val_loss: 0.9534, val_acc: 0.6560\n",
      "Epoch [173], last_lr: 0.00002, train_loss: 0.6735, val_loss: 0.9543, val_acc: 0.6540\n",
      "Epoch [174], last_lr: 0.00002, train_loss: 0.6835, val_loss: 0.9582, val_acc: 0.6500\n",
      "Epoch [175], last_lr: 0.00001, train_loss: 0.6730, val_loss: 0.9575, val_acc: 0.6500\n",
      "Epoch [176], last_lr: 0.00001, train_loss: 0.6620, val_loss: 0.9552, val_acc: 0.6500\n",
      "Epoch [177], last_lr: 0.00000, train_loss: 0.6829, val_loss: 0.9531, val_acc: 0.6500\n",
      "Epoch [178], last_lr: 0.00000, train_loss: 0.6603, val_loss: 0.9526, val_acc: 0.6520\n",
      "Epoch [179], last_lr: 0.00000, train_loss: 0.6614, val_loss: 0.9533, val_acc: 0.6540\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[{'val_loss': 7.87351655960083, 'val_acc': 0.18799999356269836}]\n",
      "Epoch [0], last_lr: 0.00016, train_loss: 7.1970, val_loss: 6.8677, val_acc: 0.1660\n",
      "Epoch [1], last_lr: 0.00017, train_loss: 6.8504, val_loss: 6.4070, val_acc: 0.1520\n",
      "Epoch [2], last_lr: 0.00019, train_loss: 6.5152, val_loss: 6.0753, val_acc: 0.1560\n",
      "Epoch [3], last_lr: 0.00021, train_loss: 6.2016, val_loss: 5.7634, val_acc: 0.1460\n",
      "Epoch [4], last_lr: 0.00024, train_loss: 5.8435, val_loss: 5.4437, val_acc: 0.1460\n",
      "Epoch [5], last_lr: 0.00027, train_loss: 5.4240, val_loss: 5.0978, val_acc: 0.1540\n",
      "Epoch [6], last_lr: 0.00031, train_loss: 5.1402, val_loss: 4.7552, val_acc: 0.1540\n",
      "Epoch [7], last_lr: 0.00036, train_loss: 4.7326, val_loss: 4.4361, val_acc: 0.1640\n",
      "Epoch [8], last_lr: 0.00041, train_loss: 4.4316, val_loss: 4.1926, val_acc: 0.2020\n",
      "Epoch [9], last_lr: 0.00047, train_loss: 4.2051, val_loss: 3.9971, val_acc: 0.2260\n",
      "Epoch [10], last_lr: 0.00053, train_loss: 3.9232, val_loss: 3.7438, val_acc: 0.2360\n",
      "Epoch [11], last_lr: 0.00060, train_loss: 3.5777, val_loss: 3.4044, val_acc: 0.2560\n",
      "Epoch [12], last_lr: 0.00068, train_loss: 3.2960, val_loss: 3.1093, val_acc: 0.2780\n",
      "Epoch [13], last_lr: 0.00075, train_loss: 3.0737, val_loss: 2.9757, val_acc: 0.2660\n",
      "Epoch [14], last_lr: 0.00084, train_loss: 2.9843, val_loss: 2.8690, val_acc: 0.2740\n",
      "Epoch [15], last_lr: 0.00092, train_loss: 2.7834, val_loss: 2.6942, val_acc: 0.3140\n",
      "Epoch [16], last_lr: 0.00102, train_loss: 2.5802, val_loss: 2.5338, val_acc: 0.3260\n",
      "Epoch [17], last_lr: 0.00111, train_loss: 2.3971, val_loss: 2.3512, val_acc: 0.3520\n",
      "Epoch [18], last_lr: 0.00121, train_loss: 2.2036, val_loss: 2.1730, val_acc: 0.3960\n",
      "Epoch [19], last_lr: 0.00131, train_loss: 1.9678, val_loss: 2.0216, val_acc: 0.4260\n",
      "Epoch [20], last_lr: 0.00141, train_loss: 1.7694, val_loss: 1.8505, val_acc: 0.4580\n",
      "Epoch [21], last_lr: 0.00152, train_loss: 1.5558, val_loss: 1.7091, val_acc: 0.4980\n",
      "Epoch [22], last_lr: 0.00163, train_loss: 1.4173, val_loss: 1.5812, val_acc: 0.5320\n",
      "Epoch [23], last_lr: 0.00174, train_loss: 1.2471, val_loss: 1.4656, val_acc: 0.5520\n",
      "Epoch [24], last_lr: 0.00185, train_loss: 1.0907, val_loss: 1.3585, val_acc: 0.5840\n",
      "Epoch [25], last_lr: 0.00196, train_loss: 0.9926, val_loss: 1.2727, val_acc: 0.5980\n",
      "Epoch [26], last_lr: 0.00207, train_loss: 0.8662, val_loss: 1.1830, val_acc: 0.6180\n",
      "Epoch [27], last_lr: 0.00218, train_loss: 0.7877, val_loss: 1.1375, val_acc: 0.6360\n",
      "Epoch [28], last_lr: 0.00230, train_loss: 0.7243, val_loss: 1.0595, val_acc: 0.6460\n",
      "Epoch [29], last_lr: 0.00241, train_loss: 0.6595, val_loss: 1.0531, val_acc: 0.6580\n",
      "Epoch [30], last_lr: 0.00252, train_loss: 0.6180, val_loss: 0.9943, val_acc: 0.6640\n",
      "Epoch [31], last_lr: 0.00262, train_loss: 0.5514, val_loss: 0.9889, val_acc: 0.6780\n",
      "Epoch [32], last_lr: 0.00273, train_loss: 0.5500, val_loss: 0.9631, val_acc: 0.6820\n",
      "Epoch [33], last_lr: 0.00284, train_loss: 0.4963, val_loss: 0.9347, val_acc: 0.6960\n",
      "Epoch [34], last_lr: 0.00294, train_loss: 0.4694, val_loss: 0.9413, val_acc: 0.6880\n",
      "Epoch [35], last_lr: 0.00304, train_loss: 0.4583, val_loss: 0.9225, val_acc: 0.6980\n",
      "Epoch [36], last_lr: 0.00313, train_loss: 0.4438, val_loss: 0.9122, val_acc: 0.7000\n",
      "Epoch [37], last_lr: 0.00322, train_loss: 0.4286, val_loss: 0.8973, val_acc: 0.7000\n",
      "Epoch [38], last_lr: 0.00331, train_loss: 0.4239, val_loss: 0.8885, val_acc: 0.7040\n",
      "Epoch [39], last_lr: 0.00339, train_loss: 0.4084, val_loss: 0.8767, val_acc: 0.7080\n",
      "Epoch [40], last_lr: 0.00347, train_loss: 0.3903, val_loss: 0.8696, val_acc: 0.7120\n",
      "Epoch [41], last_lr: 0.00355, train_loss: 0.3888, val_loss: 0.8731, val_acc: 0.7180\n",
      "Epoch [42], last_lr: 0.00362, train_loss: 0.3917, val_loss: 0.8830, val_acc: 0.7040\n",
      "Epoch [43], last_lr: 0.00368, train_loss: 0.3816, val_loss: 0.8986, val_acc: 0.7040\n",
      "Epoch [44], last_lr: 0.00374, train_loss: 0.4038, val_loss: 0.8734, val_acc: 0.7140\n",
      "Epoch [45], last_lr: 0.00379, train_loss: 0.3696, val_loss: 0.8721, val_acc: 0.7140\n",
      "Epoch [46], last_lr: 0.00384, train_loss: 0.3903, val_loss: 0.8806, val_acc: 0.7100\n",
      "Epoch [47], last_lr: 0.00388, train_loss: 0.3902, val_loss: 0.8972, val_acc: 0.6940\n",
      "Epoch [48], last_lr: 0.00392, train_loss: 0.3812, val_loss: 0.9051, val_acc: 0.7000\n",
      "Epoch [49], last_lr: 0.00395, train_loss: 0.3785, val_loss: 0.8876, val_acc: 0.7040\n",
      "Epoch [50], last_lr: 0.00397, train_loss: 0.3615, val_loss: 0.8839, val_acc: 0.7040\n",
      "Epoch [51], last_lr: 0.00399, train_loss: 0.3636, val_loss: 0.8572, val_acc: 0.7180\n",
      "Epoch [52], last_lr: 0.00400, train_loss: 0.3635, val_loss: 0.8649, val_acc: 0.7040\n",
      "Epoch [53], last_lr: 0.00400, train_loss: 0.3550, val_loss: 0.8816, val_acc: 0.7140\n",
      "Epoch [54], last_lr: 0.00400, train_loss: 0.3684, val_loss: 0.8760, val_acc: 0.7000\n",
      "Epoch [55], last_lr: 0.00400, train_loss: 0.3649, val_loss: 0.8765, val_acc: 0.7120\n",
      "Epoch [56], last_lr: 0.00399, train_loss: 0.3594, val_loss: 0.9011, val_acc: 0.7120\n",
      "Epoch [57], last_lr: 0.00399, train_loss: 0.3522, val_loss: 0.8633, val_acc: 0.7040\n",
      "Epoch [58], last_lr: 0.00398, train_loss: 0.3725, val_loss: 0.8736, val_acc: 0.6960\n",
      "Epoch [59], last_lr: 0.00398, train_loss: 0.3628, val_loss: 0.8590, val_acc: 0.7180\n",
      "Epoch [60], last_lr: 0.00397, train_loss: 0.3515, val_loss: 0.8647, val_acc: 0.7140\n",
      "Epoch [61], last_lr: 0.00396, train_loss: 0.3155, val_loss: 0.8601, val_acc: 0.7180\n",
      "Epoch [62], last_lr: 0.00395, train_loss: 0.3352, val_loss: 0.8584, val_acc: 0.7140\n",
      "Epoch [63], last_lr: 0.00394, train_loss: 0.3526, val_loss: 0.8618, val_acc: 0.7160\n",
      "Epoch [64], last_lr: 0.00393, train_loss: 0.3486, val_loss: 0.8566, val_acc: 0.7120\n",
      "Epoch [65], last_lr: 0.00391, train_loss: 0.3395, val_loss: 0.8471, val_acc: 0.7280\n",
      "Epoch [66], last_lr: 0.00390, train_loss: 0.3482, val_loss: 0.8527, val_acc: 0.7160\n",
      "Epoch [67], last_lr: 0.00388, train_loss: 0.3444, val_loss: 0.8426, val_acc: 0.7180\n",
      "Epoch [68], last_lr: 0.00386, train_loss: 0.3640, val_loss: 0.8877, val_acc: 0.7240\n",
      "Epoch [69], last_lr: 0.00384, train_loss: 0.3602, val_loss: 0.8599, val_acc: 0.7240\n",
      "Epoch [70], last_lr: 0.00382, train_loss: 0.3465, val_loss: 0.8480, val_acc: 0.7100\n",
      "Epoch [71], last_lr: 0.00380, train_loss: 0.3513, val_loss: 0.8524, val_acc: 0.7180\n",
      "Epoch [72], last_lr: 0.00378, train_loss: 0.3265, val_loss: 0.8812, val_acc: 0.7160\n",
      "Epoch [73], last_lr: 0.00376, train_loss: 0.3447, val_loss: 0.8839, val_acc: 0.7220\n",
      "Epoch [74], last_lr: 0.00373, train_loss: 0.3491, val_loss: 0.8850, val_acc: 0.7180\n",
      "Epoch [75], last_lr: 0.00371, train_loss: 0.3311, val_loss: 0.8710, val_acc: 0.7220\n",
      "Epoch [76], last_lr: 0.00368, train_loss: 0.3263, val_loss: 0.8655, val_acc: 0.7020\n",
      "Epoch [77], last_lr: 0.00365, train_loss: 0.3372, val_loss: 0.9276, val_acc: 0.7120\n",
      "Epoch [78], last_lr: 0.00362, train_loss: 0.3530, val_loss: 0.8875, val_acc: 0.7120\n",
      "Epoch [79], last_lr: 0.00359, train_loss: 0.3280, val_loss: 0.8801, val_acc: 0.7080\n",
      "Epoch [80], last_lr: 0.00356, train_loss: 0.3577, val_loss: 0.8870, val_acc: 0.7140\n",
      "Epoch [81], last_lr: 0.00353, train_loss: 0.3247, val_loss: 0.8652, val_acc: 0.7160\n",
      "Epoch [82], last_lr: 0.00350, train_loss: 0.3342, val_loss: 0.8602, val_acc: 0.7180\n",
      "Epoch [83], last_lr: 0.00347, train_loss: 0.3480, val_loss: 0.9082, val_acc: 0.7060\n",
      "Epoch [84], last_lr: 0.00343, train_loss: 0.3479, val_loss: 0.8966, val_acc: 0.7160\n",
      "Epoch [85], last_lr: 0.00340, train_loss: 0.3272, val_loss: 0.8642, val_acc: 0.7140\n",
      "Epoch [86], last_lr: 0.00336, train_loss: 0.3403, val_loss: 0.8975, val_acc: 0.7080\n",
      "Epoch [87], last_lr: 0.00332, train_loss: 0.3391, val_loss: 0.8877, val_acc: 0.7160\n",
      "Epoch [88], last_lr: 0.00329, train_loss: 0.3351, val_loss: 0.8810, val_acc: 0.7180\n",
      "Epoch [89], last_lr: 0.00325, train_loss: 0.3363, val_loss: 0.8543, val_acc: 0.7120\n",
      "Epoch [90], last_lr: 0.00321, train_loss: 0.3475, val_loss: 0.8690, val_acc: 0.7260\n",
      "Epoch [91], last_lr: 0.00317, train_loss: 0.3409, val_loss: 0.8429, val_acc: 0.7200\n",
      "Epoch [92], last_lr: 0.00313, train_loss: 0.3405, val_loss: 0.8428, val_acc: 0.7100\n",
      "Epoch [93], last_lr: 0.00309, train_loss: 0.3467, val_loss: 0.8654, val_acc: 0.7240\n",
      "Epoch [94], last_lr: 0.00304, train_loss: 0.3263, val_loss: 0.8522, val_acc: 0.7260\n",
      "Epoch [95], last_lr: 0.00300, train_loss: 0.3230, val_loss: 0.8566, val_acc: 0.7160\n",
      "Epoch [96], last_lr: 0.00296, train_loss: 0.3527, val_loss: 0.8820, val_acc: 0.7240\n",
      "Epoch [97], last_lr: 0.00291, train_loss: 0.3246, val_loss: 0.8512, val_acc: 0.7160\n",
      "Epoch [98], last_lr: 0.00287, train_loss: 0.3261, val_loss: 0.8538, val_acc: 0.7220\n",
      "Epoch [99], last_lr: 0.00282, train_loss: 0.3116, val_loss: 0.8535, val_acc: 0.7280\n",
      "Epoch [100], last_lr: 0.00278, train_loss: 0.3280, val_loss: 0.8490, val_acc: 0.7220\n",
      "Epoch [101], last_lr: 0.00273, train_loss: 0.3260, val_loss: 0.8633, val_acc: 0.7280\n",
      "Epoch [102], last_lr: 0.00268, train_loss: 0.3245, val_loss: 0.8606, val_acc: 0.7180\n",
      "Epoch [103], last_lr: 0.00264, train_loss: 0.3413, val_loss: 0.8654, val_acc: 0.7180\n",
      "Epoch [104], last_lr: 0.00259, train_loss: 0.3235, val_loss: 0.8717, val_acc: 0.7200\n",
      "Epoch [105], last_lr: 0.00254, train_loss: 0.3474, val_loss: 0.8648, val_acc: 0.7200\n",
      "Epoch [106], last_lr: 0.00249, train_loss: 0.3363, val_loss: 0.8655, val_acc: 0.7160\n",
      "Epoch [107], last_lr: 0.00245, train_loss: 0.3066, val_loss: 0.8931, val_acc: 0.7220\n",
      "Epoch [108], last_lr: 0.00240, train_loss: 0.3211, val_loss: 0.8675, val_acc: 0.7240\n",
      "Epoch [109], last_lr: 0.00235, train_loss: 0.3273, val_loss: 0.8715, val_acc: 0.7200\n",
      "Epoch [110], last_lr: 0.00230, train_loss: 0.3406, val_loss: 0.8653, val_acc: 0.7260\n",
      "Epoch [111], last_lr: 0.00225, train_loss: 0.3360, val_loss: 0.8753, val_acc: 0.7300\n",
      "Epoch [112], last_lr: 0.00220, train_loss: 0.3346, val_loss: 0.8771, val_acc: 0.7180\n",
      "Epoch [113], last_lr: 0.00215, train_loss: 0.3289, val_loss: 0.8793, val_acc: 0.7280\n",
      "Epoch [114], last_lr: 0.00210, train_loss: 0.3360, val_loss: 0.8685, val_acc: 0.7240\n",
      "Epoch [115], last_lr: 0.00205, train_loss: 0.3335, val_loss: 0.8723, val_acc: 0.7300\n",
      "Epoch [116], last_lr: 0.00200, train_loss: 0.3417, val_loss: 0.8542, val_acc: 0.7100\n",
      "Epoch [117], last_lr: 0.00195, train_loss: 0.3427, val_loss: 0.8639, val_acc: 0.7300\n",
      "Epoch [118], last_lr: 0.00190, train_loss: 0.3435, val_loss: 0.8747, val_acc: 0.7200\n",
      "Epoch [119], last_lr: 0.00185, train_loss: 0.3291, val_loss: 0.8519, val_acc: 0.7140\n",
      "Epoch [120], last_lr: 0.00180, train_loss: 0.3225, val_loss: 0.8666, val_acc: 0.7280\n",
      "Epoch [121], last_lr: 0.00175, train_loss: 0.3114, val_loss: 0.8654, val_acc: 0.7240\n",
      "Epoch [122], last_lr: 0.00170, train_loss: 0.3312, val_loss: 0.8630, val_acc: 0.7140\n",
      "Epoch [123], last_lr: 0.00165, train_loss: 0.3203, val_loss: 0.8852, val_acc: 0.7260\n",
      "Epoch [124], last_lr: 0.00160, train_loss: 0.3483, val_loss: 0.8762, val_acc: 0.7280\n",
      "Epoch [125], last_lr: 0.00155, train_loss: 0.3168, val_loss: 0.8612, val_acc: 0.7160\n",
      "Epoch [126], last_lr: 0.00151, train_loss: 0.3292, val_loss: 0.8838, val_acc: 0.7300\n",
      "Epoch [127], last_lr: 0.00146, train_loss: 0.3298, val_loss: 0.8694, val_acc: 0.7260\n",
      "Epoch [128], last_lr: 0.00141, train_loss: 0.3276, val_loss: 0.8675, val_acc: 0.7280\n",
      "Epoch [129], last_lr: 0.00136, train_loss: 0.3369, val_loss: 0.8838, val_acc: 0.7240\n",
      "Epoch [130], last_lr: 0.00132, train_loss: 0.3226, val_loss: 0.8640, val_acc: 0.7200\n",
      "Epoch [131], last_lr: 0.00127, train_loss: 0.3290, val_loss: 0.8918, val_acc: 0.7240\n",
      "Epoch [132], last_lr: 0.00122, train_loss: 0.3264, val_loss: 0.8756, val_acc: 0.7300\n",
      "Epoch [133], last_lr: 0.00118, train_loss: 0.3105, val_loss: 0.8644, val_acc: 0.7200\n",
      "Epoch [134], last_lr: 0.00113, train_loss: 0.3306, val_loss: 0.8725, val_acc: 0.7360\n",
      "Epoch [135], last_lr: 0.00109, train_loss: 0.3375, val_loss: 0.8646, val_acc: 0.7340\n",
      "Epoch [136], last_lr: 0.00104, train_loss: 0.3190, val_loss: 0.8620, val_acc: 0.7300\n",
      "Epoch [137], last_lr: 0.00100, train_loss: 0.3273, val_loss: 0.8679, val_acc: 0.7300\n",
      "Epoch [138], last_lr: 0.00096, train_loss: 0.3220, val_loss: 0.8573, val_acc: 0.7280\n",
      "Epoch [139], last_lr: 0.00091, train_loss: 0.3057, val_loss: 0.8623, val_acc: 0.7320\n",
      "Epoch [140], last_lr: 0.00087, train_loss: 0.3307, val_loss: 0.8621, val_acc: 0.7340\n",
      "Epoch [141], last_lr: 0.00083, train_loss: 0.3313, val_loss: 0.8586, val_acc: 0.7280\n",
      "Epoch [142], last_lr: 0.00079, train_loss: 0.3327, val_loss: 0.8646, val_acc: 0.7320\n",
      "Epoch [143], last_lr: 0.00075, train_loss: 0.3264, val_loss: 0.8699, val_acc: 0.7300\n",
      "Epoch [144], last_lr: 0.00071, train_loss: 0.3175, val_loss: 0.8655, val_acc: 0.7300\n",
      "Epoch [145], last_lr: 0.00068, train_loss: 0.3117, val_loss: 0.8614, val_acc: 0.7300\n",
      "Epoch [146], last_lr: 0.00064, train_loss: 0.3246, val_loss: 0.8668, val_acc: 0.7300\n",
      "Epoch [147], last_lr: 0.00060, train_loss: 0.3268, val_loss: 0.8622, val_acc: 0.7280\n",
      "Epoch [148], last_lr: 0.00057, train_loss: 0.3118, val_loss: 0.8592, val_acc: 0.7300\n",
      "Epoch [149], last_lr: 0.00053, train_loss: 0.3129, val_loss: 0.8628, val_acc: 0.7300\n",
      "Epoch [150], last_lr: 0.00050, train_loss: 0.3387, val_loss: 0.8689, val_acc: 0.7300\n",
      "Epoch [151], last_lr: 0.00047, train_loss: 0.3246, val_loss: 0.8629, val_acc: 0.7300\n",
      "Epoch [152], last_lr: 0.00044, train_loss: 0.3081, val_loss: 0.8612, val_acc: 0.7280\n",
      "Epoch [153], last_lr: 0.00041, train_loss: 0.3282, val_loss: 0.8638, val_acc: 0.7300\n",
      "Epoch [154], last_lr: 0.00038, train_loss: 0.3066, val_loss: 0.8623, val_acc: 0.7320\n",
      "Epoch [155], last_lr: 0.00035, train_loss: 0.3111, val_loss: 0.8640, val_acc: 0.7300\n",
      "Epoch [156], last_lr: 0.00032, train_loss: 0.2989, val_loss: 0.8625, val_acc: 0.7320\n",
      "Epoch [157], last_lr: 0.00029, train_loss: 0.3021, val_loss: 0.8625, val_acc: 0.7300\n",
      "Epoch [158], last_lr: 0.00027, train_loss: 0.3105, val_loss: 0.8615, val_acc: 0.7300\n",
      "Epoch [159], last_lr: 0.00024, train_loss: 0.3372, val_loss: 0.8585, val_acc: 0.7340\n",
      "Epoch [160], last_lr: 0.00022, train_loss: 0.3108, val_loss: 0.8593, val_acc: 0.7300\n",
      "Epoch [161], last_lr: 0.00020, train_loss: 0.3030, val_loss: 0.8613, val_acc: 0.7300\n",
      "Epoch [162], last_lr: 0.00018, train_loss: 0.3151, val_loss: 0.8609, val_acc: 0.7300\n",
      "Epoch [163], last_lr: 0.00016, train_loss: 0.3050, val_loss: 0.8623, val_acc: 0.7320\n",
      "Epoch [164], last_lr: 0.00014, train_loss: 0.3268, val_loss: 0.8641, val_acc: 0.7300\n",
      "Epoch [165], last_lr: 0.00012, train_loss: 0.3196, val_loss: 0.8619, val_acc: 0.7320\n",
      "Epoch [166], last_lr: 0.00010, train_loss: 0.3191, val_loss: 0.8637, val_acc: 0.7280\n",
      "Epoch [167], last_lr: 0.00009, train_loss: 0.3169, val_loss: 0.8620, val_acc: 0.7280\n",
      "Epoch [168], last_lr: 0.00007, train_loss: 0.3147, val_loss: 0.8605, val_acc: 0.7300\n",
      "Epoch [169], last_lr: 0.00006, train_loss: 0.2969, val_loss: 0.8617, val_acc: 0.7300\n",
      "Epoch [170], last_lr: 0.00005, train_loss: 0.3239, val_loss: 0.8609, val_acc: 0.7300\n",
      "Epoch [171], last_lr: 0.00004, train_loss: 0.3217, val_loss: 0.8616, val_acc: 0.7300\n",
      "Epoch [172], last_lr: 0.00003, train_loss: 0.3165, val_loss: 0.8635, val_acc: 0.7300\n",
      "Epoch [173], last_lr: 0.00002, train_loss: 0.3071, val_loss: 0.8610, val_acc: 0.7320\n",
      "Epoch [174], last_lr: 0.00002, train_loss: 0.3019, val_loss: 0.8618, val_acc: 0.7320\n",
      "Epoch [175], last_lr: 0.00001, train_loss: 0.3081, val_loss: 0.8622, val_acc: 0.7320\n",
      "Epoch [176], last_lr: 0.00001, train_loss: 0.3125, val_loss: 0.8620, val_acc: 0.7320\n",
      "Epoch [177], last_lr: 0.00000, train_loss: 0.3219, val_loss: 0.8627, val_acc: 0.7320\n",
      "Epoch [178], last_lr: 0.00000, train_loss: 0.3133, val_loss: 0.8613, val_acc: 0.7320\n",
      "Epoch [179], last_lr: 0.00000, train_loss: 0.3377, val_loss: 0.8610, val_acc: 0.7320\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[{'val_loss': 6.465752601623535, 'val_acc': 0.18400000035762787}]\n",
      "Epoch [0], last_lr: 0.00016, train_loss: 6.3935, val_loss: 6.0557, val_acc: 0.2200\n",
      "Epoch [1], last_lr: 0.00017, train_loss: 6.0682, val_loss: 5.8708, val_acc: 0.2340\n",
      "Epoch [2], last_lr: 0.00019, train_loss: 5.8275, val_loss: 5.6807, val_acc: 0.2260\n",
      "Epoch [3], last_lr: 0.00021, train_loss: 5.4803, val_loss: 5.4498, val_acc: 0.2100\n",
      "Epoch [4], last_lr: 0.00024, train_loss: 5.1754, val_loss: 5.1786, val_acc: 0.2180\n",
      "Epoch [5], last_lr: 0.00027, train_loss: 4.9344, val_loss: 4.9212, val_acc: 0.2220\n",
      "Epoch [6], last_lr: 0.00031, train_loss: 4.6788, val_loss: 4.6702, val_acc: 0.2160\n",
      "Epoch [7], last_lr: 0.00036, train_loss: 4.4534, val_loss: 4.4534, val_acc: 0.2240\n",
      "Epoch [8], last_lr: 0.00041, train_loss: 4.2171, val_loss: 4.2225, val_acc: 0.2080\n",
      "Epoch [9], last_lr: 0.00047, train_loss: 4.0126, val_loss: 3.9816, val_acc: 0.2020\n",
      "Epoch [10], last_lr: 0.00053, train_loss: 3.7504, val_loss: 3.7410, val_acc: 0.2080\n",
      "Epoch [11], last_lr: 0.00060, train_loss: 3.5127, val_loss: 3.5728, val_acc: 0.2140\n",
      "Epoch [12], last_lr: 0.00068, train_loss: 3.2948, val_loss: 3.5099, val_acc: 0.2100\n",
      "Epoch [13], last_lr: 0.00075, train_loss: 3.1300, val_loss: 3.4035, val_acc: 0.2140\n",
      "Epoch [14], last_lr: 0.00084, train_loss: 3.0136, val_loss: 3.1746, val_acc: 0.2400\n",
      "Epoch [15], last_lr: 0.00092, train_loss: 2.7416, val_loss: 2.9329, val_acc: 0.2620\n",
      "Epoch [16], last_lr: 0.00102, train_loss: 2.5249, val_loss: 2.7187, val_acc: 0.2860\n",
      "Epoch [17], last_lr: 0.00111, train_loss: 2.2960, val_loss: 2.5036, val_acc: 0.2940\n",
      "Epoch [18], last_lr: 0.00121, train_loss: 2.0771, val_loss: 2.3057, val_acc: 0.3320\n",
      "Epoch [19], last_lr: 0.00131, train_loss: 1.7979, val_loss: 2.0882, val_acc: 0.3660\n",
      "Epoch [20], last_lr: 0.00141, train_loss: 1.6034, val_loss: 1.8695, val_acc: 0.4160\n",
      "Epoch [21], last_lr: 0.00152, train_loss: 1.3686, val_loss: 1.6878, val_acc: 0.4660\n",
      "Epoch [22], last_lr: 0.00163, train_loss: 1.1727, val_loss: 1.5417, val_acc: 0.5120\n",
      "Epoch [23], last_lr: 0.00174, train_loss: 1.0272, val_loss: 1.3977, val_acc: 0.5500\n",
      "Epoch [24], last_lr: 0.00185, train_loss: 0.9084, val_loss: 1.2843, val_acc: 0.5620\n",
      "Epoch [25], last_lr: 0.00196, train_loss: 0.7939, val_loss: 1.1985, val_acc: 0.6140\n",
      "Epoch [26], last_lr: 0.00207, train_loss: 0.6854, val_loss: 1.1237, val_acc: 0.6380\n",
      "Epoch [27], last_lr: 0.00218, train_loss: 0.6103, val_loss: 1.0606, val_acc: 0.6580\n",
      "Epoch [28], last_lr: 0.00230, train_loss: 0.5501, val_loss: 1.0150, val_acc: 0.6660\n",
      "Epoch [29], last_lr: 0.00241, train_loss: 0.5132, val_loss: 0.9816, val_acc: 0.6700\n",
      "Epoch [30], last_lr: 0.00252, train_loss: 0.4572, val_loss: 0.9492, val_acc: 0.6720\n",
      "Epoch [31], last_lr: 0.00262, train_loss: 0.4578, val_loss: 0.9295, val_acc: 0.6800\n",
      "Epoch [32], last_lr: 0.00273, train_loss: 0.4319, val_loss: 0.9111, val_acc: 0.6880\n",
      "Epoch [33], last_lr: 0.00284, train_loss: 0.4061, val_loss: 0.8913, val_acc: 0.6960\n",
      "Epoch [34], last_lr: 0.00294, train_loss: 0.3973, val_loss: 0.8850, val_acc: 0.6900\n",
      "Epoch [35], last_lr: 0.00304, train_loss: 0.3900, val_loss: 0.8798, val_acc: 0.7020\n",
      "Epoch [36], last_lr: 0.00313, train_loss: 0.3800, val_loss: 0.8645, val_acc: 0.7040\n",
      "Epoch [37], last_lr: 0.00322, train_loss: 0.3499, val_loss: 0.8622, val_acc: 0.6920\n",
      "Epoch [38], last_lr: 0.00331, train_loss: 0.3548, val_loss: 0.8500, val_acc: 0.7060\n",
      "Epoch [39], last_lr: 0.00339, train_loss: 0.3358, val_loss: 0.8416, val_acc: 0.7040\n",
      "Epoch [40], last_lr: 0.00347, train_loss: 0.3256, val_loss: 0.8716, val_acc: 0.6920\n",
      "Epoch [41], last_lr: 0.00355, train_loss: 0.3367, val_loss: 0.8340, val_acc: 0.7160\n",
      "Epoch [42], last_lr: 0.00362, train_loss: 0.3188, val_loss: 0.8622, val_acc: 0.6960\n",
      "Epoch [43], last_lr: 0.00368, train_loss: 0.3050, val_loss: 0.8300, val_acc: 0.7200\n",
      "Epoch [44], last_lr: 0.00374, train_loss: 0.3086, val_loss: 0.8616, val_acc: 0.7080\n",
      "Epoch [45], last_lr: 0.00379, train_loss: 0.3143, val_loss: 0.8351, val_acc: 0.7180\n",
      "Epoch [46], last_lr: 0.00384, train_loss: 0.2966, val_loss: 0.8608, val_acc: 0.7040\n",
      "Epoch [47], last_lr: 0.00388, train_loss: 0.3109, val_loss: 0.8184, val_acc: 0.7180\n",
      "Epoch [48], last_lr: 0.00392, train_loss: 0.2885, val_loss: 0.8553, val_acc: 0.7060\n",
      "Epoch [49], last_lr: 0.00395, train_loss: 0.2999, val_loss: 0.8402, val_acc: 0.7180\n",
      "Epoch [50], last_lr: 0.00397, train_loss: 0.3017, val_loss: 0.8612, val_acc: 0.7180\n",
      "Epoch [51], last_lr: 0.00399, train_loss: 0.3016, val_loss: 0.8458, val_acc: 0.7180\n",
      "Epoch [52], last_lr: 0.00400, train_loss: 0.2991, val_loss: 0.8471, val_acc: 0.7240\n",
      "Epoch [53], last_lr: 0.00400, train_loss: 0.2950, val_loss: 0.8604, val_acc: 0.7160\n",
      "Epoch [54], last_lr: 0.00400, train_loss: 0.3015, val_loss: 0.8520, val_acc: 0.7240\n",
      "Epoch [55], last_lr: 0.00400, train_loss: 0.2866, val_loss: 0.8282, val_acc: 0.7280\n",
      "Epoch [56], last_lr: 0.00399, train_loss: 0.2700, val_loss: 0.8624, val_acc: 0.7180\n",
      "Epoch [57], last_lr: 0.00399, train_loss: 0.2865, val_loss: 0.8178, val_acc: 0.7320\n",
      "Epoch [58], last_lr: 0.00398, train_loss: 0.2935, val_loss: 0.8665, val_acc: 0.7120\n",
      "Epoch [59], last_lr: 0.00398, train_loss: 0.3050, val_loss: 0.8251, val_acc: 0.7280\n",
      "Epoch [60], last_lr: 0.00397, train_loss: 0.2892, val_loss: 0.8781, val_acc: 0.7100\n",
      "Epoch [61], last_lr: 0.00396, train_loss: 0.2781, val_loss: 0.8176, val_acc: 0.7340\n",
      "Epoch [62], last_lr: 0.00395, train_loss: 0.2848, val_loss: 0.8386, val_acc: 0.7240\n",
      "Epoch [63], last_lr: 0.00394, train_loss: 0.2955, val_loss: 0.8250, val_acc: 0.7300\n",
      "Epoch [64], last_lr: 0.00393, train_loss: 0.2763, val_loss: 0.8296, val_acc: 0.7200\n",
      "Epoch [65], last_lr: 0.00391, train_loss: 0.2753, val_loss: 0.8390, val_acc: 0.7220\n",
      "Epoch [66], last_lr: 0.00390, train_loss: 0.2806, val_loss: 0.8270, val_acc: 0.7260\n",
      "Epoch [67], last_lr: 0.00388, train_loss: 0.2825, val_loss: 0.8428, val_acc: 0.7260\n",
      "Epoch [68], last_lr: 0.00386, train_loss: 0.2776, val_loss: 0.8724, val_acc: 0.7220\n",
      "Epoch [69], last_lr: 0.00384, train_loss: 0.2779, val_loss: 0.8278, val_acc: 0.7240\n",
      "Epoch [70], last_lr: 0.00382, train_loss: 0.2874, val_loss: 0.8438, val_acc: 0.7120\n",
      "Epoch [71], last_lr: 0.00380, train_loss: 0.2690, val_loss: 0.8075, val_acc: 0.7460\n",
      "Epoch [72], last_lr: 0.00378, train_loss: 0.2633, val_loss: 0.8089, val_acc: 0.7460\n",
      "Epoch [73], last_lr: 0.00376, train_loss: 0.2771, val_loss: 0.8174, val_acc: 0.7380\n",
      "Epoch [74], last_lr: 0.00373, train_loss: 0.2754, val_loss: 0.8266, val_acc: 0.7340\n",
      "Epoch [75], last_lr: 0.00371, train_loss: 0.2708, val_loss: 0.8263, val_acc: 0.7300\n",
      "Epoch [76], last_lr: 0.00368, train_loss: 0.2590, val_loss: 0.8239, val_acc: 0.7420\n",
      "Epoch [77], last_lr: 0.00365, train_loss: 0.2637, val_loss: 0.8234, val_acc: 0.7340\n",
      "Epoch [78], last_lr: 0.00362, train_loss: 0.2651, val_loss: 0.8257, val_acc: 0.7440\n",
      "Epoch [79], last_lr: 0.00359, train_loss: 0.2517, val_loss: 0.8317, val_acc: 0.7380\n",
      "Epoch [80], last_lr: 0.00356, train_loss: 0.2640, val_loss: 0.8253, val_acc: 0.7400\n",
      "Epoch [81], last_lr: 0.00353, train_loss: 0.2695, val_loss: 0.8373, val_acc: 0.7220\n",
      "Epoch [82], last_lr: 0.00350, train_loss: 0.2736, val_loss: 0.8137, val_acc: 0.7400\n",
      "Epoch [83], last_lr: 0.00347, train_loss: 0.2645, val_loss: 0.8238, val_acc: 0.7300\n",
      "Epoch [84], last_lr: 0.00343, train_loss: 0.2553, val_loss: 0.8353, val_acc: 0.7220\n",
      "Epoch [85], last_lr: 0.00340, train_loss: 0.2641, val_loss: 0.8317, val_acc: 0.7360\n",
      "Epoch [86], last_lr: 0.00336, train_loss: 0.2479, val_loss: 0.8752, val_acc: 0.7180\n",
      "Epoch [87], last_lr: 0.00332, train_loss: 0.2704, val_loss: 0.8201, val_acc: 0.7400\n",
      "Epoch [88], last_lr: 0.00329, train_loss: 0.2654, val_loss: 0.8217, val_acc: 0.7300\n",
      "Epoch [89], last_lr: 0.00325, train_loss: 0.2457, val_loss: 0.8246, val_acc: 0.7400\n",
      "Epoch [90], last_lr: 0.00321, train_loss: 0.2567, val_loss: 0.8239, val_acc: 0.7420\n",
      "Epoch [91], last_lr: 0.00317, train_loss: 0.2772, val_loss: 0.8413, val_acc: 0.7340\n",
      "Epoch [92], last_lr: 0.00313, train_loss: 0.2681, val_loss: 0.8196, val_acc: 0.7420\n",
      "Epoch [93], last_lr: 0.00309, train_loss: 0.2688, val_loss: 0.8269, val_acc: 0.7320\n",
      "Epoch [94], last_lr: 0.00304, train_loss: 0.2528, val_loss: 0.8220, val_acc: 0.7440\n",
      "Epoch [95], last_lr: 0.00300, train_loss: 0.2584, val_loss: 0.8169, val_acc: 0.7400\n",
      "Epoch [96], last_lr: 0.00296, train_loss: 0.2730, val_loss: 0.8244, val_acc: 0.7360\n",
      "Epoch [97], last_lr: 0.00291, train_loss: 0.2649, val_loss: 0.8308, val_acc: 0.7280\n",
      "Epoch [98], last_lr: 0.00287, train_loss: 0.2704, val_loss: 0.8262, val_acc: 0.7380\n",
      "Epoch [99], last_lr: 0.00282, train_loss: 0.2610, val_loss: 0.8248, val_acc: 0.7360\n",
      "Epoch [100], last_lr: 0.00278, train_loss: 0.2650, val_loss: 0.8080, val_acc: 0.7260\n",
      "Epoch [101], last_lr: 0.00273, train_loss: 0.2572, val_loss: 0.8175, val_acc: 0.7440\n",
      "Epoch [102], last_lr: 0.00268, train_loss: 0.2623, val_loss: 0.8224, val_acc: 0.7240\n",
      "Epoch [103], last_lr: 0.00264, train_loss: 0.2612, val_loss: 0.8015, val_acc: 0.7460\n",
      "Epoch [104], last_lr: 0.00259, train_loss: 0.2580, val_loss: 0.8076, val_acc: 0.7440\n",
      "Epoch [105], last_lr: 0.00254, train_loss: 0.2612, val_loss: 0.8304, val_acc: 0.7340\n",
      "Epoch [106], last_lr: 0.00249, train_loss: 0.2518, val_loss: 0.8128, val_acc: 0.7260\n",
      "Epoch [107], last_lr: 0.00245, train_loss: 0.2500, val_loss: 0.8070, val_acc: 0.7500\n",
      "Epoch [108], last_lr: 0.00240, train_loss: 0.2574, val_loss: 0.8167, val_acc: 0.7220\n",
      "Epoch [109], last_lr: 0.00235, train_loss: 0.2387, val_loss: 0.8174, val_acc: 0.7420\n",
      "Epoch [110], last_lr: 0.00230, train_loss: 0.2534, val_loss: 0.8161, val_acc: 0.7280\n",
      "Epoch [111], last_lr: 0.00225, train_loss: 0.2453, val_loss: 0.8203, val_acc: 0.7460\n",
      "Epoch [112], last_lr: 0.00220, train_loss: 0.2479, val_loss: 0.8275, val_acc: 0.7220\n",
      "Epoch [113], last_lr: 0.00215, train_loss: 0.2529, val_loss: 0.8198, val_acc: 0.7380\n",
      "Epoch [114], last_lr: 0.00210, train_loss: 0.2512, val_loss: 0.8215, val_acc: 0.7280\n",
      "Epoch [115], last_lr: 0.00205, train_loss: 0.2550, val_loss: 0.8407, val_acc: 0.7400\n",
      "Epoch [116], last_lr: 0.00200, train_loss: 0.2381, val_loss: 0.8188, val_acc: 0.7320\n",
      "Epoch [117], last_lr: 0.00195, train_loss: 0.2410, val_loss: 0.8217, val_acc: 0.7440\n",
      "Epoch [118], last_lr: 0.00190, train_loss: 0.2388, val_loss: 0.8317, val_acc: 0.7380\n",
      "Epoch [119], last_lr: 0.00185, train_loss: 0.2419, val_loss: 0.8165, val_acc: 0.7320\n",
      "Epoch [120], last_lr: 0.00180, train_loss: 0.2388, val_loss: 0.8239, val_acc: 0.7420\n",
      "Epoch [121], last_lr: 0.00175, train_loss: 0.2399, val_loss: 0.8346, val_acc: 0.7420\n",
      "Epoch [122], last_lr: 0.00170, train_loss: 0.2412, val_loss: 0.8255, val_acc: 0.7420\n",
      "Epoch [123], last_lr: 0.00165, train_loss: 0.2470, val_loss: 0.8266, val_acc: 0.7240\n",
      "Epoch [124], last_lr: 0.00160, train_loss: 0.2547, val_loss: 0.8280, val_acc: 0.7400\n",
      "Epoch [125], last_lr: 0.00155, train_loss: 0.2416, val_loss: 0.8225, val_acc: 0.7400\n",
      "Epoch [126], last_lr: 0.00151, train_loss: 0.2429, val_loss: 0.8274, val_acc: 0.7340\n",
      "Epoch [127], last_lr: 0.00146, train_loss: 0.2399, val_loss: 0.8357, val_acc: 0.7300\n",
      "Epoch [128], last_lr: 0.00141, train_loss: 0.2550, val_loss: 0.8210, val_acc: 0.7440\n",
      "Epoch [129], last_lr: 0.00136, train_loss: 0.2579, val_loss: 0.8236, val_acc: 0.7400\n",
      "Epoch [130], last_lr: 0.00132, train_loss: 0.2542, val_loss: 0.8368, val_acc: 0.7360\n",
      "Epoch [131], last_lr: 0.00127, train_loss: 0.2312, val_loss: 0.8209, val_acc: 0.7400\n",
      "Epoch [132], last_lr: 0.00122, train_loss: 0.2377, val_loss: 0.8102, val_acc: 0.7380\n",
      "Epoch [133], last_lr: 0.00118, train_loss: 0.2470, val_loss: 0.8192, val_acc: 0.7380\n",
      "Epoch [134], last_lr: 0.00113, train_loss: 0.2340, val_loss: 0.8386, val_acc: 0.7400\n",
      "Epoch [135], last_lr: 0.00109, train_loss: 0.2465, val_loss: 0.8294, val_acc: 0.7340\n",
      "Epoch [136], last_lr: 0.00104, train_loss: 0.2388, val_loss: 0.8161, val_acc: 0.7320\n",
      "Epoch [137], last_lr: 0.00100, train_loss: 0.2511, val_loss: 0.8164, val_acc: 0.7420\n",
      "Epoch [138], last_lr: 0.00096, train_loss: 0.2236, val_loss: 0.8291, val_acc: 0.7440\n",
      "Epoch [139], last_lr: 0.00091, train_loss: 0.2416, val_loss: 0.8268, val_acc: 0.7360\n",
      "Epoch [140], last_lr: 0.00087, train_loss: 0.2474, val_loss: 0.8282, val_acc: 0.7280\n",
      "Epoch [141], last_lr: 0.00083, train_loss: 0.2529, val_loss: 0.8220, val_acc: 0.7340\n",
      "Epoch [142], last_lr: 0.00079, train_loss: 0.2441, val_loss: 0.8253, val_acc: 0.7380\n",
      "Epoch [143], last_lr: 0.00075, train_loss: 0.2410, val_loss: 0.8271, val_acc: 0.7340\n",
      "Epoch [144], last_lr: 0.00071, train_loss: 0.2382, val_loss: 0.8272, val_acc: 0.7300\n",
      "Epoch [145], last_lr: 0.00068, train_loss: 0.2394, val_loss: 0.8270, val_acc: 0.7360\n",
      "Epoch [146], last_lr: 0.00064, train_loss: 0.2421, val_loss: 0.8253, val_acc: 0.7420\n",
      "Epoch [147], last_lr: 0.00060, train_loss: 0.2447, val_loss: 0.8236, val_acc: 0.7360\n",
      "Epoch [148], last_lr: 0.00057, train_loss: 0.2471, val_loss: 0.8260, val_acc: 0.7320\n",
      "Epoch [149], last_lr: 0.00053, train_loss: 0.2481, val_loss: 0.8213, val_acc: 0.7360\n",
      "Epoch [150], last_lr: 0.00050, train_loss: 0.2340, val_loss: 0.8210, val_acc: 0.7400\n",
      "Epoch [151], last_lr: 0.00047, train_loss: 0.2409, val_loss: 0.8256, val_acc: 0.7360\n",
      "Epoch [152], last_lr: 0.00044, train_loss: 0.2375, val_loss: 0.8296, val_acc: 0.7300\n",
      "Epoch [153], last_lr: 0.00041, train_loss: 0.2439, val_loss: 0.8288, val_acc: 0.7300\n",
      "Epoch [154], last_lr: 0.00038, train_loss: 0.2518, val_loss: 0.8247, val_acc: 0.7360\n",
      "Epoch [155], last_lr: 0.00035, train_loss: 0.2420, val_loss: 0.8220, val_acc: 0.7380\n",
      "Epoch [156], last_lr: 0.00032, train_loss: 0.2420, val_loss: 0.8218, val_acc: 0.7380\n",
      "Epoch [157], last_lr: 0.00029, train_loss: 0.2347, val_loss: 0.8226, val_acc: 0.7400\n",
      "Epoch [158], last_lr: 0.00027, train_loss: 0.2418, val_loss: 0.8229, val_acc: 0.7360\n",
      "Epoch [159], last_lr: 0.00024, train_loss: 0.2115, val_loss: 0.8217, val_acc: 0.7360\n",
      "Epoch [160], last_lr: 0.00022, train_loss: 0.2320, val_loss: 0.8213, val_acc: 0.7400\n",
      "Epoch [161], last_lr: 0.00020, train_loss: 0.2393, val_loss: 0.8210, val_acc: 0.7420\n",
      "Epoch [162], last_lr: 0.00018, train_loss: 0.2471, val_loss: 0.8223, val_acc: 0.7380\n",
      "Epoch [163], last_lr: 0.00016, train_loss: 0.2464, val_loss: 0.8214, val_acc: 0.7340\n",
      "Epoch [164], last_lr: 0.00014, train_loss: 0.2532, val_loss: 0.8225, val_acc: 0.7360\n",
      "Epoch [165], last_lr: 0.00012, train_loss: 0.2384, val_loss: 0.8234, val_acc: 0.7340\n",
      "Epoch [166], last_lr: 0.00010, train_loss: 0.2563, val_loss: 0.8246, val_acc: 0.7320\n",
      "Epoch [167], last_lr: 0.00009, train_loss: 0.2464, val_loss: 0.8266, val_acc: 0.7320\n",
      "Epoch [168], last_lr: 0.00007, train_loss: 0.2488, val_loss: 0.8271, val_acc: 0.7340\n",
      "Epoch [169], last_lr: 0.00006, train_loss: 0.2404, val_loss: 0.8288, val_acc: 0.7340\n",
      "Epoch [170], last_lr: 0.00005, train_loss: 0.2508, val_loss: 0.8266, val_acc: 0.7300\n",
      "Epoch [171], last_lr: 0.00004, train_loss: 0.2361, val_loss: 0.8233, val_acc: 0.7300\n",
      "Epoch [172], last_lr: 0.00003, train_loss: 0.2434, val_loss: 0.8246, val_acc: 0.7340\n",
      "Epoch [173], last_lr: 0.00002, train_loss: 0.2397, val_loss: 0.8249, val_acc: 0.7340\n",
      "Epoch [174], last_lr: 0.00002, train_loss: 0.2389, val_loss: 0.8264, val_acc: 0.7320\n",
      "Epoch [175], last_lr: 0.00001, train_loss: 0.2368, val_loss: 0.8245, val_acc: 0.7340\n",
      "Epoch [176], last_lr: 0.00001, train_loss: 0.2416, val_loss: 0.8241, val_acc: 0.7340\n",
      "Epoch [177], last_lr: 0.00000, train_loss: 0.2440, val_loss: 0.8233, val_acc: 0.7340\n",
      "Epoch [178], last_lr: 0.00000, train_loss: 0.2390, val_loss: 0.8225, val_acc: 0.7340\n",
      "Epoch [179], last_lr: 0.00000, train_loss: 0.2440, val_loss: 0.8229, val_acc: 0.7280\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[{'val_loss': 19.253305435180664, 'val_acc': 0.15600000321865082}]\n",
      "Epoch [0], last_lr: 0.00016, train_loss: 17.7762, val_loss: 17.6689, val_acc: 0.1320\n",
      "Epoch [1], last_lr: 0.00017, train_loss: 17.4278, val_loss: 16.8483, val_acc: 0.1220\n",
      "Epoch [2], last_lr: 0.00019, train_loss: 16.9262, val_loss: 16.2658, val_acc: 0.1160\n",
      "Epoch [3], last_lr: 0.00021, train_loss: 16.5140, val_loss: 15.7143, val_acc: 0.1160\n",
      "Epoch [4], last_lr: 0.00024, train_loss: 16.0146, val_loss: 15.1249, val_acc: 0.1180\n",
      "Epoch [5], last_lr: 0.00027, train_loss: 15.3495, val_loss: 14.4935, val_acc: 0.1160\n",
      "Epoch [6], last_lr: 0.00031, train_loss: 14.6529, val_loss: 13.7713, val_acc: 0.1180\n",
      "Epoch [7], last_lr: 0.00036, train_loss: 13.9388, val_loss: 12.9408, val_acc: 0.1140\n",
      "Epoch [8], last_lr: 0.00041, train_loss: 13.0735, val_loss: 11.9827, val_acc: 0.1140\n",
      "Epoch [9], last_lr: 0.00047, train_loss: 11.9769, val_loss: 10.8892, val_acc: 0.1140\n",
      "Epoch [10], last_lr: 0.00053, train_loss: 10.8148, val_loss: 9.6429, val_acc: 0.1120\n",
      "Epoch [11], last_lr: 0.00060, train_loss: 9.5716, val_loss: 8.3490, val_acc: 0.1020\n",
      "Epoch [12], last_lr: 0.00068, train_loss: 8.3379, val_loss: 7.1810, val_acc: 0.0800\n",
      "Epoch [13], last_lr: 0.00075, train_loss: 7.2929, val_loss: 6.2817, val_acc: 0.1080\n",
      "Epoch [14], last_lr: 0.00084, train_loss: 6.4533, val_loss: 5.5325, val_acc: 0.1240\n",
      "Epoch [15], last_lr: 0.00092, train_loss: 5.7366, val_loss: 4.9890, val_acc: 0.1400\n",
      "Epoch [16], last_lr: 0.00102, train_loss: 5.2111, val_loss: 4.7894, val_acc: 0.1500\n",
      "Epoch [17], last_lr: 0.00111, train_loss: 4.9908, val_loss: 4.7581, val_acc: 0.1680\n",
      "Epoch [18], last_lr: 0.00121, train_loss: 4.7549, val_loss: 4.4925, val_acc: 0.1600\n",
      "Epoch [19], last_lr: 0.00131, train_loss: 4.4347, val_loss: 4.1351, val_acc: 0.1680\n",
      "Epoch [20], last_lr: 0.00141, train_loss: 4.0860, val_loss: 3.8245, val_acc: 0.1780\n",
      "Epoch [21], last_lr: 0.00152, train_loss: 3.7264, val_loss: 3.5259, val_acc: 0.2140\n",
      "Epoch [22], last_lr: 0.00163, train_loss: 3.3077, val_loss: 3.1897, val_acc: 0.2180\n",
      "Epoch [23], last_lr: 0.00174, train_loss: 2.9542, val_loss: 2.8351, val_acc: 0.2500\n",
      "Epoch [24], last_lr: 0.00185, train_loss: 2.5211, val_loss: 2.5177, val_acc: 0.3080\n",
      "Epoch [25], last_lr: 0.00196, train_loss: 2.1468, val_loss: 2.2155, val_acc: 0.3700\n",
      "Epoch [26], last_lr: 0.00207, train_loss: 1.7932, val_loss: 1.9450, val_acc: 0.4260\n",
      "Epoch [27], last_lr: 0.00218, train_loss: 1.4882, val_loss: 1.7229, val_acc: 0.4820\n",
      "Epoch [28], last_lr: 0.00230, train_loss: 1.1925, val_loss: 1.5244, val_acc: 0.5400\n",
      "Epoch [29], last_lr: 0.00241, train_loss: 0.9626, val_loss: 1.3613, val_acc: 0.5820\n",
      "Epoch [30], last_lr: 0.00252, train_loss: 0.8326, val_loss: 1.2330, val_acc: 0.6080\n",
      "Epoch [31], last_lr: 0.00262, train_loss: 0.7048, val_loss: 1.1349, val_acc: 0.6340\n",
      "Epoch [32], last_lr: 0.00273, train_loss: 0.5824, val_loss: 1.0609, val_acc: 0.6440\n",
      "Epoch [33], last_lr: 0.00284, train_loss: 0.5149, val_loss: 1.0125, val_acc: 0.6600\n",
      "Epoch [34], last_lr: 0.00294, train_loss: 0.4436, val_loss: 0.9730, val_acc: 0.6720\n",
      "Epoch [35], last_lr: 0.00304, train_loss: 0.4174, val_loss: 0.9468, val_acc: 0.6800\n",
      "Epoch [36], last_lr: 0.00313, train_loss: 0.3926, val_loss: 0.9234, val_acc: 0.6880\n",
      "Epoch [37], last_lr: 0.00322, train_loss: 0.3741, val_loss: 0.9056, val_acc: 0.6920\n",
      "Epoch [38], last_lr: 0.00331, train_loss: 0.3523, val_loss: 0.8966, val_acc: 0.6940\n",
      "Epoch [39], last_lr: 0.00339, train_loss: 0.3291, val_loss: 0.9018, val_acc: 0.7020\n",
      "Epoch [40], last_lr: 0.00347, train_loss: 0.3402, val_loss: 0.8836, val_acc: 0.7000\n",
      "Epoch [41], last_lr: 0.00355, train_loss: 0.3117, val_loss: 0.8854, val_acc: 0.6980\n",
      "Epoch [42], last_lr: 0.00362, train_loss: 0.3181, val_loss: 0.8860, val_acc: 0.7020\n",
      "Epoch [43], last_lr: 0.00368, train_loss: 0.3123, val_loss: 0.8579, val_acc: 0.7080\n",
      "Epoch [44], last_lr: 0.00374, train_loss: 0.3038, val_loss: 0.8497, val_acc: 0.6940\n",
      "Epoch [45], last_lr: 0.00379, train_loss: 0.2888, val_loss: 0.8510, val_acc: 0.6980\n",
      "Epoch [46], last_lr: 0.00384, train_loss: 0.3010, val_loss: 0.8345, val_acc: 0.7140\n",
      "Epoch [47], last_lr: 0.00388, train_loss: 0.2767, val_loss: 0.8309, val_acc: 0.7100\n",
      "Epoch [48], last_lr: 0.00392, train_loss: 0.2804, val_loss: 0.8391, val_acc: 0.6960\n",
      "Epoch [49], last_lr: 0.00395, train_loss: 0.2741, val_loss: 0.8220, val_acc: 0.7160\n",
      "Epoch [50], last_lr: 0.00397, train_loss: 0.2578, val_loss: 0.8235, val_acc: 0.7120\n",
      "Epoch [51], last_lr: 0.00399, train_loss: 0.2682, val_loss: 0.8247, val_acc: 0.7120\n",
      "Epoch [52], last_lr: 0.00400, train_loss: 0.2535, val_loss: 0.8222, val_acc: 0.7220\n",
      "Epoch [53], last_lr: 0.00400, train_loss: 0.2647, val_loss: 0.8196, val_acc: 0.7120\n",
      "Epoch [54], last_lr: 0.00400, train_loss: 0.2498, val_loss: 0.8143, val_acc: 0.7200\n",
      "Epoch [55], last_lr: 0.00400, train_loss: 0.2500, val_loss: 0.8170, val_acc: 0.7180\n",
      "Epoch [56], last_lr: 0.00399, train_loss: 0.2498, val_loss: 0.8261, val_acc: 0.7060\n",
      "Epoch [57], last_lr: 0.00399, train_loss: 0.2631, val_loss: 0.8370, val_acc: 0.7060\n",
      "Epoch [58], last_lr: 0.00398, train_loss: 0.2462, val_loss: 0.8217, val_acc: 0.7160\n",
      "Epoch [59], last_lr: 0.00398, train_loss: 0.2342, val_loss: 0.8189, val_acc: 0.7180\n",
      "Epoch [60], last_lr: 0.00397, train_loss: 0.2541, val_loss: 0.8364, val_acc: 0.7100\n",
      "Epoch [61], last_lr: 0.00396, train_loss: 0.2325, val_loss: 0.8239, val_acc: 0.7200\n",
      "Epoch [62], last_lr: 0.00395, train_loss: 0.2472, val_loss: 0.8232, val_acc: 0.7240\n",
      "Epoch [63], last_lr: 0.00394, train_loss: 0.2467, val_loss: 0.8329, val_acc: 0.7140\n",
      "Epoch [64], last_lr: 0.00393, train_loss: 0.2499, val_loss: 0.8442, val_acc: 0.7140\n",
      "Epoch [65], last_lr: 0.00391, train_loss: 0.2514, val_loss: 0.8473, val_acc: 0.7160\n",
      "Epoch [66], last_lr: 0.00390, train_loss: 0.2267, val_loss: 0.8278, val_acc: 0.7100\n",
      "Epoch [67], last_lr: 0.00388, train_loss: 0.2330, val_loss: 0.8277, val_acc: 0.7240\n",
      "Epoch [68], last_lr: 0.00386, train_loss: 0.2350, val_loss: 0.8450, val_acc: 0.7060\n",
      "Epoch [69], last_lr: 0.00384, train_loss: 0.2363, val_loss: 0.8411, val_acc: 0.7120\n",
      "Epoch [70], last_lr: 0.00382, train_loss: 0.2350, val_loss: 0.8409, val_acc: 0.7100\n",
      "Epoch [71], last_lr: 0.00380, train_loss: 0.2341, val_loss: 0.8319, val_acc: 0.7100\n",
      "Epoch [72], last_lr: 0.00378, train_loss: 0.2322, val_loss: 0.8582, val_acc: 0.7040\n",
      "Epoch [73], last_lr: 0.00376, train_loss: 0.2434, val_loss: 0.8421, val_acc: 0.7200\n",
      "Epoch [74], last_lr: 0.00373, train_loss: 0.2310, val_loss: 0.8509, val_acc: 0.7100\n",
      "Epoch [75], last_lr: 0.00371, train_loss: 0.2476, val_loss: 0.8501, val_acc: 0.6960\n",
      "Epoch [76], last_lr: 0.00368, train_loss: 0.2156, val_loss: 0.8314, val_acc: 0.7180\n",
      "Epoch [77], last_lr: 0.00365, train_loss: 0.2310, val_loss: 0.8521, val_acc: 0.6980\n",
      "Epoch [78], last_lr: 0.00362, train_loss: 0.2326, val_loss: 0.8397, val_acc: 0.7120\n",
      "Epoch [79], last_lr: 0.00359, train_loss: 0.2238, val_loss: 0.8340, val_acc: 0.7200\n",
      "Epoch [80], last_lr: 0.00356, train_loss: 0.2214, val_loss: 0.8655, val_acc: 0.7100\n",
      "Epoch [81], last_lr: 0.00353, train_loss: 0.2374, val_loss: 0.8223, val_acc: 0.7100\n",
      "Epoch [82], last_lr: 0.00350, train_loss: 0.2302, val_loss: 0.8282, val_acc: 0.7140\n",
      "Epoch [83], last_lr: 0.00347, train_loss: 0.2195, val_loss: 0.8213, val_acc: 0.7200\n",
      "Epoch [84], last_lr: 0.00343, train_loss: 0.2180, val_loss: 0.8306, val_acc: 0.7220\n",
      "Epoch [85], last_lr: 0.00340, train_loss: 0.2351, val_loss: 0.8384, val_acc: 0.7120\n",
      "Epoch [86], last_lr: 0.00336, train_loss: 0.2303, val_loss: 0.8494, val_acc: 0.7120\n",
      "Epoch [87], last_lr: 0.00332, train_loss: 0.2204, val_loss: 0.8546, val_acc: 0.7140\n",
      "Epoch [88], last_lr: 0.00329, train_loss: 0.2187, val_loss: 0.8597, val_acc: 0.7120\n",
      "Epoch [89], last_lr: 0.00325, train_loss: 0.2115, val_loss: 0.8651, val_acc: 0.7100\n",
      "Epoch [90], last_lr: 0.00321, train_loss: 0.2227, val_loss: 0.8498, val_acc: 0.7120\n",
      "Epoch [91], last_lr: 0.00317, train_loss: 0.2328, val_loss: 0.8712, val_acc: 0.7100\n",
      "Epoch [92], last_lr: 0.00313, train_loss: 0.2274, val_loss: 0.8446, val_acc: 0.7180\n",
      "Epoch [93], last_lr: 0.00309, train_loss: 0.2304, val_loss: 0.8477, val_acc: 0.7140\n",
      "Epoch [94], last_lr: 0.00304, train_loss: 0.2092, val_loss: 0.8547, val_acc: 0.7200\n",
      "Epoch [95], last_lr: 0.00300, train_loss: 0.2237, val_loss: 0.8564, val_acc: 0.7140\n",
      "Epoch [96], last_lr: 0.00296, train_loss: 0.2085, val_loss: 0.8563, val_acc: 0.7160\n",
      "Epoch [97], last_lr: 0.00291, train_loss: 0.2185, val_loss: 0.8512, val_acc: 0.7260\n",
      "Epoch [98], last_lr: 0.00287, train_loss: 0.2230, val_loss: 0.8571, val_acc: 0.7160\n",
      "Epoch [99], last_lr: 0.00282, train_loss: 0.2097, val_loss: 0.8638, val_acc: 0.7180\n",
      "Epoch [100], last_lr: 0.00278, train_loss: 0.2237, val_loss: 0.8594, val_acc: 0.7160\n",
      "Epoch [101], last_lr: 0.00273, train_loss: 0.2184, val_loss: 0.8641, val_acc: 0.7140\n",
      "Epoch [102], last_lr: 0.00268, train_loss: 0.2185, val_loss: 0.8659, val_acc: 0.7060\n",
      "Epoch [103], last_lr: 0.00264, train_loss: 0.2164, val_loss: 0.8737, val_acc: 0.7180\n",
      "Epoch [104], last_lr: 0.00259, train_loss: 0.2181, val_loss: 0.8737, val_acc: 0.7120\n",
      "Epoch [105], last_lr: 0.00254, train_loss: 0.2137, val_loss: 0.8683, val_acc: 0.7120\n",
      "Epoch [106], last_lr: 0.00249, train_loss: 0.2283, val_loss: 0.8652, val_acc: 0.7180\n",
      "Epoch [107], last_lr: 0.00245, train_loss: 0.2179, val_loss: 0.8575, val_acc: 0.7120\n",
      "Epoch [108], last_lr: 0.00240, train_loss: 0.2186, val_loss: 0.8747, val_acc: 0.7100\n",
      "Epoch [109], last_lr: 0.00235, train_loss: 0.2111, val_loss: 0.8562, val_acc: 0.7120\n",
      "Epoch [110], last_lr: 0.00230, train_loss: 0.2144, val_loss: 0.8707, val_acc: 0.7180\n",
      "Epoch [111], last_lr: 0.00225, train_loss: 0.1977, val_loss: 0.8601, val_acc: 0.7080\n",
      "Epoch [112], last_lr: 0.00220, train_loss: 0.1935, val_loss: 0.8636, val_acc: 0.7120\n",
      "Epoch [113], last_lr: 0.00215, train_loss: 0.2171, val_loss: 0.8604, val_acc: 0.7080\n",
      "Epoch [114], last_lr: 0.00210, train_loss: 0.2330, val_loss: 0.8734, val_acc: 0.7240\n",
      "Epoch [115], last_lr: 0.00205, train_loss: 0.2329, val_loss: 0.8819, val_acc: 0.7100\n",
      "Epoch [116], last_lr: 0.00200, train_loss: 0.2149, val_loss: 0.8752, val_acc: 0.7200\n",
      "Epoch [117], last_lr: 0.00195, train_loss: 0.2121, val_loss: 0.8758, val_acc: 0.7140\n",
      "Epoch [118], last_lr: 0.00190, train_loss: 0.2173, val_loss: 0.8844, val_acc: 0.7160\n",
      "Epoch [119], last_lr: 0.00185, train_loss: 0.2264, val_loss: 0.8691, val_acc: 0.7120\n",
      "Epoch [120], last_lr: 0.00180, train_loss: 0.2288, val_loss: 0.8713, val_acc: 0.7180\n",
      "Epoch [121], last_lr: 0.00175, train_loss: 0.2162, val_loss: 0.8704, val_acc: 0.7100\n",
      "Epoch [122], last_lr: 0.00170, train_loss: 0.2187, val_loss: 0.8679, val_acc: 0.7260\n",
      "Epoch [123], last_lr: 0.00165, train_loss: 0.2276, val_loss: 0.8620, val_acc: 0.7100\n",
      "Epoch [124], last_lr: 0.00160, train_loss: 0.2066, val_loss: 0.8595, val_acc: 0.7100\n",
      "Epoch [125], last_lr: 0.00155, train_loss: 0.2160, val_loss: 0.8687, val_acc: 0.7100\n",
      "Epoch [126], last_lr: 0.00151, train_loss: 0.2057, val_loss: 0.8596, val_acc: 0.7140\n",
      "Epoch [127], last_lr: 0.00146, train_loss: 0.2089, val_loss: 0.8593, val_acc: 0.7200\n",
      "Epoch [128], last_lr: 0.00141, train_loss: 0.2105, val_loss: 0.8623, val_acc: 0.7180\n",
      "Epoch [129], last_lr: 0.00136, train_loss: 0.2168, val_loss: 0.8590, val_acc: 0.7160\n",
      "Epoch [130], last_lr: 0.00132, train_loss: 0.2177, val_loss: 0.8626, val_acc: 0.7180\n",
      "Epoch [131], last_lr: 0.00127, train_loss: 0.2173, val_loss: 0.8781, val_acc: 0.7060\n",
      "Epoch [132], last_lr: 0.00122, train_loss: 0.2072, val_loss: 0.8645, val_acc: 0.7280\n",
      "Epoch [133], last_lr: 0.00118, train_loss: 0.1951, val_loss: 0.8658, val_acc: 0.7120\n",
      "Epoch [134], last_lr: 0.00113, train_loss: 0.2027, val_loss: 0.8684, val_acc: 0.7140\n",
      "Epoch [135], last_lr: 0.00109, train_loss: 0.2148, val_loss: 0.8617, val_acc: 0.7100\n",
      "Epoch [136], last_lr: 0.00104, train_loss: 0.2156, val_loss: 0.8588, val_acc: 0.7140\n",
      "Epoch [137], last_lr: 0.00100, train_loss: 0.2184, val_loss: 0.8602, val_acc: 0.7140\n",
      "Epoch [138], last_lr: 0.00096, train_loss: 0.2213, val_loss: 0.8633, val_acc: 0.7240\n",
      "Epoch [139], last_lr: 0.00091, train_loss: 0.2058, val_loss: 0.8657, val_acc: 0.7180\n",
      "Epoch [140], last_lr: 0.00087, train_loss: 0.2093, val_loss: 0.8702, val_acc: 0.7120\n",
      "Epoch [141], last_lr: 0.00083, train_loss: 0.2161, val_loss: 0.8732, val_acc: 0.7220\n",
      "Epoch [142], last_lr: 0.00079, train_loss: 0.2012, val_loss: 0.8716, val_acc: 0.7180\n",
      "Epoch [143], last_lr: 0.00075, train_loss: 0.1884, val_loss: 0.8790, val_acc: 0.7140\n",
      "Epoch [144], last_lr: 0.00071, train_loss: 0.2276, val_loss: 0.8793, val_acc: 0.7160\n",
      "Epoch [145], last_lr: 0.00068, train_loss: 0.2180, val_loss: 0.8790, val_acc: 0.7220\n",
      "Epoch [146], last_lr: 0.00064, train_loss: 0.2133, val_loss: 0.8773, val_acc: 0.7260\n",
      "Epoch [147], last_lr: 0.00060, train_loss: 0.2143, val_loss: 0.8718, val_acc: 0.7240\n",
      "Epoch [148], last_lr: 0.00057, train_loss: 0.2119, val_loss: 0.8761, val_acc: 0.7140\n",
      "Epoch [149], last_lr: 0.00053, train_loss: 0.2207, val_loss: 0.8752, val_acc: 0.7120\n",
      "Epoch [150], last_lr: 0.00050, train_loss: 0.2243, val_loss: 0.8716, val_acc: 0.7180\n",
      "Epoch [151], last_lr: 0.00047, train_loss: 0.2097, val_loss: 0.8722, val_acc: 0.7180\n",
      "Epoch [152], last_lr: 0.00044, train_loss: 0.2110, val_loss: 0.8761, val_acc: 0.7160\n",
      "Epoch [153], last_lr: 0.00041, train_loss: 0.2187, val_loss: 0.8758, val_acc: 0.7120\n",
      "Epoch [154], last_lr: 0.00038, train_loss: 0.2202, val_loss: 0.8764, val_acc: 0.7100\n",
      "Epoch [155], last_lr: 0.00035, train_loss: 0.2217, val_loss: 0.8780, val_acc: 0.7100\n",
      "Epoch [156], last_lr: 0.00032, train_loss: 0.2038, val_loss: 0.8719, val_acc: 0.7180\n",
      "Epoch [157], last_lr: 0.00029, train_loss: 0.2068, val_loss: 0.8714, val_acc: 0.7180\n",
      "Epoch [158], last_lr: 0.00027, train_loss: 0.2091, val_loss: 0.8691, val_acc: 0.7200\n",
      "Epoch [159], last_lr: 0.00024, train_loss: 0.2113, val_loss: 0.8714, val_acc: 0.7180\n",
      "Epoch [160], last_lr: 0.00022, train_loss: 0.2069, val_loss: 0.8718, val_acc: 0.7200\n",
      "Epoch [161], last_lr: 0.00020, train_loss: 0.1984, val_loss: 0.8727, val_acc: 0.7180\n",
      "Epoch [162], last_lr: 0.00018, train_loss: 0.2116, val_loss: 0.8723, val_acc: 0.7160\n",
      "Epoch [163], last_lr: 0.00016, train_loss: 0.2113, val_loss: 0.8742, val_acc: 0.7180\n",
      "Epoch [164], last_lr: 0.00014, train_loss: 0.2164, val_loss: 0.8730, val_acc: 0.7160\n",
      "Epoch [165], last_lr: 0.00012, train_loss: 0.2094, val_loss: 0.8761, val_acc: 0.7140\n",
      "Epoch [166], last_lr: 0.00010, train_loss: 0.2047, val_loss: 0.8737, val_acc: 0.7160\n",
      "Epoch [167], last_lr: 0.00009, train_loss: 0.2146, val_loss: 0.8760, val_acc: 0.7140\n",
      "Epoch [168], last_lr: 0.00007, train_loss: 0.2132, val_loss: 0.8728, val_acc: 0.7160\n",
      "Epoch [169], last_lr: 0.00006, train_loss: 0.2019, val_loss: 0.8736, val_acc: 0.7180\n",
      "Epoch [170], last_lr: 0.00005, train_loss: 0.2058, val_loss: 0.8715, val_acc: 0.7100\n",
      "Epoch [171], last_lr: 0.00004, train_loss: 0.2042, val_loss: 0.8713, val_acc: 0.7120\n",
      "Epoch [172], last_lr: 0.00003, train_loss: 0.2305, val_loss: 0.8719, val_acc: 0.7100\n",
      "Epoch [173], last_lr: 0.00002, train_loss: 0.2222, val_loss: 0.8728, val_acc: 0.7120\n",
      "Epoch [174], last_lr: 0.00002, train_loss: 0.2151, val_loss: 0.8727, val_acc: 0.7160\n",
      "Epoch [175], last_lr: 0.00001, train_loss: 0.1961, val_loss: 0.8715, val_acc: 0.7140\n",
      "Epoch [176], last_lr: 0.00001, train_loss: 0.2017, val_loss: 0.8718, val_acc: 0.7180\n",
      "Epoch [177], last_lr: 0.00000, train_loss: 0.2047, val_loss: 0.8708, val_acc: 0.7120\n",
      "Epoch [178], last_lr: 0.00000, train_loss: 0.2056, val_loss: 0.8720, val_acc: 0.7180\n",
      "Epoch [179], last_lr: 0.00000, train_loss: 0.2116, val_loss: 0.8718, val_acc: 0.7180\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[{'val_loss': 11.145490646362305, 'val_acc': 0.2199999988079071}]\n",
      "Epoch [0], last_lr: 0.00016, train_loss: 7.0119, val_loss: 7.9996, val_acc: 0.2360\n",
      "Epoch [1], last_lr: 0.00017, train_loss: 6.6811, val_loss: 6.7759, val_acc: 0.2480\n",
      "Epoch [2], last_lr: 0.00019, train_loss: 6.4542, val_loss: 6.1851, val_acc: 0.2560\n",
      "Epoch [3], last_lr: 0.00021, train_loss: 6.0950, val_loss: 5.8098, val_acc: 0.2700\n",
      "Epoch [4], last_lr: 0.00024, train_loss: 5.7917, val_loss: 5.4638, val_acc: 0.2780\n",
      "Epoch [5], last_lr: 0.00027, train_loss: 5.4212, val_loss: 5.0925, val_acc: 0.2760\n",
      "Epoch [6], last_lr: 0.00031, train_loss: 5.1339, val_loss: 4.7079, val_acc: 0.2740\n",
      "Epoch [7], last_lr: 0.00036, train_loss: 4.6120, val_loss: 4.3140, val_acc: 0.2700\n",
      "Epoch [8], last_lr: 0.00041, train_loss: 4.1616, val_loss: 3.9576, val_acc: 0.2340\n",
      "Epoch [9], last_lr: 0.00047, train_loss: 3.8268, val_loss: 3.7417, val_acc: 0.2280\n",
      "Epoch [10], last_lr: 0.00053, train_loss: 3.6110, val_loss: 3.7430, val_acc: 0.2100\n",
      "Epoch [11], last_lr: 0.00060, train_loss: 3.6236, val_loss: 3.7929, val_acc: 0.2240\n",
      "Epoch [12], last_lr: 0.00068, train_loss: 3.5846, val_loss: 3.7309, val_acc: 0.2280\n",
      "Epoch [13], last_lr: 0.00075, train_loss: 3.4630, val_loss: 3.6015, val_acc: 0.2460\n",
      "Epoch [14], last_lr: 0.00084, train_loss: 3.3850, val_loss: 3.4679, val_acc: 0.2420\n",
      "Epoch [15], last_lr: 0.00092, train_loss: 3.2796, val_loss: 3.3623, val_acc: 0.2420\n",
      "Epoch [16], last_lr: 0.00102, train_loss: 3.1191, val_loss: 3.2494, val_acc: 0.2500\n",
      "Epoch [17], last_lr: 0.00111, train_loss: 2.9723, val_loss: 3.1182, val_acc: 0.2740\n",
      "Epoch [18], last_lr: 0.00121, train_loss: 2.7564, val_loss: 2.9825, val_acc: 0.2840\n",
      "Epoch [19], last_lr: 0.00131, train_loss: 2.6379, val_loss: 2.8374, val_acc: 0.2900\n",
      "Epoch [20], last_lr: 0.00141, train_loss: 2.4665, val_loss: 2.6800, val_acc: 0.3140\n",
      "Epoch [21], last_lr: 0.00152, train_loss: 2.2294, val_loss: 2.5359, val_acc: 0.3320\n",
      "Epoch [22], last_lr: 0.00163, train_loss: 2.0772, val_loss: 2.3964, val_acc: 0.3580\n",
      "Epoch [23], last_lr: 0.00174, train_loss: 1.8924, val_loss: 2.2723, val_acc: 0.3640\n",
      "Epoch [24], last_lr: 0.00185, train_loss: 1.7004, val_loss: 2.1532, val_acc: 0.3880\n",
      "Epoch [25], last_lr: 0.00196, train_loss: 1.6308, val_loss: 2.0567, val_acc: 0.4000\n",
      "Epoch [26], last_lr: 0.00207, train_loss: 1.4463, val_loss: 1.9757, val_acc: 0.4100\n",
      "Epoch [27], last_lr: 0.00218, train_loss: 1.3860, val_loss: 1.9099, val_acc: 0.4120\n",
      "Epoch [28], last_lr: 0.00230, train_loss: 1.2983, val_loss: 1.8523, val_acc: 0.4220\n",
      "Epoch [29], last_lr: 0.00241, train_loss: 1.2619, val_loss: 1.8182, val_acc: 0.4320\n",
      "Epoch [30], last_lr: 0.00252, train_loss: 1.1927, val_loss: 1.7769, val_acc: 0.4220\n",
      "Epoch [31], last_lr: 0.00262, train_loss: 1.1402, val_loss: 1.7505, val_acc: 0.4420\n",
      "Epoch [32], last_lr: 0.00273, train_loss: 1.1127, val_loss: 1.7033, val_acc: 0.4400\n",
      "Epoch [33], last_lr: 0.00284, train_loss: 1.0605, val_loss: 1.6741, val_acc: 0.4360\n",
      "Epoch [34], last_lr: 0.00294, train_loss: 1.0531, val_loss: 1.6508, val_acc: 0.4500\n",
      "Epoch [35], last_lr: 0.00304, train_loss: 1.0235, val_loss: 1.6420, val_acc: 0.4440\n",
      "Epoch [36], last_lr: 0.00313, train_loss: 1.0424, val_loss: 1.6137, val_acc: 0.4520\n",
      "Epoch [37], last_lr: 0.00322, train_loss: 1.0040, val_loss: 1.6053, val_acc: 0.4400\n",
      "Epoch [38], last_lr: 0.00331, train_loss: 0.9857, val_loss: 1.5984, val_acc: 0.4460\n",
      "Epoch [39], last_lr: 0.00339, train_loss: 0.9669, val_loss: 1.5866, val_acc: 0.4540\n",
      "Epoch [40], last_lr: 0.00347, train_loss: 0.9709, val_loss: 1.5745, val_acc: 0.4580\n",
      "Epoch [41], last_lr: 0.00355, train_loss: 0.9451, val_loss: 1.5763, val_acc: 0.4560\n",
      "Epoch [42], last_lr: 0.00362, train_loss: 0.9191, val_loss: 1.5371, val_acc: 0.4480\n",
      "Epoch [43], last_lr: 0.00368, train_loss: 0.9268, val_loss: 1.5255, val_acc: 0.4520\n",
      "Epoch [44], last_lr: 0.00374, train_loss: 0.9268, val_loss: 1.5216, val_acc: 0.4560\n",
      "Epoch [45], last_lr: 0.00379, train_loss: 0.9359, val_loss: 1.5111, val_acc: 0.4560\n",
      "Epoch [46], last_lr: 0.00384, train_loss: 0.8985, val_loss: 1.5023, val_acc: 0.4360\n",
      "Epoch [47], last_lr: 0.00388, train_loss: 0.8872, val_loss: 1.5010, val_acc: 0.4460\n",
      "Epoch [48], last_lr: 0.00392, train_loss: 0.8903, val_loss: 1.5158, val_acc: 0.4400\n",
      "Epoch [49], last_lr: 0.00395, train_loss: 0.9007, val_loss: 1.5184, val_acc: 0.4440\n",
      "Epoch [50], last_lr: 0.00397, train_loss: 0.8949, val_loss: 1.5022, val_acc: 0.4400\n",
      "Epoch [51], last_lr: 0.00399, train_loss: 0.9049, val_loss: 1.5054, val_acc: 0.4460\n",
      "Epoch [52], last_lr: 0.00400, train_loss: 0.8971, val_loss: 1.4667, val_acc: 0.4580\n",
      "Epoch [53], last_lr: 0.00400, train_loss: 0.8998, val_loss: 1.4795, val_acc: 0.4620\n",
      "Epoch [54], last_lr: 0.00400, train_loss: 0.8793, val_loss: 1.4963, val_acc: 0.4540\n",
      "Epoch [55], last_lr: 0.00400, train_loss: 0.8988, val_loss: 1.4704, val_acc: 0.4660\n",
      "Epoch [56], last_lr: 0.00399, train_loss: 0.9047, val_loss: 1.4739, val_acc: 0.4440\n",
      "Epoch [57], last_lr: 0.00399, train_loss: 0.8883, val_loss: 1.4666, val_acc: 0.4640\n",
      "Epoch [58], last_lr: 0.00398, train_loss: 0.8961, val_loss: 1.4498, val_acc: 0.4580\n",
      "Epoch [59], last_lr: 0.00398, train_loss: 0.8833, val_loss: 1.4619, val_acc: 0.4760\n",
      "Epoch [60], last_lr: 0.00397, train_loss: 0.8689, val_loss: 1.4655, val_acc: 0.4620\n",
      "Epoch [61], last_lr: 0.00396, train_loss: 0.8726, val_loss: 1.4779, val_acc: 0.4480\n",
      "Epoch [62], last_lr: 0.00395, train_loss: 0.8799, val_loss: 1.4932, val_acc: 0.4620\n",
      "Epoch [63], last_lr: 0.00394, train_loss: 0.8781, val_loss: 1.4457, val_acc: 0.4560\n",
      "Epoch [64], last_lr: 0.00393, train_loss: 0.8547, val_loss: 1.4437, val_acc: 0.4500\n",
      "Epoch [65], last_lr: 0.00391, train_loss: 0.8728, val_loss: 1.4397, val_acc: 0.4560\n",
      "Epoch [66], last_lr: 0.00390, train_loss: 0.8855, val_loss: 1.4405, val_acc: 0.4620\n",
      "Epoch [67], last_lr: 0.00388, train_loss: 0.8785, val_loss: 1.4608, val_acc: 0.4680\n",
      "Epoch [68], last_lr: 0.00386, train_loss: 0.8747, val_loss: 1.4510, val_acc: 0.4480\n",
      "Epoch [69], last_lr: 0.00384, train_loss: 0.8571, val_loss: 1.4508, val_acc: 0.4520\n",
      "Epoch [70], last_lr: 0.00382, train_loss: 0.8850, val_loss: 1.4407, val_acc: 0.4620\n",
      "Epoch [71], last_lr: 0.00380, train_loss: 0.8681, val_loss: 1.4463, val_acc: 0.4500\n",
      "Epoch [72], last_lr: 0.00378, train_loss: 0.8589, val_loss: 1.4542, val_acc: 0.4560\n",
      "Epoch [73], last_lr: 0.00376, train_loss: 0.8691, val_loss: 1.4607, val_acc: 0.4600\n",
      "Epoch [74], last_lr: 0.00373, train_loss: 0.8824, val_loss: 1.4501, val_acc: 0.4600\n",
      "Epoch [75], last_lr: 0.00371, train_loss: 0.8728, val_loss: 1.4484, val_acc: 0.4720\n",
      "Epoch [76], last_lr: 0.00368, train_loss: 0.8637, val_loss: 1.4810, val_acc: 0.4480\n",
      "Epoch [77], last_lr: 0.00365, train_loss: 0.8406, val_loss: 1.4389, val_acc: 0.4700\n",
      "Epoch [78], last_lr: 0.00362, train_loss: 0.8682, val_loss: 1.4666, val_acc: 0.4560\n",
      "Epoch [79], last_lr: 0.00359, train_loss: 0.8527, val_loss: 1.4600, val_acc: 0.4640\n",
      "Epoch [80], last_lr: 0.00356, train_loss: 0.8804, val_loss: 1.4861, val_acc: 0.4600\n",
      "Epoch [81], last_lr: 0.00353, train_loss: 0.8525, val_loss: 1.4575, val_acc: 0.4520\n",
      "Epoch [82], last_lr: 0.00350, train_loss: 0.8645, val_loss: 1.4515, val_acc: 0.4480\n",
      "Epoch [83], last_lr: 0.00347, train_loss: 0.8575, val_loss: 1.4457, val_acc: 0.4620\n",
      "Epoch [84], last_lr: 0.00343, train_loss: 0.8642, val_loss: 1.4539, val_acc: 0.4580\n",
      "Epoch [85], last_lr: 0.00340, train_loss: 0.8440, val_loss: 1.4417, val_acc: 0.4540\n",
      "Epoch [86], last_lr: 0.00336, train_loss: 0.8357, val_loss: 1.4474, val_acc: 0.4620\n",
      "Epoch [87], last_lr: 0.00332, train_loss: 0.8665, val_loss: 1.4398, val_acc: 0.4600\n",
      "Epoch [88], last_lr: 0.00329, train_loss: 0.8560, val_loss: 1.4508, val_acc: 0.4560\n",
      "Epoch [89], last_lr: 0.00325, train_loss: 0.8533, val_loss: 1.4626, val_acc: 0.4680\n",
      "Epoch [90], last_lr: 0.00321, train_loss: 0.8252, val_loss: 1.4448, val_acc: 0.4700\n",
      "Epoch [91], last_lr: 0.00317, train_loss: 0.8472, val_loss: 1.4478, val_acc: 0.4580\n",
      "Epoch [92], last_lr: 0.00313, train_loss: 0.8652, val_loss: 1.4633, val_acc: 0.4580\n",
      "Epoch [93], last_lr: 0.00309, train_loss: 0.8503, val_loss: 1.4364, val_acc: 0.4620\n",
      "Epoch [94], last_lr: 0.00304, train_loss: 0.8614, val_loss: 1.4379, val_acc: 0.4660\n",
      "Epoch [95], last_lr: 0.00300, train_loss: 0.8532, val_loss: 1.4418, val_acc: 0.4560\n",
      "Epoch [96], last_lr: 0.00296, train_loss: 0.8474, val_loss: 1.4404, val_acc: 0.4560\n",
      "Epoch [97], last_lr: 0.00291, train_loss: 0.8364, val_loss: 1.4409, val_acc: 0.4600\n",
      "Epoch [98], last_lr: 0.00287, train_loss: 0.8377, val_loss: 1.4315, val_acc: 0.4640\n",
      "Epoch [99], last_lr: 0.00282, train_loss: 0.8279, val_loss: 1.4393, val_acc: 0.4600\n",
      "Epoch [100], last_lr: 0.00278, train_loss: 0.8376, val_loss: 1.4587, val_acc: 0.4560\n",
      "Epoch [101], last_lr: 0.00273, train_loss: 0.8566, val_loss: 1.4537, val_acc: 0.4520\n",
      "Epoch [102], last_lr: 0.00268, train_loss: 0.8444, val_loss: 1.4573, val_acc: 0.4460\n",
      "Epoch [103], last_lr: 0.00264, train_loss: 0.8514, val_loss: 1.4632, val_acc: 0.4520\n",
      "Epoch [104], last_lr: 0.00259, train_loss: 0.8437, val_loss: 1.4567, val_acc: 0.4420\n",
      "Epoch [105], last_lr: 0.00254, train_loss: 0.8458, val_loss: 1.4535, val_acc: 0.4540\n",
      "Epoch [106], last_lr: 0.00249, train_loss: 0.8657, val_loss: 1.4521, val_acc: 0.4480\n",
      "Epoch [107], last_lr: 0.00245, train_loss: 0.8432, val_loss: 1.4503, val_acc: 0.4580\n",
      "Epoch [108], last_lr: 0.00240, train_loss: 0.8320, val_loss: 1.4443, val_acc: 0.4700\n",
      "Epoch [109], last_lr: 0.00235, train_loss: 0.8270, val_loss: 1.4532, val_acc: 0.4540\n",
      "Epoch [110], last_lr: 0.00230, train_loss: 0.8699, val_loss: 1.4427, val_acc: 0.4680\n",
      "Epoch [111], last_lr: 0.00225, train_loss: 0.8357, val_loss: 1.4478, val_acc: 0.4480\n",
      "Epoch [112], last_lr: 0.00220, train_loss: 0.8632, val_loss: 1.4525, val_acc: 0.4560\n",
      "Epoch [113], last_lr: 0.00215, train_loss: 0.8454, val_loss: 1.4442, val_acc: 0.4540\n",
      "Epoch [114], last_lr: 0.00210, train_loss: 0.8508, val_loss: 1.4521, val_acc: 0.4520\n",
      "Epoch [115], last_lr: 0.00205, train_loss: 0.8444, val_loss: 1.4414, val_acc: 0.4640\n",
      "Epoch [116], last_lr: 0.00200, train_loss: 0.8203, val_loss: 1.4567, val_acc: 0.4540\n",
      "Epoch [117], last_lr: 0.00195, train_loss: 0.8349, val_loss: 1.4447, val_acc: 0.4600\n",
      "Epoch [118], last_lr: 0.00190, train_loss: 0.8400, val_loss: 1.4595, val_acc: 0.4620\n",
      "Epoch [119], last_lr: 0.00185, train_loss: 0.8266, val_loss: 1.4587, val_acc: 0.4480\n",
      "Epoch [120], last_lr: 0.00180, train_loss: 0.8667, val_loss: 1.4539, val_acc: 0.4700\n",
      "Epoch [121], last_lr: 0.00175, train_loss: 0.8474, val_loss: 1.4412, val_acc: 0.4700\n",
      "Epoch [122], last_lr: 0.00170, train_loss: 0.8368, val_loss: 1.4494, val_acc: 0.4620\n",
      "Epoch [123], last_lr: 0.00165, train_loss: 0.8358, val_loss: 1.4403, val_acc: 0.4740\n",
      "Epoch [124], last_lr: 0.00160, train_loss: 0.8420, val_loss: 1.4379, val_acc: 0.4600\n",
      "Epoch [125], last_lr: 0.00155, train_loss: 0.8362, val_loss: 1.4363, val_acc: 0.4760\n",
      "Epoch [126], last_lr: 0.00151, train_loss: 0.8484, val_loss: 1.4402, val_acc: 0.4600\n",
      "Epoch [127], last_lr: 0.00146, train_loss: 0.8362, val_loss: 1.4392, val_acc: 0.4580\n",
      "Epoch [128], last_lr: 0.00141, train_loss: 0.8268, val_loss: 1.4403, val_acc: 0.4560\n",
      "Epoch [129], last_lr: 0.00136, train_loss: 0.8414, val_loss: 1.4362, val_acc: 0.4600\n",
      "Epoch [130], last_lr: 0.00132, train_loss: 0.8419, val_loss: 1.4414, val_acc: 0.4540\n",
      "Epoch [131], last_lr: 0.00127, train_loss: 0.8168, val_loss: 1.4369, val_acc: 0.4680\n",
      "Epoch [132], last_lr: 0.00122, train_loss: 0.8669, val_loss: 1.4384, val_acc: 0.4560\n",
      "Epoch [133], last_lr: 0.00118, train_loss: 0.8306, val_loss: 1.4331, val_acc: 0.4640\n",
      "Epoch [134], last_lr: 0.00113, train_loss: 0.8363, val_loss: 1.4319, val_acc: 0.4640\n",
      "Epoch [135], last_lr: 0.00109, train_loss: 0.8278, val_loss: 1.4337, val_acc: 0.4540\n",
      "Epoch [136], last_lr: 0.00104, train_loss: 0.8377, val_loss: 1.4304, val_acc: 0.4680\n",
      "Epoch [137], last_lr: 0.00100, train_loss: 0.8293, val_loss: 1.4310, val_acc: 0.4580\n",
      "Epoch [138], last_lr: 0.00096, train_loss: 0.8231, val_loss: 1.4282, val_acc: 0.4740\n",
      "Epoch [139], last_lr: 0.00091, train_loss: 0.8245, val_loss: 1.4282, val_acc: 0.4700\n",
      "Epoch [140], last_lr: 0.00087, train_loss: 0.8186, val_loss: 1.4345, val_acc: 0.4680\n",
      "Epoch [141], last_lr: 0.00083, train_loss: 0.8224, val_loss: 1.4360, val_acc: 0.4660\n",
      "Epoch [142], last_lr: 0.00079, train_loss: 0.8325, val_loss: 1.4342, val_acc: 0.4720\n",
      "Epoch [143], last_lr: 0.00075, train_loss: 0.8402, val_loss: 1.4364, val_acc: 0.4640\n",
      "Epoch [144], last_lr: 0.00071, train_loss: 0.8402, val_loss: 1.4380, val_acc: 0.4700\n",
      "Epoch [145], last_lr: 0.00068, train_loss: 0.8488, val_loss: 1.4358, val_acc: 0.4680\n",
      "Epoch [146], last_lr: 0.00064, train_loss: 0.8371, val_loss: 1.4374, val_acc: 0.4600\n",
      "Epoch [147], last_lr: 0.00060, train_loss: 0.8278, val_loss: 1.4378, val_acc: 0.4700\n",
      "Epoch [148], last_lr: 0.00057, train_loss: 0.8394, val_loss: 1.4353, val_acc: 0.4600\n",
      "Epoch [149], last_lr: 0.00053, train_loss: 0.8184, val_loss: 1.4344, val_acc: 0.4620\n",
      "Epoch [150], last_lr: 0.00050, train_loss: 0.8491, val_loss: 1.4360, val_acc: 0.4700\n",
      "Epoch [151], last_lr: 0.00047, train_loss: 0.8209, val_loss: 1.4349, val_acc: 0.4660\n",
      "Epoch [152], last_lr: 0.00044, train_loss: 0.8448, val_loss: 1.4370, val_acc: 0.4640\n",
      "Epoch [153], last_lr: 0.00041, train_loss: 0.8205, val_loss: 1.4354, val_acc: 0.4620\n",
      "Epoch [154], last_lr: 0.00038, train_loss: 0.8327, val_loss: 1.4339, val_acc: 0.4620\n",
      "Epoch [155], last_lr: 0.00035, train_loss: 0.8148, val_loss: 1.4353, val_acc: 0.4660\n",
      "Epoch [156], last_lr: 0.00032, train_loss: 0.8311, val_loss: 1.4395, val_acc: 0.4660\n",
      "Epoch [157], last_lr: 0.00029, train_loss: 0.8364, val_loss: 1.4389, val_acc: 0.4680\n",
      "Epoch [158], last_lr: 0.00027, train_loss: 0.8424, val_loss: 1.4378, val_acc: 0.4580\n",
      "Epoch [159], last_lr: 0.00024, train_loss: 0.8134, val_loss: 1.4378, val_acc: 0.4600\n",
      "Epoch [160], last_lr: 0.00022, train_loss: 0.8554, val_loss: 1.4375, val_acc: 0.4560\n",
      "Epoch [161], last_lr: 0.00020, train_loss: 0.8412, val_loss: 1.4355, val_acc: 0.4600\n",
      "Epoch [162], last_lr: 0.00018, train_loss: 0.8242, val_loss: 1.4371, val_acc: 0.4680\n",
      "Epoch [163], last_lr: 0.00016, train_loss: 0.8358, val_loss: 1.4366, val_acc: 0.4700\n",
      "Epoch [164], last_lr: 0.00014, train_loss: 0.8485, val_loss: 1.4399, val_acc: 0.4680\n",
      "Epoch [165], last_lr: 0.00012, train_loss: 0.8573, val_loss: 1.4392, val_acc: 0.4680\n",
      "Epoch [166], last_lr: 0.00010, train_loss: 0.8217, val_loss: 1.4395, val_acc: 0.4640\n",
      "Epoch [167], last_lr: 0.00009, train_loss: 0.7959, val_loss: 1.4388, val_acc: 0.4640\n",
      "Epoch [168], last_lr: 0.00007, train_loss: 0.8278, val_loss: 1.4386, val_acc: 0.4620\n",
      "Epoch [169], last_lr: 0.00006, train_loss: 0.8409, val_loss: 1.4400, val_acc: 0.4660\n",
      "Epoch [170], last_lr: 0.00005, train_loss: 0.8130, val_loss: 1.4402, val_acc: 0.4640\n",
      "Epoch [171], last_lr: 0.00004, train_loss: 0.8357, val_loss: 1.4393, val_acc: 0.4620\n",
      "Epoch [172], last_lr: 0.00003, train_loss: 0.8365, val_loss: 1.4394, val_acc: 0.4680\n",
      "Epoch [173], last_lr: 0.00002, train_loss: 0.8316, val_loss: 1.4370, val_acc: 0.4660\n",
      "Epoch [174], last_lr: 0.00002, train_loss: 0.8293, val_loss: 1.4365, val_acc: 0.4660\n",
      "Epoch [175], last_lr: 0.00001, train_loss: 0.8258, val_loss: 1.4365, val_acc: 0.4640\n",
      "Epoch [176], last_lr: 0.00001, train_loss: 0.8390, val_loss: 1.4362, val_acc: 0.4640\n",
      "Epoch [177], last_lr: 0.00000, train_loss: 0.8125, val_loss: 1.4356, val_acc: 0.4640\n",
      "Epoch [178], last_lr: 0.00000, train_loss: 0.8172, val_loss: 1.4367, val_acc: 0.4700\n",
      "Epoch [179], last_lr: 0.00000, train_loss: 0.8344, val_loss: 1.4359, val_acc: 0.4660\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[{'val_loss': 8.954218864440918, 'val_acc': 0.16200000047683716}]\n",
      "Epoch [0], last_lr: 0.00016, train_loss: 6.5910, val_loss: 7.3885, val_acc: 0.1380\n",
      "Epoch [1], last_lr: 0.00017, train_loss: 6.2120, val_loss: 6.6690, val_acc: 0.1480\n",
      "Epoch [2], last_lr: 0.00019, train_loss: 5.8467, val_loss: 6.2108, val_acc: 0.1460\n",
      "Epoch [3], last_lr: 0.00021, train_loss: 5.5394, val_loss: 5.8347, val_acc: 0.1500\n",
      "Epoch [4], last_lr: 0.00024, train_loss: 5.1840, val_loss: 5.4501, val_acc: 0.1560\n",
      "Epoch [5], last_lr: 0.00027, train_loss: 4.9320, val_loss: 5.0937, val_acc: 0.1620\n",
      "Epoch [6], last_lr: 0.00031, train_loss: 4.5026, val_loss: 4.7795, val_acc: 0.1600\n",
      "Epoch [7], last_lr: 0.00036, train_loss: 4.2888, val_loss: 4.5291, val_acc: 0.1500\n",
      "Epoch [8], last_lr: 0.00041, train_loss: 4.1486, val_loss: 4.3394, val_acc: 0.1540\n",
      "Epoch [9], last_lr: 0.00047, train_loss: 3.9094, val_loss: 4.2141, val_acc: 0.1660\n",
      "Epoch [10], last_lr: 0.00053, train_loss: 3.7606, val_loss: 4.1465, val_acc: 0.1860\n",
      "Epoch [11], last_lr: 0.00060, train_loss: 3.6926, val_loss: 4.0765, val_acc: 0.1940\n",
      "Epoch [12], last_lr: 0.00068, train_loss: 3.5345, val_loss: 3.9572, val_acc: 0.2140\n",
      "Epoch [13], last_lr: 0.00075, train_loss: 3.3319, val_loss: 3.7865, val_acc: 0.2060\n",
      "Epoch [14], last_lr: 0.00084, train_loss: 3.0459, val_loss: 3.5826, val_acc: 0.2220\n",
      "Epoch [15], last_lr: 0.00092, train_loss: 2.8545, val_loss: 3.3524, val_acc: 0.2380\n",
      "Epoch [16], last_lr: 0.00102, train_loss: 2.6341, val_loss: 3.1396, val_acc: 0.2660\n",
      "Epoch [17], last_lr: 0.00111, train_loss: 2.3788, val_loss: 2.9289, val_acc: 0.3000\n",
      "Epoch [18], last_lr: 0.00121, train_loss: 2.0898, val_loss: 2.7267, val_acc: 0.3280\n",
      "Epoch [19], last_lr: 0.00131, train_loss: 1.8537, val_loss: 2.4930, val_acc: 0.3560\n",
      "Epoch [20], last_lr: 0.00141, train_loss: 1.6044, val_loss: 2.2920, val_acc: 0.4100\n",
      "Epoch [21], last_lr: 0.00152, train_loss: 1.4376, val_loss: 2.1055, val_acc: 0.4520\n",
      "Epoch [22], last_lr: 0.00163, train_loss: 1.2213, val_loss: 1.9191, val_acc: 0.4820\n",
      "Epoch [23], last_lr: 0.00174, train_loss: 1.0460, val_loss: 1.7788, val_acc: 0.5000\n",
      "Epoch [24], last_lr: 0.00185, train_loss: 0.8894, val_loss: 1.6649, val_acc: 0.5220\n",
      "Epoch [25], last_lr: 0.00196, train_loss: 0.8202, val_loss: 1.5589, val_acc: 0.5540\n",
      "Epoch [26], last_lr: 0.00207, train_loss: 0.6914, val_loss: 1.4863, val_acc: 0.5700\n",
      "Epoch [27], last_lr: 0.00218, train_loss: 0.6243, val_loss: 1.4108, val_acc: 0.6020\n",
      "Epoch [28], last_lr: 0.00230, train_loss: 0.5768, val_loss: 1.3728, val_acc: 0.6100\n",
      "Epoch [29], last_lr: 0.00241, train_loss: 0.5399, val_loss: 1.3127, val_acc: 0.6280\n",
      "Epoch [30], last_lr: 0.00252, train_loss: 0.4725, val_loss: 1.3445, val_acc: 0.6220\n",
      "Epoch [31], last_lr: 0.00262, train_loss: 0.4563, val_loss: 1.2606, val_acc: 0.6380\n",
      "Epoch [32], last_lr: 0.00273, train_loss: 0.4628, val_loss: 1.3097, val_acc: 0.6340\n",
      "Epoch [33], last_lr: 0.00284, train_loss: 0.4540, val_loss: 1.2427, val_acc: 0.6500\n",
      "Epoch [34], last_lr: 0.00294, train_loss: 0.4105, val_loss: 1.2538, val_acc: 0.6380\n",
      "Epoch [35], last_lr: 0.00304, train_loss: 0.4116, val_loss: 1.2615, val_acc: 0.6280\n",
      "Epoch [36], last_lr: 0.00313, train_loss: 0.4051, val_loss: 1.2682, val_acc: 0.6300\n",
      "Epoch [37], last_lr: 0.00322, train_loss: 0.3865, val_loss: 1.2221, val_acc: 0.6480\n",
      "Epoch [38], last_lr: 0.00331, train_loss: 0.3791, val_loss: 1.2344, val_acc: 0.6340\n",
      "Epoch [39], last_lr: 0.00339, train_loss: 0.3485, val_loss: 1.2515, val_acc: 0.6420\n",
      "Epoch [40], last_lr: 0.00347, train_loss: 0.3826, val_loss: 1.2600, val_acc: 0.6160\n",
      "Epoch [41], last_lr: 0.00355, train_loss: 0.3671, val_loss: 1.2506, val_acc: 0.6380\n",
      "Epoch [42], last_lr: 0.00362, train_loss: 0.3522, val_loss: 1.2558, val_acc: 0.6420\n",
      "Epoch [43], last_lr: 0.00368, train_loss: 0.3552, val_loss: 1.2067, val_acc: 0.6460\n",
      "Epoch [44], last_lr: 0.00374, train_loss: 0.3674, val_loss: 1.2105, val_acc: 0.6440\n",
      "Epoch [45], last_lr: 0.00379, train_loss: 0.3456, val_loss: 1.2783, val_acc: 0.6180\n",
      "Epoch [46], last_lr: 0.00384, train_loss: 0.3401, val_loss: 1.2122, val_acc: 0.6180\n",
      "Epoch [47], last_lr: 0.00388, train_loss: 0.3285, val_loss: 1.2225, val_acc: 0.6360\n",
      "Epoch [48], last_lr: 0.00392, train_loss: 0.3465, val_loss: 1.1928, val_acc: 0.6220\n",
      "Epoch [49], last_lr: 0.00395, train_loss: 0.3208, val_loss: 1.2197, val_acc: 0.6400\n",
      "Epoch [50], last_lr: 0.00397, train_loss: 0.3397, val_loss: 1.2275, val_acc: 0.6520\n",
      "Epoch [51], last_lr: 0.00399, train_loss: 0.3099, val_loss: 1.1769, val_acc: 0.6420\n",
      "Epoch [52], last_lr: 0.00400, train_loss: 0.3167, val_loss: 1.1838, val_acc: 0.6380\n",
      "Epoch [53], last_lr: 0.00400, train_loss: 0.3506, val_loss: 1.2136, val_acc: 0.6360\n",
      "Epoch [54], last_lr: 0.00400, train_loss: 0.3043, val_loss: 1.2194, val_acc: 0.6300\n",
      "Epoch [55], last_lr: 0.00400, train_loss: 0.3179, val_loss: 1.2480, val_acc: 0.6360\n",
      "Epoch [56], last_lr: 0.00399, train_loss: 0.3182, val_loss: 1.2109, val_acc: 0.6500\n",
      "Epoch [57], last_lr: 0.00399, train_loss: 0.3228, val_loss: 1.2108, val_acc: 0.6220\n",
      "Epoch [58], last_lr: 0.00398, train_loss: 0.3287, val_loss: 1.2172, val_acc: 0.6420\n",
      "Epoch [59], last_lr: 0.00398, train_loss: 0.3064, val_loss: 1.1862, val_acc: 0.6500\n",
      "Epoch [60], last_lr: 0.00397, train_loss: 0.3069, val_loss: 1.2328, val_acc: 0.6280\n",
      "Epoch [61], last_lr: 0.00396, train_loss: 0.3159, val_loss: 1.1750, val_acc: 0.6380\n",
      "Epoch [62], last_lr: 0.00395, train_loss: 0.3169, val_loss: 1.1946, val_acc: 0.6380\n",
      "Epoch [63], last_lr: 0.00394, train_loss: 0.3050, val_loss: 1.1829, val_acc: 0.6480\n",
      "Epoch [64], last_lr: 0.00393, train_loss: 0.2973, val_loss: 1.2169, val_acc: 0.6600\n",
      "Epoch [65], last_lr: 0.00391, train_loss: 0.3257, val_loss: 1.1973, val_acc: 0.6240\n",
      "Epoch [66], last_lr: 0.00390, train_loss: 0.3115, val_loss: 1.2435, val_acc: 0.6200\n",
      "Epoch [67], last_lr: 0.00388, train_loss: 0.2915, val_loss: 1.2216, val_acc: 0.6580\n",
      "Epoch [68], last_lr: 0.00386, train_loss: 0.3142, val_loss: 1.2013, val_acc: 0.6360\n",
      "Epoch [69], last_lr: 0.00384, train_loss: 0.2939, val_loss: 1.2061, val_acc: 0.6380\n",
      "Epoch [70], last_lr: 0.00382, train_loss: 0.2892, val_loss: 1.1619, val_acc: 0.6480\n",
      "Epoch [71], last_lr: 0.00380, train_loss: 0.3088, val_loss: 1.2315, val_acc: 0.6220\n",
      "Epoch [72], last_lr: 0.00378, train_loss: 0.3060, val_loss: 1.1871, val_acc: 0.6340\n",
      "Epoch [73], last_lr: 0.00376, train_loss: 0.3025, val_loss: 1.1796, val_acc: 0.6620\n",
      "Epoch [74], last_lr: 0.00373, train_loss: 0.3130, val_loss: 1.2328, val_acc: 0.6320\n",
      "Epoch [75], last_lr: 0.00371, train_loss: 0.3010, val_loss: 1.2287, val_acc: 0.6480\n",
      "Epoch [76], last_lr: 0.00368, train_loss: 0.3117, val_loss: 1.1942, val_acc: 0.6420\n",
      "Epoch [77], last_lr: 0.00365, train_loss: 0.2945, val_loss: 1.2250, val_acc: 0.6560\n",
      "Epoch [78], last_lr: 0.00362, train_loss: 0.3124, val_loss: 1.2507, val_acc: 0.6220\n",
      "Epoch [79], last_lr: 0.00359, train_loss: 0.2874, val_loss: 1.1916, val_acc: 0.6420\n",
      "Epoch [80], last_lr: 0.00356, train_loss: 0.2870, val_loss: 1.2232, val_acc: 0.6340\n",
      "Epoch [81], last_lr: 0.00353, train_loss: 0.2848, val_loss: 1.2094, val_acc: 0.6500\n",
      "Epoch [82], last_lr: 0.00350, train_loss: 0.3208, val_loss: 1.2241, val_acc: 0.6260\n",
      "Epoch [83], last_lr: 0.00347, train_loss: 0.2927, val_loss: 1.1791, val_acc: 0.6620\n",
      "Epoch [84], last_lr: 0.00343, train_loss: 0.3049, val_loss: 1.2040, val_acc: 0.6380\n",
      "Epoch [85], last_lr: 0.00340, train_loss: 0.2787, val_loss: 1.1999, val_acc: 0.6480\n",
      "Epoch [86], last_lr: 0.00336, train_loss: 0.3150, val_loss: 1.1844, val_acc: 0.6360\n",
      "Epoch [87], last_lr: 0.00332, train_loss: 0.2945, val_loss: 1.2012, val_acc: 0.6440\n",
      "Epoch [88], last_lr: 0.00329, train_loss: 0.2902, val_loss: 1.1638, val_acc: 0.6340\n",
      "Epoch [89], last_lr: 0.00325, train_loss: 0.2934, val_loss: 1.1773, val_acc: 0.6580\n",
      "Epoch [90], last_lr: 0.00321, train_loss: 0.3035, val_loss: 1.2048, val_acc: 0.6300\n",
      "Epoch [91], last_lr: 0.00317, train_loss: 0.2951, val_loss: 1.1566, val_acc: 0.6480\n",
      "Epoch [92], last_lr: 0.00313, train_loss: 0.2988, val_loss: 1.2078, val_acc: 0.6380\n",
      "Epoch [93], last_lr: 0.00309, train_loss: 0.2757, val_loss: 1.1757, val_acc: 0.6320\n",
      "Epoch [94], last_lr: 0.00304, train_loss: 0.2879, val_loss: 1.2012, val_acc: 0.6480\n",
      "Epoch [95], last_lr: 0.00300, train_loss: 0.2979, val_loss: 1.2109, val_acc: 0.6280\n",
      "Epoch [96], last_lr: 0.00296, train_loss: 0.3024, val_loss: 1.1897, val_acc: 0.6380\n",
      "Epoch [97], last_lr: 0.00291, train_loss: 0.2851, val_loss: 1.1680, val_acc: 0.6460\n",
      "Epoch [98], last_lr: 0.00287, train_loss: 0.2943, val_loss: 1.2018, val_acc: 0.6220\n",
      "Epoch [99], last_lr: 0.00282, train_loss: 0.2820, val_loss: 1.2023, val_acc: 0.6460\n",
      "Epoch [100], last_lr: 0.00278, train_loss: 0.2955, val_loss: 1.1655, val_acc: 0.6340\n",
      "Epoch [101], last_lr: 0.00273, train_loss: 0.2986, val_loss: 1.1751, val_acc: 0.6460\n",
      "Epoch [102], last_lr: 0.00268, train_loss: 0.2965, val_loss: 1.1800, val_acc: 0.6440\n",
      "Epoch [103], last_lr: 0.00264, train_loss: 0.2896, val_loss: 1.1721, val_acc: 0.6400\n",
      "Epoch [104], last_lr: 0.00259, train_loss: 0.2669, val_loss: 1.2243, val_acc: 0.6320\n",
      "Epoch [105], last_lr: 0.00254, train_loss: 0.2752, val_loss: 1.1757, val_acc: 0.6320\n",
      "Epoch [106], last_lr: 0.00249, train_loss: 0.2928, val_loss: 1.2142, val_acc: 0.6340\n",
      "Epoch [107], last_lr: 0.00245, train_loss: 0.2861, val_loss: 1.1677, val_acc: 0.6540\n",
      "Epoch [108], last_lr: 0.00240, train_loss: 0.3169, val_loss: 1.1829, val_acc: 0.6420\n",
      "Epoch [109], last_lr: 0.00235, train_loss: 0.2969, val_loss: 1.1904, val_acc: 0.6440\n",
      "Epoch [110], last_lr: 0.00230, train_loss: 0.2910, val_loss: 1.1800, val_acc: 0.6500\n",
      "Epoch [111], last_lr: 0.00225, train_loss: 0.2627, val_loss: 1.1785, val_acc: 0.6400\n",
      "Epoch [112], last_lr: 0.00220, train_loss: 0.2900, val_loss: 1.1899, val_acc: 0.6360\n",
      "Epoch [113], last_lr: 0.00215, train_loss: 0.2776, val_loss: 1.1744, val_acc: 0.6420\n",
      "Epoch [114], last_lr: 0.00210, train_loss: 0.2703, val_loss: 1.1901, val_acc: 0.6440\n",
      "Epoch [115], last_lr: 0.00205, train_loss: 0.2948, val_loss: 1.1864, val_acc: 0.6440\n",
      "Epoch [116], last_lr: 0.00200, train_loss: 0.2772, val_loss: 1.1576, val_acc: 0.6500\n",
      "Epoch [117], last_lr: 0.00195, train_loss: 0.2999, val_loss: 1.1806, val_acc: 0.6420\n",
      "Epoch [118], last_lr: 0.00190, train_loss: 0.2777, val_loss: 1.1583, val_acc: 0.6460\n",
      "Epoch [119], last_lr: 0.00185, train_loss: 0.2865, val_loss: 1.1744, val_acc: 0.6480\n",
      "Epoch [120], last_lr: 0.00180, train_loss: 0.2862, val_loss: 1.1894, val_acc: 0.6320\n",
      "Epoch [121], last_lr: 0.00175, train_loss: 0.2926, val_loss: 1.1611, val_acc: 0.6440\n",
      "Epoch [122], last_lr: 0.00170, train_loss: 0.2846, val_loss: 1.1775, val_acc: 0.6480\n",
      "Epoch [123], last_lr: 0.00165, train_loss: 0.2822, val_loss: 1.1792, val_acc: 0.6420\n",
      "Epoch [124], last_lr: 0.00160, train_loss: 0.2800, val_loss: 1.1884, val_acc: 0.6340\n",
      "Epoch [125], last_lr: 0.00155, train_loss: 0.2752, val_loss: 1.1816, val_acc: 0.6460\n",
      "Epoch [126], last_lr: 0.00151, train_loss: 0.3054, val_loss: 1.1824, val_acc: 0.6520\n",
      "Epoch [127], last_lr: 0.00146, train_loss: 0.2996, val_loss: 1.1990, val_acc: 0.6360\n",
      "Epoch [128], last_lr: 0.00141, train_loss: 0.2863, val_loss: 1.1912, val_acc: 0.6380\n",
      "Epoch [129], last_lr: 0.00136, train_loss: 0.2662, val_loss: 1.1775, val_acc: 0.6480\n",
      "Epoch [130], last_lr: 0.00132, train_loss: 0.2952, val_loss: 1.1866, val_acc: 0.6440\n",
      "Epoch [131], last_lr: 0.00127, train_loss: 0.2925, val_loss: 1.1759, val_acc: 0.6400\n",
      "Epoch [132], last_lr: 0.00122, train_loss: 0.2895, val_loss: 1.1862, val_acc: 0.6460\n",
      "Epoch [133], last_lr: 0.00118, train_loss: 0.2800, val_loss: 1.1902, val_acc: 0.6480\n",
      "Epoch [134], last_lr: 0.00113, train_loss: 0.2820, val_loss: 1.1735, val_acc: 0.6340\n",
      "Epoch [135], last_lr: 0.00109, train_loss: 0.2733, val_loss: 1.1821, val_acc: 0.6440\n",
      "Epoch [136], last_lr: 0.00104, train_loss: 0.2725, val_loss: 1.1929, val_acc: 0.6400\n",
      "Epoch [137], last_lr: 0.00100, train_loss: 0.2834, val_loss: 1.1711, val_acc: 0.6500\n",
      "Epoch [138], last_lr: 0.00096, train_loss: 0.2847, val_loss: 1.1802, val_acc: 0.6440\n",
      "Epoch [139], last_lr: 0.00091, train_loss: 0.2700, val_loss: 1.1884, val_acc: 0.6500\n",
      "Epoch [140], last_lr: 0.00087, train_loss: 0.2744, val_loss: 1.1866, val_acc: 0.6380\n",
      "Epoch [141], last_lr: 0.00083, train_loss: 0.2911, val_loss: 1.1932, val_acc: 0.6360\n",
      "Epoch [142], last_lr: 0.00079, train_loss: 0.2734, val_loss: 1.1820, val_acc: 0.6440\n",
      "Epoch [143], last_lr: 0.00075, train_loss: 0.2859, val_loss: 1.1775, val_acc: 0.6440\n",
      "Epoch [144], last_lr: 0.00071, train_loss: 0.2802, val_loss: 1.1786, val_acc: 0.6500\n",
      "Epoch [145], last_lr: 0.00068, train_loss: 0.2695, val_loss: 1.1899, val_acc: 0.6440\n",
      "Epoch [146], last_lr: 0.00064, train_loss: 0.2662, val_loss: 1.1868, val_acc: 0.6400\n",
      "Epoch [147], last_lr: 0.00060, train_loss: 0.2982, val_loss: 1.1830, val_acc: 0.6480\n",
      "Epoch [148], last_lr: 0.00057, train_loss: 0.2756, val_loss: 1.1743, val_acc: 0.6460\n",
      "Epoch [149], last_lr: 0.00053, train_loss: 0.2859, val_loss: 1.1784, val_acc: 0.6440\n",
      "Epoch [150], last_lr: 0.00050, train_loss: 0.2755, val_loss: 1.1798, val_acc: 0.6460\n",
      "Epoch [151], last_lr: 0.00047, train_loss: 0.2764, val_loss: 1.1857, val_acc: 0.6440\n",
      "Epoch [152], last_lr: 0.00044, train_loss: 0.2838, val_loss: 1.1860, val_acc: 0.6420\n",
      "Epoch [153], last_lr: 0.00041, train_loss: 0.2967, val_loss: 1.1822, val_acc: 0.6440\n",
      "Epoch [154], last_lr: 0.00038, train_loss: 0.2765, val_loss: 1.1720, val_acc: 0.6420\n",
      "Epoch [155], last_lr: 0.00035, train_loss: 0.2878, val_loss: 1.1702, val_acc: 0.6460\n",
      "Epoch [156], last_lr: 0.00032, train_loss: 0.2739, val_loss: 1.1724, val_acc: 0.6400\n",
      "Epoch [157], last_lr: 0.00029, train_loss: 0.2787, val_loss: 1.1785, val_acc: 0.6420\n",
      "Epoch [158], last_lr: 0.00027, train_loss: 0.2921, val_loss: 1.1806, val_acc: 0.6420\n",
      "Epoch [159], last_lr: 0.00024, train_loss: 0.2698, val_loss: 1.1896, val_acc: 0.6460\n",
      "Epoch [160], last_lr: 0.00022, train_loss: 0.2807, val_loss: 1.1881, val_acc: 0.6440\n",
      "Epoch [161], last_lr: 0.00020, train_loss: 0.2857, val_loss: 1.1885, val_acc: 0.6440\n",
      "Epoch [162], last_lr: 0.00018, train_loss: 0.2877, val_loss: 1.1869, val_acc: 0.6440\n",
      "Epoch [163], last_lr: 0.00016, train_loss: 0.3009, val_loss: 1.1823, val_acc: 0.6420\n",
      "Epoch [164], last_lr: 0.00014, train_loss: 0.2740, val_loss: 1.1813, val_acc: 0.6440\n",
      "Epoch [165], last_lr: 0.00012, train_loss: 0.2847, val_loss: 1.1787, val_acc: 0.6460\n",
      "Epoch [166], last_lr: 0.00010, train_loss: 0.2841, val_loss: 1.1805, val_acc: 0.6440\n",
      "Epoch [167], last_lr: 0.00009, train_loss: 0.2769, val_loss: 1.1811, val_acc: 0.6480\n",
      "Epoch [168], last_lr: 0.00007, train_loss: 0.2784, val_loss: 1.1834, val_acc: 0.6480\n",
      "Epoch [169], last_lr: 0.00006, train_loss: 0.2976, val_loss: 1.1848, val_acc: 0.6440\n",
      "Epoch [170], last_lr: 0.00005, train_loss: 0.2933, val_loss: 1.1834, val_acc: 0.6420\n",
      "Epoch [171], last_lr: 0.00004, train_loss: 0.2966, val_loss: 1.1831, val_acc: 0.6440\n",
      "Epoch [172], last_lr: 0.00003, train_loss: 0.2748, val_loss: 1.1813, val_acc: 0.6400\n",
      "Epoch [173], last_lr: 0.00002, train_loss: 0.2676, val_loss: 1.1836, val_acc: 0.6440\n",
      "Epoch [174], last_lr: 0.00002, train_loss: 0.2818, val_loss: 1.1834, val_acc: 0.6440\n",
      "Epoch [175], last_lr: 0.00001, train_loss: 0.2820, val_loss: 1.1825, val_acc: 0.6460\n",
      "Epoch [176], last_lr: 0.00001, train_loss: 0.2935, val_loss: 1.1841, val_acc: 0.6440\n",
      "Epoch [177], last_lr: 0.00000, train_loss: 0.2742, val_loss: 1.1842, val_acc: 0.6460\n",
      "Epoch [178], last_lr: 0.00000, train_loss: 0.3028, val_loss: 1.1825, val_acc: 0.6420\n",
      "Epoch [179], last_lr: 0.00000, train_loss: 0.2894, val_loss: 1.1809, val_acc: 0.6440\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[{'val_loss': 14.043022155761719, 'val_acc': 0.20000000298023224}]\n",
      "Epoch [0], last_lr: 0.00016, train_loss: 15.7532, val_loss: 14.2545, val_acc: 0.2000\n",
      "Epoch [1], last_lr: 0.00017, train_loss: 15.2065, val_loss: 14.4245, val_acc: 0.2000\n",
      "Epoch [2], last_lr: 0.00019, train_loss: 14.6558, val_loss: 14.2387, val_acc: 0.2000\n",
      "Epoch [3], last_lr: 0.00021, train_loss: 13.9760, val_loss: 13.8447, val_acc: 0.2020\n",
      "Epoch [4], last_lr: 0.00024, train_loss: 13.3381, val_loss: 13.2450, val_acc: 0.2020\n",
      "Epoch [5], last_lr: 0.00027, train_loss: 12.5369, val_loss: 12.4913, val_acc: 0.1980\n",
      "Epoch [6], last_lr: 0.00031, train_loss: 11.7362, val_loss: 11.5863, val_acc: 0.2020\n",
      "Epoch [7], last_lr: 0.00036, train_loss: 10.7649, val_loss: 10.6258, val_acc: 0.1980\n",
      "Epoch [8], last_lr: 0.00041, train_loss: 9.7657, val_loss: 9.5748, val_acc: 0.2000\n",
      "Epoch [9], last_lr: 0.00047, train_loss: 8.7069, val_loss: 8.5042, val_acc: 0.1920\n",
      "Epoch [10], last_lr: 0.00053, train_loss: 7.7245, val_loss: 7.4419, val_acc: 0.1920\n",
      "Epoch [11], last_lr: 0.00060, train_loss: 6.6966, val_loss: 6.3926, val_acc: 0.1660\n",
      "Epoch [12], last_lr: 0.00068, train_loss: 5.8097, val_loss: 5.4988, val_acc: 0.1400\n",
      "Epoch [13], last_lr: 0.00075, train_loss: 5.2335, val_loss: 4.9754, val_acc: 0.1480\n",
      "Epoch [14], last_lr: 0.00084, train_loss: 4.9465, val_loss: 4.6509, val_acc: 0.1580\n",
      "Epoch [15], last_lr: 0.00092, train_loss: 4.6923, val_loss: 4.3549, val_acc: 0.1740\n",
      "Epoch [16], last_lr: 0.00102, train_loss: 4.4337, val_loss: 4.2651, val_acc: 0.1740\n",
      "Epoch [17], last_lr: 0.00111, train_loss: 4.2181, val_loss: 4.1418, val_acc: 0.1760\n",
      "Epoch [18], last_lr: 0.00121, train_loss: 3.9225, val_loss: 3.8864, val_acc: 0.1820\n",
      "Epoch [19], last_lr: 0.00131, train_loss: 3.6424, val_loss: 3.6129, val_acc: 0.2060\n",
      "Epoch [20], last_lr: 0.00141, train_loss: 3.3185, val_loss: 3.3265, val_acc: 0.2240\n",
      "Epoch [21], last_lr: 0.00152, train_loss: 2.9871, val_loss: 3.0640, val_acc: 0.2420\n",
      "Epoch [22], last_lr: 0.00163, train_loss: 2.6713, val_loss: 2.7485, val_acc: 0.2820\n",
      "Epoch [23], last_lr: 0.00174, train_loss: 2.3769, val_loss: 2.4690, val_acc: 0.3280\n",
      "Epoch [24], last_lr: 0.00185, train_loss: 1.9778, val_loss: 2.2254, val_acc: 0.3660\n",
      "Epoch [25], last_lr: 0.00196, train_loss: 1.7417, val_loss: 2.0101, val_acc: 0.3980\n",
      "Epoch [26], last_lr: 0.00207, train_loss: 1.4438, val_loss: 1.8377, val_acc: 0.4320\n",
      "Epoch [27], last_lr: 0.00218, train_loss: 1.2284, val_loss: 1.7021, val_acc: 0.4640\n",
      "Epoch [28], last_lr: 0.00230, train_loss: 1.0917, val_loss: 1.5824, val_acc: 0.4820\n",
      "Epoch [29], last_lr: 0.00241, train_loss: 0.9429, val_loss: 1.4888, val_acc: 0.5040\n",
      "Epoch [30], last_lr: 0.00252, train_loss: 0.8432, val_loss: 1.4101, val_acc: 0.5180\n",
      "Epoch [31], last_lr: 0.00262, train_loss: 0.7778, val_loss: 1.3437, val_acc: 0.5400\n",
      "Epoch [32], last_lr: 0.00273, train_loss: 0.6886, val_loss: 1.3047, val_acc: 0.5420\n",
      "Epoch [33], last_lr: 0.00284, train_loss: 0.6381, val_loss: 1.2689, val_acc: 0.5720\n",
      "Epoch [34], last_lr: 0.00294, train_loss: 0.5974, val_loss: 1.2552, val_acc: 0.5680\n",
      "Epoch [35], last_lr: 0.00304, train_loss: 0.5612, val_loss: 1.2307, val_acc: 0.5720\n",
      "Epoch [36], last_lr: 0.00313, train_loss: 0.5569, val_loss: 1.2220, val_acc: 0.5800\n",
      "Epoch [37], last_lr: 0.00322, train_loss: 0.5303, val_loss: 1.2082, val_acc: 0.5900\n",
      "Epoch [38], last_lr: 0.00331, train_loss: 0.4872, val_loss: 1.2149, val_acc: 0.5700\n",
      "Epoch [39], last_lr: 0.00339, train_loss: 0.5010, val_loss: 1.1912, val_acc: 0.5840\n",
      "Epoch [40], last_lr: 0.00347, train_loss: 0.4805, val_loss: 1.1863, val_acc: 0.5780\n",
      "Epoch [41], last_lr: 0.00355, train_loss: 0.4770, val_loss: 1.1910, val_acc: 0.5840\n",
      "Epoch [42], last_lr: 0.00362, train_loss: 0.4528, val_loss: 1.1782, val_acc: 0.5860\n",
      "Epoch [43], last_lr: 0.00368, train_loss: 0.4521, val_loss: 1.1836, val_acc: 0.5860\n",
      "Epoch [44], last_lr: 0.00374, train_loss: 0.4344, val_loss: 1.1845, val_acc: 0.5800\n",
      "Epoch [45], last_lr: 0.00379, train_loss: 0.4608, val_loss: 1.1848, val_acc: 0.5860\n",
      "Epoch [46], last_lr: 0.00384, train_loss: 0.4545, val_loss: 1.1700, val_acc: 0.6000\n",
      "Epoch [47], last_lr: 0.00388, train_loss: 0.4249, val_loss: 1.1593, val_acc: 0.5860\n",
      "Epoch [48], last_lr: 0.00392, train_loss: 0.4213, val_loss: 1.1635, val_acc: 0.5960\n",
      "Epoch [49], last_lr: 0.00395, train_loss: 0.4027, val_loss: 1.1685, val_acc: 0.5900\n",
      "Epoch [50], last_lr: 0.00397, train_loss: 0.4130, val_loss: 1.1832, val_acc: 0.5860\n",
      "Epoch [51], last_lr: 0.00399, train_loss: 0.4196, val_loss: 1.1883, val_acc: 0.5900\n",
      "Epoch [52], last_lr: 0.00400, train_loss: 0.4068, val_loss: 1.1849, val_acc: 0.6040\n",
      "Epoch [53], last_lr: 0.00400, train_loss: 0.4114, val_loss: 1.1812, val_acc: 0.5960\n",
      "Epoch [54], last_lr: 0.00400, train_loss: 0.4141, val_loss: 1.2187, val_acc: 0.5760\n",
      "Epoch [55], last_lr: 0.00400, train_loss: 0.4120, val_loss: 1.1702, val_acc: 0.5860\n",
      "Epoch [56], last_lr: 0.00399, train_loss: 0.3964, val_loss: 1.2112, val_acc: 0.5800\n",
      "Epoch [57], last_lr: 0.00399, train_loss: 0.4302, val_loss: 1.1758, val_acc: 0.6020\n",
      "Epoch [58], last_lr: 0.00398, train_loss: 0.4118, val_loss: 1.1810, val_acc: 0.5880\n",
      "Epoch [59], last_lr: 0.00398, train_loss: 0.3804, val_loss: 1.1706, val_acc: 0.5920\n",
      "Epoch [60], last_lr: 0.00397, train_loss: 0.4085, val_loss: 1.2044, val_acc: 0.5980\n",
      "Epoch [61], last_lr: 0.00396, train_loss: 0.4017, val_loss: 1.1785, val_acc: 0.6120\n",
      "Epoch [62], last_lr: 0.00395, train_loss: 0.3990, val_loss: 1.2159, val_acc: 0.5780\n",
      "Epoch [63], last_lr: 0.00394, train_loss: 0.4236, val_loss: 1.1649, val_acc: 0.5960\n",
      "Epoch [64], last_lr: 0.00393, train_loss: 0.3827, val_loss: 1.1652, val_acc: 0.5940\n",
      "Epoch [65], last_lr: 0.00391, train_loss: 0.3723, val_loss: 1.2053, val_acc: 0.5840\n",
      "Epoch [66], last_lr: 0.00390, train_loss: 0.4036, val_loss: 1.1767, val_acc: 0.6060\n",
      "Epoch [67], last_lr: 0.00388, train_loss: 0.4033, val_loss: 1.2163, val_acc: 0.5800\n",
      "Epoch [68], last_lr: 0.00386, train_loss: 0.4138, val_loss: 1.1702, val_acc: 0.6080\n",
      "Epoch [69], last_lr: 0.00384, train_loss: 0.4081, val_loss: 1.1618, val_acc: 0.6020\n",
      "Epoch [70], last_lr: 0.00382, train_loss: 0.3855, val_loss: 1.2001, val_acc: 0.5960\n",
      "Epoch [71], last_lr: 0.00380, train_loss: 0.3880, val_loss: 1.2041, val_acc: 0.5960\n",
      "Epoch [72], last_lr: 0.00378, train_loss: 0.4165, val_loss: 1.1705, val_acc: 0.6120\n",
      "Epoch [73], last_lr: 0.00376, train_loss: 0.3885, val_loss: 1.1786, val_acc: 0.6000\n",
      "Epoch [74], last_lr: 0.00373, train_loss: 0.3763, val_loss: 1.1823, val_acc: 0.5920\n",
      "Epoch [75], last_lr: 0.00371, train_loss: 0.3809, val_loss: 1.1763, val_acc: 0.6000\n",
      "Epoch [76], last_lr: 0.00368, train_loss: 0.3878, val_loss: 1.2153, val_acc: 0.5840\n",
      "Epoch [77], last_lr: 0.00365, train_loss: 0.3942, val_loss: 1.1820, val_acc: 0.6060\n",
      "Epoch [78], last_lr: 0.00362, train_loss: 0.3828, val_loss: 1.1802, val_acc: 0.6020\n",
      "Epoch [79], last_lr: 0.00359, train_loss: 0.3773, val_loss: 1.1929, val_acc: 0.5820\n",
      "Epoch [80], last_lr: 0.00356, train_loss: 0.3881, val_loss: 1.1834, val_acc: 0.6060\n",
      "Epoch [81], last_lr: 0.00353, train_loss: 0.4018, val_loss: 1.1784, val_acc: 0.6000\n",
      "Epoch [82], last_lr: 0.00350, train_loss: 0.3668, val_loss: 1.1748, val_acc: 0.5940\n",
      "Epoch [83], last_lr: 0.00347, train_loss: 0.3700, val_loss: 1.1913, val_acc: 0.5940\n",
      "Epoch [84], last_lr: 0.00343, train_loss: 0.3918, val_loss: 1.1757, val_acc: 0.6060\n",
      "Epoch [85], last_lr: 0.00340, train_loss: 0.3862, val_loss: 1.1937, val_acc: 0.5880\n",
      "Epoch [86], last_lr: 0.00336, train_loss: 0.3918, val_loss: 1.1823, val_acc: 0.6040\n",
      "Epoch [87], last_lr: 0.00332, train_loss: 0.3799, val_loss: 1.1664, val_acc: 0.5980\n",
      "Epoch [88], last_lr: 0.00329, train_loss: 0.3673, val_loss: 1.1948, val_acc: 0.6060\n",
      "Epoch [89], last_lr: 0.00325, train_loss: 0.3976, val_loss: 1.1719, val_acc: 0.5960\n",
      "Epoch [90], last_lr: 0.00321, train_loss: 0.3955, val_loss: 1.1875, val_acc: 0.5960\n",
      "Epoch [91], last_lr: 0.00317, train_loss: 0.3735, val_loss: 1.1915, val_acc: 0.5960\n",
      "Epoch [92], last_lr: 0.00313, train_loss: 0.3728, val_loss: 1.1796, val_acc: 0.6060\n",
      "Epoch [93], last_lr: 0.00309, train_loss: 0.3787, val_loss: 1.1697, val_acc: 0.6000\n",
      "Epoch [94], last_lr: 0.00304, train_loss: 0.3878, val_loss: 1.1861, val_acc: 0.6120\n",
      "Epoch [95], last_lr: 0.00300, train_loss: 0.3956, val_loss: 1.1637, val_acc: 0.6020\n",
      "Epoch [96], last_lr: 0.00296, train_loss: 0.3712, val_loss: 1.1779, val_acc: 0.6000\n",
      "Epoch [97], last_lr: 0.00291, train_loss: 0.3819, val_loss: 1.1700, val_acc: 0.6040\n",
      "Epoch [98], last_lr: 0.00287, train_loss: 0.3838, val_loss: 1.2054, val_acc: 0.6040\n",
      "Epoch [99], last_lr: 0.00282, train_loss: 0.3937, val_loss: 1.1676, val_acc: 0.6040\n",
      "Epoch [100], last_lr: 0.00278, train_loss: 0.3651, val_loss: 1.1742, val_acc: 0.6080\n",
      "Epoch [101], last_lr: 0.00273, train_loss: 0.3649, val_loss: 1.1919, val_acc: 0.6060\n",
      "Epoch [102], last_lr: 0.00268, train_loss: 0.3808, val_loss: 1.1772, val_acc: 0.5960\n",
      "Epoch [103], last_lr: 0.00264, train_loss: 0.3773, val_loss: 1.1743, val_acc: 0.6060\n",
      "Epoch [104], last_lr: 0.00259, train_loss: 0.3668, val_loss: 1.1889, val_acc: 0.6060\n",
      "Epoch [105], last_lr: 0.00254, train_loss: 0.3607, val_loss: 1.1850, val_acc: 0.5880\n",
      "Epoch [106], last_lr: 0.00249, train_loss: 0.3757, val_loss: 1.1930, val_acc: 0.6060\n",
      "Epoch [107], last_lr: 0.00245, train_loss: 0.3604, val_loss: 1.1828, val_acc: 0.6080\n",
      "Epoch [108], last_lr: 0.00240, train_loss: 0.3825, val_loss: 1.1849, val_acc: 0.6080\n",
      "Epoch [109], last_lr: 0.00235, train_loss: 0.3672, val_loss: 1.1775, val_acc: 0.6000\n",
      "Epoch [110], last_lr: 0.00230, train_loss: 0.3778, val_loss: 1.1916, val_acc: 0.6020\n",
      "Epoch [111], last_lr: 0.00225, train_loss: 0.3805, val_loss: 1.1865, val_acc: 0.6000\n",
      "Epoch [112], last_lr: 0.00220, train_loss: 0.3560, val_loss: 1.1869, val_acc: 0.6080\n",
      "Epoch [113], last_lr: 0.00215, train_loss: 0.3789, val_loss: 1.1787, val_acc: 0.6100\n",
      "Epoch [114], last_lr: 0.00210, train_loss: 0.3708, val_loss: 1.1851, val_acc: 0.5960\n",
      "Epoch [115], last_lr: 0.00205, train_loss: 0.3715, val_loss: 1.1856, val_acc: 0.6060\n",
      "Epoch [116], last_lr: 0.00200, train_loss: 0.3606, val_loss: 1.1858, val_acc: 0.6040\n",
      "Epoch [117], last_lr: 0.00195, train_loss: 0.3548, val_loss: 1.1910, val_acc: 0.6040\n",
      "Epoch [118], last_lr: 0.00190, train_loss: 0.3723, val_loss: 1.1756, val_acc: 0.6080\n",
      "Epoch [119], last_lr: 0.00185, train_loss: 0.3613, val_loss: 1.1794, val_acc: 0.6060\n",
      "Epoch [120], last_lr: 0.00180, train_loss: 0.3633, val_loss: 1.1876, val_acc: 0.6120\n",
      "Epoch [121], last_lr: 0.00175, train_loss: 0.3553, val_loss: 1.1810, val_acc: 0.6060\n",
      "Epoch [122], last_lr: 0.00170, train_loss: 0.3634, val_loss: 1.1801, val_acc: 0.6040\n",
      "Epoch [123], last_lr: 0.00165, train_loss: 0.3672, val_loss: 1.1726, val_acc: 0.6020\n",
      "Epoch [124], last_lr: 0.00160, train_loss: 0.3659, val_loss: 1.1900, val_acc: 0.6020\n",
      "Epoch [125], last_lr: 0.00155, train_loss: 0.3645, val_loss: 1.1733, val_acc: 0.6040\n",
      "Epoch [126], last_lr: 0.00151, train_loss: 0.3707, val_loss: 1.1777, val_acc: 0.6080\n",
      "Epoch [127], last_lr: 0.00146, train_loss: 0.3595, val_loss: 1.1814, val_acc: 0.6020\n",
      "Epoch [128], last_lr: 0.00141, train_loss: 0.3655, val_loss: 1.1801, val_acc: 0.6020\n",
      "Epoch [129], last_lr: 0.00136, train_loss: 0.3595, val_loss: 1.1797, val_acc: 0.6040\n",
      "Epoch [130], last_lr: 0.00132, train_loss: 0.3666, val_loss: 1.1837, val_acc: 0.6040\n",
      "Epoch [131], last_lr: 0.00127, train_loss: 0.3573, val_loss: 1.1842, val_acc: 0.6040\n",
      "Epoch [132], last_lr: 0.00122, train_loss: 0.3674, val_loss: 1.1779, val_acc: 0.6040\n",
      "Epoch [133], last_lr: 0.00118, train_loss: 0.3593, val_loss: 1.1839, val_acc: 0.6000\n",
      "Epoch [134], last_lr: 0.00113, train_loss: 0.3571, val_loss: 1.1972, val_acc: 0.6020\n",
      "Epoch [135], last_lr: 0.00109, train_loss: 0.3693, val_loss: 1.1860, val_acc: 0.6100\n",
      "Epoch [136], last_lr: 0.00104, train_loss: 0.3493, val_loss: 1.1859, val_acc: 0.6060\n",
      "Epoch [137], last_lr: 0.00100, train_loss: 0.3532, val_loss: 1.1852, val_acc: 0.6080\n",
      "Epoch [138], last_lr: 0.00096, train_loss: 0.3654, val_loss: 1.1839, val_acc: 0.6000\n",
      "Epoch [139], last_lr: 0.00091, train_loss: 0.3768, val_loss: 1.1878, val_acc: 0.6100\n",
      "Epoch [140], last_lr: 0.00087, train_loss: 0.3791, val_loss: 1.1843, val_acc: 0.5980\n",
      "Epoch [141], last_lr: 0.00083, train_loss: 0.3650, val_loss: 1.1878, val_acc: 0.6060\n",
      "Epoch [142], last_lr: 0.00079, train_loss: 0.3399, val_loss: 1.1866, val_acc: 0.6080\n",
      "Epoch [143], last_lr: 0.00075, train_loss: 0.3557, val_loss: 1.1857, val_acc: 0.6020\n",
      "Epoch [144], last_lr: 0.00071, train_loss: 0.3444, val_loss: 1.1943, val_acc: 0.6060\n",
      "Epoch [145], last_lr: 0.00068, train_loss: 0.3642, val_loss: 1.2027, val_acc: 0.6040\n",
      "Epoch [146], last_lr: 0.00064, train_loss: 0.3607, val_loss: 1.1900, val_acc: 0.6000\n",
      "Epoch [147], last_lr: 0.00060, train_loss: 0.3693, val_loss: 1.1871, val_acc: 0.5980\n",
      "Epoch [148], last_lr: 0.00057, train_loss: 0.3511, val_loss: 1.1933, val_acc: 0.6060\n",
      "Epoch [149], last_lr: 0.00053, train_loss: 0.3703, val_loss: 1.1916, val_acc: 0.5980\n",
      "Epoch [150], last_lr: 0.00050, train_loss: 0.3683, val_loss: 1.1933, val_acc: 0.6080\n",
      "Epoch [151], last_lr: 0.00047, train_loss: 0.3677, val_loss: 1.1905, val_acc: 0.6080\n",
      "Epoch [152], last_lr: 0.00044, train_loss: 0.3633, val_loss: 1.1914, val_acc: 0.6040\n",
      "Epoch [153], last_lr: 0.00041, train_loss: 0.3633, val_loss: 1.1894, val_acc: 0.6000\n",
      "Epoch [154], last_lr: 0.00038, train_loss: 0.3560, val_loss: 1.1912, val_acc: 0.6060\n",
      "Epoch [155], last_lr: 0.00035, train_loss: 0.3658, val_loss: 1.1924, val_acc: 0.5980\n",
      "Epoch [156], last_lr: 0.00032, train_loss: 0.3581, val_loss: 1.1938, val_acc: 0.6080\n",
      "Epoch [157], last_lr: 0.00029, train_loss: 0.3623, val_loss: 1.1938, val_acc: 0.6040\n",
      "Epoch [158], last_lr: 0.00027, train_loss: 0.3528, val_loss: 1.1925, val_acc: 0.6100\n",
      "Epoch [159], last_lr: 0.00024, train_loss: 0.3644, val_loss: 1.1923, val_acc: 0.6100\n",
      "Epoch [160], last_lr: 0.00022, train_loss: 0.3494, val_loss: 1.1931, val_acc: 0.6060\n",
      "Epoch [161], last_lr: 0.00020, train_loss: 0.3599, val_loss: 1.1933, val_acc: 0.6020\n",
      "Epoch [162], last_lr: 0.00018, train_loss: 0.3570, val_loss: 1.1945, val_acc: 0.6020\n",
      "Epoch [163], last_lr: 0.00016, train_loss: 0.3673, val_loss: 1.1943, val_acc: 0.5980\n",
      "Epoch [164], last_lr: 0.00014, train_loss: 0.3606, val_loss: 1.1937, val_acc: 0.6000\n",
      "Epoch [165], last_lr: 0.00012, train_loss: 0.3436, val_loss: 1.1939, val_acc: 0.6060\n",
      "Epoch [166], last_lr: 0.00010, train_loss: 0.3585, val_loss: 1.1933, val_acc: 0.6040\n",
      "Epoch [167], last_lr: 0.00009, train_loss: 0.3614, val_loss: 1.1934, val_acc: 0.6020\n",
      "Epoch [168], last_lr: 0.00007, train_loss: 0.3632, val_loss: 1.1942, val_acc: 0.6080\n",
      "Epoch [169], last_lr: 0.00006, train_loss: 0.3708, val_loss: 1.1947, val_acc: 0.6080\n",
      "Epoch [170], last_lr: 0.00005, train_loss: 0.3628, val_loss: 1.1942, val_acc: 0.6100\n",
      "Epoch [171], last_lr: 0.00004, train_loss: 0.3600, val_loss: 1.1921, val_acc: 0.6020\n",
      "Epoch [172], last_lr: 0.00003, train_loss: 0.3598, val_loss: 1.1927, val_acc: 0.6040\n",
      "Epoch [173], last_lr: 0.00002, train_loss: 0.3615, val_loss: 1.1917, val_acc: 0.6100\n",
      "Epoch [174], last_lr: 0.00002, train_loss: 0.3528, val_loss: 1.1929, val_acc: 0.6100\n",
      "Epoch [175], last_lr: 0.00001, train_loss: 0.3583, val_loss: 1.1930, val_acc: 0.6080\n",
      "Epoch [176], last_lr: 0.00001, train_loss: 0.3664, val_loss: 1.1939, val_acc: 0.6060\n",
      "Epoch [177], last_lr: 0.00000, train_loss: 0.3438, val_loss: 1.1946, val_acc: 0.6060\n",
      "Epoch [178], last_lr: 0.00000, train_loss: 0.3737, val_loss: 1.1946, val_acc: 0.6080\n",
      "Epoch [179], last_lr: 0.00000, train_loss: 0.3613, val_loss: 1.1949, val_acc: 0.6080\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[{'val_loss': 7.388343811035156, 'val_acc': 0.1899999976158142}]\n",
      "Epoch [0], last_lr: 0.00016, train_loss: 9.9017, val_loss: 7.7740, val_acc: 0.1620\n",
      "Epoch [1], last_lr: 0.00017, train_loss: 9.5012, val_loss: 8.3051, val_acc: 0.1800\n",
      "Epoch [2], last_lr: 0.00019, train_loss: 9.0591, val_loss: 8.4508, val_acc: 0.1880\n",
      "Epoch [3], last_lr: 0.00021, train_loss: 8.6886, val_loss: 8.2511, val_acc: 0.1840\n",
      "Epoch [4], last_lr: 0.00024, train_loss: 8.3363, val_loss: 7.9214, val_acc: 0.1920\n",
      "Epoch [5], last_lr: 0.00027, train_loss: 7.8830, val_loss: 7.5252, val_acc: 0.1960\n",
      "Epoch [6], last_lr: 0.00031, train_loss: 7.4313, val_loss: 7.1138, val_acc: 0.2060\n",
      "Epoch [7], last_lr: 0.00036, train_loss: 7.0576, val_loss: 6.6421, val_acc: 0.2180\n",
      "Epoch [8], last_lr: 0.00041, train_loss: 6.5710, val_loss: 6.1246, val_acc: 0.2440\n",
      "Epoch [9], last_lr: 0.00047, train_loss: 6.0465, val_loss: 5.5873, val_acc: 0.2680\n",
      "Epoch [10], last_lr: 0.00053, train_loss: 5.5950, val_loss: 5.0923, val_acc: 0.2940\n",
      "Epoch [11], last_lr: 0.00060, train_loss: 5.1727, val_loss: 4.7264, val_acc: 0.3140\n",
      "Epoch [12], last_lr: 0.00068, train_loss: 4.8311, val_loss: 4.4023, val_acc: 0.3160\n",
      "Epoch [13], last_lr: 0.00075, train_loss: 4.4372, val_loss: 3.9898, val_acc: 0.3320\n",
      "Epoch [14], last_lr: 0.00084, train_loss: 3.9418, val_loss: 3.4625, val_acc: 0.3380\n",
      "Epoch [15], last_lr: 0.00092, train_loss: 3.3658, val_loss: 2.8936, val_acc: 0.3540\n",
      "Epoch [16], last_lr: 0.00102, train_loss: 2.7145, val_loss: 2.4809, val_acc: 0.3420\n",
      "Epoch [17], last_lr: 0.00111, train_loss: 2.5510, val_loss: 2.5116, val_acc: 0.2640\n",
      "Epoch [18], last_lr: 0.00121, train_loss: 2.5459, val_loss: 2.3856, val_acc: 0.2840\n",
      "Epoch [19], last_lr: 0.00131, train_loss: 2.3646, val_loss: 2.2360, val_acc: 0.3780\n",
      "Epoch [20], last_lr: 0.00141, train_loss: 2.2231, val_loss: 2.1688, val_acc: 0.3840\n",
      "Epoch [21], last_lr: 0.00152, train_loss: 2.0537, val_loss: 2.0544, val_acc: 0.3540\n",
      "Epoch [22], last_lr: 0.00163, train_loss: 1.9196, val_loss: 1.9550, val_acc: 0.3760\n",
      "Epoch [23], last_lr: 0.00174, train_loss: 1.7650, val_loss: 1.8568, val_acc: 0.4000\n",
      "Epoch [24], last_lr: 0.00185, train_loss: 1.6664, val_loss: 1.7625, val_acc: 0.4040\n",
      "Epoch [25], last_lr: 0.00196, train_loss: 1.4800, val_loss: 1.6789, val_acc: 0.4160\n",
      "Epoch [26], last_lr: 0.00207, train_loss: 1.3983, val_loss: 1.6117, val_acc: 0.4360\n",
      "Epoch [27], last_lr: 0.00218, train_loss: 1.3288, val_loss: 1.5479, val_acc: 0.4420\n",
      "Epoch [28], last_lr: 0.00230, train_loss: 1.2190, val_loss: 1.5003, val_acc: 0.4540\n",
      "Epoch [29], last_lr: 0.00241, train_loss: 1.1912, val_loss: 1.4546, val_acc: 0.4660\n",
      "Epoch [30], last_lr: 0.00252, train_loss: 1.0866, val_loss: 1.4192, val_acc: 0.4940\n",
      "Epoch [31], last_lr: 0.00262, train_loss: 1.0701, val_loss: 1.3833, val_acc: 0.4860\n",
      "Epoch [32], last_lr: 0.00273, train_loss: 1.0159, val_loss: 1.3536, val_acc: 0.5120\n",
      "Epoch [33], last_lr: 0.00284, train_loss: 0.9788, val_loss: 1.3249, val_acc: 0.5140\n",
      "Epoch [34], last_lr: 0.00294, train_loss: 0.9788, val_loss: 1.2994, val_acc: 0.5320\n",
      "Epoch [35], last_lr: 0.00304, train_loss: 0.9468, val_loss: 1.2801, val_acc: 0.5360\n",
      "Epoch [36], last_lr: 0.00313, train_loss: 0.9190, val_loss: 1.2773, val_acc: 0.5300\n",
      "Epoch [37], last_lr: 0.00322, train_loss: 0.9095, val_loss: 1.2539, val_acc: 0.5440\n",
      "Epoch [38], last_lr: 0.00331, train_loss: 0.8926, val_loss: 1.2739, val_acc: 0.5320\n",
      "Epoch [39], last_lr: 0.00339, train_loss: 0.8921, val_loss: 1.2453, val_acc: 0.5520\n",
      "Epoch [40], last_lr: 0.00347, train_loss: 0.8809, val_loss: 1.2470, val_acc: 0.5600\n",
      "Epoch [41], last_lr: 0.00355, train_loss: 0.8733, val_loss: 1.2374, val_acc: 0.5460\n",
      "Epoch [42], last_lr: 0.00362, train_loss: 0.8634, val_loss: 1.2278, val_acc: 0.5680\n",
      "Epoch [43], last_lr: 0.00368, train_loss: 0.8663, val_loss: 1.2148, val_acc: 0.5680\n",
      "Epoch [44], last_lr: 0.00374, train_loss: 0.8470, val_loss: 1.2117, val_acc: 0.5540\n",
      "Epoch [45], last_lr: 0.00379, train_loss: 0.8480, val_loss: 1.2409, val_acc: 0.5680\n",
      "Epoch [46], last_lr: 0.00384, train_loss: 0.8355, val_loss: 1.2185, val_acc: 0.5620\n",
      "Epoch [47], last_lr: 0.00388, train_loss: 0.8045, val_loss: 1.2024, val_acc: 0.5700\n",
      "Epoch [48], last_lr: 0.00392, train_loss: 0.8323, val_loss: 1.2387, val_acc: 0.5780\n",
      "Epoch [49], last_lr: 0.00395, train_loss: 0.8263, val_loss: 1.2101, val_acc: 0.5640\n",
      "Epoch [50], last_lr: 0.00397, train_loss: 0.8270, val_loss: 1.2043, val_acc: 0.5600\n",
      "Epoch [51], last_lr: 0.00399, train_loss: 0.8222, val_loss: 1.1844, val_acc: 0.5700\n",
      "Epoch [52], last_lr: 0.00400, train_loss: 0.7963, val_loss: 1.2270, val_acc: 0.5480\n",
      "Epoch [53], last_lr: 0.00400, train_loss: 0.8226, val_loss: 1.1890, val_acc: 0.5720\n",
      "Epoch [54], last_lr: 0.00400, train_loss: 0.8065, val_loss: 1.1890, val_acc: 0.5700\n",
      "Epoch [55], last_lr: 0.00400, train_loss: 0.7939, val_loss: 1.2169, val_acc: 0.5580\n",
      "Epoch [56], last_lr: 0.00399, train_loss: 0.8077, val_loss: 1.2393, val_acc: 0.5580\n",
      "Epoch [57], last_lr: 0.00399, train_loss: 0.8095, val_loss: 1.1840, val_acc: 0.5640\n",
      "Epoch [58], last_lr: 0.00398, train_loss: 0.7985, val_loss: 1.2151, val_acc: 0.5680\n",
      "Epoch [59], last_lr: 0.00398, train_loss: 0.8171, val_loss: 1.1715, val_acc: 0.5820\n",
      "Epoch [60], last_lr: 0.00397, train_loss: 0.7931, val_loss: 1.1846, val_acc: 0.5680\n",
      "Epoch [61], last_lr: 0.00396, train_loss: 0.8110, val_loss: 1.1743, val_acc: 0.5680\n",
      "Epoch [62], last_lr: 0.00395, train_loss: 0.7874, val_loss: 1.1895, val_acc: 0.5840\n",
      "Epoch [63], last_lr: 0.00394, train_loss: 0.7926, val_loss: 1.1596, val_acc: 0.5640\n",
      "Epoch [64], last_lr: 0.00393, train_loss: 0.7905, val_loss: 1.1796, val_acc: 0.5640\n",
      "Epoch [65], last_lr: 0.00391, train_loss: 0.7835, val_loss: 1.1621, val_acc: 0.5800\n",
      "Epoch [66], last_lr: 0.00390, train_loss: 0.7864, val_loss: 1.1847, val_acc: 0.5600\n",
      "Epoch [67], last_lr: 0.00388, train_loss: 0.8079, val_loss: 1.1720, val_acc: 0.5720\n",
      "Epoch [68], last_lr: 0.00386, train_loss: 0.7627, val_loss: 1.1583, val_acc: 0.5600\n",
      "Epoch [69], last_lr: 0.00384, train_loss: 0.7708, val_loss: 1.1850, val_acc: 0.5800\n",
      "Epoch [70], last_lr: 0.00382, train_loss: 0.7931, val_loss: 1.1679, val_acc: 0.5860\n",
      "Epoch [71], last_lr: 0.00380, train_loss: 0.7632, val_loss: 1.1578, val_acc: 0.5700\n",
      "Epoch [72], last_lr: 0.00378, train_loss: 0.7526, val_loss: 1.1695, val_acc: 0.5560\n",
      "Epoch [73], last_lr: 0.00376, train_loss: 0.7705, val_loss: 1.1960, val_acc: 0.5820\n",
      "Epoch [74], last_lr: 0.00373, train_loss: 0.7505, val_loss: 1.1510, val_acc: 0.5560\n",
      "Epoch [75], last_lr: 0.00371, train_loss: 0.7634, val_loss: 1.1501, val_acc: 0.5640\n",
      "Epoch [76], last_lr: 0.00368, train_loss: 0.7499, val_loss: 1.1785, val_acc: 0.5780\n",
      "Epoch [77], last_lr: 0.00365, train_loss: 0.7965, val_loss: 1.1558, val_acc: 0.5660\n",
      "Epoch [78], last_lr: 0.00362, train_loss: 0.7426, val_loss: 1.1679, val_acc: 0.5600\n",
      "Epoch [79], last_lr: 0.00359, train_loss: 0.7991, val_loss: 1.1806, val_acc: 0.5780\n",
      "Epoch [80], last_lr: 0.00356, train_loss: 0.7723, val_loss: 1.1430, val_acc: 0.5780\n",
      "Epoch [81], last_lr: 0.00353, train_loss: 0.7400, val_loss: 1.1544, val_acc: 0.5720\n",
      "Epoch [82], last_lr: 0.00350, train_loss: 0.7391, val_loss: 1.1476, val_acc: 0.5740\n",
      "Epoch [83], last_lr: 0.00347, train_loss: 0.7571, val_loss: 1.1612, val_acc: 0.5700\n",
      "Epoch [84], last_lr: 0.00343, train_loss: 0.7502, val_loss: 1.1523, val_acc: 0.5540\n",
      "Epoch [85], last_lr: 0.00340, train_loss: 0.7476, val_loss: 1.1490, val_acc: 0.5640\n",
      "Epoch [86], last_lr: 0.00336, train_loss: 0.7419, val_loss: 1.2004, val_acc: 0.5720\n",
      "Epoch [87], last_lr: 0.00332, train_loss: 0.7894, val_loss: 1.1470, val_acc: 0.5600\n",
      "Epoch [88], last_lr: 0.00329, train_loss: 0.7307, val_loss: 1.1520, val_acc: 0.5720\n",
      "Epoch [89], last_lr: 0.00325, train_loss: 0.7572, val_loss: 1.1415, val_acc: 0.5800\n",
      "Epoch [90], last_lr: 0.00321, train_loss: 0.7643, val_loss: 1.1571, val_acc: 0.5540\n",
      "Epoch [91], last_lr: 0.00317, train_loss: 0.7738, val_loss: 1.1538, val_acc: 0.5820\n",
      "Epoch [92], last_lr: 0.00313, train_loss: 0.7453, val_loss: 1.1572, val_acc: 0.5400\n",
      "Epoch [93], last_lr: 0.00309, train_loss: 0.7576, val_loss: 1.1588, val_acc: 0.5720\n",
      "Epoch [94], last_lr: 0.00304, train_loss: 0.7563, val_loss: 1.1386, val_acc: 0.5720\n",
      "Epoch [95], last_lr: 0.00300, train_loss: 0.7712, val_loss: 1.1802, val_acc: 0.5480\n",
      "Epoch [96], last_lr: 0.00296, train_loss: 0.7764, val_loss: 1.1422, val_acc: 0.5720\n",
      "Epoch [97], last_lr: 0.00291, train_loss: 0.7661, val_loss: 1.1449, val_acc: 0.5720\n",
      "Epoch [98], last_lr: 0.00287, train_loss: 0.7439, val_loss: 1.1392, val_acc: 0.5760\n",
      "Epoch [99], last_lr: 0.00282, train_loss: 0.7813, val_loss: 1.1510, val_acc: 0.5660\n",
      "Epoch [100], last_lr: 0.00278, train_loss: 0.7478, val_loss: 1.1384, val_acc: 0.5780\n",
      "Epoch [101], last_lr: 0.00273, train_loss: 0.7507, val_loss: 1.1522, val_acc: 0.5660\n",
      "Epoch [102], last_lr: 0.00268, train_loss: 0.7322, val_loss: 1.1476, val_acc: 0.5660\n",
      "Epoch [103], last_lr: 0.00264, train_loss: 0.7329, val_loss: 1.1472, val_acc: 0.5620\n",
      "Epoch [104], last_lr: 0.00259, train_loss: 0.7380, val_loss: 1.1389, val_acc: 0.5700\n",
      "Epoch [105], last_lr: 0.00254, train_loss: 0.7399, val_loss: 1.1593, val_acc: 0.5620\n",
      "Epoch [106], last_lr: 0.00249, train_loss: 0.7646, val_loss: 1.1379, val_acc: 0.5740\n",
      "Epoch [107], last_lr: 0.00245, train_loss: 0.7476, val_loss: 1.1613, val_acc: 0.5600\n",
      "Epoch [108], last_lr: 0.00240, train_loss: 0.7475, val_loss: 1.1340, val_acc: 0.5700\n",
      "Epoch [109], last_lr: 0.00235, train_loss: 0.7500, val_loss: 1.1406, val_acc: 0.5520\n",
      "Epoch [110], last_lr: 0.00230, train_loss: 0.7377, val_loss: 1.1429, val_acc: 0.5780\n",
      "Epoch [111], last_lr: 0.00225, train_loss: 0.7382, val_loss: 1.1392, val_acc: 0.5500\n",
      "Epoch [112], last_lr: 0.00220, train_loss: 0.7364, val_loss: 1.1454, val_acc: 0.5760\n",
      "Epoch [113], last_lr: 0.00215, train_loss: 0.7466, val_loss: 1.1399, val_acc: 0.5580\n",
      "Epoch [114], last_lr: 0.00210, train_loss: 0.7508, val_loss: 1.1438, val_acc: 0.5800\n",
      "Epoch [115], last_lr: 0.00205, train_loss: 0.7457, val_loss: 1.1426, val_acc: 0.5560\n",
      "Epoch [116], last_lr: 0.00200, train_loss: 0.7580, val_loss: 1.1485, val_acc: 0.5880\n",
      "Epoch [117], last_lr: 0.00195, train_loss: 0.7429, val_loss: 1.1335, val_acc: 0.5780\n",
      "Epoch [118], last_lr: 0.00190, train_loss: 0.7315, val_loss: 1.1354, val_acc: 0.5780\n",
      "Epoch [119], last_lr: 0.00185, train_loss: 0.7380, val_loss: 1.1347, val_acc: 0.5600\n",
      "Epoch [120], last_lr: 0.00180, train_loss: 0.7368, val_loss: 1.1299, val_acc: 0.5780\n",
      "Epoch [121], last_lr: 0.00175, train_loss: 0.7389, val_loss: 1.1339, val_acc: 0.5660\n",
      "Epoch [122], last_lr: 0.00170, train_loss: 0.7359, val_loss: 1.1319, val_acc: 0.5760\n",
      "Epoch [123], last_lr: 0.00165, train_loss: 0.7471, val_loss: 1.1260, val_acc: 0.5740\n",
      "Epoch [124], last_lr: 0.00160, train_loss: 0.7282, val_loss: 1.1288, val_acc: 0.5780\n",
      "Epoch [125], last_lr: 0.00155, train_loss: 0.7447, val_loss: 1.1292, val_acc: 0.5740\n",
      "Epoch [126], last_lr: 0.00151, train_loss: 0.7211, val_loss: 1.1305, val_acc: 0.5820\n",
      "Epoch [127], last_lr: 0.00146, train_loss: 0.7201, val_loss: 1.1299, val_acc: 0.5660\n",
      "Epoch [128], last_lr: 0.00141, train_loss: 0.7367, val_loss: 1.1325, val_acc: 0.5800\n",
      "Epoch [129], last_lr: 0.00136, train_loss: 0.7407, val_loss: 1.1348, val_acc: 0.5720\n",
      "Epoch [130], last_lr: 0.00132, train_loss: 0.7229, val_loss: 1.1317, val_acc: 0.5820\n",
      "Epoch [131], last_lr: 0.00127, train_loss: 0.7281, val_loss: 1.1323, val_acc: 0.5720\n",
      "Epoch [132], last_lr: 0.00122, train_loss: 0.7280, val_loss: 1.1338, val_acc: 0.5720\n",
      "Epoch [133], last_lr: 0.00118, train_loss: 0.7325, val_loss: 1.1354, val_acc: 0.5760\n",
      "Epoch [134], last_lr: 0.00113, train_loss: 0.7206, val_loss: 1.1331, val_acc: 0.5760\n",
      "Epoch [135], last_lr: 0.00109, train_loss: 0.7269, val_loss: 1.1345, val_acc: 0.5740\n",
      "Epoch [136], last_lr: 0.00104, train_loss: 0.7454, val_loss: 1.1366, val_acc: 0.5740\n",
      "Epoch [137], last_lr: 0.00100, train_loss: 0.7179, val_loss: 1.1309, val_acc: 0.5740\n",
      "Epoch [138], last_lr: 0.00096, train_loss: 0.7280, val_loss: 1.1291, val_acc: 0.5680\n",
      "Epoch [139], last_lr: 0.00091, train_loss: 0.7294, val_loss: 1.1323, val_acc: 0.5640\n",
      "Epoch [140], last_lr: 0.00087, train_loss: 0.7211, val_loss: 1.1310, val_acc: 0.5680\n",
      "Epoch [141], last_lr: 0.00083, train_loss: 0.7252, val_loss: 1.1280, val_acc: 0.5700\n",
      "Epoch [142], last_lr: 0.00079, train_loss: 0.7361, val_loss: 1.1316, val_acc: 0.5640\n",
      "Epoch [143], last_lr: 0.00075, train_loss: 0.7335, val_loss: 1.1303, val_acc: 0.5660\n",
      "Epoch [144], last_lr: 0.00071, train_loss: 0.7180, val_loss: 1.1294, val_acc: 0.5660\n",
      "Epoch [145], last_lr: 0.00068, train_loss: 0.7464, val_loss: 1.1306, val_acc: 0.5680\n",
      "Epoch [146], last_lr: 0.00064, train_loss: 0.7249, val_loss: 1.1311, val_acc: 0.5660\n",
      "Epoch [147], last_lr: 0.00060, train_loss: 0.7266, val_loss: 1.1300, val_acc: 0.5640\n",
      "Epoch [148], last_lr: 0.00057, train_loss: 0.7342, val_loss: 1.1269, val_acc: 0.5660\n",
      "Epoch [149], last_lr: 0.00053, train_loss: 0.7340, val_loss: 1.1273, val_acc: 0.5680\n",
      "Epoch [150], last_lr: 0.00050, train_loss: 0.7333, val_loss: 1.1282, val_acc: 0.5660\n",
      "Epoch [151], last_lr: 0.00047, train_loss: 0.7403, val_loss: 1.1301, val_acc: 0.5620\n",
      "Epoch [152], last_lr: 0.00044, train_loss: 0.7305, val_loss: 1.1281, val_acc: 0.5680\n",
      "Epoch [153], last_lr: 0.00041, train_loss: 0.7311, val_loss: 1.1283, val_acc: 0.5740\n",
      "Epoch [154], last_lr: 0.00038, train_loss: 0.7248, val_loss: 1.1279, val_acc: 0.5740\n",
      "Epoch [155], last_lr: 0.00035, train_loss: 0.7214, val_loss: 1.1285, val_acc: 0.5700\n",
      "Epoch [156], last_lr: 0.00032, train_loss: 0.7165, val_loss: 1.1286, val_acc: 0.5640\n",
      "Epoch [157], last_lr: 0.00029, train_loss: 0.7340, val_loss: 1.1274, val_acc: 0.5680\n",
      "Epoch [158], last_lr: 0.00027, train_loss: 0.7329, val_loss: 1.1266, val_acc: 0.5700\n",
      "Epoch [159], last_lr: 0.00024, train_loss: 0.7259, val_loss: 1.1279, val_acc: 0.5660\n",
      "Epoch [160], last_lr: 0.00022, train_loss: 0.7188, val_loss: 1.1280, val_acc: 0.5680\n",
      "Epoch [161], last_lr: 0.00020, train_loss: 0.7238, val_loss: 1.1284, val_acc: 0.5700\n",
      "Epoch [162], last_lr: 0.00018, train_loss: 0.7268, val_loss: 1.1279, val_acc: 0.5680\n",
      "Epoch [163], last_lr: 0.00016, train_loss: 0.7187, val_loss: 1.1288, val_acc: 0.5660\n",
      "Epoch [164], last_lr: 0.00014, train_loss: 0.7178, val_loss: 1.1307, val_acc: 0.5640\n",
      "Epoch [165], last_lr: 0.00012, train_loss: 0.7392, val_loss: 1.1314, val_acc: 0.5660\n",
      "Epoch [166], last_lr: 0.00010, train_loss: 0.7210, val_loss: 1.1308, val_acc: 0.5680\n",
      "Epoch [167], last_lr: 0.00009, train_loss: 0.7385, val_loss: 1.1300, val_acc: 0.5700\n",
      "Epoch [168], last_lr: 0.00007, train_loss: 0.7382, val_loss: 1.1270, val_acc: 0.5700\n",
      "Epoch [169], last_lr: 0.00006, train_loss: 0.7197, val_loss: 1.1278, val_acc: 0.5680\n",
      "Epoch [170], last_lr: 0.00005, train_loss: 0.7453, val_loss: 1.1264, val_acc: 0.5680\n",
      "Epoch [171], last_lr: 0.00004, train_loss: 0.7337, val_loss: 1.1275, val_acc: 0.5640\n",
      "Epoch [172], last_lr: 0.00003, train_loss: 0.7282, val_loss: 1.1276, val_acc: 0.5680\n",
      "Epoch [173], last_lr: 0.00002, train_loss: 0.7155, val_loss: 1.1273, val_acc: 0.5680\n",
      "Epoch [174], last_lr: 0.00002, train_loss: 0.7140, val_loss: 1.1282, val_acc: 0.5640\n",
      "Epoch [175], last_lr: 0.00001, train_loss: 0.7234, val_loss: 1.1291, val_acc: 0.5600\n",
      "Epoch [176], last_lr: 0.00001, train_loss: 0.7251, val_loss: 1.1280, val_acc: 0.5640\n",
      "Epoch [177], last_lr: 0.00000, train_loss: 0.7231, val_loss: 1.1299, val_acc: 0.5680\n",
      "Epoch [178], last_lr: 0.00000, train_loss: 0.7410, val_loss: 1.1282, val_acc: 0.5640\n",
      "Epoch [179], last_lr: 0.00000, train_loss: 0.7339, val_loss: 1.1281, val_acc: 0.5680\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[{'val_loss': 10.228128433227539, 'val_acc': 0.20000000298023224}]\n",
      "Epoch [0], last_lr: 0.00016, train_loss: 8.3998, val_loss: 8.5778, val_acc: 0.2100\n",
      "Epoch [1], last_lr: 0.00017, train_loss: 7.9861, val_loss: 7.9662, val_acc: 0.2160\n",
      "Epoch [2], last_lr: 0.00019, train_loss: 7.6184, val_loss: 7.5549, val_acc: 0.2140\n",
      "Epoch [3], last_lr: 0.00021, train_loss: 7.1312, val_loss: 7.1331, val_acc: 0.2180\n",
      "Epoch [4], last_lr: 0.00024, train_loss: 6.7523, val_loss: 6.6890, val_acc: 0.2300\n",
      "Epoch [5], last_lr: 0.00027, train_loss: 6.1769, val_loss: 6.1454, val_acc: 0.2360\n",
      "Epoch [6], last_lr: 0.00031, train_loss: 5.7385, val_loss: 5.5666, val_acc: 0.2580\n",
      "Epoch [7], last_lr: 0.00036, train_loss: 5.1177, val_loss: 4.9602, val_acc: 0.2680\n",
      "Epoch [8], last_lr: 0.00041, train_loss: 4.5439, val_loss: 4.3783, val_acc: 0.2960\n",
      "Epoch [9], last_lr: 0.00047, train_loss: 3.9810, val_loss: 3.7957, val_acc: 0.3100\n",
      "Epoch [10], last_lr: 0.00053, train_loss: 3.4464, val_loss: 3.2190, val_acc: 0.3320\n",
      "Epoch [11], last_lr: 0.00060, train_loss: 2.9631, val_loss: 2.7149, val_acc: 0.3800\n",
      "Epoch [12], last_lr: 0.00068, train_loss: 2.4954, val_loss: 2.4444, val_acc: 0.3780\n",
      "Epoch [13], last_lr: 0.00075, train_loss: 2.3562, val_loss: 2.4480, val_acc: 0.3820\n",
      "Epoch [14], last_lr: 0.00084, train_loss: 2.3449, val_loss: 2.4303, val_acc: 0.4200\n",
      "Epoch [15], last_lr: 0.00092, train_loss: 2.2139, val_loss: 2.3041, val_acc: 0.4120\n",
      "Epoch [16], last_lr: 0.00102, train_loss: 2.1014, val_loss: 2.1629, val_acc: 0.4100\n",
      "Epoch [17], last_lr: 0.00111, train_loss: 2.0197, val_loss: 2.0494, val_acc: 0.4220\n",
      "Epoch [18], last_lr: 0.00121, train_loss: 1.8808, val_loss: 1.9366, val_acc: 0.4420\n",
      "Epoch [19], last_lr: 0.00131, train_loss: 1.7582, val_loss: 1.8266, val_acc: 0.4600\n",
      "Epoch [20], last_lr: 0.00141, train_loss: 1.6465, val_loss: 1.6700, val_acc: 0.4800\n",
      "Epoch [21], last_lr: 0.00152, train_loss: 1.5018, val_loss: 1.5346, val_acc: 0.5140\n",
      "Epoch [22], last_lr: 0.00163, train_loss: 1.3418, val_loss: 1.4087, val_acc: 0.5480\n",
      "Epoch [23], last_lr: 0.00174, train_loss: 1.1921, val_loss: 1.3095, val_acc: 0.5880\n",
      "Epoch [24], last_lr: 0.00185, train_loss: 1.0576, val_loss: 1.2194, val_acc: 0.6220\n",
      "Epoch [25], last_lr: 0.00196, train_loss: 0.9653, val_loss: 1.1533, val_acc: 0.6560\n",
      "Epoch [26], last_lr: 0.00207, train_loss: 0.9207, val_loss: 1.0918, val_acc: 0.6720\n",
      "Epoch [27], last_lr: 0.00218, train_loss: 0.8423, val_loss: 1.0513, val_acc: 0.6860\n",
      "Epoch [28], last_lr: 0.00230, train_loss: 0.7393, val_loss: 1.0010, val_acc: 0.7120\n",
      "Epoch [29], last_lr: 0.00241, train_loss: 0.7262, val_loss: 0.9739, val_acc: 0.7220\n",
      "Epoch [30], last_lr: 0.00252, train_loss: 0.6650, val_loss: 0.9430, val_acc: 0.7320\n",
      "Epoch [31], last_lr: 0.00262, train_loss: 0.6675, val_loss: 0.9266, val_acc: 0.7340\n",
      "Epoch [32], last_lr: 0.00273, train_loss: 0.6393, val_loss: 0.9111, val_acc: 0.7380\n",
      "Epoch [33], last_lr: 0.00284, train_loss: 0.6116, val_loss: 0.8900, val_acc: 0.7340\n",
      "Epoch [34], last_lr: 0.00294, train_loss: 0.5720, val_loss: 0.8789, val_acc: 0.7440\n",
      "Epoch [35], last_lr: 0.00304, train_loss: 0.5760, val_loss: 0.8875, val_acc: 0.7440\n",
      "Epoch [36], last_lr: 0.00313, train_loss: 0.5656, val_loss: 0.8516, val_acc: 0.7440\n",
      "Epoch [37], last_lr: 0.00322, train_loss: 0.5331, val_loss: 0.8608, val_acc: 0.7520\n",
      "Epoch [38], last_lr: 0.00331, train_loss: 0.5574, val_loss: 0.8350, val_acc: 0.7500\n",
      "Epoch [39], last_lr: 0.00339, train_loss: 0.5533, val_loss: 0.8290, val_acc: 0.7520\n",
      "Epoch [40], last_lr: 0.00347, train_loss: 0.5053, val_loss: 0.8630, val_acc: 0.7380\n",
      "Epoch [41], last_lr: 0.00355, train_loss: 0.5344, val_loss: 0.8142, val_acc: 0.7580\n",
      "Epoch [42], last_lr: 0.00362, train_loss: 0.5097, val_loss: 0.8453, val_acc: 0.7320\n",
      "Epoch [43], last_lr: 0.00368, train_loss: 0.5009, val_loss: 0.8084, val_acc: 0.7600\n",
      "Epoch [44], last_lr: 0.00374, train_loss: 0.4883, val_loss: 0.8162, val_acc: 0.7440\n",
      "Epoch [45], last_lr: 0.00379, train_loss: 0.5087, val_loss: 0.7892, val_acc: 0.7620\n",
      "Epoch [46], last_lr: 0.00384, train_loss: 0.4623, val_loss: 0.8084, val_acc: 0.7580\n",
      "Epoch [47], last_lr: 0.00388, train_loss: 0.4938, val_loss: 0.7739, val_acc: 0.7780\n",
      "Epoch [48], last_lr: 0.00392, train_loss: 0.4566, val_loss: 0.8258, val_acc: 0.7440\n",
      "Epoch [49], last_lr: 0.00395, train_loss: 0.4908, val_loss: 0.7772, val_acc: 0.7700\n",
      "Epoch [50], last_lr: 0.00397, train_loss: 0.4504, val_loss: 0.8008, val_acc: 0.7540\n",
      "Epoch [51], last_lr: 0.00399, train_loss: 0.4587, val_loss: 0.7729, val_acc: 0.7600\n",
      "Epoch [52], last_lr: 0.00400, train_loss: 0.4419, val_loss: 0.7750, val_acc: 0.7680\n",
      "Epoch [53], last_lr: 0.00400, train_loss: 0.4323, val_loss: 0.7954, val_acc: 0.7560\n",
      "Epoch [54], last_lr: 0.00400, train_loss: 0.4346, val_loss: 0.7754, val_acc: 0.7700\n",
      "Epoch [55], last_lr: 0.00400, train_loss: 0.4424, val_loss: 0.7851, val_acc: 0.7620\n",
      "Epoch [56], last_lr: 0.00399, train_loss: 0.4467, val_loss: 0.7516, val_acc: 0.7720\n",
      "Epoch [57], last_lr: 0.00399, train_loss: 0.4310, val_loss: 0.8231, val_acc: 0.7480\n",
      "Epoch [58], last_lr: 0.00398, train_loss: 0.4638, val_loss: 0.7540, val_acc: 0.7680\n",
      "Epoch [59], last_lr: 0.00398, train_loss: 0.4231, val_loss: 0.7936, val_acc: 0.7460\n",
      "Epoch [60], last_lr: 0.00397, train_loss: 0.4532, val_loss: 0.7546, val_acc: 0.7700\n",
      "Epoch [61], last_lr: 0.00396, train_loss: 0.4200, val_loss: 0.8253, val_acc: 0.7460\n",
      "Epoch [62], last_lr: 0.00395, train_loss: 0.4751, val_loss: 0.7505, val_acc: 0.7600\n",
      "Epoch [63], last_lr: 0.00394, train_loss: 0.4028, val_loss: 0.7475, val_acc: 0.7760\n",
      "Epoch [64], last_lr: 0.00393, train_loss: 0.4182, val_loss: 0.7821, val_acc: 0.7640\n",
      "Epoch [65], last_lr: 0.00391, train_loss: 0.4526, val_loss: 0.7663, val_acc: 0.7660\n",
      "Epoch [66], last_lr: 0.00390, train_loss: 0.4119, val_loss: 0.8043, val_acc: 0.7540\n",
      "Epoch [67], last_lr: 0.00388, train_loss: 0.4421, val_loss: 0.7726, val_acc: 0.7580\n",
      "Epoch [68], last_lr: 0.00386, train_loss: 0.4236, val_loss: 0.7726, val_acc: 0.7720\n",
      "Epoch [69], last_lr: 0.00384, train_loss: 0.4386, val_loss: 0.7608, val_acc: 0.7540\n",
      "Epoch [70], last_lr: 0.00382, train_loss: 0.4162, val_loss: 0.7556, val_acc: 0.7780\n",
      "Epoch [71], last_lr: 0.00380, train_loss: 0.4067, val_loss: 0.8005, val_acc: 0.7540\n",
      "Epoch [72], last_lr: 0.00378, train_loss: 0.4629, val_loss: 0.7522, val_acc: 0.7620\n",
      "Epoch [73], last_lr: 0.00376, train_loss: 0.4174, val_loss: 0.7777, val_acc: 0.7740\n",
      "Epoch [74], last_lr: 0.00373, train_loss: 0.4323, val_loss: 0.7747, val_acc: 0.7500\n",
      "Epoch [75], last_lr: 0.00371, train_loss: 0.4475, val_loss: 0.7522, val_acc: 0.7620\n",
      "Epoch [76], last_lr: 0.00368, train_loss: 0.3955, val_loss: 0.7799, val_acc: 0.7640\n",
      "Epoch [77], last_lr: 0.00365, train_loss: 0.4268, val_loss: 0.7491, val_acc: 0.7740\n",
      "Epoch [78], last_lr: 0.00362, train_loss: 0.4122, val_loss: 0.7414, val_acc: 0.7740\n",
      "Epoch [79], last_lr: 0.00359, train_loss: 0.3949, val_loss: 0.8075, val_acc: 0.7440\n",
      "Epoch [80], last_lr: 0.00356, train_loss: 0.4659, val_loss: 0.7547, val_acc: 0.7600\n",
      "Epoch [81], last_lr: 0.00353, train_loss: 0.4258, val_loss: 0.8042, val_acc: 0.7340\n",
      "Epoch [82], last_lr: 0.00350, train_loss: 0.4590, val_loss: 0.7456, val_acc: 0.7680\n",
      "Epoch [83], last_lr: 0.00347, train_loss: 0.4068, val_loss: 0.7645, val_acc: 0.7580\n",
      "Epoch [84], last_lr: 0.00343, train_loss: 0.4058, val_loss: 0.7512, val_acc: 0.7720\n",
      "Epoch [85], last_lr: 0.00340, train_loss: 0.4164, val_loss: 0.7702, val_acc: 0.7600\n",
      "Epoch [86], last_lr: 0.00336, train_loss: 0.4099, val_loss: 0.7486, val_acc: 0.7720\n",
      "Epoch [87], last_lr: 0.00332, train_loss: 0.4081, val_loss: 0.7449, val_acc: 0.7740\n",
      "Epoch [88], last_lr: 0.00329, train_loss: 0.3964, val_loss: 0.7580, val_acc: 0.7720\n",
      "Epoch [89], last_lr: 0.00325, train_loss: 0.3983, val_loss: 0.7522, val_acc: 0.7780\n",
      "Epoch [90], last_lr: 0.00321, train_loss: 0.4053, val_loss: 0.7515, val_acc: 0.7680\n",
      "Epoch [91], last_lr: 0.00317, train_loss: 0.4077, val_loss: 0.7608, val_acc: 0.7700\n",
      "Epoch [92], last_lr: 0.00313, train_loss: 0.4252, val_loss: 0.7559, val_acc: 0.7620\n",
      "Epoch [93], last_lr: 0.00309, train_loss: 0.4273, val_loss: 0.7429, val_acc: 0.7740\n",
      "Epoch [94], last_lr: 0.00304, train_loss: 0.4061, val_loss: 0.7446, val_acc: 0.7720\n",
      "Epoch [95], last_lr: 0.00300, train_loss: 0.4139, val_loss: 0.7424, val_acc: 0.7740\n",
      "Epoch [96], last_lr: 0.00296, train_loss: 0.3938, val_loss: 0.7671, val_acc: 0.7640\n",
      "Epoch [97], last_lr: 0.00291, train_loss: 0.4060, val_loss: 0.7384, val_acc: 0.7720\n",
      "Epoch [98], last_lr: 0.00287, train_loss: 0.4030, val_loss: 0.7463, val_acc: 0.7680\n",
      "Epoch [99], last_lr: 0.00282, train_loss: 0.4024, val_loss: 0.7372, val_acc: 0.7780\n",
      "Epoch [100], last_lr: 0.00278, train_loss: 0.3752, val_loss: 0.7498, val_acc: 0.7680\n",
      "Epoch [101], last_lr: 0.00273, train_loss: 0.4059, val_loss: 0.7420, val_acc: 0.7740\n",
      "Epoch [102], last_lr: 0.00268, train_loss: 0.4137, val_loss: 0.7408, val_acc: 0.7720\n",
      "Epoch [103], last_lr: 0.00264, train_loss: 0.3687, val_loss: 0.7593, val_acc: 0.7680\n",
      "Epoch [104], last_lr: 0.00259, train_loss: 0.3964, val_loss: 0.7500, val_acc: 0.7620\n",
      "Epoch [105], last_lr: 0.00254, train_loss: 0.3904, val_loss: 0.7555, val_acc: 0.7760\n",
      "Epoch [106], last_lr: 0.00249, train_loss: 0.4098, val_loss: 0.7442, val_acc: 0.7680\n",
      "Epoch [107], last_lr: 0.00245, train_loss: 0.4261, val_loss: 0.7338, val_acc: 0.7660\n",
      "Epoch [108], last_lr: 0.00240, train_loss: 0.3921, val_loss: 0.7386, val_acc: 0.7660\n",
      "Epoch [109], last_lr: 0.00235, train_loss: 0.3771, val_loss: 0.7398, val_acc: 0.7640\n",
      "Epoch [110], last_lr: 0.00230, train_loss: 0.3993, val_loss: 0.7354, val_acc: 0.7700\n",
      "Epoch [111], last_lr: 0.00225, train_loss: 0.4061, val_loss: 0.7391, val_acc: 0.7680\n",
      "Epoch [112], last_lr: 0.00220, train_loss: 0.3879, val_loss: 0.7419, val_acc: 0.7680\n",
      "Epoch [113], last_lr: 0.00215, train_loss: 0.3910, val_loss: 0.7349, val_acc: 0.7680\n",
      "Epoch [114], last_lr: 0.00210, train_loss: 0.3926, val_loss: 0.7398, val_acc: 0.7680\n",
      "Epoch [115], last_lr: 0.00205, train_loss: 0.3767, val_loss: 0.7379, val_acc: 0.7660\n",
      "Epoch [116], last_lr: 0.00200, train_loss: 0.3965, val_loss: 0.7369, val_acc: 0.7680\n",
      "Epoch [117], last_lr: 0.00195, train_loss: 0.3835, val_loss: 0.7410, val_acc: 0.7660\n",
      "Epoch [118], last_lr: 0.00190, train_loss: 0.4106, val_loss: 0.7342, val_acc: 0.7700\n",
      "Epoch [119], last_lr: 0.00185, train_loss: 0.3871, val_loss: 0.7388, val_acc: 0.7720\n",
      "Epoch [120], last_lr: 0.00180, train_loss: 0.3927, val_loss: 0.7363, val_acc: 0.7680\n",
      "Epoch [121], last_lr: 0.00175, train_loss: 0.3912, val_loss: 0.7326, val_acc: 0.7640\n",
      "Epoch [122], last_lr: 0.00170, train_loss: 0.3859, val_loss: 0.7365, val_acc: 0.7700\n",
      "Epoch [123], last_lr: 0.00165, train_loss: 0.3755, val_loss: 0.7314, val_acc: 0.7720\n",
      "Epoch [124], last_lr: 0.00160, train_loss: 0.3967, val_loss: 0.7383, val_acc: 0.7720\n",
      "Epoch [125], last_lr: 0.00155, train_loss: 0.3772, val_loss: 0.7435, val_acc: 0.7720\n",
      "Epoch [126], last_lr: 0.00151, train_loss: 0.4042, val_loss: 0.7327, val_acc: 0.7700\n",
      "Epoch [127], last_lr: 0.00146, train_loss: 0.3913, val_loss: 0.7345, val_acc: 0.7680\n",
      "Epoch [128], last_lr: 0.00141, train_loss: 0.3824, val_loss: 0.7387, val_acc: 0.7760\n",
      "Epoch [129], last_lr: 0.00136, train_loss: 0.3844, val_loss: 0.7315, val_acc: 0.7720\n",
      "Epoch [130], last_lr: 0.00132, train_loss: 0.3783, val_loss: 0.7323, val_acc: 0.7700\n",
      "Epoch [131], last_lr: 0.00127, train_loss: 0.3846, val_loss: 0.7366, val_acc: 0.7740\n",
      "Epoch [132], last_lr: 0.00122, train_loss: 0.3846, val_loss: 0.7303, val_acc: 0.7720\n",
      "Epoch [133], last_lr: 0.00118, train_loss: 0.4113, val_loss: 0.7296, val_acc: 0.7760\n",
      "Epoch [134], last_lr: 0.00113, train_loss: 0.3676, val_loss: 0.7362, val_acc: 0.7700\n",
      "Epoch [135], last_lr: 0.00109, train_loss: 0.3624, val_loss: 0.7320, val_acc: 0.7780\n",
      "Epoch [136], last_lr: 0.00104, train_loss: 0.3856, val_loss: 0.7347, val_acc: 0.7740\n",
      "Epoch [137], last_lr: 0.00100, train_loss: 0.3893, val_loss: 0.7330, val_acc: 0.7720\n",
      "Epoch [138], last_lr: 0.00096, train_loss: 0.3738, val_loss: 0.7325, val_acc: 0.7700\n",
      "Epoch [139], last_lr: 0.00091, train_loss: 0.3818, val_loss: 0.7310, val_acc: 0.7720\n",
      "Epoch [140], last_lr: 0.00087, train_loss: 0.3859, val_loss: 0.7338, val_acc: 0.7760\n",
      "Epoch [141], last_lr: 0.00083, train_loss: 0.3881, val_loss: 0.7333, val_acc: 0.7720\n",
      "Epoch [142], last_lr: 0.00079, train_loss: 0.3782, val_loss: 0.7293, val_acc: 0.7760\n",
      "Epoch [143], last_lr: 0.00075, train_loss: 0.3782, val_loss: 0.7286, val_acc: 0.7780\n",
      "Epoch [144], last_lr: 0.00071, train_loss: 0.3732, val_loss: 0.7325, val_acc: 0.7760\n",
      "Epoch [145], last_lr: 0.00068, train_loss: 0.4015, val_loss: 0.7361, val_acc: 0.7740\n",
      "Epoch [146], last_lr: 0.00064, train_loss: 0.3999, val_loss: 0.7285, val_acc: 0.7740\n",
      "Epoch [147], last_lr: 0.00060, train_loss: 0.3787, val_loss: 0.7277, val_acc: 0.7740\n",
      "Epoch [148], last_lr: 0.00057, train_loss: 0.3597, val_loss: 0.7262, val_acc: 0.7780\n",
      "Epoch [149], last_lr: 0.00053, train_loss: 0.3842, val_loss: 0.7312, val_acc: 0.7740\n",
      "Epoch [150], last_lr: 0.00050, train_loss: 0.3784, val_loss: 0.7320, val_acc: 0.7760\n",
      "Epoch [151], last_lr: 0.00047, train_loss: 0.3849, val_loss: 0.7302, val_acc: 0.7740\n",
      "Epoch [152], last_lr: 0.00044, train_loss: 0.3763, val_loss: 0.7308, val_acc: 0.7760\n",
      "Epoch [153], last_lr: 0.00041, train_loss: 0.3864, val_loss: 0.7303, val_acc: 0.7780\n",
      "Epoch [154], last_lr: 0.00038, train_loss: 0.3873, val_loss: 0.7312, val_acc: 0.7760\n",
      "Epoch [155], last_lr: 0.00035, train_loss: 0.3795, val_loss: 0.7296, val_acc: 0.7740\n",
      "Epoch [156], last_lr: 0.00032, train_loss: 0.3763, val_loss: 0.7292, val_acc: 0.7740\n",
      "Epoch [157], last_lr: 0.00029, train_loss: 0.3866, val_loss: 0.7283, val_acc: 0.7740\n",
      "Epoch [158], last_lr: 0.00027, train_loss: 0.3724, val_loss: 0.7285, val_acc: 0.7740\n",
      "Epoch [159], last_lr: 0.00024, train_loss: 0.3905, val_loss: 0.7289, val_acc: 0.7720\n",
      "Epoch [160], last_lr: 0.00022, train_loss: 0.3868, val_loss: 0.7299, val_acc: 0.7760\n",
      "Epoch [161], last_lr: 0.00020, train_loss: 0.3924, val_loss: 0.7298, val_acc: 0.7760\n",
      "Epoch [162], last_lr: 0.00018, train_loss: 0.3796, val_loss: 0.7293, val_acc: 0.7740\n",
      "Epoch [163], last_lr: 0.00016, train_loss: 0.4020, val_loss: 0.7287, val_acc: 0.7740\n",
      "Epoch [164], last_lr: 0.00014, train_loss: 0.3688, val_loss: 0.7284, val_acc: 0.7740\n",
      "Epoch [165], last_lr: 0.00012, train_loss: 0.3969, val_loss: 0.7301, val_acc: 0.7740\n",
      "Epoch [166], last_lr: 0.00010, train_loss: 0.4040, val_loss: 0.7295, val_acc: 0.7780\n",
      "Epoch [167], last_lr: 0.00009, train_loss: 0.3819, val_loss: 0.7301, val_acc: 0.7760\n",
      "Epoch [168], last_lr: 0.00007, train_loss: 0.3786, val_loss: 0.7297, val_acc: 0.7740\n",
      "Epoch [169], last_lr: 0.00006, train_loss: 0.3741, val_loss: 0.7277, val_acc: 0.7780\n",
      "Epoch [170], last_lr: 0.00005, train_loss: 0.3868, val_loss: 0.7290, val_acc: 0.7740\n",
      "Epoch [171], last_lr: 0.00004, train_loss: 0.3809, val_loss: 0.7274, val_acc: 0.7780\n",
      "Epoch [172], last_lr: 0.00003, train_loss: 0.3933, val_loss: 0.7281, val_acc: 0.7780\n",
      "Epoch [173], last_lr: 0.00002, train_loss: 0.3688, val_loss: 0.7277, val_acc: 0.7780\n",
      "Epoch [174], last_lr: 0.00002, train_loss: 0.3758, val_loss: 0.7282, val_acc: 0.7760\n",
      "Epoch [175], last_lr: 0.00001, train_loss: 0.3931, val_loss: 0.7286, val_acc: 0.7760\n",
      "Epoch [176], last_lr: 0.00001, train_loss: 0.3809, val_loss: 0.7290, val_acc: 0.7800\n",
      "Epoch [177], last_lr: 0.00000, train_loss: 0.3886, val_loss: 0.7297, val_acc: 0.7820\n",
      "Epoch [178], last_lr: 0.00000, train_loss: 0.3955, val_loss: 0.7307, val_acc: 0.7760\n",
      "Epoch [179], last_lr: 0.00000, train_loss: 0.3798, val_loss: 0.7309, val_acc: 0.7760\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[{'val_loss': 13.4122953414917, 'val_acc': 0.17399999499320984}]\n",
      "Epoch [0], last_lr: 0.00016, train_loss: 13.6901, val_loss: 13.0200, val_acc: 0.1860\n",
      "Epoch [1], last_lr: 0.00017, train_loss: 13.2293, val_loss: 12.9163, val_acc: 0.2000\n",
      "Epoch [2], last_lr: 0.00019, train_loss: 12.8650, val_loss: 12.7191, val_acc: 0.2020\n",
      "Epoch [3], last_lr: 0.00021, train_loss: 12.3549, val_loss: 12.3656, val_acc: 0.2080\n",
      "Epoch [4], last_lr: 0.00024, train_loss: 11.8280, val_loss: 11.8875, val_acc: 0.2080\n",
      "Epoch [5], last_lr: 0.00027, train_loss: 11.3456, val_loss: 11.2917, val_acc: 0.2100\n",
      "Epoch [6], last_lr: 0.00031, train_loss: 10.6452, val_loss: 10.5892, val_acc: 0.2080\n",
      "Epoch [7], last_lr: 0.00036, train_loss: 9.8928, val_loss: 9.7616, val_acc: 0.2060\n",
      "Epoch [8], last_lr: 0.00041, train_loss: 9.0440, val_loss: 8.8417, val_acc: 0.2180\n",
      "Epoch [9], last_lr: 0.00047, train_loss: 8.0973, val_loss: 7.8668, val_acc: 0.2400\n",
      "Epoch [10], last_lr: 0.00053, train_loss: 7.1696, val_loss: 6.9682, val_acc: 0.2440\n",
      "Epoch [11], last_lr: 0.00060, train_loss: 6.3901, val_loss: 6.3049, val_acc: 0.2400\n",
      "Epoch [12], last_lr: 0.00068, train_loss: 5.6795, val_loss: 5.6619, val_acc: 0.2440\n",
      "Epoch [13], last_lr: 0.00075, train_loss: 4.9878, val_loss: 4.8194, val_acc: 0.2560\n",
      "Epoch [14], last_lr: 0.00084, train_loss: 4.0593, val_loss: 3.8585, val_acc: 0.2380\n",
      "Epoch [15], last_lr: 0.00092, train_loss: 3.1893, val_loss: 3.2550, val_acc: 0.1800\n",
      "Epoch [16], last_lr: 0.00102, train_loss: 2.7958, val_loss: 3.0634, val_acc: 0.2300\n",
      "Epoch [17], last_lr: 0.00111, train_loss: 2.5862, val_loss: 2.7222, val_acc: 0.2560\n",
      "Epoch [18], last_lr: 0.00121, train_loss: 2.3039, val_loss: 2.4078, val_acc: 0.3100\n",
      "Epoch [19], last_lr: 0.00131, train_loss: 2.1149, val_loss: 2.2256, val_acc: 0.3660\n",
      "Epoch [20], last_lr: 0.00141, train_loss: 1.8696, val_loss: 1.9888, val_acc: 0.3520\n",
      "Epoch [21], last_lr: 0.00152, train_loss: 1.6167, val_loss: 1.7846, val_acc: 0.4140\n",
      "Epoch [22], last_lr: 0.00163, train_loss: 1.4153, val_loss: 1.5187, val_acc: 0.4960\n",
      "Epoch [23], last_lr: 0.00174, train_loss: 1.1509, val_loss: 1.3011, val_acc: 0.5800\n",
      "Epoch [24], last_lr: 0.00185, train_loss: 0.9708, val_loss: 1.1372, val_acc: 0.6460\n",
      "Epoch [25], last_lr: 0.00196, train_loss: 0.8501, val_loss: 0.9706, val_acc: 0.6880\n",
      "Epoch [26], last_lr: 0.00207, train_loss: 0.6893, val_loss: 0.8694, val_acc: 0.7180\n",
      "Epoch [27], last_lr: 0.00218, train_loss: 0.5924, val_loss: 0.7874, val_acc: 0.7420\n",
      "Epoch [28], last_lr: 0.00230, train_loss: 0.5170, val_loss: 0.7092, val_acc: 0.7740\n",
      "Epoch [29], last_lr: 0.00241, train_loss: 0.4426, val_loss: 0.6600, val_acc: 0.7900\n",
      "Epoch [30], last_lr: 0.00252, train_loss: 0.4112, val_loss: 0.6208, val_acc: 0.8000\n",
      "Epoch [31], last_lr: 0.00262, train_loss: 0.3492, val_loss: 0.5720, val_acc: 0.8120\n",
      "Epoch [32], last_lr: 0.00273, train_loss: 0.3286, val_loss: 0.5668, val_acc: 0.8220\n",
      "Epoch [33], last_lr: 0.00284, train_loss: 0.3037, val_loss: 0.5409, val_acc: 0.8260\n",
      "Epoch [34], last_lr: 0.00294, train_loss: 0.2915, val_loss: 0.5295, val_acc: 0.8320\n",
      "Epoch [35], last_lr: 0.00304, train_loss: 0.2589, val_loss: 0.5140, val_acc: 0.8400\n",
      "Epoch [36], last_lr: 0.00313, train_loss: 0.2636, val_loss: 0.5100, val_acc: 0.8360\n",
      "Epoch [37], last_lr: 0.00322, train_loss: 0.2416, val_loss: 0.5036, val_acc: 0.8460\n",
      "Epoch [38], last_lr: 0.00331, train_loss: 0.2352, val_loss: 0.5022, val_acc: 0.8400\n",
      "Epoch [39], last_lr: 0.00339, train_loss: 0.2258, val_loss: 0.4849, val_acc: 0.8460\n",
      "Epoch [40], last_lr: 0.00347, train_loss: 0.2128, val_loss: 0.4879, val_acc: 0.8440\n",
      "Epoch [41], last_lr: 0.00355, train_loss: 0.2235, val_loss: 0.4888, val_acc: 0.8460\n",
      "Epoch [42], last_lr: 0.00362, train_loss: 0.1994, val_loss: 0.4862, val_acc: 0.8460\n",
      "Epoch [43], last_lr: 0.00368, train_loss: 0.2042, val_loss: 0.4861, val_acc: 0.8460\n",
      "Epoch [44], last_lr: 0.00374, train_loss: 0.1841, val_loss: 0.4778, val_acc: 0.8520\n",
      "Epoch [45], last_lr: 0.00379, train_loss: 0.1869, val_loss: 0.4865, val_acc: 0.8520\n",
      "Epoch [46], last_lr: 0.00384, train_loss: 0.1903, val_loss: 0.4894, val_acc: 0.8500\n",
      "Epoch [47], last_lr: 0.00388, train_loss: 0.1789, val_loss: 0.5052, val_acc: 0.8300\n",
      "Epoch [48], last_lr: 0.00392, train_loss: 0.1806, val_loss: 0.4901, val_acc: 0.8500\n",
      "Epoch [49], last_lr: 0.00395, train_loss: 0.1898, val_loss: 0.4801, val_acc: 0.8500\n",
      "Epoch [50], last_lr: 0.00397, train_loss: 0.1694, val_loss: 0.4971, val_acc: 0.8400\n",
      "Epoch [51], last_lr: 0.00399, train_loss: 0.1838, val_loss: 0.4660, val_acc: 0.8520\n",
      "Epoch [52], last_lr: 0.00400, train_loss: 0.1626, val_loss: 0.4779, val_acc: 0.8480\n",
      "Epoch [53], last_lr: 0.00400, train_loss: 0.1701, val_loss: 0.5024, val_acc: 0.8500\n",
      "Epoch [54], last_lr: 0.00400, train_loss: 0.1685, val_loss: 0.4847, val_acc: 0.8540\n",
      "Epoch [55], last_lr: 0.00400, train_loss: 0.1714, val_loss: 0.4957, val_acc: 0.8460\n",
      "Epoch [56], last_lr: 0.00399, train_loss: 0.1831, val_loss: 0.4817, val_acc: 0.8580\n",
      "Epoch [57], last_lr: 0.00399, train_loss: 0.1786, val_loss: 0.4807, val_acc: 0.8500\n",
      "Epoch [58], last_lr: 0.00398, train_loss: 0.1684, val_loss: 0.4936, val_acc: 0.8480\n",
      "Epoch [59], last_lr: 0.00398, train_loss: 0.1608, val_loss: 0.4789, val_acc: 0.8480\n",
      "Epoch [60], last_lr: 0.00397, train_loss: 0.1575, val_loss: 0.4838, val_acc: 0.8460\n",
      "Epoch [61], last_lr: 0.00396, train_loss: 0.1569, val_loss: 0.4723, val_acc: 0.8500\n",
      "Epoch [62], last_lr: 0.00395, train_loss: 0.1600, val_loss: 0.4845, val_acc: 0.8420\n",
      "Epoch [63], last_lr: 0.00394, train_loss: 0.1604, val_loss: 0.4908, val_acc: 0.8500\n",
      "Epoch [64], last_lr: 0.00393, train_loss: 0.1635, val_loss: 0.4769, val_acc: 0.8500\n",
      "Epoch [65], last_lr: 0.00391, train_loss: 0.1674, val_loss: 0.4759, val_acc: 0.8460\n",
      "Epoch [66], last_lr: 0.00390, train_loss: 0.1747, val_loss: 0.4789, val_acc: 0.8480\n",
      "Epoch [67], last_lr: 0.00388, train_loss: 0.1596, val_loss: 0.5014, val_acc: 0.8460\n",
      "Epoch [68], last_lr: 0.00386, train_loss: 0.1478, val_loss: 0.4767, val_acc: 0.8600\n",
      "Epoch [69], last_lr: 0.00384, train_loss: 0.1694, val_loss: 0.4884, val_acc: 0.8440\n",
      "Epoch [70], last_lr: 0.00382, train_loss: 0.1740, val_loss: 0.4822, val_acc: 0.8500\n",
      "Epoch [71], last_lr: 0.00380, train_loss: 0.1585, val_loss: 0.4846, val_acc: 0.8500\n",
      "Epoch [72], last_lr: 0.00378, train_loss: 0.1578, val_loss: 0.4553, val_acc: 0.8560\n",
      "Epoch [73], last_lr: 0.00376, train_loss: 0.1555, val_loss: 0.4972, val_acc: 0.8440\n",
      "Epoch [74], last_lr: 0.00373, train_loss: 0.1704, val_loss: 0.4658, val_acc: 0.8440\n",
      "Epoch [75], last_lr: 0.00371, train_loss: 0.1674, val_loss: 0.4803, val_acc: 0.8500\n",
      "Epoch [76], last_lr: 0.00368, train_loss: 0.1502, val_loss: 0.4718, val_acc: 0.8520\n",
      "Epoch [77], last_lr: 0.00365, train_loss: 0.1548, val_loss: 0.4597, val_acc: 0.8540\n",
      "Epoch [78], last_lr: 0.00362, train_loss: 0.1512, val_loss: 0.4597, val_acc: 0.8500\n",
      "Epoch [79], last_lr: 0.00359, train_loss: 0.1513, val_loss: 0.4707, val_acc: 0.8460\n",
      "Epoch [80], last_lr: 0.00356, train_loss: 0.1395, val_loss: 0.4606, val_acc: 0.8520\n",
      "Epoch [81], last_lr: 0.00353, train_loss: 0.1546, val_loss: 0.4592, val_acc: 0.8500\n",
      "Epoch [82], last_lr: 0.00350, train_loss: 0.1600, val_loss: 0.4580, val_acc: 0.8540\n",
      "Epoch [83], last_lr: 0.00347, train_loss: 0.1413, val_loss: 0.4695, val_acc: 0.8440\n",
      "Epoch [84], last_lr: 0.00343, train_loss: 0.1541, val_loss: 0.4477, val_acc: 0.8500\n",
      "Epoch [85], last_lr: 0.00340, train_loss: 0.1449, val_loss: 0.4724, val_acc: 0.8520\n",
      "Epoch [86], last_lr: 0.00336, train_loss: 0.1476, val_loss: 0.4605, val_acc: 0.8500\n",
      "Epoch [87], last_lr: 0.00332, train_loss: 0.1480, val_loss: 0.4680, val_acc: 0.8520\n",
      "Epoch [88], last_lr: 0.00329, train_loss: 0.1564, val_loss: 0.4767, val_acc: 0.8540\n",
      "Epoch [89], last_lr: 0.00325, train_loss: 0.1541, val_loss: 0.4531, val_acc: 0.8520\n",
      "Epoch [90], last_lr: 0.00321, train_loss: 0.1617, val_loss: 0.4498, val_acc: 0.8500\n",
      "Epoch [91], last_lr: 0.00317, train_loss: 0.1342, val_loss: 0.4735, val_acc: 0.8460\n",
      "Epoch [92], last_lr: 0.00313, train_loss: 0.1508, val_loss: 0.4563, val_acc: 0.8540\n",
      "Epoch [93], last_lr: 0.00309, train_loss: 0.1495, val_loss: 0.4535, val_acc: 0.8580\n",
      "Epoch [94], last_lr: 0.00304, train_loss: 0.1567, val_loss: 0.4876, val_acc: 0.8520\n",
      "Epoch [95], last_lr: 0.00300, train_loss: 0.1472, val_loss: 0.4541, val_acc: 0.8540\n",
      "Epoch [96], last_lr: 0.00296, train_loss: 0.1358, val_loss: 0.4907, val_acc: 0.8440\n",
      "Epoch [97], last_lr: 0.00291, train_loss: 0.1544, val_loss: 0.4853, val_acc: 0.8500\n",
      "Epoch [98], last_lr: 0.00287, train_loss: 0.1519, val_loss: 0.4634, val_acc: 0.8480\n",
      "Epoch [99], last_lr: 0.00282, train_loss: 0.1499, val_loss: 0.4673, val_acc: 0.8440\n",
      "Epoch [100], last_lr: 0.00278, train_loss: 0.1438, val_loss: 0.4636, val_acc: 0.8440\n",
      "Epoch [101], last_lr: 0.00273, train_loss: 0.1455, val_loss: 0.4676, val_acc: 0.8560\n",
      "Epoch [102], last_lr: 0.00268, train_loss: 0.1450, val_loss: 0.4773, val_acc: 0.8380\n",
      "Epoch [103], last_lr: 0.00264, train_loss: 0.1523, val_loss: 0.4573, val_acc: 0.8460\n",
      "Epoch [104], last_lr: 0.00259, train_loss: 0.1434, val_loss: 0.4578, val_acc: 0.8420\n",
      "Epoch [105], last_lr: 0.00254, train_loss: 0.1522, val_loss: 0.4751, val_acc: 0.8540\n",
      "Epoch [106], last_lr: 0.00249, train_loss: 0.1323, val_loss: 0.4536, val_acc: 0.8360\n",
      "Epoch [107], last_lr: 0.00245, train_loss: 0.1572, val_loss: 0.4561, val_acc: 0.8580\n",
      "Epoch [108], last_lr: 0.00240, train_loss: 0.1493, val_loss: 0.4891, val_acc: 0.8440\n",
      "Epoch [109], last_lr: 0.00235, train_loss: 0.1394, val_loss: 0.4394, val_acc: 0.8500\n",
      "Epoch [110], last_lr: 0.00230, train_loss: 0.1425, val_loss: 0.4488, val_acc: 0.8420\n",
      "Epoch [111], last_lr: 0.00225, train_loss: 0.1424, val_loss: 0.4817, val_acc: 0.8460\n",
      "Epoch [112], last_lr: 0.00220, train_loss: 0.1586, val_loss: 0.4867, val_acc: 0.8400\n",
      "Epoch [113], last_lr: 0.00215, train_loss: 0.1510, val_loss: 0.4461, val_acc: 0.8480\n",
      "Epoch [114], last_lr: 0.00210, train_loss: 0.1433, val_loss: 0.4545, val_acc: 0.8500\n",
      "Epoch [115], last_lr: 0.00205, train_loss: 0.1571, val_loss: 0.4475, val_acc: 0.8480\n",
      "Epoch [116], last_lr: 0.00200, train_loss: 0.1380, val_loss: 0.4588, val_acc: 0.8420\n",
      "Epoch [117], last_lr: 0.00195, train_loss: 0.1394, val_loss: 0.4559, val_acc: 0.8480\n",
      "Epoch [118], last_lr: 0.00190, train_loss: 0.1358, val_loss: 0.4610, val_acc: 0.8420\n",
      "Epoch [119], last_lr: 0.00185, train_loss: 0.1412, val_loss: 0.4589, val_acc: 0.8440\n",
      "Epoch [120], last_lr: 0.00180, train_loss: 0.1467, val_loss: 0.4561, val_acc: 0.8460\n",
      "Epoch [121], last_lr: 0.00175, train_loss: 0.1465, val_loss: 0.4659, val_acc: 0.8400\n",
      "Epoch [122], last_lr: 0.00170, train_loss: 0.1480, val_loss: 0.4563, val_acc: 0.8460\n",
      "Epoch [123], last_lr: 0.00165, train_loss: 0.1360, val_loss: 0.4675, val_acc: 0.8480\n",
      "Epoch [124], last_lr: 0.00160, train_loss: 0.1521, val_loss: 0.4702, val_acc: 0.8440\n",
      "Epoch [125], last_lr: 0.00155, train_loss: 0.1467, val_loss: 0.4721, val_acc: 0.8440\n",
      "Epoch [126], last_lr: 0.00151, train_loss: 0.1548, val_loss: 0.4652, val_acc: 0.8500\n",
      "Epoch [127], last_lr: 0.00146, train_loss: 0.1442, val_loss: 0.4573, val_acc: 0.8540\n",
      "Epoch [128], last_lr: 0.00141, train_loss: 0.1322, val_loss: 0.4755, val_acc: 0.8420\n",
      "Epoch [129], last_lr: 0.00136, train_loss: 0.1442, val_loss: 0.4705, val_acc: 0.8460\n",
      "Epoch [130], last_lr: 0.00132, train_loss: 0.1270, val_loss: 0.4560, val_acc: 0.8460\n",
      "Epoch [131], last_lr: 0.00127, train_loss: 0.1488, val_loss: 0.4617, val_acc: 0.8440\n",
      "Epoch [132], last_lr: 0.00122, train_loss: 0.1401, val_loss: 0.4626, val_acc: 0.8460\n",
      "Epoch [133], last_lr: 0.00118, train_loss: 0.1485, val_loss: 0.4655, val_acc: 0.8440\n",
      "Epoch [134], last_lr: 0.00113, train_loss: 0.1331, val_loss: 0.4738, val_acc: 0.8460\n",
      "Epoch [135], last_lr: 0.00109, train_loss: 0.1430, val_loss: 0.4705, val_acc: 0.8480\n",
      "Epoch [136], last_lr: 0.00104, train_loss: 0.1313, val_loss: 0.4539, val_acc: 0.8460\n",
      "Epoch [137], last_lr: 0.00100, train_loss: 0.1438, val_loss: 0.4550, val_acc: 0.8460\n",
      "Epoch [138], last_lr: 0.00096, train_loss: 0.1578, val_loss: 0.4451, val_acc: 0.8380\n",
      "Epoch [139], last_lr: 0.00091, train_loss: 0.1399, val_loss: 0.4434, val_acc: 0.8540\n",
      "Epoch [140], last_lr: 0.00087, train_loss: 0.1420, val_loss: 0.4570, val_acc: 0.8460\n",
      "Epoch [141], last_lr: 0.00083, train_loss: 0.1315, val_loss: 0.4756, val_acc: 0.8460\n",
      "Epoch [142], last_lr: 0.00079, train_loss: 0.1294, val_loss: 0.4726, val_acc: 0.8400\n",
      "Epoch [143], last_lr: 0.00075, train_loss: 0.1377, val_loss: 0.4612, val_acc: 0.8520\n",
      "Epoch [144], last_lr: 0.00071, train_loss: 0.1356, val_loss: 0.4542, val_acc: 0.8420\n",
      "Epoch [145], last_lr: 0.00068, train_loss: 0.1435, val_loss: 0.4534, val_acc: 0.8460\n",
      "Epoch [146], last_lr: 0.00064, train_loss: 0.1314, val_loss: 0.4480, val_acc: 0.8440\n",
      "Epoch [147], last_lr: 0.00060, train_loss: 0.1379, val_loss: 0.4524, val_acc: 0.8500\n",
      "Epoch [148], last_lr: 0.00057, train_loss: 0.1438, val_loss: 0.4594, val_acc: 0.8440\n",
      "Epoch [149], last_lr: 0.00053, train_loss: 0.1407, val_loss: 0.4637, val_acc: 0.8480\n",
      "Epoch [150], last_lr: 0.00050, train_loss: 0.1397, val_loss: 0.4620, val_acc: 0.8460\n",
      "Epoch [151], last_lr: 0.00047, train_loss: 0.1354, val_loss: 0.4634, val_acc: 0.8460\n",
      "Epoch [152], last_lr: 0.00044, train_loss: 0.1422, val_loss: 0.4625, val_acc: 0.8420\n",
      "Epoch [153], last_lr: 0.00041, train_loss: 0.1280, val_loss: 0.4579, val_acc: 0.8460\n",
      "Epoch [154], last_lr: 0.00038, train_loss: 0.1547, val_loss: 0.4559, val_acc: 0.8480\n",
      "Epoch [155], last_lr: 0.00035, train_loss: 0.1354, val_loss: 0.4556, val_acc: 0.8500\n",
      "Epoch [156], last_lr: 0.00032, train_loss: 0.1383, val_loss: 0.4567, val_acc: 0.8480\n",
      "Epoch [157], last_lr: 0.00029, train_loss: 0.1302, val_loss: 0.4571, val_acc: 0.8460\n",
      "Epoch [158], last_lr: 0.00027, train_loss: 0.1385, val_loss: 0.4579, val_acc: 0.8480\n",
      "Epoch [159], last_lr: 0.00024, train_loss: 0.1403, val_loss: 0.4577, val_acc: 0.8480\n",
      "Epoch [160], last_lr: 0.00022, train_loss: 0.1499, val_loss: 0.4558, val_acc: 0.8500\n",
      "Epoch [161], last_lr: 0.00020, train_loss: 0.1266, val_loss: 0.4569, val_acc: 0.8480\n",
      "Epoch [162], last_lr: 0.00018, train_loss: 0.1543, val_loss: 0.4574, val_acc: 0.8440\n",
      "Epoch [163], last_lr: 0.00016, train_loss: 0.1301, val_loss: 0.4613, val_acc: 0.8440\n",
      "Epoch [164], last_lr: 0.00014, train_loss: 0.1366, val_loss: 0.4615, val_acc: 0.8440\n",
      "Epoch [165], last_lr: 0.00012, train_loss: 0.1315, val_loss: 0.4629, val_acc: 0.8460\n",
      "Epoch [166], last_lr: 0.00010, train_loss: 0.1290, val_loss: 0.4626, val_acc: 0.8500\n",
      "Epoch [167], last_lr: 0.00009, train_loss: 0.1432, val_loss: 0.4629, val_acc: 0.8500\n",
      "Epoch [168], last_lr: 0.00007, train_loss: 0.1349, val_loss: 0.4605, val_acc: 0.8500\n",
      "Epoch [169], last_lr: 0.00006, train_loss: 0.1389, val_loss: 0.4602, val_acc: 0.8480\n",
      "Epoch [170], last_lr: 0.00005, train_loss: 0.1232, val_loss: 0.4601, val_acc: 0.8460\n",
      "Epoch [171], last_lr: 0.00004, train_loss: 0.1314, val_loss: 0.4601, val_acc: 0.8480\n",
      "Epoch [172], last_lr: 0.00003, train_loss: 0.1350, val_loss: 0.4616, val_acc: 0.8480\n",
      "Epoch [173], last_lr: 0.00002, train_loss: 0.1286, val_loss: 0.4619, val_acc: 0.8480\n",
      "Epoch [174], last_lr: 0.00002, train_loss: 0.1339, val_loss: 0.4618, val_acc: 0.8480\n",
      "Epoch [175], last_lr: 0.00001, train_loss: 0.1347, val_loss: 0.4616, val_acc: 0.8480\n",
      "Epoch [176], last_lr: 0.00001, train_loss: 0.1323, val_loss: 0.4635, val_acc: 0.8460\n",
      "Epoch [177], last_lr: 0.00000, train_loss: 0.1383, val_loss: 0.4622, val_acc: 0.8480\n",
      "Epoch [178], last_lr: 0.00000, train_loss: 0.1416, val_loss: 0.4633, val_acc: 0.8460\n",
      "Epoch [179], last_lr: 0.00000, train_loss: 0.1285, val_loss: 0.4633, val_acc: 0.8460\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    train_data = CIFAR100('./data', train=True,\n",
    "                 transform=transform_train,\n",
    "                 download=True, coarse=True, coarseNumber=i)\n",
    "    test_data = CIFAR100('./data', train=False,\n",
    "                    transform=transform_test,\n",
    "                    download=True, coarse=True, coarseNumber=i)\n",
    "\n",
    "    train_length = train_data.__len__() # Length training dataset\n",
    "    train_indices = np.arange(train_length)\n",
    "        \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "                            train_data, \n",
    "                            batch_size=batch_size, \n",
    "                            num_workers=2,\n",
    "                            pin_memory=True,\n",
    "                        )\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "                            test_data, \n",
    "                            batch_size=batch_size*2,\n",
    "                            num_workers=2,\n",
    "                            pin_memory=True\n",
    "                        )\n",
    "\n",
    "    device = get_default_device()\n",
    "    trainloader = DeviceDataLoader(train_loader, device)\n",
    "    testloader = DeviceDataLoader(test_loader, device)\n",
    "\n",
    "\n",
    "    model20To100 = ResNet9(3, 100, True)\n",
    "    model20To100.load_state_dict(torch.load('../group_1028_to_parent_Loss_parent_and_child_pretrained_model.h5'))\n",
    "    for param in model20To100.parameters():\n",
    "        param.requires_grad=False\n",
    "\n",
    "    model20To100.classifier_child = nn.Sequential(model20To100.classifier_parent,\n",
    "                                            nn.ReLU(),\n",
    "                                            nn.Linear(20, 5)\n",
    "                                            )\n",
    "                                            \n",
    "    model20To100=to_device(model20To100, device)\n",
    "    history = [evaluate(model20To100, testloader)]\n",
    "    print(history)\n",
    "    history += fit_one_cycle(int(epochs*1.5), max_lr*4, model20To100, trainloader, testloader, \n",
    "                                grad_clip=grad_clip, \n",
    "                                weight_decay=weight_decay, \n",
    "                                opt_func=opt_func)\n",
    "\n",
    "    torch.save(model20To100.state_dict(), 'group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}.h5'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[{'val_loss': 8.877899169921875, 'val_acc': 0.20200000703334808}]\n",
      "Epoch [0], last_lr: 0.00069, train_loss: 8.9810, val_loss: 7.4642, val_acc: 0.2000\n",
      "Epoch [1], last_lr: 0.00073, train_loss: 7.3676, val_loss: 6.1479, val_acc: 0.1900\n",
      "Epoch [2], last_lr: 0.00079, train_loss: 5.9737, val_loss: 5.1398, val_acc: 0.1760\n",
      "Epoch [3], last_lr: 0.00089, train_loss: 5.2015, val_loss: 4.5594, val_acc: 0.1520\n",
      "Epoch [4], last_lr: 0.00101, train_loss: 4.7271, val_loss: 4.3650, val_acc: 0.1740\n",
      "Epoch [5], last_lr: 0.00115, train_loss: 4.6097, val_loss: 4.3891, val_acc: 0.1520\n",
      "Epoch [6], last_lr: 0.00132, train_loss: 4.3877, val_loss: 4.2968, val_acc: 0.1580\n",
      "Epoch [7], last_lr: 0.00152, train_loss: 4.2434, val_loss: 4.0475, val_acc: 0.1620\n",
      "Epoch [8], last_lr: 0.00175, train_loss: 3.9980, val_loss: 3.7658, val_acc: 0.1920\n",
      "Epoch [9], last_lr: 0.00199, train_loss: 3.7360, val_loss: 3.4943, val_acc: 0.2020\n",
      "Epoch [10], last_lr: 0.00226, train_loss: 3.4656, val_loss: 3.2092, val_acc: 0.2000\n",
      "Epoch [11], last_lr: 0.00256, train_loss: 3.0629, val_loss: 2.9424, val_acc: 0.2340\n",
      "Epoch [12], last_lr: 0.00287, train_loss: 2.6587, val_loss: 2.5966, val_acc: 0.2640\n",
      "Epoch [13], last_lr: 0.00320, train_loss: 2.3739, val_loss: 2.2992, val_acc: 0.3180\n",
      "Epoch [14], last_lr: 0.00356, train_loss: 2.0432, val_loss: 2.0614, val_acc: 0.3500\n",
      "Epoch [15], last_lr: 0.00393, train_loss: 1.7592, val_loss: 1.8939, val_acc: 0.3900\n",
      "Epoch [16], last_lr: 0.00432, train_loss: 1.5438, val_loss: 1.7843, val_acc: 0.4180\n",
      "Epoch [17], last_lr: 0.00472, train_loss: 1.4099, val_loss: 1.6920, val_acc: 0.4560\n",
      "Epoch [18], last_lr: 0.00514, train_loss: 1.2716, val_loss: 1.6420, val_acc: 0.4680\n",
      "Epoch [19], last_lr: 0.00557, train_loss: 1.1652, val_loss: 1.5846, val_acc: 0.4560\n",
      "Epoch [20], last_lr: 0.00601, train_loss: 1.0485, val_loss: 1.5657, val_acc: 0.4500\n",
      "Epoch [21], last_lr: 0.00646, train_loss: 1.0170, val_loss: 1.5355, val_acc: 0.4520\n",
      "Epoch [22], last_lr: 0.00692, train_loss: 1.0073, val_loss: 1.5334, val_acc: 0.4580\n",
      "Epoch [23], last_lr: 0.00739, train_loss: 0.9767, val_loss: 1.5131, val_acc: 0.4560\n",
      "Epoch [24], last_lr: 0.00786, train_loss: 0.9243, val_loss: 1.4927, val_acc: 0.4480\n",
      "Epoch [25], last_lr: 0.00833, train_loss: 0.9574, val_loss: 1.4787, val_acc: 0.4520\n",
      "Epoch [26], last_lr: 0.00881, train_loss: 0.9294, val_loss: 1.5101, val_acc: 0.4480\n",
      "Epoch [27], last_lr: 0.00928, train_loss: 0.9450, val_loss: 1.5391, val_acc: 0.4340\n",
      "Epoch [28], last_lr: 0.00976, train_loss: 0.9348, val_loss: 1.4992, val_acc: 0.4500\n",
      "Epoch [29], last_lr: 0.01023, train_loss: 0.9382, val_loss: 1.5347, val_acc: 0.4460\n",
      "Epoch [30], last_lr: 0.01069, train_loss: 0.9448, val_loss: 1.5517, val_acc: 0.4440\n",
      "Epoch [31], last_lr: 0.01115, train_loss: 0.9426, val_loss: 1.5150, val_acc: 0.4460\n",
      "Epoch [32], last_lr: 0.01161, train_loss: 0.9119, val_loss: 1.5454, val_acc: 0.4220\n",
      "Epoch [33], last_lr: 0.01205, train_loss: 0.9499, val_loss: 1.5208, val_acc: 0.4380\n",
      "Epoch [34], last_lr: 0.01248, train_loss: 0.9432, val_loss: 1.5615, val_acc: 0.4320\n",
      "Epoch [35], last_lr: 0.01290, train_loss: 0.9469, val_loss: 1.5628, val_acc: 0.4380\n",
      "Epoch [36], last_lr: 0.01331, train_loss: 1.0448, val_loss: 1.5850, val_acc: 0.4480\n",
      "Epoch [37], last_lr: 0.01370, train_loss: 1.0074, val_loss: 1.5673, val_acc: 0.4480\n",
      "Epoch [38], last_lr: 0.01407, train_loss: 0.9936, val_loss: 1.4295, val_acc: 0.4560\n",
      "Epoch [39], last_lr: 0.01443, train_loss: 0.9638, val_loss: 1.4286, val_acc: 0.4660\n",
      "Epoch [40], last_lr: 0.01476, train_loss: 1.1003, val_loss: 1.5889, val_acc: 0.4340\n",
      "Epoch [41], last_lr: 0.01508, train_loss: 1.0156, val_loss: 1.5313, val_acc: 0.4520\n",
      "Epoch [42], last_lr: 0.01538, train_loss: 0.9878, val_loss: 1.5006, val_acc: 0.4800\n",
      "Epoch [43], last_lr: 0.01565, train_loss: 0.9966, val_loss: 1.5354, val_acc: 0.4540\n",
      "Epoch [44], last_lr: 0.01590, train_loss: 1.0637, val_loss: 1.5985, val_acc: 0.4380\n",
      "Epoch [45], last_lr: 0.01613, train_loss: 1.1669, val_loss: 1.4510, val_acc: 0.4500\n",
      "Epoch [46], last_lr: 0.01633, train_loss: 1.0191, val_loss: 1.5097, val_acc: 0.4460\n",
      "Epoch [47], last_lr: 0.01651, train_loss: 1.2545, val_loss: 2.0478, val_acc: 0.3960\n",
      "Epoch [48], last_lr: 0.01666, train_loss: 1.2786, val_loss: 1.4890, val_acc: 0.4580\n",
      "Epoch [49], last_lr: 0.01678, train_loss: 1.0182, val_loss: 1.5487, val_acc: 0.4400\n",
      "Epoch [50], last_lr: 0.01688, train_loss: 0.9855, val_loss: 1.4720, val_acc: 0.4560\n",
      "Epoch [51], last_lr: 0.01694, train_loss: 0.9592, val_loss: 1.6151, val_acc: 0.4160\n",
      "Epoch [52], last_lr: 0.01699, train_loss: 0.9181, val_loss: 1.4714, val_acc: 0.4380\n",
      "Epoch [53], last_lr: 0.01700, train_loss: 0.9531, val_loss: 1.6666, val_acc: 0.4120\n",
      "Epoch [54], last_lr: 0.01700, train_loss: 1.0021, val_loss: 1.7262, val_acc: 0.3880\n",
      "Epoch [55], last_lr: 0.01699, train_loss: 0.9650, val_loss: 1.5450, val_acc: 0.4300\n",
      "Epoch [56], last_lr: 0.01698, train_loss: 0.9688, val_loss: 1.5020, val_acc: 0.4360\n",
      "Epoch [57], last_lr: 0.01696, train_loss: 0.9443, val_loss: 1.5017, val_acc: 0.4520\n",
      "Epoch [58], last_lr: 0.01693, train_loss: 0.9243, val_loss: 1.4874, val_acc: 0.4500\n",
      "Epoch [59], last_lr: 0.01691, train_loss: 0.9375, val_loss: 1.7315, val_acc: 0.3880\n",
      "Epoch [60], last_lr: 0.01687, train_loss: 1.0693, val_loss: 1.6972, val_acc: 0.4000\n",
      "Epoch [61], last_lr: 0.01683, train_loss: 1.0037, val_loss: 1.7065, val_acc: 0.4100\n",
      "Epoch [62], last_lr: 0.01679, train_loss: 0.9696, val_loss: 1.5717, val_acc: 0.4540\n",
      "Epoch [63], last_lr: 0.01674, train_loss: 0.9476, val_loss: 1.5287, val_acc: 0.4520\n",
      "Epoch [64], last_lr: 0.01668, train_loss: 0.9774, val_loss: 1.5171, val_acc: 0.4660\n",
      "Epoch [65], last_lr: 0.01662, train_loss: 0.9708, val_loss: 1.6539, val_acc: 0.4120\n",
      "Epoch [66], last_lr: 0.01656, train_loss: 1.0233, val_loss: 1.5922, val_acc: 0.4300\n",
      "Epoch [67], last_lr: 0.01649, train_loss: 0.9900, val_loss: 1.5983, val_acc: 0.4540\n",
      "Epoch [68], last_lr: 0.01641, train_loss: 0.9579, val_loss: 1.4671, val_acc: 0.4820\n",
      "Epoch [69], last_lr: 0.01633, train_loss: 0.9630, val_loss: 1.4716, val_acc: 0.4840\n",
      "Epoch [70], last_lr: 0.01625, train_loss: 0.9809, val_loss: 1.6154, val_acc: 0.4700\n",
      "Epoch [71], last_lr: 0.01616, train_loss: 0.9488, val_loss: 1.5944, val_acc: 0.4200\n",
      "Epoch [72], last_lr: 0.01606, train_loss: 0.9215, val_loss: 1.5235, val_acc: 0.4500\n",
      "Epoch [73], last_lr: 0.01596, train_loss: 0.9150, val_loss: 1.6310, val_acc: 0.4220\n",
      "Epoch [74], last_lr: 0.01586, train_loss: 0.9621, val_loss: 1.8734, val_acc: 0.3760\n",
      "Epoch [75], last_lr: 0.01575, train_loss: 1.1553, val_loss: 1.9350, val_acc: 0.4140\n",
      "Epoch [76], last_lr: 0.01564, train_loss: 1.1863, val_loss: 1.8099, val_acc: 0.3900\n",
      "Epoch [77], last_lr: 0.01552, train_loss: 1.1805, val_loss: 1.7251, val_acc: 0.4260\n",
      "Epoch [78], last_lr: 0.01540, train_loss: 1.1816, val_loss: 1.6961, val_acc: 0.4080\n",
      "Epoch [79], last_lr: 0.01528, train_loss: 1.1508, val_loss: 1.5855, val_acc: 0.3980\n",
      "Epoch [80], last_lr: 0.01515, train_loss: 0.9613, val_loss: 1.6635, val_acc: 0.4120\n",
      "Epoch [81], last_lr: 0.01501, train_loss: 0.9313, val_loss: 1.5212, val_acc: 0.4220\n",
      "Epoch [82], last_lr: 0.01487, train_loss: 0.9352, val_loss: 1.5635, val_acc: 0.4280\n",
      "Epoch [83], last_lr: 0.01473, train_loss: 1.1315, val_loss: 1.7366, val_acc: 0.4100\n",
      "Epoch [84], last_lr: 0.01458, train_loss: 1.2281, val_loss: 1.8010, val_acc: 0.4200\n",
      "Epoch [85], last_lr: 0.01444, train_loss: 1.0663, val_loss: 1.4426, val_acc: 0.4720\n",
      "Epoch [86], last_lr: 0.01428, train_loss: 0.8896, val_loss: 1.5791, val_acc: 0.4180\n",
      "Epoch [87], last_lr: 0.01412, train_loss: 0.9355, val_loss: 1.6932, val_acc: 0.3980\n",
      "Epoch [88], last_lr: 0.01396, train_loss: 1.1601, val_loss: 1.9017, val_acc: 0.4020\n",
      "Epoch [89], last_lr: 0.01380, train_loss: 1.0768, val_loss: 1.6009, val_acc: 0.4500\n",
      "Epoch [90], last_lr: 0.01363, train_loss: 0.9525, val_loss: 1.6967, val_acc: 0.4300\n",
      "Epoch [91], last_lr: 0.01346, train_loss: 1.0002, val_loss: 1.7619, val_acc: 0.3780\n",
      "Epoch [92], last_lr: 0.01329, train_loss: 1.0465, val_loss: 1.6665, val_acc: 0.4200\n",
      "Epoch [93], last_lr: 0.01311, train_loss: 1.0405, val_loss: 1.7559, val_acc: 0.4080\n",
      "Epoch [94], last_lr: 0.01293, train_loss: 1.0859, val_loss: 1.5339, val_acc: 0.4440\n",
      "Epoch [95], last_lr: 0.01275, train_loss: 1.0682, val_loss: 1.7655, val_acc: 0.4060\n",
      "Epoch [96], last_lr: 0.01257, train_loss: 1.0086, val_loss: 1.4896, val_acc: 0.4400\n",
      "Epoch [97], last_lr: 0.01238, train_loss: 0.8681, val_loss: 1.5301, val_acc: 0.4180\n",
      "Epoch [98], last_lr: 0.01219, train_loss: 0.9204, val_loss: 1.5916, val_acc: 0.4180\n",
      "Epoch [99], last_lr: 0.01200, train_loss: 0.9416, val_loss: 1.5308, val_acc: 0.4340\n",
      "Epoch [100], last_lr: 0.01180, train_loss: 1.0075, val_loss: 1.6630, val_acc: 0.4380\n",
      "Epoch [101], last_lr: 0.01161, train_loss: 1.0256, val_loss: 1.5423, val_acc: 0.4720\n",
      "Epoch [102], last_lr: 0.01141, train_loss: 0.8940, val_loss: 1.5910, val_acc: 0.4300\n",
      "Epoch [103], last_lr: 0.01121, train_loss: 0.9035, val_loss: 1.5279, val_acc: 0.4300\n",
      "Epoch [104], last_lr: 0.01101, train_loss: 0.9806, val_loss: 1.5361, val_acc: 0.4240\n",
      "Epoch [105], last_lr: 0.01080, train_loss: 0.9272, val_loss: 1.5715, val_acc: 0.4400\n",
      "Epoch [106], last_lr: 0.01060, train_loss: 0.9033, val_loss: 1.5406, val_acc: 0.4500\n",
      "Epoch [107], last_lr: 0.01039, train_loss: 0.9332, val_loss: 1.6077, val_acc: 0.4220\n",
      "Epoch [108], last_lr: 0.01018, train_loss: 0.9621, val_loss: 1.5762, val_acc: 0.4340\n",
      "Epoch [109], last_lr: 0.00998, train_loss: 0.9164, val_loss: 1.4201, val_acc: 0.4540\n",
      "Epoch [110], last_lr: 0.00977, train_loss: 0.8818, val_loss: 1.4228, val_acc: 0.4660\n",
      "Epoch [111], last_lr: 0.00956, train_loss: 0.8707, val_loss: 1.4486, val_acc: 0.4680\n",
      "Epoch [112], last_lr: 0.00935, train_loss: 0.9130, val_loss: 1.4304, val_acc: 0.4740\n",
      "Epoch [113], last_lr: 0.00914, train_loss: 0.8931, val_loss: 1.4696, val_acc: 0.4440\n",
      "Epoch [114], last_lr: 0.00892, train_loss: 0.8861, val_loss: 1.4966, val_acc: 0.4460\n",
      "Epoch [115], last_lr: 0.00871, train_loss: 0.8585, val_loss: 1.4469, val_acc: 0.4580\n",
      "Epoch [116], last_lr: 0.00850, train_loss: 0.8585, val_loss: 1.4534, val_acc: 0.4580\n",
      "Epoch [117], last_lr: 0.00829, train_loss: 0.8809, val_loss: 1.4803, val_acc: 0.4660\n",
      "Epoch [118], last_lr: 0.00808, train_loss: 0.8859, val_loss: 1.4819, val_acc: 0.4320\n",
      "Epoch [119], last_lr: 0.00786, train_loss: 0.9177, val_loss: 1.5189, val_acc: 0.4500\n",
      "Epoch [120], last_lr: 0.00765, train_loss: 0.9072, val_loss: 1.4397, val_acc: 0.4640\n",
      "Epoch [121], last_lr: 0.00744, train_loss: 0.8796, val_loss: 1.4356, val_acc: 0.4620\n",
      "Epoch [122], last_lr: 0.00723, train_loss: 0.8922, val_loss: 1.4345, val_acc: 0.4760\n",
      "Epoch [123], last_lr: 0.00702, train_loss: 0.8453, val_loss: 1.4660, val_acc: 0.4580\n",
      "Epoch [124], last_lr: 0.00682, train_loss: 0.8742, val_loss: 1.4575, val_acc: 0.4580\n",
      "Epoch [125], last_lr: 0.00661, train_loss: 0.8827, val_loss: 1.4647, val_acc: 0.4520\n",
      "Epoch [126], last_lr: 0.00640, train_loss: 0.8848, val_loss: 1.5169, val_acc: 0.4520\n",
      "Epoch [127], last_lr: 0.00620, train_loss: 0.8845, val_loss: 1.4596, val_acc: 0.4620\n",
      "Epoch [128], last_lr: 0.00599, train_loss: 0.8750, val_loss: 1.4444, val_acc: 0.4440\n",
      "Epoch [129], last_lr: 0.00579, train_loss: 0.8835, val_loss: 1.4454, val_acc: 0.4660\n",
      "Epoch [130], last_lr: 0.00559, train_loss: 0.8540, val_loss: 1.4584, val_acc: 0.4520\n",
      "Epoch [131], last_lr: 0.00539, train_loss: 0.8546, val_loss: 1.4688, val_acc: 0.4700\n",
      "Epoch [132], last_lr: 0.00520, train_loss: 0.8484, val_loss: 1.4470, val_acc: 0.4540\n",
      "Epoch [133], last_lr: 0.00500, train_loss: 0.8666, val_loss: 1.4699, val_acc: 0.4480\n",
      "Epoch [134], last_lr: 0.00481, train_loss: 0.8601, val_loss: 1.4753, val_acc: 0.4740\n",
      "Epoch [135], last_lr: 0.00462, train_loss: 0.8431, val_loss: 1.4663, val_acc: 0.4400\n",
      "Epoch [136], last_lr: 0.00443, train_loss: 0.8480, val_loss: 1.4646, val_acc: 0.4700\n",
      "Epoch [137], last_lr: 0.00425, train_loss: 0.8604, val_loss: 1.4983, val_acc: 0.4620\n",
      "Epoch [138], last_lr: 0.00407, train_loss: 0.8590, val_loss: 1.4700, val_acc: 0.4620\n",
      "Epoch [139], last_lr: 0.00389, train_loss: 0.8525, val_loss: 1.4680, val_acc: 0.4540\n",
      "Epoch [140], last_lr: 0.00371, train_loss: 0.8397, val_loss: 1.4505, val_acc: 0.4620\n",
      "Epoch [141], last_lr: 0.00354, train_loss: 0.8518, val_loss: 1.4539, val_acc: 0.4560\n",
      "Epoch [142], last_lr: 0.00337, train_loss: 0.8432, val_loss: 1.4351, val_acc: 0.4700\n",
      "Epoch [143], last_lr: 0.00320, train_loss: 0.8375, val_loss: 1.4338, val_acc: 0.4580\n",
      "Epoch [144], last_lr: 0.00304, train_loss: 0.8474, val_loss: 1.4315, val_acc: 0.4640\n",
      "Epoch [145], last_lr: 0.00288, train_loss: 0.8419, val_loss: 1.4327, val_acc: 0.4720\n",
      "Epoch [146], last_lr: 0.00272, train_loss: 0.8158, val_loss: 1.4472, val_acc: 0.4660\n",
      "Epoch [147], last_lr: 0.00257, train_loss: 0.8409, val_loss: 1.4421, val_acc: 0.4740\n",
      "Epoch [148], last_lr: 0.00242, train_loss: 0.8258, val_loss: 1.4458, val_acc: 0.4640\n",
      "Epoch [149], last_lr: 0.00227, train_loss: 0.8571, val_loss: 1.4423, val_acc: 0.4560\n",
      "Epoch [150], last_lr: 0.00213, train_loss: 0.8201, val_loss: 1.4462, val_acc: 0.4600\n",
      "Epoch [151], last_lr: 0.00199, train_loss: 0.8430, val_loss: 1.4506, val_acc: 0.4540\n",
      "Epoch [152], last_lr: 0.00185, train_loss: 0.8156, val_loss: 1.4489, val_acc: 0.4620\n",
      "Epoch [153], last_lr: 0.00172, train_loss: 0.8522, val_loss: 1.4491, val_acc: 0.4560\n",
      "Epoch [154], last_lr: 0.00160, train_loss: 0.8382, val_loss: 1.4625, val_acc: 0.4480\n",
      "Epoch [155], last_lr: 0.00148, train_loss: 0.8228, val_loss: 1.4531, val_acc: 0.4540\n",
      "Epoch [156], last_lr: 0.00136, train_loss: 0.8344, val_loss: 1.4554, val_acc: 0.4680\n",
      "Epoch [157], last_lr: 0.00125, train_loss: 0.8093, val_loss: 1.4582, val_acc: 0.4480\n",
      "Epoch [158], last_lr: 0.00114, train_loss: 0.8207, val_loss: 1.4575, val_acc: 0.4460\n",
      "Epoch [159], last_lr: 0.00104, train_loss: 0.8360, val_loss: 1.4507, val_acc: 0.4540\n",
      "Epoch [160], last_lr: 0.00094, train_loss: 0.8249, val_loss: 1.4436, val_acc: 0.4620\n",
      "Epoch [161], last_lr: 0.00084, train_loss: 0.8439, val_loss: 1.4483, val_acc: 0.4580\n",
      "Epoch [162], last_lr: 0.00075, train_loss: 0.8159, val_loss: 1.4458, val_acc: 0.4660\n",
      "Epoch [163], last_lr: 0.00067, train_loss: 0.8299, val_loss: 1.4431, val_acc: 0.4640\n",
      "Epoch [164], last_lr: 0.00059, train_loss: 0.8339, val_loss: 1.4462, val_acc: 0.4660\n",
      "Epoch [165], last_lr: 0.00051, train_loss: 0.8185, val_loss: 1.4435, val_acc: 0.4600\n",
      "Epoch [166], last_lr: 0.00044, train_loss: 0.8217, val_loss: 1.4434, val_acc: 0.4600\n",
      "Epoch [167], last_lr: 0.00038, train_loss: 0.8297, val_loss: 1.4438, val_acc: 0.4580\n",
      "Epoch [168], last_lr: 0.00032, train_loss: 0.8394, val_loss: 1.4429, val_acc: 0.4660\n",
      "Epoch [169], last_lr: 0.00026, train_loss: 0.8248, val_loss: 1.4414, val_acc: 0.4620\n",
      "Epoch [170], last_lr: 0.00021, train_loss: 0.8298, val_loss: 1.4420, val_acc: 0.4640\n",
      "Epoch [171], last_lr: 0.00017, train_loss: 0.8304, val_loss: 1.4415, val_acc: 0.4600\n",
      "Epoch [172], last_lr: 0.00013, train_loss: 0.8289, val_loss: 1.4405, val_acc: 0.4620\n",
      "Epoch [173], last_lr: 0.00010, train_loss: 0.8335, val_loss: 1.4415, val_acc: 0.4600\n",
      "Epoch [174], last_lr: 0.00007, train_loss: 0.8391, val_loss: 1.4419, val_acc: 0.4600\n",
      "Epoch [175], last_lr: 0.00004, train_loss: 0.8296, val_loss: 1.4414, val_acc: 0.4600\n",
      "Epoch [176], last_lr: 0.00002, train_loss: 0.8394, val_loss: 1.4408, val_acc: 0.4600\n",
      "Epoch [177], last_lr: 0.00001, train_loss: 0.8387, val_loss: 1.4409, val_acc: 0.4620\n",
      "Epoch [178], last_lr: 0.00000, train_loss: 0.8202, val_loss: 1.4420, val_acc: 0.4620\n",
      "Epoch [179], last_lr: 0.00000, train_loss: 0.8326, val_loss: 1.4414, val_acc: 0.4600\n"
     ]
    }
   ],
   "source": [
    "train_data = CIFAR100('./data', train=True,\n",
    "                transform=transform_train,\n",
    "                download=True, coarse=True, coarseNumber=14)\n",
    "test_data = CIFAR100('./data', train=False,\n",
    "                transform=transform_test,\n",
    "                download=True, coarse=True, coarseNumber=14)\n",
    "\n",
    "train_length = train_data.__len__() # Length training dataset\n",
    "train_indices = np.arange(train_length)\n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                        train_data, \n",
    "                        batch_size=batch_size, \n",
    "                        num_workers=2,\n",
    "                        pin_memory=True,\n",
    "                    )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                        test_data, \n",
    "                        batch_size=batch_size*2,\n",
    "                        num_workers=2,\n",
    "                        pin_memory=True\n",
    "                    )\n",
    "\n",
    "device = get_default_device()\n",
    "trainloader = DeviceDataLoader(train_loader, device)\n",
    "testloader = DeviceDataLoader(test_loader, device)\n",
    "\n",
    "\n",
    "model20To100 = ResNet9(3, 100, True)\n",
    "model20To100.load_state_dict(torch.load('../group_1028_to_parent_Loss_parent_and_child_pretrained_model.h5'))\n",
    "for param in model20To100.parameters():\n",
    "    param.requires_grad=False\n",
    "\n",
    "model20To100.classifier_child = nn.Sequential(model20To100.classifier_parent,\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(20, 5)\n",
    "                                        )\n",
    "                                        \n",
    "model20To100=to_device(model20To100, device)\n",
    "history = [evaluate(model20To100, testloader)]\n",
    "print(history)\n",
    "history += fit_one_cycle(int(epochs*1.5), max_lr*17, model20To100, trainloader, testloader, \n",
    "                            grad_clip=grad_clip, \n",
    "                            weight_decay=weight_decay, \n",
    "                            opt_func=opt_func)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model20To100.state_dict(), 'group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}.h5'.format(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
