{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'11': {'15': 0, '19': 1, '21': 2, '31': 3, '38': 4}, '15': {'27': 0, '29': 1, '44': 2, '78': 3, '93': 4}, '4': {'0': 0, '51': 1, '53': 2, '57': 3, '83': 4}, '14': {'2': 0, '11': 1, '35': 2, '46': 3, '98': 4}, '1': {'1': 0, '32': 1, '67': 2, '73': 3, '91': 4}, '5': {'22': 0, '39': 1, '40': 2, '86': 3, '87': 4}, '18': {'8': 0, '13': 1, '48': 2, '58': 3, '90': 4}, '3': {'9': 0, '10': 1, '16': 2, '28': 3, '61': 4}, '10': {'23': 0, '33': 1, '49': 2, '60': 3, '71': 4}, '17': {'47': 0, '52': 1, '56': 2, '59': 3, '96': 4}, '2': {'54': 0, '62': 1, '70': 2, '82': 3, '92': 4}, '9': {'12': 0, '17': 1, '37': 2, '68': 3, '76': 4}, '8': {'3': 0, '42': 1, '43': 2, '88': 3, '97': 4}, '16': {'36': 0, '50': 1, '65': 2, '74': 3, '80': 4}, '6': {'5': 0, '20': 1, '25': 2, '84': 3, '94': 4}, '12': {'34': 0, '63': 1, '64': 2, '66': 3, '75': 4}, '19': {'41': 0, '69': 1, '81': 2, '85': 3, '89': 4}, '7': {'6': 0, '7': 1, '14': 2, '18': 3, '24': 4}, '13': {'26': 0, '45': 1, '77': 2, '79': 3, '99': 4}, '0': {'4': 0, '30': 1, '55': 2, '72': 3, '95': 4}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "f = open('../parent_to_child_class_from_0_to_5.json')\n",
    "parent_to_child_class_from_0_to_5 = json.load(f)\n",
    "print(parent_to_child_class_from_0_to_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import errno\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "if sys.version_info[0] == 2:\n",
    "    import cPickle as pickle\n",
    "else:\n",
    "    import pickle\n",
    "\n",
    "import torch.utils.data as data\n",
    "from torchvision.datasets.utils import download_url, check_integrity\n",
    "import torchvision.transforms as tt\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from sklearn.metrics import *\n",
    "from torchsummary import summary\n",
    "\n",
    "class CIFAR10(data.Dataset):\n",
    "    \"\"\"`CIFAR10 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where directory\n",
    "            ``cifar-10-batches-py`` exists.\n",
    "        train (bool, optional): If True, creates dataset from training set, otherwise\n",
    "            creates from test set.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "    \"\"\"\n",
    "    base_folder = 'cifar-10-batches-py'\n",
    "    url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "    filename = \"cifar-10-python.tar.gz\"\n",
    "    tgz_md5 = 'c58f30108f718f92721af3b95e74349a'\n",
    "    train_list = [\n",
    "        ['data_batch_1', 'c99cafc152244af753f735de768cd75f'],\n",
    "        ['data_batch_2', 'd4bba439e000b95fd0a9bffe97cbabec'],\n",
    "        ['data_batch_3', '54ebc095f3ab1f0389bbae665268c751'],\n",
    "        ['data_batch_4', '634d18415352ddfa80567beed471001a'],\n",
    "        ['data_batch_5', '482c414d41f54cd18b22e5b47cb7c3cb'],\n",
    "    ]\n",
    "\n",
    "    test_list = [\n",
    "        ['test_batch', '40351d587109b95175f43aff81a1287e'],\n",
    "    ]\n",
    "\n",
    "    meta = {\n",
    "        \"filename\": \"batches.meta\",\n",
    "        \"key\": \"label_names\",\n",
    "        \"md5\": \"5ff9c542aee3614f3951f8cda6e48888\",\n",
    "    }\n",
    "\n",
    "\n",
    "    def __init__(self, root, train=True,\n",
    "                 transform=None, target_transform=None,\n",
    "                 download=False, coarse=False):\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train = train  # training set or test set\n",
    "        self.coarse = coarse\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_integrity():\n",
    "            raise RuntimeError('Dataset not found or corrupted.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "        # now load the picked numpy arrays\n",
    "        if self.train:\n",
    "            self.train_data = []\n",
    "            self.train_labels = []\n",
    "            self.train_coarse_labels = []\n",
    "            for fentry in self.train_list:\n",
    "                f = fentry[0]\n",
    "                file = os.path.join(self.root, self.base_folder, f)\n",
    "                fo = open(file, 'rb')\n",
    "                if sys.version_info[0] == 2:\n",
    "                    entry = pickle.load(fo)\n",
    "                else:\n",
    "                    entry = pickle.load(fo, encoding='latin1')\n",
    "                self.train_data.append(entry['data'])\n",
    "                if 'labels' in entry:\n",
    "                    self.train_labels += entry['labels']\n",
    "                else:\n",
    "                    self.train_labels += entry['fine_labels']\n",
    "                    if self.coarse:\n",
    "                        self.train_coarse_labels += entry['coarse_labels']\n",
    "                fo.close()\n",
    "\n",
    "            self.train_data = np.concatenate(self.train_data)\n",
    "            self.train_data = self.train_data.reshape((len(self.train_data), 3, 32, 32))\n",
    "            self.train_data = self.train_data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "        else:\n",
    "            f = self.test_list[0][0]\n",
    "            file = os.path.join(self.root, self.base_folder, f)\n",
    "            fo = open(file, 'rb')\n",
    "            if sys.version_info[0] == 2:\n",
    "                entry = pickle.load(fo)\n",
    "            else:\n",
    "                entry = pickle.load(fo, encoding='latin1')\n",
    "            self.test_data = entry['data']\n",
    "\n",
    "            if 'labels' in entry:\n",
    "                self.test_labels = entry['labels']\n",
    "            else:\n",
    "                self.test_labels = entry['fine_labels']\n",
    "                if self.coarse:\n",
    "                    self.test_coarse_labels = entry['coarse_labels']\n",
    "            fo.close()\n",
    "            self.test_data = self.test_data.reshape((len(self.test_data), 3, 32, 32))\n",
    "            self.test_data = self.test_data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        if self.train:\n",
    "            img, target = self.train_data[index], self.train_labels[index]\n",
    "            if self.coarse:\n",
    "                coarse_target = self.train_coarse_labels[index]\n",
    "        else:\n",
    "            img, target = self.test_data[index], self.test_labels[index]\n",
    "            if self.coarse:\n",
    "                coarse_target = self.test_coarse_labels[index]\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        if not self.coarse:\n",
    "            return img, target\n",
    "        else:\n",
    "            return img, target, coarse_target\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_data)\n",
    "        else:\n",
    "            return len(self.test_data)\n",
    "\n",
    "    def _check_integrity(self):\n",
    "        root = self.root\n",
    "        for fentry in (self.train_list + self.test_list):\n",
    "            filename, md5 = fentry[0], fentry[1]\n",
    "            fpath = os.path.join(root, self.base_folder, filename)\n",
    "            if not check_integrity(fpath, md5):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def download(self):\n",
    "        import tarfile\n",
    "\n",
    "        if self._check_integrity():\n",
    "            print('Files already downloaded and verified')\n",
    "            return\n",
    "\n",
    "        root = self.root\n",
    "        download_url(self.url, root, self.filename, self.tgz_md5)\n",
    "\n",
    "        # extract file\n",
    "        cwd = os.getcwd()\n",
    "        tar = tarfile.open(os.path.join(root, self.filename), \"r:gz\")\n",
    "        os.chdir(root)\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "        os.chdir(cwd)\n",
    "\n",
    "\n",
    "class CIFAR100(CIFAR10):\n",
    "    \"\"\"`CIFAR100 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
    "    This is a subclass of the `CIFAR10` Dataset.\n",
    "    \"\"\"\n",
    "    base_folder = 'cifar-100-python'\n",
    "    url = \"https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\"\n",
    "    filename = \"cifar-100-python.tar.gz\"\n",
    "    tgz_md5 = 'eb9058c3a382ffc7106e4002c42a8d85'\n",
    "    train_list = [\n",
    "        ['train', '16019d7e3df5f24257cddd939b257f8d'],\n",
    "    ]\n",
    "\n",
    "    test_list = [\n",
    "        ['test', 'f0ef6b0ae62326f3e7ffdfab6717acfc'],\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 400\n",
    "epochs = 120\n",
    "max_lr = 0.001\n",
    "grad_clip = 0.01\n",
    "weight_decay =0.001\n",
    "opt_func = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = tt.Compose([tt.RandomCrop(32, padding=4,padding_mode='reflect'), \n",
    "                         tt.RandomHorizontalFlip(), \n",
    "                         tt.ToTensor(), \n",
    "                         #tt.Normalize(mean,std,inplace=True) \n",
    "                         ]\n",
    "                         )\n",
    "transform_test = tt.Compose([tt.ToTensor(), \n",
    "                             #tt.Normalize(mean,std)\n",
    "                             ])\n",
    "\n",
    "train_data = CIFAR100('./data', train=True,\n",
    "                 transform=transform_train,\n",
    "                 download=True, coarse=True)\n",
    "test_data = CIFAR100('./data', train=False,\n",
    "                 transform=transform_test,\n",
    "                 download=True, coarse=True)\n",
    "\n",
    "train_length = train_data.__len__() # Length training dataset\n",
    "train_indices = np.arange(train_length)\n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                        train_data, \n",
    "                        batch_size=batch_size, \n",
    "                        num_workers=2,\n",
    "                        pin_memory=True,\n",
    "                    )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                        test_data, \n",
    "                        batch_size=batch_size*2,\n",
    "                        num_workers=2,\n",
    "                        pin_memory=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()\n",
    "trainloader = DeviceDataLoader(train_loader, device)\n",
    "testloader = DeviceDataLoader(test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def __init__(self, fine):\n",
    "        super(ImageClassificationBase, self).__init__()\n",
    "        self.fine = fine\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, fine, coarse = batch \n",
    "        # if self.fine:\n",
    "        #     labels=fine\n",
    "        # else:\n",
    "        #     labels=coarse\n",
    "        out_parent, out_child = self(images)                  # Generate predictions\n",
    "        loss_parent = F.cross_entropy(out_parent, coarse)\n",
    "        loss_child = F.cross_entropy(out_child, fine) # Calculate loss\n",
    "        return loss_parent+1.5*loss_child\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, fine, coarse = batch \n",
    "        # if self.fine:\n",
    "        #     labels=fine\n",
    "        # else:\n",
    "        #     labels=coarse\n",
    "        #out = self(images)                    # Generate predictions\n",
    "        #loss = F.cross_entropy(out, labels)\n",
    "        out_parent, out_child = self(images)                  # Generate predictions\n",
    "        loss_parent = F.cross_entropy(out_parent, coarse)\n",
    "        loss_child = F.cross_entropy(out_child, fine)   # Calculate loss\n",
    "        acc_parent = accuracy(out_parent, coarse)\n",
    "        acc_child = accuracy(out_child, fine)           # Calculate accuracy\n",
    "        return {'val_loss_parent': loss_parent.detach(), 'val_acc_parent': acc_parent, 'val_loss_child':loss_child.detach(), 'val_acc_child': acc_child}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses_parent = [x['val_loss_parent'] for x in outputs]\n",
    "        epoch_loss_parent = torch.stack(batch_losses_parent).mean()   # Combine losses\n",
    "        #\n",
    "        batch_accs_parent = [x['val_acc_parent'] for x in outputs]\n",
    "        epoch_acc_parent = torch.stack(batch_accs_parent).mean()  # Combine accuracies\n",
    "        ###     \n",
    "        batch_losses_child = [x['val_loss_child'] for x in outputs]\n",
    "        epoch_loss_child = torch.stack(batch_losses_child).mean()   # Combine losses\n",
    "        #\n",
    "        batch_accs_child = [x['val_acc_child'] for x in outputs]\n",
    "        epoch_acc_child = torch.stack(batch_accs_child).mean() \n",
    "        return {'val_loss_parent': epoch_loss_parent.item(), 'val_acc_parent': epoch_acc_parent.item(), 'val_loss_child':epoch_loss_child.item(), \n",
    "                'val_acc_child':epoch_acc_child.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss_parent: {:.4f}, val_acc_parent: {:.4f}, val_loss_child: {:.4f}, val_acc_child: {:.4f}\".format(\n",
    "            epoch, result['lrs'][-1], result['train_loss'], result['val_loss_parent'], result['val_acc_parent'], result['val_loss_child'], result['val_acc_child']))\n",
    "        \n",
    "def conv_block(in_channels, out_channels, pool=False):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
    "              nn.BatchNorm2d(out_channels), \n",
    "              nn.ReLU(inplace=True)]\n",
    "    if pool: layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class ResNet9(ImageClassificationBase):\n",
    "    def __init__(self, in_channels, num_classes, fine):\n",
    "        super().__init__(fine)\n",
    "        \n",
    "        self.conv1 = conv_block(in_channels, 64)\n",
    "        self.conv2 = conv_block(64, 128, pool=True) \n",
    "        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128)) \n",
    "        \n",
    "        self.conv3 = conv_block(128, 256, pool=True)\n",
    "        self.conv4 = conv_block(256, 512, pool=True) \n",
    "        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512)) \n",
    "        self.conv5 = conv_block(512, 1028, pool=True) \n",
    "        self.res3 = nn.Sequential(conv_block(1028, 1028), conv_block(1028, 1028))\n",
    "\n",
    "        #-------------------\n",
    "        self.classifier_parent = nn.Sequential(nn.MaxPool2d(2), # 1028 x 1 x 1\n",
    "                                        nn.Flatten(), # 1028 \n",
    "                                        nn.Linear(1028, 20))\n",
    "                                 # 1028 -> 100 \n",
    "\n",
    "        self.classifier_child = nn.Sequential(self.classifier_parent,\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(20, num_classes)\n",
    "                                ) # 1028 -> 100 \n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.conv1(xb)\n",
    "        out = self.conv2(out)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.conv5(out)\n",
    "        out = self.res3(out) + out\n",
    "        parent_out=self.classifier_parent(out)\n",
    "        #child_out = self.classifier_child(out)\n",
    "        return parent_out\n",
    "\n",
    "model100 = to_device(ResNet9(3, 100, True), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in test_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def fit_one_cycle(epochs, max_lr, model, train_loader, test_loader, \n",
    "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
    "    torch.cuda.empty_cache()\n",
    "    history = []\n",
    "    \n",
    "    # Set up cutom optimizer with weight decay\n",
    "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
    "    # Set up one-cycle learning rate scheduler\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n",
    "                                                steps_per_epoch=len(train_loader))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        lrs = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            if grad_clip: \n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Record & update learning rate\n",
    "            lrs.append(get_lr(optimizer))\n",
    "            sched.step()\n",
    "        \n",
    "        # Validation phase\n",
    "        result = evaluate(model, test_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        result['lrs'] = lrs\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate testing accuracy, predicted label, confusion matrix, and table for classification report\n",
    "def test_label_predictions(model, device, test_loader, fine):\n",
    "    model.eval()\n",
    "    actuals = []\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        if fine:\n",
    "            for data, target, _ in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                prediction = output.argmax(dim=1, keepdim=True)\n",
    "                print(\"predicted \", prediction, \" actual: \", target)\n",
    "                actuals.extend(target.view_as(prediction))\n",
    "                predictions.extend(prediction)\n",
    "        else:\n",
    "            for data, _, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                prediction = output.argmax(dim=1, keepdim=True)\n",
    "                print(\"predicted \", prediction, \" actual: \", target)\n",
    "                actuals.extend(target.view_as(prediction))\n",
    "                predictions.extend(prediction)\n",
    "\n",
    "    return [i.item() for i in actuals], [i.item() for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelX_to_parent = ResNet9(3, 100, True)\n",
    "# modelX_to_parent.classifier_child = nn.Sequential(modelX_to_parent.classifier_parent,\n",
    "#                                         nn.ReLU(),\n",
    "#                                         nn.Linear(20, 5)\n",
    "#                                         )\n",
    "modelX_to_parent.load_state_dict(torch.load('../group_1028_to_parent_Loss_parent_and_child_pretrained_model.h5'))\n",
    "for param in modelX_to_parent.parameters():\n",
    "    param.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelX_to_parent=to_device(modelX_to_parent, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc0 = nn.Linear(20, 5)\n",
    "        self.fc1 = nn.Linear(20, 5)\n",
    "        self.fc2 = nn.Linear(20, 5)\n",
    "        self.fc3 = nn.Linear(20, 5)\n",
    "        self.fc4 = nn.Linear(20, 5)\n",
    "        self.fc5 = nn.Linear(20, 5)\n",
    "        self.fc6 = nn.Linear(20, 5)\n",
    "        self.fc7 = nn.Linear(20, 5)\n",
    "        self.fc8 = nn.Linear(20, 5)\n",
    "        self.fc9 = nn.Linear(20, 5)\n",
    "        self.fc10 = nn.Linear(20, 5)\n",
    "        self.fc11 = nn.Linear(20, 5)\n",
    "        self.fc12 = nn.Linear(20, 5)\n",
    "        self.fc13 = nn.Linear(20, 5)\n",
    "        self.fc14 = nn.Linear(20, 5)\n",
    "        self.fc15 = nn.Linear(20, 5)\n",
    "        self.fc16 = nn.Linear(20, 5)\n",
    "        self.fc17 = nn.Linear(20, 5)\n",
    "        self.fc18 = nn.Linear(20, 5)\n",
    "        self.fc19 = nn.Linear(20, 5)\n",
    "\n",
    "        self.dict={0:self.fc0,\n",
    "                   1:self.fc1,\n",
    "                   2:self.fc2,\n",
    "                   3:self.fc3,\n",
    "                   4:self.fc4,\n",
    "                   5:self.fc5,\n",
    "                   6:self.fc6,\n",
    "                   7:self.fc7,\n",
    "                   8:self.fc8,\n",
    "                   9:self.fc9,\n",
    "                   10:self.fc1,\n",
    "                   11:self.fc11,\n",
    "                   12:self.fc12,\n",
    "                   13:self.fc13,\n",
    "                   14:self.fc14,\n",
    "                   15:self.fc15,\n",
    "                   16:self.fc16,\n",
    "                   17:self.fc17,\n",
    "                   18:self.fc18,\n",
    "                   19:self.fc19\n",
    "                   }\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(x)\n",
    "        y=torch.zeros(x.shape[0],1)\n",
    "        for i in range(x.shape[0]):\n",
    "            parent=x[i].argmax(dim=0).item()\n",
    "            child=self.dict[parent](x[i]).argmax(dim=0).item()\n",
    "            y[i]=torch.tensor(int(list(parent_to_child_class_from_0_to_5[str(parent)].keys())[list(parent_to_child_class_from_0_to_5[str(parent)].values()).index(child)]))\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=to_device(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.fc0.weight=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_weight_reduced_size.pt\".format(0)))\n",
    "    model.fc0.bias=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_bias_reduced_size.pt\".format(0)))\n",
    "    model.fc1.weight=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_weight_reduced_size.pt\".format(1)))\n",
    "    model.fc1.bias=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_bias_reduced_size.pt\".format(1)))\n",
    "    model.fc2.weight=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_weight_reduced_size.pt\".format(2)))\n",
    "    model.fc2.bias=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_bias_reduced_size.pt\".format(2)))\n",
    "    model.fc3.weight=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_weight_reduced_size.pt\".format(3)))\n",
    "    model.fc3.bias=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_bias_reduced_size.pt\".format(3)))\n",
    "    model.fc4.weight=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_weight_reduced_size.pt\".format(4)))\n",
    "    model.fc4.bias=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_bias_reduced_size.pt\".format(4)))\n",
    "\n",
    "    model.fc5.weight=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_weight_reduced_size.pt\".format(5)))\n",
    "    model.fc5.bias=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_bias_reduced_size.pt\".format(5)))\n",
    "    model.fc6.weight=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_weight_reduced_size.pt\".format(6)))\n",
    "    model.fc6.bias=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_bias_reduced_size.pt\".format(6)))\n",
    "    model.fc7.weight=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_weight_reduced_size.pt\".format(7)))\n",
    "    model.fc7.bias=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_bias_reduced_size.pt\".format(7)))\n",
    "    model.fc8.weight=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_weight_reduced_size.pt\".format(8)))\n",
    "    model.fc8.bias=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_bias_reduced_size.pt\".format(8)))\n",
    "    model.fc9.weight=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_weight_reduced_size.pt\".format(9)))\n",
    "    model.fc9.bias=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_bias_reduced_size.pt\".format(9)))\n",
    "\n",
    "    model.fc10.weight=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_weight_reduced_size.pt\".format(10)))\n",
    "    model.fc10.bias=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_bias_reduced_size.pt\".format(10)))\n",
    "    model.fc11.weight=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_weight_reduced_size.pt\".format(11)))\n",
    "    model.fc11.bias=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_bias_reduced_size.pt\".format(11)))\n",
    "    model.fc12.weight=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_weight_reduced_size.pt\".format(12)))\n",
    "    model.fc12.bias=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_bias_reduced_size.pt\".format(12)))\n",
    "    model.fc13.weight=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_weight_reduced_size.pt\".format(13)))\n",
    "    model.fc13.bias=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_bias_reduced_size.pt\".format(13)))\n",
    "    model.fc14.weight=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_weight_reduced_size.pt\".format(14)))\n",
    "    model.fc14.bias=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_bias_reduced_size.pt\".format(14)))\n",
    "\n",
    "    model.fc15.weight=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_weight_reduced_size.pt\".format(15)))\n",
    "    model.fc15.bias=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_bias_reduced_size.pt\".format(15)))\n",
    "    model.fc16.weight=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_weight_reduced_size.pt\".format(16)))\n",
    "    model.fc16.bias=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_bias_reduced_size.pt\".format(16)))\n",
    "    model.fc17.weight=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_weight_reduced_size.pt\".format(17)))\n",
    "    model.fc17.bias=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_bias_reduced_size.pt\".format(17)))\n",
    "    model.fc18.weight=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_weight_reduced_size.pt\".format(18)))\n",
    "    model.fc18.bias=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_bias_reduced_size.pt\".format(18)))\n",
    "    model.fc19.weight=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_weight_reduced_size.pt\".format(19)))\n",
    "    model.fc19.bias=nn.Parameter(torch.load(\"group_1028_to_parent_Loss_parent_and_child_pretrained_model_For_parent_{}_bias_reduced_size.pt\".format(19)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptflops import get_model_complexity_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28804.0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "macs_classifier, params_classifier = get_model_complexity_info(modelX_to_parent.classifier_parent, (1028,2,2), as_strings=False, print_per_layer_stat=False, verbose=False) \n",
    "print(macs_classifier)\n",
    "print(params_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105.0\n",
      "105\n"
     ]
    }
   ],
   "source": [
    "macs_classifier, params_classifier = get_model_complexity_info(model.fc0, (1,1,20), as_strings=False, print_per_layer_stat=False, verbose=False) \n",
    "print(macs_classifier)\n",
    "print(params_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28909.0\n"
     ]
    }
   ],
   "source": [
    "# MACs for parent and child summed up\n",
    "print(28804.0+105.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelX_to_parent.eval()\n",
    "model.eval()\n",
    "actuals = []\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for data, target, _ in testloader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = modelX_to_parent(data)\n",
    "        output_child=model(output)\n",
    "        prediction=output_child\n",
    "        actuals.extend(target.view_as(prediction))\n",
    "        predictions.extend(prediction)\n",
    "\n",
    "y_test, y_pred= [i.item() for i in actuals], [i.item() for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.635500\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score: %f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[95,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0, 84,  0, ...,  0,  0,  0],\n",
       "       [ 1,  1, 55, ...,  0,  1,  0],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 69,  1,  1],\n",
       "       [ 1,  0,  1, ...,  0, 29,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0, 73]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.95      0.84       100\n",
      "           1       0.84      0.84      0.84       100\n",
      "           2       0.71      0.55      0.62       100\n",
      "           3       0.71      0.42      0.53       100\n",
      "           4       0.50      0.56      0.53       100\n",
      "           5       0.55      0.78      0.65       100\n",
      "           6       0.56      0.81      0.66       100\n",
      "           7       0.64      0.73      0.68       100\n",
      "           8       0.89      0.78      0.83       100\n",
      "           9       0.82      0.81      0.81       100\n",
      "          10       0.70      0.32      0.44       100\n",
      "          11       0.45      0.54      0.49       100\n",
      "          12       0.74      0.71      0.72       100\n",
      "          13       0.57      0.69      0.62       100\n",
      "          14       0.71      0.60      0.65       100\n",
      "          15       0.60      0.73      0.66       100\n",
      "          16       0.64      0.63      0.63       100\n",
      "          17       0.79      0.88      0.83       100\n",
      "          18       0.68      0.52      0.59       100\n",
      "          19       0.76      0.59      0.66       100\n",
      "          20       0.70      0.87      0.77       100\n",
      "          21       0.70      0.89      0.78       100\n",
      "          22       0.63      0.75      0.68       100\n",
      "          23       0.00      0.00      0.00       100\n",
      "          24       0.75      0.81      0.78       100\n",
      "          25       0.72      0.38      0.50       100\n",
      "          26       0.55      0.69      0.61       100\n",
      "          27       0.47      0.58      0.52       100\n",
      "          28       0.77      0.74      0.76       100\n",
      "          29       0.78      0.66      0.71       100\n",
      "          30       0.56      0.58      0.57       100\n",
      "          31       0.63      0.62      0.63       100\n",
      "          32       0.70      0.61      0.65       100\n",
      "          33       0.00      0.00      0.00       100\n",
      "          34       0.75      0.71      0.73       100\n",
      "          35       0.36      0.63      0.45       100\n",
      "          36       0.62      0.83      0.71       100\n",
      "          37       0.81      0.66      0.73       100\n",
      "          38       0.57      0.58      0.58       100\n",
      "          39       0.79      0.81      0.80       100\n",
      "          40       0.73      0.61      0.66       100\n",
      "          41       0.88      0.91      0.89       100\n",
      "          42       0.77      0.64      0.70       100\n",
      "          43       0.65      0.78      0.71       100\n",
      "          44       0.42      0.41      0.42       100\n",
      "          45       0.61      0.44      0.51       100\n",
      "          46       0.65      0.32      0.43       100\n",
      "          47       0.54      0.63      0.58       100\n",
      "          48       0.84      0.97      0.90       100\n",
      "          49       0.15      0.15      0.15       100\n",
      "          50       0.43      0.45      0.44       100\n",
      "          51       0.73      0.70      0.71       100\n",
      "          52       0.36      0.81      0.50       100\n",
      "          53       0.70      0.92      0.79       100\n",
      "          54       0.77      0.70      0.73       100\n",
      "          55       0.38      0.33      0.35       100\n",
      "          56       0.92      0.85      0.89       100\n",
      "          57       0.72      0.71      0.71       100\n",
      "          58       0.87      0.81      0.84       100\n",
      "          59       0.78      0.21      0.33       100\n",
      "          60       0.07      0.19      0.11       100\n",
      "          61       0.61      0.74      0.67       100\n",
      "          62       0.67      0.77      0.72       100\n",
      "          63       0.71      0.67      0.69       100\n",
      "          64       0.47      0.49      0.48       100\n",
      "          65       0.67      0.46      0.54       100\n",
      "          66       0.74      0.77      0.75       100\n",
      "          67       0.56      0.59      0.58       100\n",
      "          68       0.82      0.94      0.88       100\n",
      "          69       0.87      0.72      0.79       100\n",
      "          70       0.68      0.70      0.69       100\n",
      "          71       0.16      0.17      0.16       100\n",
      "          72       0.39      0.35      0.37       100\n",
      "          73       0.51      0.53      0.52       100\n",
      "          74       0.45      0.50      0.47       100\n",
      "          75       0.96      0.81      0.88       100\n",
      "          76       0.79      0.89      0.84       100\n",
      "          77       0.61      0.67      0.64       100\n",
      "          78       0.59      0.56      0.57       100\n",
      "          79       0.74      0.68      0.71       100\n",
      "          80       0.51      0.49      0.50       100\n",
      "          81       0.61      0.69      0.65       100\n",
      "          82       0.81      0.89      0.85       100\n",
      "          83       0.85      0.44      0.58       100\n",
      "          84       0.79      0.56      0.65       100\n",
      "          85       0.81      0.77      0.79       100\n",
      "          86       0.80      0.72      0.76       100\n",
      "          87       0.66      0.75      0.70       100\n",
      "          88       0.71      0.76      0.73       100\n",
      "          89       0.81      0.82      0.82       100\n",
      "          90       0.81      0.70      0.75       100\n",
      "          91       0.74      0.78      0.76       100\n",
      "          92       0.66      0.62      0.64       100\n",
      "          93       0.61      0.54      0.57       100\n",
      "          94       0.85      0.95      0.90       100\n",
      "          95       0.59      0.74      0.65       100\n",
      "          96       0.70      0.23      0.35       100\n",
      "          97       0.73      0.69      0.71       100\n",
      "          98       0.45      0.29      0.35       100\n",
      "          99       0.64      0.73      0.68       100\n",
      "\n",
      "    accuracy                           0.64     10000\n",
      "   macro avg       0.65      0.64      0.63     10000\n",
      "weighted avg       0.65      0.64      0.63     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arsen.abzhanov/.conda/envs/Copy_of_CV701_env_for_Temporal_Santosh/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arsen.abzhanov/.conda/envs/Copy_of_CV701_env_for_Temporal_Santosh/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arsen.abzhanov/.conda/envs/Copy_of_CV701_env_for_Temporal_Santosh/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'15': 0, '19': 1, '21': 2, '31': 3, '38': 4}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_to_child_class_from_0_to_5['11']\n",
    "# i will use argmax and pass here instead of 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'15': 0, '19': 1, '21': 2, '31': 3, '38': 4}\n"
     ]
    }
   ],
   "source": [
    "res=11\n",
    "parent_dict=parent_to_child_class_from_0_to_5[str(res)]\n",
    "print(parent_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'38'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(parent_to_child_class_from_0_to_5['11'].keys())[list(parent_to_child_class_from_0_to_5['11'].values()).index(4)]\n",
    "# i will use argmax and pass here instead of 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'38'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(parent_dict.keys())[list(parent_dict.values()).index(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Copy_of_CV701_env_for_Temporal_Santosh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
