{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import errno\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "if sys.version_info[0] == 2:\n",
    "    import cPickle as pickle\n",
    "else:\n",
    "    import pickle\n",
    "\n",
    "import torch.utils.data as data\n",
    "from torchvision.datasets.utils import download_url, check_integrity\n",
    "import torchvision.transforms as tt\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "\n",
    "class CIFAR10(data.Dataset):\n",
    "    \"\"\"`CIFAR10 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where directory\n",
    "            ``cifar-10-batches-py`` exists.\n",
    "        train (bool, optional): If True, creates dataset from training set, otherwise\n",
    "            creates from test set.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "    \"\"\"\n",
    "    base_folder = 'cifar-10-batches-py'\n",
    "    url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "    filename = \"cifar-10-python.tar.gz\"\n",
    "    tgz_md5 = 'c58f30108f718f92721af3b95e74349a'\n",
    "    train_list = [\n",
    "        ['data_batch_1', 'c99cafc152244af753f735de768cd75f'],\n",
    "        ['data_batch_2', 'd4bba439e000b95fd0a9bffe97cbabec'],\n",
    "        ['data_batch_3', '54ebc095f3ab1f0389bbae665268c751'],\n",
    "        ['data_batch_4', '634d18415352ddfa80567beed471001a'],\n",
    "        ['data_batch_5', '482c414d41f54cd18b22e5b47cb7c3cb'],\n",
    "    ]\n",
    "\n",
    "    test_list = [\n",
    "        ['test_batch', '40351d587109b95175f43aff81a1287e'],\n",
    "    ]\n",
    "\n",
    "    meta = {\n",
    "        \"filename\": \"batches.meta\",\n",
    "        \"key\": \"label_names\",\n",
    "        \"md5\": \"5ff9c542aee3614f3951f8cda6e48888\",\n",
    "    }\n",
    "\n",
    "\n",
    "    def __init__(self, root, train=True,\n",
    "                 transform=None, target_transform=None,\n",
    "                 download=False, coarse=False):\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train = train  # training set or test set\n",
    "        self.coarse = coarse\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_integrity():\n",
    "            raise RuntimeError('Dataset not found or corrupted.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "        # now load the picked numpy arrays\n",
    "        if self.train:\n",
    "            self.train_data = []\n",
    "            self.train_labels = []\n",
    "            self.train_coarse_labels = []\n",
    "            for fentry in self.train_list:\n",
    "                f = fentry[0]\n",
    "                file = os.path.join(self.root, self.base_folder, f)\n",
    "                fo = open(file, 'rb')\n",
    "                if sys.version_info[0] == 2:\n",
    "                    entry = pickle.load(fo)\n",
    "                else:\n",
    "                    entry = pickle.load(fo, encoding='latin1')\n",
    "                self.train_data.append(entry['data'])\n",
    "                if 'labels' in entry:\n",
    "                    self.train_labels += entry['labels']\n",
    "                else:\n",
    "                    self.train_labels += entry['fine_labels']\n",
    "                    if self.coarse:\n",
    "                        self.train_coarse_labels += entry['coarse_labels']\n",
    "                fo.close()\n",
    "\n",
    "            self.train_data = np.concatenate(self.train_data)\n",
    "            self.train_data = self.train_data.reshape((50000, 3, 32, 32))\n",
    "            self.train_data = self.train_data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "        else:\n",
    "            f = self.test_list[0][0]\n",
    "            file = os.path.join(self.root, self.base_folder, f)\n",
    "            fo = open(file, 'rb')\n",
    "            if sys.version_info[0] == 2:\n",
    "                entry = pickle.load(fo)\n",
    "            else:\n",
    "                entry = pickle.load(fo, encoding='latin1')\n",
    "            self.test_data = entry['data']\n",
    "            if 'labels' in entry:\n",
    "                self.test_labels = entry['labels']\n",
    "            else:\n",
    "                self.test_labels = entry['fine_labels']\n",
    "                if self.coarse:\n",
    "                    self.test_coarse_labels = entry['coarse_labels']\n",
    "            fo.close()\n",
    "            self.test_data = self.test_data.reshape((10000, 3, 32, 32))\n",
    "            self.test_data = self.test_data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        if self.train:\n",
    "            img, target = self.train_data[index], self.train_labels[index]\n",
    "            if self.coarse:\n",
    "                coarse_target = self.train_coarse_labels[index]\n",
    "        else:\n",
    "            img, target = self.test_data[index], self.test_labels[index]\n",
    "            if self.coarse:\n",
    "                coarse_target = self.test_coarse_labels[index]\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        if not self.coarse:\n",
    "            return img, target\n",
    "        else:\n",
    "            return img, target, coarse_target\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_data)\n",
    "        else:\n",
    "            return len(self.test_data)\n",
    "\n",
    "    def _check_integrity(self):\n",
    "        root = self.root\n",
    "        for fentry in (self.train_list + self.test_list):\n",
    "            filename, md5 = fentry[0], fentry[1]\n",
    "            fpath = os.path.join(root, self.base_folder, filename)\n",
    "            if not check_integrity(fpath, md5):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def download(self):\n",
    "        import tarfile\n",
    "\n",
    "        if self._check_integrity():\n",
    "            print('Files already downloaded and verified')\n",
    "            return\n",
    "\n",
    "        root = self.root\n",
    "        download_url(self.url, root, self.filename, self.tgz_md5)\n",
    "\n",
    "        # extract file\n",
    "        cwd = os.getcwd()\n",
    "        tar = tarfile.open(os.path.join(root, self.filename), \"r:gz\")\n",
    "        os.chdir(root)\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "        os.chdir(cwd)\n",
    "\n",
    "\n",
    "class CIFAR100(CIFAR10):\n",
    "    \"\"\"`CIFAR100 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
    "    This is a subclass of the `CIFAR10` Dataset.\n",
    "    \"\"\"\n",
    "    base_folder = 'cifar-100-python'\n",
    "    url = \"https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\"\n",
    "    filename = \"cifar-100-python.tar.gz\"\n",
    "    tgz_md5 = 'eb9058c3a382ffc7106e4002c42a8d85'\n",
    "    train_list = [\n",
    "        ['train', '16019d7e3df5f24257cddd939b257f8d'],\n",
    "    ]\n",
    "\n",
    "    test_list = [\n",
    "        ['test', 'f0ef6b0ae62326f3e7ffdfab6717acfc'],\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = tt.Compose([tt.RandomCrop(32, padding=4,padding_mode='reflect'), \n",
    "                         tt.RandomHorizontalFlip(), \n",
    "                         tt.ToTensor(), \n",
    "                         #tt.Normalize(mean,std,inplace=True) \n",
    "                         ]\n",
    "                         )\n",
    "transform_test = tt.Compose([tt.ToTensor(), \n",
    "                             #tt.Normalize(mean,std)\n",
    "                             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 400\n",
    "epochs = 120\n",
    "max_lr = 0.001\n",
    "grad_clip = 0.01\n",
    "weight_decay =0.001\n",
    "opt_func = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = CIFAR100('./data', train=True,\n",
    "                 transform=transform_train,\n",
    "                 download=True, coarse=True)\n",
    "test_data = CIFAR100('./data', train=False,\n",
    "                 transform=transform_test,\n",
    "                 download=True, coarse=True)\n",
    "\n",
    "train_length = train_data.__len__() # Length training dataset\n",
    "train_indices = np.arange(train_length)\n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                        train_data, \n",
    "                        batch_size=batch_size, \n",
    "                        num_workers=2,\n",
    "                        pin_memory=True,\n",
    "                    )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                        test_data, \n",
    "                        batch_size=batch_size*2,\n",
    "                        num_workers=2,\n",
    "                        pin_memory=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DeviceDataLoader(train_loader, device)\n",
    "testloader = DeviceDataLoader(test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet9(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (res1): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (res2): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv5): Sequential(\n",
       "    (0): Conv2d(512, 1028, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(1028, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (res3): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(1028, 1028, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1028, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(1028, 1028, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1028, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier_parent): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=1028, out_features=20, bias=True)\n",
       "  )\n",
       "  (classifier_child): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Flatten(start_dim=1, end_dim=-1)\n",
       "      (2): Linear(in_features=1028, out_features=20, bias=True)\n",
       "    )\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=20, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def __init__(self, fine):\n",
    "        super(ImageClassificationBase, self).__init__()\n",
    "        self.fine = fine\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, fine, coarse = batch \n",
    "        # if self.fine:\n",
    "        #     labels=fine\n",
    "        # else:\n",
    "        #     labels=coarse\n",
    "        out_parent, out_child = self(images)                  # Generate predictions\n",
    "        loss_parent = F.cross_entropy(out_parent, coarse)\n",
    "        loss_child = F.cross_entropy(out_child, fine) # Calculate loss\n",
    "        return loss_parent+1.5*loss_child\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, fine, coarse = batch \n",
    "        # if self.fine:\n",
    "        #     labels=fine\n",
    "        # else:\n",
    "        #     labels=coarse\n",
    "        #out = self(images)                    # Generate predictions\n",
    "        #loss = F.cross_entropy(out, labels)\n",
    "        out_parent, out_child = self(images)                  # Generate predictions\n",
    "        loss_parent = F.cross_entropy(out_parent, coarse)\n",
    "        loss_child = F.cross_entropy(out_child, fine)   # Calculate loss\n",
    "        acc_parent = accuracy(out_parent, coarse)\n",
    "        acc_child = accuracy(out_child, fine)           # Calculate accuracy\n",
    "        return {'val_loss_parent': loss_parent.detach(), 'val_acc_parent': acc_parent, 'val_loss_child':loss_child.detach(), 'val_acc_child': acc_child}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses_parent = [x['val_loss_parent'] for x in outputs]\n",
    "        epoch_loss_parent = torch.stack(batch_losses_parent).mean()   # Combine losses\n",
    "        #\n",
    "        batch_accs_parent = [x['val_acc_parent'] for x in outputs]\n",
    "        epoch_acc_parent = torch.stack(batch_accs_parent).mean()  # Combine accuracies\n",
    "        ###     \n",
    "        batch_losses_child = [x['val_loss_child'] for x in outputs]\n",
    "        epoch_loss_child = torch.stack(batch_losses_child).mean()   # Combine losses\n",
    "        #\n",
    "        batch_accs_child = [x['val_acc_child'] for x in outputs]\n",
    "        epoch_acc_child = torch.stack(batch_accs_child).mean() \n",
    "        return {'val_loss_parent': epoch_loss_parent.item(), 'val_acc_parent': epoch_acc_parent.item(), 'val_loss_child':epoch_loss_child.item(), \n",
    "                'val_acc_child':epoch_acc_child.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss_parent: {:.4f}, val_acc_parent: {:.4f}, val_loss_child: {:.4f}, val_acc_child: {:.4f}\".format(\n",
    "            epoch, result['lrs'][-1], result['train_loss'], result['val_loss_parent'], result['val_acc_parent'], result['val_loss_child'], result['val_acc_child']))\n",
    "        \n",
    "def conv_block(in_channels, out_channels, pool=False):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
    "              nn.BatchNorm2d(out_channels), \n",
    "              nn.ReLU(inplace=True)]\n",
    "    if pool: layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class ResNet9(ImageClassificationBase):\n",
    "    def __init__(self, in_channels, num_classes, fine):\n",
    "        super().__init__(fine)\n",
    "        \n",
    "        self.conv1 = conv_block(in_channels, 64)\n",
    "        self.conv2 = conv_block(64, 128, pool=True) \n",
    "        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128)) \n",
    "        \n",
    "        self.conv3 = conv_block(128, 256, pool=True)\n",
    "        self.conv4 = conv_block(256, 512, pool=True) \n",
    "        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512)) \n",
    "        self.conv5 = conv_block(512, 1028, pool=True) \n",
    "        self.res3 = nn.Sequential(conv_block(1028, 1028), conv_block(1028, 1028))\n",
    "\n",
    "        #-------------------\n",
    "        self.classifier_parent = nn.Sequential(nn.MaxPool2d(2), # 1028 x 1 x 1\n",
    "                                        nn.Flatten(), # 1028 \n",
    "                                        nn.Linear(1028, 20))\n",
    "                                 # 1028 -> 100 \n",
    "\n",
    "        self.classifier_child = nn.Sequential(self.classifier_parent,\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(20, num_classes)\n",
    "                                ) # 1028 -> 100 \n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.conv1(xb)\n",
    "        out = self.conv2(out)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.conv5(out)\n",
    "        out = self.res3(out) + out\n",
    "        parent_out=self.classifier_parent(out)\n",
    "        child_out = self.classifier_child(out)\n",
    "        return parent_out,child_out\n",
    "\n",
    "model100 = to_device(ResNet9(3, 100, True), device)\n",
    "model100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in test_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def fit_one_cycle(epochs, max_lr, model, train_loader, test_loader, \n",
    "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
    "    torch.cuda.empty_cache()\n",
    "    history = []\n",
    "    \n",
    "    # Set up cutom optimizer with weight decay\n",
    "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
    "    # Set up one-cycle learning rate scheduler\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n",
    "                                                steps_per_epoch=len(train_loader))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        lrs = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            if grad_clip: \n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Record & update learning rate\n",
    "            lrs.append(get_lr(optimizer))\n",
    "            sched.step()\n",
    "        \n",
    "        # Validation phase\n",
    "        result = evaluate(model, test_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        result['lrs'] = lrs\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'val_loss_parent': 2.9959964752197266,\n",
       "  'val_acc_parent': 0.05019231140613556,\n",
       "  'val_loss_child': 4.614645004272461,\n",
       "  'val_acc_child': 0.007980769500136375}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial evaluation\n",
    "history = [evaluate(model100, testloader)]\n",
    "history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              ReLU-3           [-1, 64, 32, 32]               0\n",
      "            Conv2d-4          [-1, 128, 32, 32]          73,856\n",
      "       BatchNorm2d-5          [-1, 128, 32, 32]             256\n",
      "              ReLU-6          [-1, 128, 32, 32]               0\n",
      "         MaxPool2d-7          [-1, 128, 16, 16]               0\n",
      "            Conv2d-8          [-1, 128, 16, 16]         147,584\n",
      "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
      "             ReLU-10          [-1, 128, 16, 16]               0\n",
      "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
      "             ReLU-13          [-1, 128, 16, 16]               0\n",
      "           Conv2d-14          [-1, 256, 16, 16]         295,168\n",
      "      BatchNorm2d-15          [-1, 256, 16, 16]             512\n",
      "             ReLU-16          [-1, 256, 16, 16]               0\n",
      "        MaxPool2d-17            [-1, 256, 8, 8]               0\n",
      "           Conv2d-18            [-1, 512, 8, 8]       1,180,160\n",
      "      BatchNorm2d-19            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-20            [-1, 512, 8, 8]               0\n",
      "        MaxPool2d-21            [-1, 512, 4, 4]               0\n",
      "           Conv2d-22            [-1, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-23            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-24            [-1, 512, 4, 4]               0\n",
      "           Conv2d-25            [-1, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-27            [-1, 512, 4, 4]               0\n",
      "           Conv2d-28           [-1, 1028, 4, 4]       4,738,052\n",
      "      BatchNorm2d-29           [-1, 1028, 4, 4]           2,056\n",
      "             ReLU-30           [-1, 1028, 4, 4]               0\n",
      "        MaxPool2d-31           [-1, 1028, 2, 2]               0\n",
      "           Conv2d-32           [-1, 1028, 2, 2]       9,512,084\n",
      "      BatchNorm2d-33           [-1, 1028, 2, 2]           2,056\n",
      "             ReLU-34           [-1, 1028, 2, 2]               0\n",
      "           Conv2d-35           [-1, 1028, 2, 2]       9,512,084\n",
      "      BatchNorm2d-36           [-1, 1028, 2, 2]           2,056\n",
      "             ReLU-37           [-1, 1028, 2, 2]               0\n",
      "        MaxPool2d-38           [-1, 1028, 1, 1]               0\n",
      "        MaxPool2d-39           [-1, 1028, 1, 1]               0\n",
      "          Flatten-40                 [-1, 1028]               0\n",
      "          Flatten-41                 [-1, 1028]               0\n",
      "           Linear-42                   [-1, 20]          20,580\n",
      "           Linear-43                   [-1, 20]          20,580\n",
      "        MaxPool2d-44           [-1, 1028, 1, 1]               0\n",
      "        MaxPool2d-45           [-1, 1028, 1, 1]               0\n",
      "          Flatten-46                 [-1, 1028]               0\n",
      "          Flatten-47                 [-1, 1028]               0\n",
      "           Linear-48                   [-1, 20]          20,580\n",
      "           Linear-49                   [-1, 20]          20,580\n",
      "             ReLU-50                   [-1, 20]               0\n",
      "           Linear-51                  [-1, 100]           2,100\n",
      "================================================================\n",
      "Total params: 30,423,048\n",
      "Trainable params: 30,423,048\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 9.72\n",
      "Params size (MB): 116.05\n",
      "Estimated Total Size (MB): 125.79\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "print(summary(model100,(3, 32, 32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], last_lr: 0.00007, train_loss: 9.2023, val_loss_parent: 1.9886, val_acc_parent: 0.3788, val_loss_child: 4.5966, val_acc_child: 0.0081\n",
      "Epoch [1], last_lr: 0.00015, train_loss: 8.7919, val_loss_parent: 1.9202, val_acc_parent: 0.4112, val_loss_child: 4.5332, val_acc_child: 0.0213\n",
      "Epoch [2], last_lr: 0.00028, train_loss: 8.4333, val_loss_parent: 1.8691, val_acc_parent: 0.4133, val_loss_child: 4.2591, val_acc_child: 0.0644\n",
      "Epoch [3], last_lr: 0.00044, train_loss: 7.6067, val_loss_parent: 2.0189, val_acc_parent: 0.3985, val_loss_child: 3.6549, val_acc_child: 0.1531\n",
      "Epoch [4], last_lr: 0.00060, train_loss: 6.3395, val_loss_parent: 2.3233, val_acc_parent: 0.4078, val_loss_child: 3.2704, val_acc_child: 0.2287\n",
      "Epoch [5], last_lr: 0.00076, train_loss: 5.5387, val_loss_parent: 2.1886, val_acc_parent: 0.4289, val_loss_child: 2.9241, val_acc_child: 0.2766\n",
      "Epoch [6], last_lr: 0.00089, train_loss: 5.0016, val_loss_parent: 1.8432, val_acc_parent: 0.4979, val_loss_child: 2.7381, val_acc_child: 0.3177\n",
      "Epoch [7], last_lr: 0.00097, train_loss: 4.5660, val_loss_parent: 1.8916, val_acc_parent: 0.5028, val_loss_child: 2.7066, val_acc_child: 0.3280\n",
      "Epoch [8], last_lr: 0.00100, train_loss: 4.1952, val_loss_parent: 1.8034, val_acc_parent: 0.5361, val_loss_child: 2.5190, val_acc_child: 0.3664\n",
      "Epoch [9], last_lr: 0.00099, train_loss: 3.8768, val_loss_parent: 1.7833, val_acc_parent: 0.5426, val_loss_child: 2.4095, val_acc_child: 0.3860\n",
      "Epoch [10], last_lr: 0.00098, train_loss: 3.5969, val_loss_parent: 1.5243, val_acc_parent: 0.5882, val_loss_child: 2.2236, val_acc_child: 0.4263\n",
      "Epoch [11], last_lr: 0.00095, train_loss: 3.3256, val_loss_parent: 1.3429, val_acc_parent: 0.6316, val_loss_child: 2.0939, val_acc_child: 0.4502\n",
      "Epoch [12], last_lr: 0.00091, train_loss: 3.0970, val_loss_parent: 1.3993, val_acc_parent: 0.6277, val_loss_child: 2.0998, val_acc_child: 0.4582\n",
      "Epoch [13], last_lr: 0.00087, train_loss: 2.8717, val_loss_parent: 1.3584, val_acc_parent: 0.6488, val_loss_child: 2.0455, val_acc_child: 0.4711\n",
      "Epoch [14], last_lr: 0.00081, train_loss: 2.6858, val_loss_parent: 1.1102, val_acc_parent: 0.6907, val_loss_child: 1.7625, val_acc_child: 0.5309\n",
      "Epoch [15], last_lr: 0.00075, train_loss: 2.4884, val_loss_parent: 1.7900, val_acc_parent: 0.5934, val_loss_child: 2.3867, val_acc_child: 0.4346\n",
      "Epoch [16], last_lr: 0.00068, train_loss: 2.2776, val_loss_parent: 1.2313, val_acc_parent: 0.6838, val_loss_child: 1.8884, val_acc_child: 0.5242\n",
      "Epoch [17], last_lr: 0.00061, train_loss: 2.1057, val_loss_parent: 1.3291, val_acc_parent: 0.6798, val_loss_child: 1.9349, val_acc_child: 0.5268\n",
      "Epoch [18], last_lr: 0.00054, train_loss: 1.8967, val_loss_parent: 1.0633, val_acc_parent: 0.7279, val_loss_child: 1.6106, val_acc_child: 0.5811\n",
      "Epoch [19], last_lr: 0.00046, train_loss: 1.7085, val_loss_parent: 1.0654, val_acc_parent: 0.7362, val_loss_child: 1.6009, val_acc_child: 0.5934\n",
      "Epoch [20], last_lr: 0.00039, train_loss: 1.4953, val_loss_parent: 1.0617, val_acc_parent: 0.7490, val_loss_child: 1.5104, val_acc_child: 0.6103\n",
      "Epoch [21], last_lr: 0.00032, train_loss: 1.2572, val_loss_parent: 1.0671, val_acc_parent: 0.7566, val_loss_child: 1.5453, val_acc_child: 0.6144\n",
      "Epoch [22], last_lr: 0.00025, train_loss: 1.0682, val_loss_parent: 1.0546, val_acc_parent: 0.7641, val_loss_child: 1.5178, val_acc_child: 0.6282\n",
      "Epoch [23], last_lr: 0.00019, train_loss: 0.8840, val_loss_parent: 0.9577, val_acc_parent: 0.7833, val_loss_child: 1.3523, val_acc_child: 0.6616\n",
      "Epoch [24], last_lr: 0.00013, train_loss: 0.6891, val_loss_parent: 0.9457, val_acc_parent: 0.7926, val_loss_child: 1.3081, val_acc_child: 0.6787\n",
      "Epoch [25], last_lr: 0.00009, train_loss: 0.5543, val_loss_parent: 0.9254, val_acc_parent: 0.8017, val_loss_child: 1.3106, val_acc_child: 0.6809\n",
      "Epoch [26], last_lr: 0.00005, train_loss: 0.4360, val_loss_parent: 0.9010, val_acc_parent: 0.8055, val_loss_child: 1.2819, val_acc_child: 0.6923\n",
      "Epoch [27], last_lr: 0.00002, train_loss: 0.3543, val_loss_parent: 0.9026, val_acc_parent: 0.8087, val_loss_child: 1.2583, val_acc_child: 0.7015\n",
      "Epoch [28], last_lr: 0.00001, train_loss: 0.3135, val_loss_parent: 0.9008, val_acc_parent: 0.8104, val_loss_child: 1.2497, val_acc_child: 0.7037\n",
      "Epoch [29], last_lr: 0.00000, train_loss: 0.2955, val_loss_parent: 0.9029, val_acc_parent: 0.8106, val_loss_child: 1.2523, val_acc_child: 0.7045\n"
     ]
    }
   ],
   "source": [
    "# Fitting the first 1/4 epochs\n",
    "current_time=time.time()\n",
    "history += fit_one_cycle(int(epochs/4), max_lr, model100, trainloader, testloader, \n",
    "                             grad_clip=grad_clip, \n",
    "                             weight_decay=weight_decay, \n",
    "                             opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model to h5 file\n",
    "torch.save(model100.state_dict(), 'group20To100_parent_and_child_pretrained_model_delete.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
