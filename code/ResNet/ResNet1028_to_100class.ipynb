{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.utils import download_url, check_integrity\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as tt\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import *\n",
    "from torchsummary import summary\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import errno\n",
    "import sys\n",
    "if sys.version_info[0] == 2:\n",
    "    import cPickle as pickle\n",
    "else:\n",
    "    import pickle\n",
    "\n",
    "import torch.utils.data as data\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "class CIFAR10(data.Dataset):\n",
    "    \"\"\"`CIFAR10 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where directory\n",
    "            ``cifar-10-batches-py`` exists.\n",
    "        train (bool, optional): If True, creates dataset from training set, otherwise\n",
    "            creates from test set.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "    \"\"\"\n",
    "    base_folder = 'cifar-10-batches-py'\n",
    "    url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "    filename = \"cifar-10-python.tar.gz\"\n",
    "    tgz_md5 = 'c58f30108f718f92721af3b95e74349a'\n",
    "    train_list = [\n",
    "        ['data_batch_1', 'c99cafc152244af753f735de768cd75f'],\n",
    "        ['data_batch_2', 'd4bba439e000b95fd0a9bffe97cbabec'],\n",
    "        ['data_batch_3', '54ebc095f3ab1f0389bbae665268c751'],\n",
    "        ['data_batch_4', '634d18415352ddfa80567beed471001a'],\n",
    "        ['data_batch_5', '482c414d41f54cd18b22e5b47cb7c3cb'],\n",
    "    ]\n",
    "\n",
    "    test_list = [\n",
    "        ['test_batch', '40351d587109b95175f43aff81a1287e'],\n",
    "    ]\n",
    "\n",
    "    meta = {\n",
    "        \"filename\": \"batches.meta\",\n",
    "        \"key\": \"label_names\",\n",
    "        \"md5\": \"5ff9c542aee3614f3951f8cda6e48888\",\n",
    "    }\n",
    "\n",
    "\n",
    "    def __init__(self, root, train=True,\n",
    "                 transform=None, target_transform=None,\n",
    "                 download=False, coarse=False, coarseNumber=None):\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train = train  # training set or test set\n",
    "        self.coarse = coarse\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_integrity():\n",
    "            raise RuntimeError('Dataset not found or corrupted.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "        # now load the picked numpy arrays\n",
    "        if self.train:\n",
    "            self.train_data = []\n",
    "            self.train_labels = []\n",
    "            self.train_coarse_labels = []\n",
    "            for fentry in self.train_list:\n",
    "                f = fentry[0]\n",
    "                file = os.path.join(self.root, self.base_folder, f)\n",
    "                fo = open(file, 'rb')\n",
    "                if sys.version_info[0] == 2:\n",
    "                    entry = pickle.load(fo)\n",
    "                else:\n",
    "                    entry = pickle.load(fo, encoding='latin1')\n",
    "                self.train_data.append(entry['data'])\n",
    "                if 'labels' in entry:\n",
    "                    self.train_labels += entry['labels']\n",
    "                else:\n",
    "                    self.train_labels += entry['fine_labels']\n",
    "                    if self.coarse:\n",
    "                        self.train_coarse_labels += entry['coarse_labels']\n",
    "                fo.close()\n",
    "\n",
    "            self.train_data = np.concatenate(self.train_data)\n",
    "            self.train_data = self.train_data.reshape((len(self.train_data), 3, 32, 32))\n",
    "            self.train_data = self.train_data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "        else:\n",
    "            f = self.test_list[0][0]\n",
    "            file = os.path.join(self.root, self.base_folder, f)\n",
    "            fo = open(file, 'rb')\n",
    "            if sys.version_info[0] == 2:\n",
    "                entry = pickle.load(fo)\n",
    "            else:\n",
    "                entry = pickle.load(fo, encoding='latin1')\n",
    "            self.test_data = entry['data']\n",
    "\n",
    "            if 'labels' in entry:\n",
    "                self.test_labels = entry['labels']\n",
    "            else:\n",
    "                self.test_labels = entry['fine_labels']\n",
    "                if self.coarse:\n",
    "                    self.test_coarse_labels = entry['coarse_labels']\n",
    "            fo.close()\n",
    "            self.test_data = self.test_data.reshape((len(self.test_data), 3, 32, 32))\n",
    "            self.test_data = self.test_data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        if self.train:\n",
    "            img, target = self.train_data[index], self.train_labels[index]\n",
    "            if self.coarse:\n",
    "                coarse_target = self.train_coarse_labels[index]\n",
    "        else:\n",
    "            img, target = self.test_data[index], self.test_labels[index]\n",
    "            if self.coarse:\n",
    "                coarse_target = self.test_coarse_labels[index]\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        if not self.coarse:\n",
    "            return img, target\n",
    "        else:\n",
    "            return img, target, coarse_target\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_data)\n",
    "        else:\n",
    "            return len(self.test_data)\n",
    "\n",
    "    def _check_integrity(self):\n",
    "        root = self.root\n",
    "        for fentry in (self.train_list + self.test_list):\n",
    "            filename, md5 = fentry[0], fentry[1]\n",
    "            fpath = os.path.join(root, self.base_folder, filename)\n",
    "            if not check_integrity(fpath, md5):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def download(self):\n",
    "        import tarfile\n",
    "\n",
    "        if self._check_integrity():\n",
    "            print('Files already downloaded and verified')\n",
    "            return\n",
    "\n",
    "        root = self.root\n",
    "        download_url(self.url, root, self.filename, self.tgz_md5)\n",
    "\n",
    "        # extract file\n",
    "        cwd = os.getcwd()\n",
    "        tar = tarfile.open(os.path.join(root, self.filename), \"r:gz\")\n",
    "        os.chdir(root)\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "        os.chdir(cwd)\n",
    "\n",
    "\n",
    "class CIFAR100(CIFAR10):\n",
    "    \"\"\"`CIFAR100 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
    "    This is a subclass of the `CIFAR10` Dataset.\n",
    "    \"\"\"\n",
    "    base_folder = 'cifar-100-python'\n",
    "    url = \"https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\"\n",
    "    filename = \"cifar-100-python.tar.gz\"\n",
    "    tgz_md5 = 'eb9058c3a382ffc7106e4002c42a8d85'\n",
    "    train_list = [\n",
    "        ['train', '16019d7e3df5f24257cddd939b257f8d'],\n",
    "    ]\n",
    "\n",
    "    test_list = [\n",
    "        ['test', 'f0ef6b0ae62326f3e7ffdfab6717acfc'],\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 400\n",
    "epochs = 120\n",
    "max_lr = 0.001\n",
    "grad_clip = 0.01\n",
    "weight_decay =0.001\n",
    "opt_func = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = torchvision.datasets.CIFAR100('./', train=True, download=True)\n",
    "\n",
    "# # Stick all the images together to form a 1600000 X 32 X 3 array\n",
    "# x = np.concatenate([np.asarray(train_data[i][0]) for i in range(len(train_data))])\n",
    "\n",
    "# # calculate the mean and std along the (0, 1) axes\n",
    "# mean = np.mean(x, axis=(0, 1))/255\n",
    "# std = np.std(x, axis=(0, 1))/255\n",
    "# # the the mean and std\n",
    "# mean=mean.tolist()\n",
    "# std=std.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = tt.Compose([tt.RandomCrop(32, padding=4,padding_mode='reflect'), \n",
    "                         tt.RandomHorizontalFlip(), \n",
    "                         tt.ToTensor(), \n",
    "                         #tt.Normalize(mean,std,inplace=True)\n",
    "                         ]\n",
    "                         )\n",
    "transform_test = tt.Compose([tt.ToTensor(), \n",
    "                             #tt.Normalize(mean,std)\n",
    "                             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = CIFAR100('./data', train=True,\n",
    "                 transform=transform_train,\n",
    "                 download=True, coarse=True, coarseNumber=2)\n",
    "test_data = CIFAR100('./data', train=False,\n",
    "                 transform=transform_test,\n",
    "                 download=True, coarse=True, coarseNumber=2)\n",
    "\n",
    "train_length = train_data.__len__() # Length training dataset\n",
    "train_indices = np.arange(train_length)\n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                        train_data, \n",
    "                        batch_size=batch_size, \n",
    "                        num_workers=2,\n",
    "                        pin_memory=True,\n",
    "                    )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                        test_data, \n",
    "                        batch_size=batch_size*2,\n",
    "                        num_workers=2,\n",
    "                        pin_memory=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset = torchvision.datasets.CIFAR100(\"./\",\n",
    "#                                          train=True,\n",
    "#                                          download=True,\n",
    "#                                          transform=transform_train)\n",
    "# trainloader = torch.utils.data.DataLoader(\n",
    "#     trainset, batch_size, shuffle=True, num_workers=2,pin_memory=True)\n",
    "\n",
    "# testset = torchvision.datasets.CIFAR100(\"./\",\n",
    "#                                         train=False,\n",
    "#                                         download=True,\n",
    "#                                         transform=transform_test)\n",
    "# testloader = torch.utils.data.DataLoader(\n",
    "#     testset, batch_size*2,pin_memory=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()\n",
    "trainloader = DeviceDataLoader(train_loader, device)\n",
    "testloader = DeviceDataLoader(test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet9(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (res1): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (res2): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv5): Sequential(\n",
       "    (0): Conv2d(512, 1028, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(1028, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (res3): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(1028, 1028, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1028, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(1028, 1028, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1028, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=1028, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, labels, _ = batch\n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels, _ = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))\n",
    "        \n",
    "def conv_block(in_channels, out_channels, pool=False):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
    "              nn.BatchNorm2d(out_channels), \n",
    "              nn.ReLU(inplace=True)]\n",
    "    if pool: layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class ResNet9(ImageClassificationBase):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = conv_block(in_channels, 64)\n",
    "        self.conv2 = conv_block(64, 128, pool=True) \n",
    "        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128)) \n",
    "        \n",
    "        self.conv3 = conv_block(128, 256, pool=True)\n",
    "        self.conv4 = conv_block(256, 512, pool=True) \n",
    "        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512)) \n",
    "        self.conv5 = conv_block(512, 1028, pool=True) \n",
    "        self.res3 = nn.Sequential(conv_block(1028, 1028), conv_block(1028, 1028))  \n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.MaxPool2d(2), # 1028 x 1 x 1\n",
    "                                        nn.Flatten(), # 1028 \n",
    "                                        nn.Linear(1028, num_classes)) # 1028 -> 100\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.conv1(xb)\n",
    "        out = self.conv2(out)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.conv5(out)\n",
    "        out = self.res3(out) + out\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "model = to_device(ResNet9(3, 100), device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in test_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def fit_one_cycle(epochs, max_lr, model, train_loader, test_loader, \n",
    "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
    "    torch.cuda.empty_cache()\n",
    "    history = []\n",
    "    \n",
    "    # Set up cutom optimizer with weight decay\n",
    "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
    "    # Set up one-cycle learning rate scheduler\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n",
    "                                                steps_per_epoch=len(train_loader))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        lrs = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            if grad_clip: \n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Record & update learning rate\n",
    "            lrs.append(get_lr(optimizer))\n",
    "            sched.step()\n",
    "        \n",
    "        # Validation phase\n",
    "        result = evaluate(model, test_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        result['lrs'] = lrs\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 4.60545015335083, 'val_acc': 0.009903847239911556}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial evaluation\n",
    "history = [evaluate(model, testloader)]\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], last_lr: 0.00007, train_loss: 3.6283, val_loss: 3.1294, val_acc: 0.2367\n",
      "Epoch [1], last_lr: 0.00015, train_loss: 2.9224, val_loss: 2.8756, val_acc: 0.2837\n",
      "Epoch [2], last_lr: 0.00028, train_loss: 2.5919, val_loss: 2.4817, val_acc: 0.3571\n",
      "Epoch [3], last_lr: 0.00044, train_loss: 2.3264, val_loss: 2.4682, val_acc: 0.3585\n",
      "Epoch [4], last_lr: 0.00060, train_loss: 2.1155, val_loss: 2.5546, val_acc: 0.3681\n",
      "Epoch [5], last_lr: 0.00076, train_loss: 1.9220, val_loss: 2.4240, val_acc: 0.4053\n",
      "Epoch [6], last_lr: 0.00089, train_loss: 1.7781, val_loss: 2.4332, val_acc: 0.4009\n",
      "Epoch [7], last_lr: 0.00097, train_loss: 1.6203, val_loss: 2.1855, val_acc: 0.4386\n",
      "Epoch [8], last_lr: 0.00100, train_loss: 1.4919, val_loss: 2.0961, val_acc: 0.4655\n",
      "Epoch [9], last_lr: 0.00099, train_loss: 1.3713, val_loss: 2.0059, val_acc: 0.4817\n",
      "Epoch [10], last_lr: 0.00098, train_loss: 1.2722, val_loss: 1.9088, val_acc: 0.5008\n",
      "Epoch [11], last_lr: 0.00095, train_loss: 1.1799, val_loss: 1.9642, val_acc: 0.4955\n",
      "Epoch [12], last_lr: 0.00091, train_loss: 1.0851, val_loss: 1.7954, val_acc: 0.5281\n",
      "Epoch [13], last_lr: 0.00087, train_loss: 1.0154, val_loss: 1.9551, val_acc: 0.5021\n",
      "Epoch [14], last_lr: 0.00081, train_loss: 0.9469, val_loss: 1.6066, val_acc: 0.5627\n",
      "Epoch [15], last_lr: 0.00075, train_loss: 0.8691, val_loss: 1.6851, val_acc: 0.5477\n",
      "Epoch [16], last_lr: 0.00068, train_loss: 0.7981, val_loss: 1.6428, val_acc: 0.5608\n",
      "Epoch [17], last_lr: 0.00061, train_loss: 0.7248, val_loss: 1.5685, val_acc: 0.5800\n",
      "Epoch [18], last_lr: 0.00054, train_loss: 0.6619, val_loss: 1.4685, val_acc: 0.5984\n",
      "Epoch [19], last_lr: 0.00046, train_loss: 0.5799, val_loss: 1.5372, val_acc: 0.5924\n",
      "Epoch [20], last_lr: 0.00039, train_loss: 0.4950, val_loss: 1.4049, val_acc: 0.6408\n",
      "Epoch [21], last_lr: 0.00032, train_loss: 0.4090, val_loss: 1.2766, val_acc: 0.6693\n",
      "Epoch [22], last_lr: 0.00025, train_loss: 0.3380, val_loss: 1.2729, val_acc: 0.6651\n",
      "Epoch [23], last_lr: 0.00019, train_loss: 0.2513, val_loss: 1.1497, val_acc: 0.6998\n",
      "Epoch [24], last_lr: 0.00013, train_loss: 0.1831, val_loss: 1.1145, val_acc: 0.7083\n",
      "Epoch [25], last_lr: 0.00009, train_loss: 0.1213, val_loss: 1.0674, val_acc: 0.7251\n",
      "Epoch [26], last_lr: 0.00005, train_loss: 0.0846, val_loss: 1.0318, val_acc: 0.7339\n",
      "Epoch [27], last_lr: 0.00002, train_loss: 0.0635, val_loss: 1.0190, val_acc: 0.7369\n",
      "Epoch [28], last_lr: 0.00001, train_loss: 0.0482, val_loss: 1.0138, val_acc: 0.7402\n",
      "Epoch [29], last_lr: 0.00000, train_loss: 0.0444, val_loss: 1.0136, val_acc: 0.7404\n"
     ]
    }
   ],
   "source": [
    "# Fitting the first 1/4 epochs\n",
    "current_time=time.time()\n",
    "history += fit_one_cycle(int(epochs/4), max_lr, model, trainloader, testloader, \n",
    "                             grad_clip=grad_clip, \n",
    "                             weight_decay=weight_decay, \n",
    "                             opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the second 1/4 epochs\n",
    "# history += fit_one_cycle(int(epochs/4), max_lr/10, model, trainloader, testloader, \n",
    "#                              grad_clip=grad_clip, \n",
    "#                              weight_decay=weight_decay, \n",
    "#                              opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history += fit_one_cycle(int(epochs/8), max_lr/100, model, trainloader, testloader, \n",
    "#                              grad_clip=grad_clip, \n",
    "#                              weight_decay=weight_decay, \n",
    "#                              opt_func=opt_func)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model to h5 file\n",
    "torch.save(model.state_dict(), 'group_1028_to_100_pretrained_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[87  0  0 ...  0  1  0]\n",
      " [ 0 86  0 ...  0  0  0]\n",
      " [ 1  0 59 ...  0  4  0]\n",
      " ...\n",
      " [ 0  0  0 ... 79  0  0]\n",
      " [ 0  0  4 ...  0 55  1]\n",
      " [ 0  1  1 ...  0  0 79]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89       100\n",
      "           1       0.79      0.86      0.82       100\n",
      "           2       0.63      0.59      0.61       100\n",
      "           3       0.61      0.58      0.59       100\n",
      "           4       0.55      0.63      0.59       100\n",
      "           5       0.80      0.73      0.76       100\n",
      "           6       0.78      0.83      0.81       100\n",
      "           7       0.76      0.74      0.75       100\n",
      "           8       0.92      0.85      0.89       100\n",
      "           9       0.83      0.86      0.85       100\n",
      "          10       0.63      0.57      0.60       100\n",
      "          11       0.51      0.49      0.50       100\n",
      "          12       0.79      0.84      0.81       100\n",
      "          13       0.69      0.66      0.68       100\n",
      "          14       0.75      0.65      0.70       100\n",
      "          15       0.72      0.81      0.76       100\n",
      "          16       0.72      0.78      0.75       100\n",
      "          17       0.86      0.82      0.84       100\n",
      "          18       0.70      0.66      0.68       100\n",
      "          19       0.70      0.64      0.67       100\n",
      "          20       0.86      0.87      0.87       100\n",
      "          21       0.82      0.89      0.86       100\n",
      "          22       0.74      0.72      0.73       100\n",
      "          23       0.80      0.83      0.81       100\n",
      "          24       0.88      0.83      0.86       100\n",
      "          25       0.71      0.64      0.67       100\n",
      "          26       0.75      0.69      0.72       100\n",
      "          27       0.72      0.58      0.64       100\n",
      "          28       0.79      0.80      0.80       100\n",
      "          29       0.79      0.74      0.76       100\n",
      "          30       0.75      0.61      0.67       100\n",
      "          31       0.80      0.70      0.74       100\n",
      "          32       0.72      0.66      0.69       100\n",
      "          33       0.74      0.59      0.66       100\n",
      "          34       0.82      0.79      0.81       100\n",
      "          35       0.51      0.57      0.54       100\n",
      "          36       0.85      0.82      0.84       100\n",
      "          37       0.75      0.78      0.76       100\n",
      "          38       0.63      0.69      0.66       100\n",
      "          39       0.90      0.86      0.88       100\n",
      "          40       0.69      0.73      0.71       100\n",
      "          41       0.88      0.89      0.89       100\n",
      "          42       0.73      0.76      0.75       100\n",
      "          43       0.85      0.82      0.84       100\n",
      "          44       0.47      0.61      0.53       100\n",
      "          45       0.61      0.68      0.64       100\n",
      "          46       0.55      0.51      0.53       100\n",
      "          47       0.65      0.69      0.67       100\n",
      "          48       0.85      0.91      0.88       100\n",
      "          49       0.77      0.86      0.82       100\n",
      "          50       0.52      0.57      0.54       100\n",
      "          51       0.73      0.73      0.73       100\n",
      "          52       0.62      0.63      0.62       100\n",
      "          53       0.86      0.89      0.87       100\n",
      "          54       0.76      0.90      0.83       100\n",
      "          55       0.47      0.49      0.48       100\n",
      "          56       0.93      0.90      0.91       100\n",
      "          57       0.76      0.78      0.77       100\n",
      "          58       0.90      0.82      0.86       100\n",
      "          59       0.73      0.70      0.71       100\n",
      "          60       0.85      0.82      0.83       100\n",
      "          61       0.76      0.76      0.76       100\n",
      "          62       0.68      0.80      0.74       100\n",
      "          63       0.75      0.74      0.74       100\n",
      "          64       0.59      0.54      0.56       100\n",
      "          65       0.66      0.65      0.65       100\n",
      "          66       0.81      0.79      0.80       100\n",
      "          67       0.68      0.69      0.69       100\n",
      "          68       0.86      0.95      0.90       100\n",
      "          69       0.82      0.80      0.81       100\n",
      "          70       0.81      0.76      0.78       100\n",
      "          71       0.82      0.80      0.81       100\n",
      "          72       0.46      0.52      0.49       100\n",
      "          73       0.58      0.62      0.60       100\n",
      "          74       0.59      0.58      0.58       100\n",
      "          75       0.89      0.91      0.90       100\n",
      "          76       0.85      0.88      0.86       100\n",
      "          77       0.74      0.67      0.71       100\n",
      "          78       0.67      0.64      0.66       100\n",
      "          79       0.71      0.86      0.78       100\n",
      "          80       0.64      0.61      0.63       100\n",
      "          81       0.73      0.75      0.74       100\n",
      "          82       0.95      0.88      0.91       100\n",
      "          83       0.70      0.69      0.69       100\n",
      "          84       0.70      0.72      0.71       100\n",
      "          85       0.87      0.85      0.86       100\n",
      "          86       0.82      0.75      0.79       100\n",
      "          87       0.78      0.81      0.79       100\n",
      "          88       0.83      0.75      0.79       100\n",
      "          89       0.85      0.88      0.86       100\n",
      "          90       0.76      0.87      0.81       100\n",
      "          91       0.82      0.84      0.83       100\n",
      "          92       0.68      0.65      0.67       100\n",
      "          93       0.66      0.67      0.67       100\n",
      "          94       0.91      0.88      0.89       100\n",
      "          95       0.76      0.72      0.74       100\n",
      "          96       0.67      0.68      0.67       100\n",
      "          97       0.80      0.79      0.79       100\n",
      "          98       0.56      0.55      0.56       100\n",
      "          99       0.72      0.79      0.75       100\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.74      0.74      0.74     10000\n",
      "weighted avg       0.74      0.74      0.74     10000\n",
      "\n",
      "F1 score: 0.739025\n",
      "Recall score: 0.739000\n",
      "Accuracy score: 0.739000\n"
     ]
    }
   ],
   "source": [
    "# Generate testing accuracy, predicted label, confusion matrix, and table for classification report\n",
    "def test_label_predictions(model, device, test_loader):\n",
    "    model.eval()\n",
    "    actuals = []\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for data, target, _ in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            prediction = output.argmax(dim=1, keepdim=True)\n",
    "            actuals.extend(target.view_as(prediction))\n",
    "            predictions.extend(prediction)\n",
    "    return [i.item() for i in actuals], [i.item() for i in predictions]\n",
    "\n",
    "y_test, y_pred = test_label_predictions(model, device, testloader)\n",
    "cm=confusion_matrix(y_test, y_pred)\n",
    "cr=classification_report(y_test, y_pred)\n",
    "fs=f1_score(y_test,y_pred,average='weighted')\n",
    "rs=recall_score(y_test, y_pred,average='weighted')\n",
    "accuracy=accuracy_score(y_test, y_pred)\n",
    "print('Confusion matrix:')\n",
    "print(cm)\n",
    "print(cr)\n",
    "print('F1 score: %f' % fs)\n",
    "print('Recall score: %f' % rs)\n",
    "print('Accuracy score: %f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              ReLU-3           [-1, 64, 32, 32]               0\n",
      "            Conv2d-4          [-1, 128, 32, 32]          73,856\n",
      "       BatchNorm2d-5          [-1, 128, 32, 32]             256\n",
      "              ReLU-6          [-1, 128, 32, 32]               0\n",
      "         MaxPool2d-7          [-1, 128, 16, 16]               0\n",
      "            Conv2d-8          [-1, 128, 16, 16]         147,584\n",
      "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
      "             ReLU-10          [-1, 128, 16, 16]               0\n",
      "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
      "             ReLU-13          [-1, 128, 16, 16]               0\n",
      "           Conv2d-14          [-1, 256, 16, 16]         295,168\n",
      "      BatchNorm2d-15          [-1, 256, 16, 16]             512\n",
      "             ReLU-16          [-1, 256, 16, 16]               0\n",
      "        MaxPool2d-17            [-1, 256, 8, 8]               0\n",
      "           Conv2d-18            [-1, 512, 8, 8]       1,180,160\n",
      "      BatchNorm2d-19            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-20            [-1, 512, 8, 8]               0\n",
      "        MaxPool2d-21            [-1, 512, 4, 4]               0\n",
      "           Conv2d-22            [-1, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-23            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-24            [-1, 512, 4, 4]               0\n",
      "           Conv2d-25            [-1, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-27            [-1, 512, 4, 4]               0\n",
      "           Conv2d-28           [-1, 1028, 4, 4]       4,738,052\n",
      "      BatchNorm2d-29           [-1, 1028, 4, 4]           2,056\n",
      "             ReLU-30           [-1, 1028, 4, 4]               0\n",
      "        MaxPool2d-31           [-1, 1028, 2, 2]               0\n",
      "           Conv2d-32           [-1, 1028, 2, 2]       9,512,084\n",
      "      BatchNorm2d-33           [-1, 1028, 2, 2]           2,056\n",
      "             ReLU-34           [-1, 1028, 2, 2]               0\n",
      "           Conv2d-35           [-1, 1028, 2, 2]       9,512,084\n",
      "      BatchNorm2d-36           [-1, 1028, 2, 2]           2,056\n",
      "             ReLU-37           [-1, 1028, 2, 2]               0\n",
      "        MaxPool2d-38           [-1, 1028, 1, 1]               0\n",
      "          Flatten-39                 [-1, 1028]               0\n",
      "           Linear-40                  [-1, 100]         102,900\n",
      "================================================================\n",
      "Total params: 30,441,528\n",
      "Trainable params: 30,441,528\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 9.68\n",
      "Params size (MB): 116.13\n",
      "Estimated Total Size (MB): 125.81\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(summary(model,(3, 32, 32)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
