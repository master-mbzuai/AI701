{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.utils import download_url, check_integrity\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as tt\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import *\n",
    "from torchsummary import summary\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import errno\n",
    "import sys\n",
    "if sys.version_info[0] == 2:\n",
    "    import cPickle as pickle\n",
    "else:\n",
    "    import pickle\n",
    "\n",
    "import torch.utils.data as data\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "class CIFAR10(data.Dataset):\n",
    "    \"\"\"`CIFAR10 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where directory\n",
    "            ``cifar-10-batches-py`` exists.\n",
    "        train (bool, optional): If True, creates dataset from training set, otherwise\n",
    "            creates from test set.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "    \"\"\"\n",
    "    base_folder = 'cifar-10-batches-py'\n",
    "    url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "    filename = \"cifar-10-python.tar.gz\"\n",
    "    tgz_md5 = 'c58f30108f718f92721af3b95e74349a'\n",
    "    train_list = [\n",
    "        ['data_batch_1', 'c99cafc152244af753f735de768cd75f'],\n",
    "        ['data_batch_2', 'd4bba439e000b95fd0a9bffe97cbabec'],\n",
    "        ['data_batch_3', '54ebc095f3ab1f0389bbae665268c751'],\n",
    "        ['data_batch_4', '634d18415352ddfa80567beed471001a'],\n",
    "        ['data_batch_5', '482c414d41f54cd18b22e5b47cb7c3cb'],\n",
    "    ]\n",
    "\n",
    "    test_list = [\n",
    "        ['test_batch', '40351d587109b95175f43aff81a1287e'],\n",
    "    ]\n",
    "\n",
    "    meta = {\n",
    "        \"filename\": \"batches.meta\",\n",
    "        \"key\": \"label_names\",\n",
    "        \"md5\": \"5ff9c542aee3614f3951f8cda6e48888\",\n",
    "    }\n",
    "\n",
    "\n",
    "    def __init__(self, root, train=True,\n",
    "                 transform=None, target_transform=None,\n",
    "                 download=False, coarse=False):\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train = train  # training set or test set\n",
    "        self.coarse = coarse\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_integrity():\n",
    "            raise RuntimeError('Dataset not found or corrupted.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "        # now load the picked numpy arrays\n",
    "        if self.train:\n",
    "            self.train_data = []\n",
    "            self.train_labels = []\n",
    "            self.train_coarse_labels = []\n",
    "            for fentry in self.train_list:\n",
    "                f = fentry[0]\n",
    "                file = os.path.join(self.root, self.base_folder, f)\n",
    "                fo = open(file, 'rb')\n",
    "                if sys.version_info[0] == 2:\n",
    "                    entry = pickle.load(fo)\n",
    "                else:\n",
    "                    entry = pickle.load(fo, encoding='latin1')\n",
    "                self.train_data.append(entry['data'])\n",
    "                if 'labels' in entry:\n",
    "                    self.train_labels += entry['labels']\n",
    "                else:\n",
    "                    self.train_labels += entry['fine_labels']\n",
    "                    if self.coarse:\n",
    "                        self.train_coarse_labels += entry['coarse_labels']\n",
    "                fo.close()\n",
    "\n",
    "            self.train_data = np.concatenate(self.train_data)\n",
    "            self.train_data = self.train_data.reshape((len(self.train_data), 3, 32, 32))\n",
    "            self.train_data = self.train_data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "        else:\n",
    "            f = self.test_list[0][0]\n",
    "            file = os.path.join(self.root, self.base_folder, f)\n",
    "            fo = open(file, 'rb')\n",
    "            if sys.version_info[0] == 2:\n",
    "                entry = pickle.load(fo)\n",
    "            else:\n",
    "                entry = pickle.load(fo, encoding='latin1')\n",
    "            self.test_data = entry['data']\n",
    "\n",
    "            if 'labels' in entry:\n",
    "                self.test_labels = entry['labels']\n",
    "            else:\n",
    "                self.test_labels = entry['fine_labels']\n",
    "                if self.coarse:\n",
    "                    self.test_coarse_labels = entry['coarse_labels']\n",
    "            fo.close()\n",
    "            self.test_data = self.test_data.reshape((len(self.test_data), 3, 32, 32))\n",
    "            self.test_data = self.test_data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        if self.train:\n",
    "            img, target = self.train_data[index], self.train_labels[index]\n",
    "            if self.coarse:\n",
    "                coarse_target = self.train_coarse_labels[index]\n",
    "        else:\n",
    "            img, target = self.test_data[index], self.test_labels[index]\n",
    "            if self.coarse:\n",
    "                coarse_target = self.test_coarse_labels[index]\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        if not self.coarse:\n",
    "            return img, target\n",
    "        else:\n",
    "            return img, target, coarse_target\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_data)\n",
    "        else:\n",
    "            return len(self.test_data)\n",
    "\n",
    "    def _check_integrity(self):\n",
    "        root = self.root\n",
    "        for fentry in (self.train_list + self.test_list):\n",
    "            filename, md5 = fentry[0], fentry[1]\n",
    "            fpath = os.path.join(root, self.base_folder, filename)\n",
    "            if not check_integrity(fpath, md5):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def download(self):\n",
    "        import tarfile\n",
    "\n",
    "        if self._check_integrity():\n",
    "            print('Files already downloaded and verified')\n",
    "            return\n",
    "\n",
    "        root = self.root\n",
    "        download_url(self.url, root, self.filename, self.tgz_md5)\n",
    "\n",
    "        # extract file\n",
    "        cwd = os.getcwd()\n",
    "        tar = tarfile.open(os.path.join(root, self.filename), \"r:gz\")\n",
    "        os.chdir(root)\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "        os.chdir(cwd)\n",
    "\n",
    "\n",
    "class CIFAR100(CIFAR10):\n",
    "    \"\"\"`CIFAR100 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
    "    This is a subclass of the `CIFAR10` Dataset.\n",
    "    \"\"\"\n",
    "    base_folder = 'cifar-100-python'\n",
    "    url = \"https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\"\n",
    "    filename = \"cifar-100-python.tar.gz\"\n",
    "    tgz_md5 = 'eb9058c3a382ffc7106e4002c42a8d85'\n",
    "    train_list = [\n",
    "        ['train', '16019d7e3df5f24257cddd939b257f8d'],\n",
    "    ]\n",
    "\n",
    "    test_list = [\n",
    "        ['test', 'f0ef6b0ae62326f3e7ffdfab6717acfc'],\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 400\n",
    "epochs = 120\n",
    "max_lr = 0.001\n",
    "grad_clip = 0.01\n",
    "weight_decay =0.001\n",
    "opt_func = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = tt.Compose([tt.RandomCrop(32, padding=4,padding_mode='reflect'), \n",
    "                         tt.RandomHorizontalFlip(), \n",
    "                         tt.ToTensor(), \n",
    "\n",
    "                         ]\n",
    "                         )\n",
    "transform_test = tt.Compose([tt.ToTensor(), \n",
    "\n",
    "                             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, labels, _ = batch\n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels, _ = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc =  accuracy(out, labels)         # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc }\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))\n",
    "        \n",
    "def conv_block(in_channels, out_channels, pool=False):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
    "              nn.BatchNorm2d(out_channels), \n",
    "              nn.ReLU(inplace=True)]\n",
    "    if pool: layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class ResNet9(ImageClassificationBase):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = conv_block(in_channels, 64)\n",
    "        self.conv2 = conv_block(64, 128, pool=True) \n",
    "        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128)) \n",
    "        \n",
    "        self.conv3 = conv_block(128, 256, pool=True)\n",
    "        self.conv4 = conv_block(256, 512, pool=True) \n",
    "        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512)) \n",
    "        self.conv5 = conv_block(512, 1028, pool=True) \n",
    "        self.res3 = nn.Sequential(conv_block(1028, 1028), conv_block(1028, 1028))  \n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.MaxPool2d(2), # 1028 x 1 x 1\n",
    "                                        nn.Flatten(), # 1028 \n",
    "                                        nn.Linear(1028, 20),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(20, num_classes),\n",
    "                                        ) # 1028 -> 100\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.conv1(xb)\n",
    "        out = self.conv2(out)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.conv5(out)\n",
    "        out = self.res3(out) + out\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in test_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def fit_one_cycle(epochs, max_lr, model, train_loader, test_loader, \n",
    "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
    "    torch.cuda.empty_cache()\n",
    "    history = []\n",
    "    \n",
    "    # Set up cutom optimizer with weight decay\n",
    "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
    "    # Set up one-cycle learning rate scheduler\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n",
    "                                                steps_per_epoch=len(train_loader))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        lrs = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            if grad_clip: \n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Record & update learning rate\n",
    "            lrs.append(get_lr(optimizer))\n",
    "            sched.step()\n",
    "        \n",
    "        # Validation phase\n",
    "        result = evaluate(model, test_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        result['lrs'] = lrs\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate testing accuracy, predicted label, confusion matrix, and table for classification report\n",
    "def test_label_predictions(model, device, test_loader):\n",
    "    model.eval()\n",
    "    actuals = []\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for data, target, _ in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            prediction = output.argmax(dim=1, keepdim=True)\n",
    "            actuals.extend(target.view_as(prediction))\n",
    "            predictions.extend(prediction)\n",
    "    return [i.item() for i in actuals], [i.item() for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = CIFAR100('./data', train=True,\n",
    "                transform=transform_train,\n",
    "                download=True, coarse=True)\n",
    "test_data = CIFAR100('./data', train=False,\n",
    "                transform=transform_test,\n",
    "                download=True, coarse=True)\n",
    "\n",
    "train_length = train_data.__len__() # Length training dataset\n",
    "train_indices = np.arange(train_length)\n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                        train_data, \n",
    "                        batch_size=batch_size, \n",
    "                        num_workers=2,\n",
    "                        pin_memory=True,\n",
    "                    )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                        test_data, \n",
    "                        batch_size=batch_size*2,\n",
    "                        num_workers=2,\n",
    "                        pin_memory=True\n",
    "                    )\n",
    "device = get_default_device()\n",
    "trainloader = DeviceDataLoader(train_loader, device)\n",
    "testloader = DeviceDataLoader(test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list=[]\n",
    "d_list=[0, 10, 20, 30, 40, 50 ,60 , 70, 80, 90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'val_loss': 4.605464935302734, 'val_acc': 0.009903847239911556}]\n",
      "Epoch [0], last_lr: 0.00005, train_loss: 3.6510, val_loss: 3.1127, val_acc: 0.2437\n",
      "Epoch [1], last_lr: 0.00008, train_loss: 2.9504, val_loss: 2.7107, val_acc: 0.3182\n",
      "Epoch [2], last_lr: 0.00013, train_loss: 2.5947, val_loss: 2.6219, val_acc: 0.3333\n",
      "Epoch [3], last_lr: 0.00020, train_loss: 2.3534, val_loss: 2.4172, val_acc: 0.3674\n",
      "Epoch [4], last_lr: 0.00028, train_loss: 2.1630, val_loss: 2.2426, val_acc: 0.4102\n",
      "Epoch [5], last_lr: 0.00037, train_loss: 1.9935, val_loss: 2.1695, val_acc: 0.4292\n",
      "Epoch [6], last_lr: 0.00047, train_loss: 1.8514, val_loss: 2.1083, val_acc: 0.4521\n",
      "Epoch [7], last_lr: 0.00057, train_loss: 1.7232, val_loss: 2.1970, val_acc: 0.4352\n",
      "Epoch [8], last_lr: 0.00067, train_loss: 1.6090, val_loss: 2.1690, val_acc: 0.4556\n",
      "Epoch [9], last_lr: 0.00076, train_loss: 1.5092, val_loss: 2.1903, val_acc: 0.4549\n",
      "Epoch [10], last_lr: 0.00084, train_loss: 1.4242, val_loss: 1.9585, val_acc: 0.4822\n",
      "Epoch [11], last_lr: 0.00091, train_loss: 1.3439, val_loss: 1.8988, val_acc: 0.5003\n",
      "Epoch [12], last_lr: 0.00096, train_loss: 1.2738, val_loss: 2.0015, val_acc: 0.4800\n",
      "Epoch [13], last_lr: 0.00099, train_loss: 1.1970, val_loss: 1.6619, val_acc: 0.5502\n",
      "Epoch [14], last_lr: 0.00100, train_loss: 1.1331, val_loss: 1.8692, val_acc: 0.5117\n",
      "Epoch [15], last_lr: 0.00100, train_loss: 1.0721, val_loss: 1.5604, val_acc: 0.5765\n",
      "Epoch [16], last_lr: 0.00099, train_loss: 1.0108, val_loss: 1.8013, val_acc: 0.5230\n",
      "Epoch [17], last_lr: 0.00098, train_loss: 0.9548, val_loss: 1.6537, val_acc: 0.5532\n",
      "Epoch [18], last_lr: 0.00097, train_loss: 0.9136, val_loss: 1.6110, val_acc: 0.5688\n",
      "Epoch [19], last_lr: 0.00095, train_loss: 0.8695, val_loss: 1.6868, val_acc: 0.5467\n",
      "Epoch [20], last_lr: 0.00093, train_loss: 0.8210, val_loss: 1.6413, val_acc: 0.5659\n",
      "Epoch [21], last_lr: 0.00090, train_loss: 0.7807, val_loss: 1.9083, val_acc: 0.5281\n",
      "Epoch [22], last_lr: 0.00088, train_loss: 0.7354, val_loss: 1.6362, val_acc: 0.5750\n",
      "Epoch [23], last_lr: 0.00085, train_loss: 0.7019, val_loss: 1.6833, val_acc: 0.5599\n",
      "Epoch [24], last_lr: 0.00081, train_loss: 0.6719, val_loss: 1.7067, val_acc: 0.5551\n",
      "Epoch [25], last_lr: 0.00078, train_loss: 0.6302, val_loss: 1.6228, val_acc: 0.5790\n",
      "Epoch [26], last_lr: 0.00074, train_loss: 0.5926, val_loss: 1.5913, val_acc: 0.6017\n",
      "Epoch [27], last_lr: 0.00070, train_loss: 0.5553, val_loss: 1.6375, val_acc: 0.5880\n",
      "Epoch [28], last_lr: 0.00065, train_loss: 0.5117, val_loss: 1.5463, val_acc: 0.6026\n",
      "Epoch [29], last_lr: 0.00061, train_loss: 0.4730, val_loss: 1.5329, val_acc: 0.6188\n",
      "Epoch [30], last_lr: 0.00057, train_loss: 0.4359, val_loss: 1.5497, val_acc: 0.6136\n",
      "Epoch [31], last_lr: 0.00052, train_loss: 0.3924, val_loss: 1.4286, val_acc: 0.6459\n",
      "Epoch [32], last_lr: 0.00048, train_loss: 0.3531, val_loss: 1.4536, val_acc: 0.6343\n",
      "Epoch [33], last_lr: 0.00043, train_loss: 0.3061, val_loss: 1.3657, val_acc: 0.6459\n",
      "Epoch [34], last_lr: 0.00039, train_loss: 0.2627, val_loss: 1.3788, val_acc: 0.6522\n",
      "Epoch [35], last_lr: 0.00035, train_loss: 0.2336, val_loss: 1.3143, val_acc: 0.6690\n",
      "Epoch [36], last_lr: 0.00030, train_loss: 0.1945, val_loss: 1.3281, val_acc: 0.6727\n",
      "Epoch [37], last_lr: 0.00026, train_loss: 0.1585, val_loss: 1.2251, val_acc: 0.6949\n",
      "Epoch [38], last_lr: 0.00022, train_loss: 0.1228, val_loss: 1.2200, val_acc: 0.7022\n",
      "Epoch [39], last_lr: 0.00019, train_loss: 0.0943, val_loss: 1.2005, val_acc: 0.7101\n",
      "Epoch [40], last_lr: 0.00015, train_loss: 0.0701, val_loss: 1.1532, val_acc: 0.7231\n",
      "Epoch [41], last_lr: 0.00012, train_loss: 0.0523, val_loss: 1.1225, val_acc: 0.7308\n",
      "Epoch [42], last_lr: 0.00010, train_loss: 0.0383, val_loss: 1.1007, val_acc: 0.7371\n",
      "Epoch [43], last_lr: 0.00007, train_loss: 0.0286, val_loss: 1.1119, val_acc: 0.7380\n",
      "Epoch [44], last_lr: 0.00005, train_loss: 0.0234, val_loss: 1.0942, val_acc: 0.7386\n",
      "Epoch [45], last_lr: 0.00003, train_loss: 0.0180, val_loss: 1.0852, val_acc: 0.7434\n",
      "Epoch [46], last_lr: 0.00002, train_loss: 0.0162, val_loss: 1.0847, val_acc: 0.7434\n",
      "Epoch [47], last_lr: 0.00001, train_loss: 0.0143, val_loss: 1.0851, val_acc: 0.7440\n",
      "Epoch [48], last_lr: 0.00000, train_loss: 0.0136, val_loss: 1.0838, val_acc: 0.7449\n",
      "Epoch [49], last_lr: 0.00000, train_loss: 0.0128, val_loss: 1.0837, val_acc: 0.7449\n",
      "Accuracy score: 0.743400\n",
      "[{'val_loss': 4.620845317840576, 'val_acc': 0.009807691909372807}]\n",
      "Epoch [0], last_lr: 0.00005, train_loss: 4.5624, val_loss: 4.5107, val_acc: 0.0239\n",
      "Epoch [1], last_lr: 0.00008, train_loss: 4.5010, val_loss: 4.4760, val_acc: 0.0307\n",
      "Epoch [2], last_lr: 0.00013, train_loss: 4.4482, val_loss: 4.4221, val_acc: 0.0412\n",
      "Epoch [3], last_lr: 0.00020, train_loss: 4.3733, val_loss: 4.3605, val_acc: 0.0528\n",
      "Epoch [4], last_lr: 0.00028, train_loss: 4.2642, val_loss: 4.2016, val_acc: 0.0879\n",
      "Epoch [5], last_lr: 0.00037, train_loss: 4.0997, val_loss: 4.1296, val_acc: 0.1102\n",
      "Epoch [6], last_lr: 0.00047, train_loss: 3.8745, val_loss: 3.9664, val_acc: 0.1190\n",
      "Epoch [7], last_lr: 0.00057, train_loss: 3.6071, val_loss: 3.6106, val_acc: 0.1624\n",
      "Epoch [8], last_lr: 0.00067, train_loss: 3.3346, val_loss: 3.3398, val_acc: 0.2053\n",
      "Epoch [9], last_lr: 0.00076, train_loss: 3.0977, val_loss: 3.3893, val_acc: 0.1989\n",
      "Epoch [10], last_lr: 0.00084, train_loss: 2.8977, val_loss: 3.0436, val_acc: 0.2598\n",
      "Epoch [11], last_lr: 0.00091, train_loss: 2.7332, val_loss: 3.1194, val_acc: 0.2473\n",
      "Epoch [12], last_lr: 0.00096, train_loss: 2.6023, val_loss: 3.0412, val_acc: 0.2619\n",
      "Epoch [13], last_lr: 0.00099, train_loss: 2.4735, val_loss: 2.9917, val_acc: 0.2716\n",
      "Epoch [14], last_lr: 0.00100, train_loss: 2.3663, val_loss: 2.6661, val_acc: 0.3262\n",
      "Epoch [15], last_lr: 0.00100, train_loss: 2.2552, val_loss: 2.5673, val_acc: 0.3456\n",
      "Epoch [16], last_lr: 0.00099, train_loss: 2.1529, val_loss: 2.5693, val_acc: 0.3554\n",
      "Epoch [17], last_lr: 0.00098, train_loss: 2.0483, val_loss: 2.6097, val_acc: 0.3634\n",
      "Epoch [18], last_lr: 0.00097, train_loss: 1.9588, val_loss: 2.5019, val_acc: 0.3893\n",
      "Epoch [19], last_lr: 0.00095, train_loss: 1.8637, val_loss: 2.5788, val_acc: 0.3873\n",
      "Epoch [20], last_lr: 0.00093, train_loss: 1.7894, val_loss: 2.4891, val_acc: 0.4038\n",
      "Epoch [21], last_lr: 0.00090, train_loss: 1.7016, val_loss: 2.5420, val_acc: 0.4102\n",
      "Epoch [22], last_lr: 0.00088, train_loss: 1.6317, val_loss: 2.3474, val_acc: 0.4384\n",
      "Epoch [23], last_lr: 0.00085, train_loss: 1.5582, val_loss: 2.2017, val_acc: 0.4608\n",
      "Epoch [24], last_lr: 0.00081, train_loss: 1.4894, val_loss: 2.2362, val_acc: 0.4718\n",
      "Epoch [25], last_lr: 0.00078, train_loss: 1.4143, val_loss: 2.0891, val_acc: 0.4959\n",
      "Epoch [26], last_lr: 0.00074, train_loss: 1.3362, val_loss: 2.2821, val_acc: 0.4777\n",
      "Epoch [27], last_lr: 0.00070, train_loss: 1.2717, val_loss: 2.3066, val_acc: 0.4895\n",
      "Epoch [28], last_lr: 0.00065, train_loss: 1.2040, val_loss: 2.1259, val_acc: 0.5160\n",
      "Epoch [29], last_lr: 0.00061, train_loss: 1.1254, val_loss: 2.2321, val_acc: 0.5228\n",
      "Epoch [30], last_lr: 0.00057, train_loss: 1.0726, val_loss: 1.9760, val_acc: 0.5553\n",
      "Epoch [31], last_lr: 0.00052, train_loss: 0.9953, val_loss: 1.9232, val_acc: 0.5692\n",
      "Epoch [32], last_lr: 0.00048, train_loss: 0.9084, val_loss: 1.9873, val_acc: 0.5588\n",
      "Epoch [33], last_lr: 0.00043, train_loss: 0.8503, val_loss: 1.8167, val_acc: 0.5870\n",
      "Epoch [34], last_lr: 0.00039, train_loss: 0.7711, val_loss: 1.8719, val_acc: 0.5950\n",
      "Epoch [35], last_lr: 0.00035, train_loss: 0.7097, val_loss: 1.7584, val_acc: 0.6099\n",
      "Epoch [36], last_lr: 0.00030, train_loss: 0.6373, val_loss: 1.8546, val_acc: 0.6159\n",
      "Epoch [37], last_lr: 0.00026, train_loss: 0.5723, val_loss: 1.7852, val_acc: 0.6260\n",
      "Epoch [38], last_lr: 0.00022, train_loss: 0.5004, val_loss: 1.8568, val_acc: 0.6275\n",
      "Epoch [39], last_lr: 0.00019, train_loss: 0.4387, val_loss: 1.8586, val_acc: 0.6371\n",
      "Epoch [40], last_lr: 0.00015, train_loss: 0.3782, val_loss: 1.8584, val_acc: 0.6426\n",
      "Epoch [41], last_lr: 0.00012, train_loss: 0.3308, val_loss: 1.9296, val_acc: 0.6424\n",
      "Epoch [42], last_lr: 0.00010, train_loss: 0.2823, val_loss: 1.9052, val_acc: 0.6508\n",
      "Epoch [43], last_lr: 0.00007, train_loss: 0.2469, val_loss: 1.9047, val_acc: 0.6534\n",
      "Epoch [44], last_lr: 0.00005, train_loss: 0.2173, val_loss: 1.9265, val_acc: 0.6573\n",
      "Epoch [45], last_lr: 0.00003, train_loss: 0.1935, val_loss: 1.9154, val_acc: 0.6618\n",
      "Epoch [46], last_lr: 0.00002, train_loss: 0.1763, val_loss: 1.9168, val_acc: 0.6625\n",
      "Epoch [47], last_lr: 0.00001, train_loss: 0.1672, val_loss: 1.9163, val_acc: 0.6649\n",
      "Epoch [48], last_lr: 0.00000, train_loss: 0.1564, val_loss: 1.9257, val_acc: 0.6656\n",
      "Epoch [49], last_lr: 0.00000, train_loss: 0.1558, val_loss: 1.9302, val_acc: 0.6651\n",
      "Accuracy score: 0.663600\n",
      "[{'val_loss': 4.6139140129089355, 'val_acc': 0.009903847239911556}]\n",
      "Epoch [0], last_lr: 0.00005, train_loss: 4.4814, val_loss: 4.3817, val_acc: 0.0590\n",
      "Epoch [1], last_lr: 0.00008, train_loss: 4.3264, val_loss: 4.2422, val_acc: 0.0905\n",
      "Epoch [2], last_lr: 0.00013, train_loss: 4.1672, val_loss: 4.0938, val_acc: 0.1182\n",
      "Epoch [3], last_lr: 0.00020, train_loss: 3.9385, val_loss: 3.7809, val_acc: 0.1792\n",
      "Epoch [4], last_lr: 0.00028, train_loss: 3.5911, val_loss: 3.5542, val_acc: 0.2108\n",
      "Epoch [5], last_lr: 0.00037, train_loss: 3.1644, val_loss: 3.2089, val_acc: 0.2588\n",
      "Epoch [6], last_lr: 0.00047, train_loss: 2.8065, val_loss: 3.0149, val_acc: 0.2866\n",
      "Epoch [7], last_lr: 0.00057, train_loss: 2.5083, val_loss: 2.6667, val_acc: 0.3465\n",
      "Epoch [8], last_lr: 0.00067, train_loss: 2.2987, val_loss: 2.7721, val_acc: 0.3277\n",
      "Epoch [9], last_lr: 0.00076, train_loss: 2.1305, val_loss: 3.0434, val_acc: 0.3205\n",
      "Epoch [10], last_lr: 0.00084, train_loss: 1.9984, val_loss: 2.8803, val_acc: 0.3397\n",
      "Epoch [11], last_lr: 0.00091, train_loss: 1.8935, val_loss: 2.9112, val_acc: 0.3481\n",
      "Epoch [12], last_lr: 0.00096, train_loss: 1.8079, val_loss: 2.6237, val_acc: 0.3734\n",
      "Epoch [13], last_lr: 0.00099, train_loss: 1.7173, val_loss: 2.1345, val_acc: 0.4574\n",
      "Epoch [14], last_lr: 0.00100, train_loss: 1.6313, val_loss: 2.2271, val_acc: 0.4448\n",
      "Epoch [15], last_lr: 0.00100, train_loss: 1.5526, val_loss: 2.5220, val_acc: 0.4078\n",
      "Epoch [16], last_lr: 0.00099, train_loss: 1.4704, val_loss: 2.2482, val_acc: 0.4427\n",
      "Epoch [17], last_lr: 0.00098, train_loss: 1.4050, val_loss: 2.0990, val_acc: 0.4747\n",
      "Epoch [18], last_lr: 0.00097, train_loss: 1.3398, val_loss: 1.8513, val_acc: 0.5191\n",
      "Epoch [19], last_lr: 0.00095, train_loss: 1.2770, val_loss: 2.1860, val_acc: 0.4632\n",
      "Epoch [20], last_lr: 0.00093, train_loss: 1.2181, val_loss: 2.1645, val_acc: 0.4850\n",
      "Epoch [21], last_lr: 0.00090, train_loss: 1.1698, val_loss: 1.9082, val_acc: 0.5203\n",
      "Epoch [22], last_lr: 0.00088, train_loss: 1.1055, val_loss: 2.0736, val_acc: 0.5037\n",
      "Epoch [23], last_lr: 0.00085, train_loss: 1.0589, val_loss: 1.8739, val_acc: 0.5246\n",
      "Epoch [24], last_lr: 0.00081, train_loss: 0.9890, val_loss: 1.8485, val_acc: 0.5431\n",
      "Epoch [25], last_lr: 0.00078, train_loss: 0.9483, val_loss: 1.7984, val_acc: 0.5550\n",
      "Epoch [26], last_lr: 0.00074, train_loss: 0.8892, val_loss: 1.9115, val_acc: 0.5424\n",
      "Epoch [27], last_lr: 0.00070, train_loss: 0.8454, val_loss: 1.8286, val_acc: 0.5558\n",
      "Epoch [28], last_lr: 0.00065, train_loss: 0.7860, val_loss: 1.6162, val_acc: 0.5986\n",
      "Epoch [29], last_lr: 0.00061, train_loss: 0.7319, val_loss: 1.7639, val_acc: 0.5821\n",
      "Epoch [30], last_lr: 0.00057, train_loss: 0.6686, val_loss: 1.6389, val_acc: 0.6049\n",
      "Epoch [31], last_lr: 0.00052, train_loss: 0.6148, val_loss: 1.6961, val_acc: 0.5988\n",
      "Epoch [32], last_lr: 0.00048, train_loss: 0.5650, val_loss: 1.6219, val_acc: 0.6210\n",
      "Epoch [33], last_lr: 0.00043, train_loss: 0.5027, val_loss: 1.5910, val_acc: 0.6306\n",
      "Epoch [34], last_lr: 0.00039, train_loss: 0.4511, val_loss: 1.6137, val_acc: 0.6264\n",
      "Epoch [35], last_lr: 0.00035, train_loss: 0.3946, val_loss: 1.6664, val_acc: 0.6278\n",
      "Epoch [36], last_lr: 0.00030, train_loss: 0.3388, val_loss: 1.5837, val_acc: 0.6451\n",
      "Epoch [37], last_lr: 0.00026, train_loss: 0.2915, val_loss: 1.5498, val_acc: 0.6498\n",
      "Epoch [38], last_lr: 0.00022, train_loss: 0.2341, val_loss: 1.5263, val_acc: 0.6634\n",
      "Epoch [39], last_lr: 0.00019, train_loss: 0.1987, val_loss: 1.4719, val_acc: 0.6780\n",
      "Epoch [40], last_lr: 0.00015, train_loss: 0.1476, val_loss: 1.4709, val_acc: 0.6892\n",
      "Epoch [41], last_lr: 0.00012, train_loss: 0.1241, val_loss: 1.4932, val_acc: 0.6911\n",
      "Epoch [42], last_lr: 0.00010, train_loss: 0.0954, val_loss: 1.4682, val_acc: 0.6980\n",
      "Epoch [43], last_lr: 0.00007, train_loss: 0.0782, val_loss: 1.4565, val_acc: 0.6987\n",
      "Epoch [44], last_lr: 0.00005, train_loss: 0.0628, val_loss: 1.4638, val_acc: 0.7040\n",
      "Epoch [45], last_lr: 0.00003, train_loss: 0.0516, val_loss: 1.4552, val_acc: 0.7051\n",
      "Epoch [46], last_lr: 0.00002, train_loss: 0.0453, val_loss: 1.4462, val_acc: 0.7077\n",
      "Epoch [47], last_lr: 0.00001, train_loss: 0.0412, val_loss: 1.4479, val_acc: 0.7083\n",
      "Epoch [48], last_lr: 0.00000, train_loss: 0.0378, val_loss: 1.4452, val_acc: 0.7079\n",
      "Epoch [49], last_lr: 0.00000, train_loss: 0.0371, val_loss: 1.4474, val_acc: 0.7085\n",
      "Accuracy score: 0.708700\n",
      "[{'val_loss': 4.610894680023193, 'val_acc': 0.009903847239911556}]\n",
      "Epoch [0], last_lr: 0.00005, train_loss: 4.4147, val_loss: 4.2563, val_acc: 0.0731\n",
      "Epoch [1], last_lr: 0.00008, train_loss: 4.1413, val_loss: 3.9969, val_acc: 0.1311\n",
      "Epoch [2], last_lr: 0.00013, train_loss: 3.8274, val_loss: 3.6711, val_acc: 0.1881\n",
      "Epoch [3], last_lr: 0.00020, train_loss: 3.3626, val_loss: 3.3706, val_acc: 0.2346\n",
      "Epoch [4], last_lr: 0.00028, train_loss: 2.8951, val_loss: 3.0820, val_acc: 0.2870\n",
      "Epoch [5], last_lr: 0.00037, train_loss: 2.5680, val_loss: 2.7063, val_acc: 0.3460\n",
      "Epoch [6], last_lr: 0.00047, train_loss: 2.3101, val_loss: 2.6901, val_acc: 0.3505\n",
      "Epoch [7], last_lr: 0.00057, train_loss: 2.1201, val_loss: 2.4981, val_acc: 0.3788\n",
      "Epoch [8], last_lr: 0.00067, train_loss: 1.9687, val_loss: 2.5520, val_acc: 0.3869\n",
      "Epoch [9], last_lr: 0.00076, train_loss: 1.8514, val_loss: 2.3431, val_acc: 0.4097\n",
      "Epoch [10], last_lr: 0.00084, train_loss: 1.7465, val_loss: 2.3569, val_acc: 0.4123\n",
      "Epoch [11], last_lr: 0.00091, train_loss: 1.6626, val_loss: 2.2759, val_acc: 0.4303\n",
      "Epoch [12], last_lr: 0.00096, train_loss: 1.5805, val_loss: 2.1295, val_acc: 0.4500\n",
      "Epoch [13], last_lr: 0.00099, train_loss: 1.5035, val_loss: 2.4220, val_acc: 0.4138\n",
      "Epoch [14], last_lr: 0.00100, train_loss: 1.4408, val_loss: 1.9915, val_acc: 0.4888\n",
      "Epoch [15], last_lr: 0.00100, train_loss: 1.3658, val_loss: 2.0487, val_acc: 0.4751\n",
      "Epoch [16], last_lr: 0.00099, train_loss: 1.3036, val_loss: 2.1155, val_acc: 0.4711\n",
      "Epoch [17], last_lr: 0.00098, train_loss: 1.2441, val_loss: 1.8504, val_acc: 0.5185\n",
      "Epoch [18], last_lr: 0.00097, train_loss: 1.1866, val_loss: 2.1717, val_acc: 0.4619\n",
      "Epoch [19], last_lr: 0.00095, train_loss: 1.1259, val_loss: 1.7233, val_acc: 0.5507\n",
      "Epoch [20], last_lr: 0.00093, train_loss: 1.0768, val_loss: 1.9918, val_acc: 0.5080\n",
      "Epoch [21], last_lr: 0.00090, train_loss: 1.0307, val_loss: 1.7217, val_acc: 0.5490\n",
      "Epoch [22], last_lr: 0.00088, train_loss: 0.9806, val_loss: 1.7334, val_acc: 0.5417\n",
      "Epoch [23], last_lr: 0.00085, train_loss: 0.9356, val_loss: 1.7335, val_acc: 0.5638\n",
      "Epoch [24], last_lr: 0.00081, train_loss: 0.8926, val_loss: 1.7653, val_acc: 0.5572\n",
      "Epoch [25], last_lr: 0.00078, train_loss: 0.8393, val_loss: 1.6934, val_acc: 0.5788\n",
      "Epoch [26], last_lr: 0.00074, train_loss: 0.7883, val_loss: 1.8640, val_acc: 0.5529\n",
      "Epoch [27], last_lr: 0.00070, train_loss: 0.7507, val_loss: 1.6507, val_acc: 0.5913\n",
      "Epoch [28], last_lr: 0.00065, train_loss: 0.6933, val_loss: 1.6929, val_acc: 0.5940\n",
      "Epoch [29], last_lr: 0.00061, train_loss: 0.6482, val_loss: 1.7530, val_acc: 0.5770\n",
      "Epoch [30], last_lr: 0.00057, train_loss: 0.5924, val_loss: 1.6139, val_acc: 0.6131\n",
      "Epoch [31], last_lr: 0.00052, train_loss: 0.5351, val_loss: 1.5270, val_acc: 0.6302\n",
      "Epoch [32], last_lr: 0.00048, train_loss: 0.4800, val_loss: 1.5923, val_acc: 0.6225\n",
      "Epoch [33], last_lr: 0.00043, train_loss: 0.4331, val_loss: 1.5272, val_acc: 0.6293\n",
      "Epoch [34], last_lr: 0.00039, train_loss: 0.3709, val_loss: 1.5732, val_acc: 0.6285\n",
      "Epoch [35], last_lr: 0.00035, train_loss: 0.3260, val_loss: 1.5082, val_acc: 0.6455\n",
      "Epoch [36], last_lr: 0.00030, train_loss: 0.2909, val_loss: 1.4442, val_acc: 0.6587\n",
      "Epoch [37], last_lr: 0.00026, train_loss: 0.2387, val_loss: 1.5335, val_acc: 0.6553\n",
      "Epoch [38], last_lr: 0.00022, train_loss: 0.1888, val_loss: 1.4188, val_acc: 0.6750\n",
      "Epoch [39], last_lr: 0.00019, train_loss: 0.1489, val_loss: 1.4209, val_acc: 0.6812\n",
      "Epoch [40], last_lr: 0.00015, train_loss: 0.1191, val_loss: 1.4032, val_acc: 0.6862\n",
      "Epoch [41], last_lr: 0.00012, train_loss: 0.0896, val_loss: 1.3471, val_acc: 0.6976\n",
      "Epoch [42], last_lr: 0.00010, train_loss: 0.0660, val_loss: 1.3291, val_acc: 0.7057\n",
      "Epoch [43], last_lr: 0.00007, train_loss: 0.0513, val_loss: 1.3226, val_acc: 0.7108\n",
      "Epoch [44], last_lr: 0.00005, train_loss: 0.0422, val_loss: 1.3184, val_acc: 0.7159\n",
      "Epoch [45], last_lr: 0.00003, train_loss: 0.0347, val_loss: 1.3154, val_acc: 0.7140\n",
      "Epoch [46], last_lr: 0.00002, train_loss: 0.0318, val_loss: 1.3150, val_acc: 0.7161\n",
      "Epoch [47], last_lr: 0.00001, train_loss: 0.0273, val_loss: 1.3155, val_acc: 0.7159\n",
      "Epoch [48], last_lr: 0.00000, train_loss: 0.0249, val_loss: 1.3130, val_acc: 0.7172\n",
      "Epoch [49], last_lr: 0.00000, train_loss: 0.0251, val_loss: 1.3126, val_acc: 0.7173\n",
      "Accuracy score: 0.716500\n",
      "[{'val_loss': 4.608613967895508, 'val_acc': 0.010384615510702133}]\n",
      "Epoch [0], last_lr: 0.00005, train_loss: 4.3750, val_loss: 4.1656, val_acc: 0.1104\n",
      "Epoch [1], last_lr: 0.00008, train_loss: 4.0272, val_loss: 3.8252, val_acc: 0.1672\n",
      "Epoch [2], last_lr: 0.00013, train_loss: 3.5821, val_loss: 3.4117, val_acc: 0.2291\n",
      "Epoch [3], last_lr: 0.00020, train_loss: 3.0394, val_loss: 3.0613, val_acc: 0.2754\n",
      "Epoch [4], last_lr: 0.00028, train_loss: 2.6593, val_loss: 2.6195, val_acc: 0.3504\n",
      "Epoch [5], last_lr: 0.00037, train_loss: 2.3866, val_loss: 2.4001, val_acc: 0.3945\n",
      "Epoch [6], last_lr: 0.00047, train_loss: 2.1706, val_loss: 2.4300, val_acc: 0.3944\n",
      "Epoch [7], last_lr: 0.00057, train_loss: 2.0060, val_loss: 2.2228, val_acc: 0.4248\n",
      "Epoch [8], last_lr: 0.00067, train_loss: 1.8724, val_loss: 2.0096, val_acc: 0.4709\n",
      "Epoch [9], last_lr: 0.00076, train_loss: 1.7582, val_loss: 2.0372, val_acc: 0.4617\n",
      "Epoch [10], last_lr: 0.00084, train_loss: 1.6739, val_loss: 2.1420, val_acc: 0.4387\n",
      "Epoch [11], last_lr: 0.00091, train_loss: 1.5985, val_loss: 2.1910, val_acc: 0.4414\n",
      "Epoch [12], last_lr: 0.00096, train_loss: 1.5292, val_loss: 2.0617, val_acc: 0.4585\n",
      "Epoch [13], last_lr: 0.00099, train_loss: 1.4558, val_loss: 2.2258, val_acc: 0.4384\n",
      "Epoch [14], last_lr: 0.00100, train_loss: 1.3928, val_loss: 2.0348, val_acc: 0.4739\n",
      "Epoch [15], last_lr: 0.00100, train_loss: 1.3278, val_loss: 1.8017, val_acc: 0.5138\n",
      "Epoch [16], last_lr: 0.00099, train_loss: 1.2631, val_loss: 1.8934, val_acc: 0.4974\n",
      "Epoch [17], last_lr: 0.00098, train_loss: 1.2093, val_loss: 2.0820, val_acc: 0.4689\n",
      "Epoch [18], last_lr: 0.00097, train_loss: 1.1523, val_loss: 1.8124, val_acc: 0.5188\n",
      "Epoch [19], last_lr: 0.00095, train_loss: 1.1011, val_loss: 1.9294, val_acc: 0.5041\n",
      "Epoch [20], last_lr: 0.00093, train_loss: 1.0532, val_loss: 1.7620, val_acc: 0.5414\n",
      "Epoch [21], last_lr: 0.00090, train_loss: 1.0055, val_loss: 1.9059, val_acc: 0.5174\n",
      "Epoch [22], last_lr: 0.00088, train_loss: 0.9564, val_loss: 1.9414, val_acc: 0.5214\n",
      "Epoch [23], last_lr: 0.00085, train_loss: 0.9037, val_loss: 1.9699, val_acc: 0.5064\n",
      "Epoch [24], last_lr: 0.00081, train_loss: 0.8570, val_loss: 1.6987, val_acc: 0.5628\n",
      "Epoch [25], last_lr: 0.00078, train_loss: 0.8147, val_loss: 1.7192, val_acc: 0.5608\n",
      "Epoch [26], last_lr: 0.00074, train_loss: 0.7774, val_loss: 1.6670, val_acc: 0.5736\n",
      "Epoch [27], last_lr: 0.00070, train_loss: 0.7283, val_loss: 1.6654, val_acc: 0.5839\n",
      "Epoch [28], last_lr: 0.00065, train_loss: 0.6797, val_loss: 1.5930, val_acc: 0.5981\n",
      "Epoch [29], last_lr: 0.00061, train_loss: 0.6275, val_loss: 1.6751, val_acc: 0.5934\n",
      "Epoch [30], last_lr: 0.00057, train_loss: 0.5799, val_loss: 1.6135, val_acc: 0.6001\n",
      "Epoch [31], last_lr: 0.00052, train_loss: 0.5343, val_loss: 1.7372, val_acc: 0.6045\n",
      "Epoch [32], last_lr: 0.00048, train_loss: 0.4767, val_loss: 1.6405, val_acc: 0.6139\n",
      "Epoch [33], last_lr: 0.00043, train_loss: 0.4202, val_loss: 1.5938, val_acc: 0.6224\n",
      "Epoch [34], last_lr: 0.00039, train_loss: 0.3729, val_loss: 1.5383, val_acc: 0.6323\n",
      "Epoch [35], last_lr: 0.00035, train_loss: 0.3192, val_loss: 1.4790, val_acc: 0.6494\n",
      "Epoch [36], last_lr: 0.00030, train_loss: 0.2738, val_loss: 1.4347, val_acc: 0.6562\n",
      "Epoch [37], last_lr: 0.00026, train_loss: 0.2255, val_loss: 1.4028, val_acc: 0.6712\n",
      "Epoch [38], last_lr: 0.00022, train_loss: 0.1782, val_loss: 1.3383, val_acc: 0.6891\n",
      "Epoch [39], last_lr: 0.00019, train_loss: 0.1355, val_loss: 1.3489, val_acc: 0.6879\n",
      "Epoch [40], last_lr: 0.00015, train_loss: 0.1114, val_loss: 1.3359, val_acc: 0.6914\n",
      "Epoch [41], last_lr: 0.00012, train_loss: 0.0857, val_loss: 1.2759, val_acc: 0.7065\n",
      "Epoch [42], last_lr: 0.00010, train_loss: 0.0636, val_loss: 1.2671, val_acc: 0.7112\n",
      "Epoch [43], last_lr: 0.00007, train_loss: 0.0511, val_loss: 1.2551, val_acc: 0.7157\n",
      "Epoch [44], last_lr: 0.00005, train_loss: 0.0401, val_loss: 1.2365, val_acc: 0.7177\n",
      "Epoch [45], last_lr: 0.00003, train_loss: 0.0323, val_loss: 1.2364, val_acc: 0.7232\n",
      "Epoch [46], last_lr: 0.00002, train_loss: 0.0274, val_loss: 1.2310, val_acc: 0.7258\n",
      "Epoch [47], last_lr: 0.00001, train_loss: 0.0253, val_loss: 1.2321, val_acc: 0.7239\n",
      "Epoch [48], last_lr: 0.00000, train_loss: 0.0232, val_loss: 1.2311, val_acc: 0.7245\n",
      "Epoch [49], last_lr: 0.00000, train_loss: 0.0228, val_loss: 1.2305, val_acc: 0.7231\n",
      "Accuracy score: 0.721800\n",
      "[{'val_loss': 4.608125686645508, 'val_acc': 0.009903846308588982}]\n",
      "Epoch [0], last_lr: 0.00005, train_loss: 4.3255, val_loss: 4.0450, val_acc: 0.1327\n",
      "Epoch [1], last_lr: 0.00008, train_loss: 3.8308, val_loss: 3.5495, val_acc: 0.2129\n",
      "Epoch [2], last_lr: 0.00013, train_loss: 3.2541, val_loss: 3.1969, val_acc: 0.2503\n",
      "Epoch [3], last_lr: 0.00020, train_loss: 2.7804, val_loss: 2.9961, val_acc: 0.2810\n",
      "Epoch [4], last_lr: 0.00028, train_loss: 2.4747, val_loss: 2.5068, val_acc: 0.3660\n",
      "Epoch [5], last_lr: 0.00037, train_loss: 2.2254, val_loss: 2.3826, val_acc: 0.3980\n",
      "Epoch [6], last_lr: 0.00047, train_loss: 2.0462, val_loss: 2.1967, val_acc: 0.4263\n",
      "Epoch [7], last_lr: 0.00057, train_loss: 1.8842, val_loss: 2.2990, val_acc: 0.4119\n",
      "Epoch [8], last_lr: 0.00067, train_loss: 1.7713, val_loss: 2.6133, val_acc: 0.3771\n",
      "Epoch [9], last_lr: 0.00076, train_loss: 1.6718, val_loss: 2.2597, val_acc: 0.4273\n",
      "Epoch [10], last_lr: 0.00084, train_loss: 1.5847, val_loss: 2.7821, val_acc: 0.3626\n",
      "Epoch [11], last_lr: 0.00091, train_loss: 1.5105, val_loss: 2.1035, val_acc: 0.4496\n",
      "Epoch [12], last_lr: 0.00096, train_loss: 1.4495, val_loss: 2.1783, val_acc: 0.4484\n",
      "Epoch [13], last_lr: 0.00099, train_loss: 1.3842, val_loss: 1.9671, val_acc: 0.4887\n",
      "Epoch [14], last_lr: 0.00100, train_loss: 1.3111, val_loss: 2.0184, val_acc: 0.4824\n",
      "Epoch [15], last_lr: 0.00100, train_loss: 1.2573, val_loss: 1.9923, val_acc: 0.4885\n",
      "Epoch [16], last_lr: 0.00099, train_loss: 1.1917, val_loss: 1.8413, val_acc: 0.5229\n",
      "Epoch [17], last_lr: 0.00098, train_loss: 1.1393, val_loss: 1.9859, val_acc: 0.4977\n",
      "Epoch [18], last_lr: 0.00097, train_loss: 1.0855, val_loss: 1.9122, val_acc: 0.5192\n",
      "Epoch [19], last_lr: 0.00095, train_loss: 1.0367, val_loss: 1.8526, val_acc: 0.5244\n",
      "Epoch [20], last_lr: 0.00093, train_loss: 0.9906, val_loss: 1.6288, val_acc: 0.5743\n",
      "Epoch [21], last_lr: 0.00090, train_loss: 0.9484, val_loss: 1.8367, val_acc: 0.5344\n",
      "Epoch [22], last_lr: 0.00088, train_loss: 0.9078, val_loss: 1.7346, val_acc: 0.5586\n",
      "Epoch [23], last_lr: 0.00085, train_loss: 0.8589, val_loss: 1.7910, val_acc: 0.5515\n",
      "Epoch [24], last_lr: 0.00081, train_loss: 0.8176, val_loss: 1.9226, val_acc: 0.5238\n",
      "Epoch [25], last_lr: 0.00078, train_loss: 0.7720, val_loss: 1.6896, val_acc: 0.5752\n",
      "Epoch [26], last_lr: 0.00074, train_loss: 0.7337, val_loss: 1.8527, val_acc: 0.5524\n",
      "Epoch [27], last_lr: 0.00070, train_loss: 0.6803, val_loss: 1.6803, val_acc: 0.5823\n",
      "Epoch [28], last_lr: 0.00065, train_loss: 0.6414, val_loss: 1.6305, val_acc: 0.5982\n",
      "Epoch [29], last_lr: 0.00061, train_loss: 0.5914, val_loss: 1.5099, val_acc: 0.6129\n",
      "Epoch [30], last_lr: 0.00057, train_loss: 0.5344, val_loss: 1.5543, val_acc: 0.6189\n",
      "Epoch [31], last_lr: 0.00052, train_loss: 0.4862, val_loss: 1.5032, val_acc: 0.6242\n",
      "Epoch [32], last_lr: 0.00048, train_loss: 0.4414, val_loss: 1.4719, val_acc: 0.6393\n",
      "Epoch [33], last_lr: 0.00043, train_loss: 0.3941, val_loss: 1.5845, val_acc: 0.6186\n",
      "Epoch [34], last_lr: 0.00039, train_loss: 0.3490, val_loss: 1.4796, val_acc: 0.6411\n",
      "Epoch [35], last_lr: 0.00035, train_loss: 0.2975, val_loss: 1.4655, val_acc: 0.6456\n",
      "Epoch [36], last_lr: 0.00030, train_loss: 0.2538, val_loss: 1.3908, val_acc: 0.6604\n",
      "Epoch [37], last_lr: 0.00026, train_loss: 0.2099, val_loss: 1.3810, val_acc: 0.6776\n",
      "Epoch [38], last_lr: 0.00022, train_loss: 0.1637, val_loss: 1.3534, val_acc: 0.6872\n",
      "Epoch [39], last_lr: 0.00019, train_loss: 0.1303, val_loss: 1.3117, val_acc: 0.6971\n",
      "Epoch [40], last_lr: 0.00015, train_loss: 0.0992, val_loss: 1.2966, val_acc: 0.7006\n",
      "Epoch [41], last_lr: 0.00012, train_loss: 0.0771, val_loss: 1.2696, val_acc: 0.7061\n",
      "Epoch [42], last_lr: 0.00010, train_loss: 0.0604, val_loss: 1.2521, val_acc: 0.7162\n",
      "Epoch [43], last_lr: 0.00007, train_loss: 0.0458, val_loss: 1.2269, val_acc: 0.7208\n",
      "Epoch [44], last_lr: 0.00005, train_loss: 0.0369, val_loss: 1.2301, val_acc: 0.7219\n",
      "Epoch [45], last_lr: 0.00003, train_loss: 0.0300, val_loss: 1.2207, val_acc: 0.7267\n",
      "Epoch [46], last_lr: 0.00002, train_loss: 0.0263, val_loss: 1.2164, val_acc: 0.7291\n",
      "Epoch [47], last_lr: 0.00001, train_loss: 0.0236, val_loss: 1.2130, val_acc: 0.7290\n",
      "Epoch [48], last_lr: 0.00000, train_loss: 0.0212, val_loss: 1.2137, val_acc: 0.7290\n",
      "Epoch [49], last_lr: 0.00000, train_loss: 0.0212, val_loss: 1.2133, val_acc: 0.7295\n",
      "Accuracy score: 0.728800\n",
      "[{'val_loss': 4.607626914978027, 'val_acc': 0.009903847239911556}]\n",
      "Epoch [0], last_lr: 0.00005, train_loss: 4.2731, val_loss: 3.9802, val_acc: 0.1330\n",
      "Epoch [1], last_lr: 0.00008, train_loss: 3.7505, val_loss: 3.4747, val_acc: 0.2140\n",
      "Epoch [2], last_lr: 0.00013, train_loss: 3.1904, val_loss: 3.1079, val_acc: 0.2563\n",
      "Epoch [3], last_lr: 0.00020, train_loss: 2.7352, val_loss: 2.7074, val_acc: 0.3299\n",
      "Epoch [4], last_lr: 0.00028, train_loss: 2.4093, val_loss: 2.4893, val_acc: 0.3675\n",
      "Epoch [5], last_lr: 0.00037, train_loss: 2.1760, val_loss: 2.4233, val_acc: 0.3808\n",
      "Epoch [6], last_lr: 0.00047, train_loss: 2.0015, val_loss: 2.4536, val_acc: 0.3846\n",
      "Epoch [7], last_lr: 0.00057, train_loss: 1.8566, val_loss: 2.2663, val_acc: 0.4239\n",
      "Epoch [8], last_lr: 0.00067, train_loss: 1.7354, val_loss: 2.0178, val_acc: 0.4673\n",
      "Epoch [9], last_lr: 0.00076, train_loss: 1.6509, val_loss: 2.1276, val_acc: 0.4527\n",
      "Epoch [10], last_lr: 0.00084, train_loss: 1.5690, val_loss: 2.0720, val_acc: 0.4588\n",
      "Epoch [11], last_lr: 0.00091, train_loss: 1.4945, val_loss: 2.2025, val_acc: 0.4350\n",
      "Epoch [12], last_lr: 0.00096, train_loss: 1.4325, val_loss: 2.2172, val_acc: 0.4240\n",
      "Epoch [13], last_lr: 0.00099, train_loss: 1.3721, val_loss: 2.0526, val_acc: 0.4737\n",
      "Epoch [14], last_lr: 0.00100, train_loss: 1.3075, val_loss: 1.9869, val_acc: 0.4889\n",
      "Epoch [15], last_lr: 0.00100, train_loss: 1.2389, val_loss: 1.7583, val_acc: 0.5285\n",
      "Epoch [16], last_lr: 0.00099, train_loss: 1.1902, val_loss: 1.8956, val_acc: 0.5028\n",
      "Epoch [17], last_lr: 0.00098, train_loss: 1.1306, val_loss: 1.8668, val_acc: 0.5170\n",
      "Epoch [18], last_lr: 0.00097, train_loss: 1.0788, val_loss: 1.7043, val_acc: 0.5510\n",
      "Epoch [19], last_lr: 0.00095, train_loss: 1.0367, val_loss: 1.6671, val_acc: 0.5572\n",
      "Epoch [20], last_lr: 0.00093, train_loss: 0.9905, val_loss: 1.7567, val_acc: 0.5399\n",
      "Epoch [21], last_lr: 0.00090, train_loss: 0.9317, val_loss: 1.6419, val_acc: 0.5631\n",
      "Epoch [22], last_lr: 0.00088, train_loss: 0.9015, val_loss: 1.8580, val_acc: 0.5248\n",
      "Epoch [23], last_lr: 0.00085, train_loss: 0.8606, val_loss: 2.0509, val_acc: 0.4977\n",
      "Epoch [24], last_lr: 0.00081, train_loss: 0.8131, val_loss: 1.7016, val_acc: 0.5637\n",
      "Epoch [25], last_lr: 0.00078, train_loss: 0.7679, val_loss: 1.7090, val_acc: 0.5636\n",
      "Epoch [26], last_lr: 0.00074, train_loss: 0.7188, val_loss: 1.6778, val_acc: 0.5683\n",
      "Epoch [27], last_lr: 0.00070, train_loss: 0.6768, val_loss: 1.6570, val_acc: 0.5865\n",
      "Epoch [28], last_lr: 0.00065, train_loss: 0.6185, val_loss: 1.6324, val_acc: 0.5971\n",
      "Epoch [29], last_lr: 0.00061, train_loss: 0.5814, val_loss: 1.4785, val_acc: 0.6138\n",
      "Epoch [30], last_lr: 0.00057, train_loss: 0.5367, val_loss: 1.5537, val_acc: 0.6084\n",
      "Epoch [31], last_lr: 0.00052, train_loss: 0.4878, val_loss: 1.4941, val_acc: 0.6321\n",
      "Epoch [32], last_lr: 0.00048, train_loss: 0.4427, val_loss: 1.4976, val_acc: 0.6277\n",
      "Epoch [33], last_lr: 0.00043, train_loss: 0.3877, val_loss: 1.4914, val_acc: 0.6332\n",
      "Epoch [34], last_lr: 0.00039, train_loss: 0.3369, val_loss: 1.5107, val_acc: 0.6412\n",
      "Epoch [35], last_lr: 0.00035, train_loss: 0.2906, val_loss: 1.4582, val_acc: 0.6484\n",
      "Epoch [36], last_lr: 0.00030, train_loss: 0.2518, val_loss: 1.3288, val_acc: 0.6762\n",
      "Epoch [37], last_lr: 0.00026, train_loss: 0.1964, val_loss: 1.3526, val_acc: 0.6791\n",
      "Epoch [38], last_lr: 0.00022, train_loss: 0.1633, val_loss: 1.3459, val_acc: 0.6791\n",
      "Epoch [39], last_lr: 0.00019, train_loss: 0.1256, val_loss: 1.2730, val_acc: 0.6963\n",
      "Epoch [40], last_lr: 0.00015, train_loss: 0.1017, val_loss: 1.2514, val_acc: 0.7088\n",
      "Epoch [41], last_lr: 0.00012, train_loss: 0.0719, val_loss: 1.2117, val_acc: 0.7198\n",
      "Epoch [42], last_lr: 0.00010, train_loss: 0.0557, val_loss: 1.2117, val_acc: 0.7245\n",
      "Epoch [43], last_lr: 0.00007, train_loss: 0.0438, val_loss: 1.1932, val_acc: 0.7283\n",
      "Epoch [44], last_lr: 0.00005, train_loss: 0.0340, val_loss: 1.1885, val_acc: 0.7296\n",
      "Epoch [45], last_lr: 0.00003, train_loss: 0.0281, val_loss: 1.1780, val_acc: 0.7351\n",
      "Epoch [46], last_lr: 0.00002, train_loss: 0.0249, val_loss: 1.1820, val_acc: 0.7335\n",
      "Epoch [47], last_lr: 0.00001, train_loss: 0.0221, val_loss: 1.1781, val_acc: 0.7353\n",
      "Epoch [48], last_lr: 0.00000, train_loss: 0.0203, val_loss: 1.1778, val_acc: 0.7368\n",
      "Epoch [49], last_lr: 0.00000, train_loss: 0.0205, val_loss: 1.1783, val_acc: 0.7368\n",
      "Accuracy score: 0.736100\n",
      "[{'val_loss': 4.6079864501953125, 'val_acc': 0.010384614579379559}]\n",
      "Epoch [0], last_lr: 0.00005, train_loss: 4.2420, val_loss: 3.9114, val_acc: 0.1497\n",
      "Epoch [1], last_lr: 0.00008, train_loss: 3.6499, val_loss: 3.3964, val_acc: 0.2280\n",
      "Epoch [2], last_lr: 0.00013, train_loss: 3.1022, val_loss: 2.9041, val_acc: 0.3004\n",
      "Epoch [3], last_lr: 0.00020, train_loss: 2.6987, val_loss: 2.8801, val_acc: 0.2918\n",
      "Epoch [4], last_lr: 0.00028, train_loss: 2.4178, val_loss: 2.5171, val_acc: 0.3590\n",
      "Epoch [5], last_lr: 0.00037, train_loss: 2.2057, val_loss: 2.2883, val_acc: 0.4036\n",
      "Epoch [6], last_lr: 0.00047, train_loss: 2.0240, val_loss: 2.3140, val_acc: 0.3982\n",
      "Epoch [7], last_lr: 0.00057, train_loss: 1.8710, val_loss: 2.2488, val_acc: 0.4119\n",
      "Epoch [8], last_lr: 0.00067, train_loss: 1.7583, val_loss: 2.0935, val_acc: 0.4477\n",
      "Epoch [9], last_lr: 0.00076, train_loss: 1.6595, val_loss: 2.2013, val_acc: 0.4352\n",
      "Epoch [10], last_lr: 0.00084, train_loss: 1.5706, val_loss: 2.1148, val_acc: 0.4540\n",
      "Epoch [11], last_lr: 0.00091, train_loss: 1.4986, val_loss: 1.9925, val_acc: 0.4715\n",
      "Epoch [12], last_lr: 0.00096, train_loss: 1.4317, val_loss: 2.4258, val_acc: 0.4033\n",
      "Epoch [13], last_lr: 0.00099, train_loss: 1.3696, val_loss: 1.8216, val_acc: 0.5044\n",
      "Epoch [14], last_lr: 0.00100, train_loss: 1.3018, val_loss: 2.0366, val_acc: 0.4643\n",
      "Epoch [15], last_lr: 0.00100, train_loss: 1.2377, val_loss: 1.8643, val_acc: 0.5029\n",
      "Epoch [16], last_lr: 0.00099, train_loss: 1.1878, val_loss: 1.8591, val_acc: 0.4982\n",
      "Epoch [17], last_lr: 0.00098, train_loss: 1.1279, val_loss: 1.8527, val_acc: 0.5119\n",
      "Epoch [18], last_lr: 0.00097, train_loss: 1.0801, val_loss: 1.7777, val_acc: 0.5225\n",
      "Epoch [19], last_lr: 0.00095, train_loss: 1.0340, val_loss: 1.9307, val_acc: 0.4972\n",
      "Epoch [20], last_lr: 0.00093, train_loss: 0.9837, val_loss: 1.7105, val_acc: 0.5412\n",
      "Epoch [21], last_lr: 0.00090, train_loss: 0.9330, val_loss: 1.6593, val_acc: 0.5580\n",
      "Epoch [22], last_lr: 0.00088, train_loss: 0.8976, val_loss: 1.7348, val_acc: 0.5420\n",
      "Epoch [23], last_lr: 0.00085, train_loss: 0.8517, val_loss: 1.8505, val_acc: 0.5403\n",
      "Epoch [24], last_lr: 0.00081, train_loss: 0.8069, val_loss: 1.7146, val_acc: 0.5572\n",
      "Epoch [25], last_lr: 0.00078, train_loss: 0.7580, val_loss: 1.6564, val_acc: 0.5662\n",
      "Epoch [26], last_lr: 0.00074, train_loss: 0.7147, val_loss: 1.6358, val_acc: 0.5727\n",
      "Epoch [27], last_lr: 0.00070, train_loss: 0.6771, val_loss: 1.5713, val_acc: 0.5896\n",
      "Epoch [28], last_lr: 0.00065, train_loss: 0.6292, val_loss: 1.5512, val_acc: 0.6052\n",
      "Epoch [29], last_lr: 0.00061, train_loss: 0.5825, val_loss: 1.6301, val_acc: 0.5923\n",
      "Epoch [30], last_lr: 0.00057, train_loss: 0.5350, val_loss: 1.5553, val_acc: 0.6142\n",
      "Epoch [31], last_lr: 0.00052, train_loss: 0.4853, val_loss: 1.4790, val_acc: 0.6298\n",
      "Epoch [32], last_lr: 0.00048, train_loss: 0.4355, val_loss: 1.4672, val_acc: 0.6403\n",
      "Epoch [33], last_lr: 0.00043, train_loss: 0.3825, val_loss: 1.5122, val_acc: 0.6394\n",
      "Epoch [34], last_lr: 0.00039, train_loss: 0.3421, val_loss: 1.5103, val_acc: 0.6379\n",
      "Epoch [35], last_lr: 0.00035, train_loss: 0.2845, val_loss: 1.3696, val_acc: 0.6714\n",
      "Epoch [36], last_lr: 0.00030, train_loss: 0.2467, val_loss: 1.3423, val_acc: 0.6759\n",
      "Epoch [37], last_lr: 0.00026, train_loss: 0.2065, val_loss: 1.3240, val_acc: 0.6855\n",
      "Epoch [38], last_lr: 0.00022, train_loss: 0.1661, val_loss: 1.3063, val_acc: 0.6920\n",
      "Epoch [39], last_lr: 0.00019, train_loss: 0.1304, val_loss: 1.3054, val_acc: 0.6985\n",
      "Epoch [40], last_lr: 0.00015, train_loss: 0.0988, val_loss: 1.2617, val_acc: 0.7053\n",
      "Epoch [41], last_lr: 0.00012, train_loss: 0.0800, val_loss: 1.2515, val_acc: 0.7082\n",
      "Epoch [42], last_lr: 0.00010, train_loss: 0.0600, val_loss: 1.2199, val_acc: 0.7178\n",
      "Epoch [43], last_lr: 0.00007, train_loss: 0.0470, val_loss: 1.1969, val_acc: 0.7244\n",
      "Epoch [44], last_lr: 0.00005, train_loss: 0.0380, val_loss: 1.1838, val_acc: 0.7255\n",
      "Epoch [45], last_lr: 0.00003, train_loss: 0.0308, val_loss: 1.1776, val_acc: 0.7285\n",
      "Epoch [46], last_lr: 0.00002, train_loss: 0.0263, val_loss: 1.1742, val_acc: 0.7309\n",
      "Epoch [47], last_lr: 0.00001, train_loss: 0.0230, val_loss: 1.1771, val_acc: 0.7309\n",
      "Epoch [48], last_lr: 0.00000, train_loss: 0.0219, val_loss: 1.1759, val_acc: 0.7313\n",
      "Epoch [49], last_lr: 0.00000, train_loss: 0.0206, val_loss: 1.1752, val_acc: 0.7307\n",
      "Accuracy score: 0.729900\n",
      "[{'val_loss': 4.607424736022949, 'val_acc': 0.009999999776482582}]\n",
      "Epoch [0], last_lr: 0.00005, train_loss: 4.1711, val_loss: 3.8110, val_acc: 0.1584\n",
      "Epoch [1], last_lr: 0.00008, train_loss: 3.5423, val_loss: 3.2195, val_acc: 0.2473\n",
      "Epoch [2], last_lr: 0.00013, train_loss: 2.9497, val_loss: 2.7774, val_acc: 0.3182\n",
      "Epoch [3], last_lr: 0.00020, train_loss: 2.5677, val_loss: 2.5920, val_acc: 0.3493\n",
      "Epoch [4], last_lr: 0.00028, train_loss: 2.2945, val_loss: 2.3704, val_acc: 0.3870\n",
      "Epoch [5], last_lr: 0.00037, train_loss: 2.1045, val_loss: 2.1248, val_acc: 0.4338\n",
      "Epoch [6], last_lr: 0.00047, train_loss: 1.9411, val_loss: 2.1159, val_acc: 0.4407\n",
      "Epoch [7], last_lr: 0.00057, train_loss: 1.8036, val_loss: 2.0053, val_acc: 0.4678\n",
      "Epoch [8], last_lr: 0.00067, train_loss: 1.7026, val_loss: 2.0796, val_acc: 0.4528\n",
      "Epoch [9], last_lr: 0.00076, train_loss: 1.6127, val_loss: 2.0949, val_acc: 0.4509\n",
      "Epoch [10], last_lr: 0.00084, train_loss: 1.5301, val_loss: 1.9516, val_acc: 0.4783\n",
      "Epoch [11], last_lr: 0.00091, train_loss: 1.4568, val_loss: 2.2457, val_acc: 0.4343\n",
      "Epoch [12], last_lr: 0.00096, train_loss: 1.4026, val_loss: 2.1226, val_acc: 0.4505\n",
      "Epoch [13], last_lr: 0.00099, train_loss: 1.3336, val_loss: 2.1073, val_acc: 0.4483\n",
      "Epoch [14], last_lr: 0.00100, train_loss: 1.2852, val_loss: 1.8729, val_acc: 0.5048\n",
      "Epoch [15], last_lr: 0.00100, train_loss: 1.2143, val_loss: 2.0572, val_acc: 0.4667\n",
      "Epoch [16], last_lr: 0.00099, train_loss: 1.1706, val_loss: 2.0036, val_acc: 0.4798\n",
      "Epoch [17], last_lr: 0.00098, train_loss: 1.1104, val_loss: 1.9457, val_acc: 0.4956\n",
      "Epoch [18], last_lr: 0.00097, train_loss: 1.0619, val_loss: 1.8399, val_acc: 0.5098\n",
      "Epoch [19], last_lr: 0.00095, train_loss: 1.0136, val_loss: 1.9089, val_acc: 0.4964\n",
      "Epoch [20], last_lr: 0.00093, train_loss: 0.9731, val_loss: 1.7979, val_acc: 0.5289\n",
      "Epoch [21], last_lr: 0.00090, train_loss: 0.9316, val_loss: 1.8406, val_acc: 0.5231\n",
      "Epoch [22], last_lr: 0.00088, train_loss: 0.8819, val_loss: 1.8203, val_acc: 0.5212\n",
      "Epoch [23], last_lr: 0.00085, train_loss: 0.8389, val_loss: 1.7117, val_acc: 0.5597\n",
      "Epoch [24], last_lr: 0.00081, train_loss: 0.8006, val_loss: 1.8306, val_acc: 0.5457\n",
      "Epoch [25], last_lr: 0.00078, train_loss: 0.7539, val_loss: 1.5815, val_acc: 0.5840\n",
      "Epoch [26], last_lr: 0.00074, train_loss: 0.7041, val_loss: 1.5926, val_acc: 0.5864\n",
      "Epoch [27], last_lr: 0.00070, train_loss: 0.6622, val_loss: 1.8104, val_acc: 0.5638\n",
      "Epoch [28], last_lr: 0.00065, train_loss: 0.6246, val_loss: 1.6237, val_acc: 0.5888\n",
      "Epoch [29], last_lr: 0.00061, train_loss: 0.5745, val_loss: 1.6960, val_acc: 0.5859\n",
      "Epoch [30], last_lr: 0.00057, train_loss: 0.5319, val_loss: 1.4616, val_acc: 0.6257\n",
      "Epoch [31], last_lr: 0.00052, train_loss: 0.4780, val_loss: 1.6027, val_acc: 0.6130\n",
      "Epoch [32], last_lr: 0.00048, train_loss: 0.4308, val_loss: 1.5099, val_acc: 0.6274\n",
      "Epoch [33], last_lr: 0.00043, train_loss: 0.3854, val_loss: 1.4285, val_acc: 0.6389\n",
      "Epoch [34], last_lr: 0.00039, train_loss: 0.3314, val_loss: 1.5776, val_acc: 0.6137\n",
      "Epoch [35], last_lr: 0.00035, train_loss: 0.2887, val_loss: 1.5187, val_acc: 0.6378\n",
      "Epoch [36], last_lr: 0.00030, train_loss: 0.2439, val_loss: 1.4733, val_acc: 0.6532\n",
      "Epoch [37], last_lr: 0.00026, train_loss: 0.1999, val_loss: 1.3186, val_acc: 0.6776\n",
      "Epoch [38], last_lr: 0.00022, train_loss: 0.1627, val_loss: 1.3518, val_acc: 0.6753\n",
      "Epoch [39], last_lr: 0.00019, train_loss: 0.1232, val_loss: 1.3033, val_acc: 0.7009\n",
      "Epoch [40], last_lr: 0.00015, train_loss: 0.0991, val_loss: 1.2393, val_acc: 0.7132\n",
      "Epoch [41], last_lr: 0.00012, train_loss: 0.0731, val_loss: 1.2303, val_acc: 0.7127\n",
      "Epoch [42], last_lr: 0.00010, train_loss: 0.0553, val_loss: 1.1949, val_acc: 0.7213\n",
      "Epoch [43], last_lr: 0.00007, train_loss: 0.0450, val_loss: 1.1873, val_acc: 0.7275\n",
      "Epoch [44], last_lr: 0.00005, train_loss: 0.0353, val_loss: 1.1760, val_acc: 0.7270\n",
      "Epoch [45], last_lr: 0.00003, train_loss: 0.0282, val_loss: 1.1650, val_acc: 0.7316\n",
      "Epoch [46], last_lr: 0.00002, train_loss: 0.0255, val_loss: 1.1621, val_acc: 0.7329\n",
      "Epoch [47], last_lr: 0.00001, train_loss: 0.0214, val_loss: 1.1595, val_acc: 0.7338\n",
      "Epoch [48], last_lr: 0.00000, train_loss: 0.0212, val_loss: 1.1591, val_acc: 0.7334\n",
      "Epoch [49], last_lr: 0.00000, train_loss: 0.0202, val_loss: 1.1594, val_acc: 0.7335\n",
      "Accuracy score: 0.731900\n",
      "[{'val_loss': 4.606997013092041, 'val_acc': 0.011634614318609238}]\n",
      "Epoch [0], last_lr: 0.00005, train_loss: 4.1246, val_loss: 3.7498, val_acc: 0.1677\n",
      "Epoch [1], last_lr: 0.00008, train_loss: 3.4577, val_loss: 3.1492, val_acc: 0.2547\n",
      "Epoch [2], last_lr: 0.00013, train_loss: 2.9048, val_loss: 2.7579, val_acc: 0.3110\n",
      "Epoch [3], last_lr: 0.00020, train_loss: 2.5520, val_loss: 2.5740, val_acc: 0.3479\n",
      "Epoch [4], last_lr: 0.00028, train_loss: 2.3134, val_loss: 2.3987, val_acc: 0.3796\n",
      "Epoch [5], last_lr: 0.00037, train_loss: 2.1006, val_loss: 2.2568, val_acc: 0.4039\n",
      "Epoch [6], last_lr: 0.00047, train_loss: 1.9353, val_loss: 2.2287, val_acc: 0.4135\n",
      "Epoch [7], last_lr: 0.00057, train_loss: 1.8067, val_loss: 2.2045, val_acc: 0.4181\n",
      "Epoch [8], last_lr: 0.00067, train_loss: 1.6898, val_loss: 2.1580, val_acc: 0.4273\n",
      "Epoch [9], last_lr: 0.00076, train_loss: 1.6025, val_loss: 2.4241, val_acc: 0.4158\n",
      "Epoch [10], last_lr: 0.00084, train_loss: 1.5150, val_loss: 2.5441, val_acc: 0.3829\n",
      "Epoch [11], last_lr: 0.00091, train_loss: 1.4506, val_loss: 2.0065, val_acc: 0.4687\n",
      "Epoch [12], last_lr: 0.00096, train_loss: 1.3958, val_loss: 1.8630, val_acc: 0.4967\n",
      "Epoch [13], last_lr: 0.00099, train_loss: 1.3249, val_loss: 2.0789, val_acc: 0.4675\n",
      "Epoch [14], last_lr: 0.00100, train_loss: 1.2699, val_loss: 2.0006, val_acc: 0.4779\n",
      "Epoch [15], last_lr: 0.00100, train_loss: 1.2139, val_loss: 1.9922, val_acc: 0.4761\n",
      "Epoch [16], last_lr: 0.00099, train_loss: 1.1572, val_loss: 1.9019, val_acc: 0.4996\n",
      "Epoch [17], last_lr: 0.00098, train_loss: 1.1079, val_loss: 1.7906, val_acc: 0.5283\n",
      "Epoch [18], last_lr: 0.00097, train_loss: 1.0472, val_loss: 2.1082, val_acc: 0.4653\n",
      "Epoch [19], last_lr: 0.00095, train_loss: 1.0041, val_loss: 1.8779, val_acc: 0.5052\n",
      "Epoch [20], last_lr: 0.00093, train_loss: 0.9619, val_loss: 2.0160, val_acc: 0.4843\n",
      "Epoch [21], last_lr: 0.00090, train_loss: 0.9259, val_loss: 1.8060, val_acc: 0.5353\n",
      "Epoch [22], last_lr: 0.00088, train_loss: 0.8735, val_loss: 1.7978, val_acc: 0.5417\n",
      "Epoch [23], last_lr: 0.00085, train_loss: 0.8291, val_loss: 1.6706, val_acc: 0.5649\n",
      "Epoch [24], last_lr: 0.00081, train_loss: 0.7936, val_loss: 1.6625, val_acc: 0.5690\n",
      "Epoch [25], last_lr: 0.00078, train_loss: 0.7500, val_loss: 1.5985, val_acc: 0.5834\n",
      "Epoch [26], last_lr: 0.00074, train_loss: 0.7091, val_loss: 1.6638, val_acc: 0.5729\n",
      "Epoch [27], last_lr: 0.00070, train_loss: 0.6649, val_loss: 1.5945, val_acc: 0.5880\n",
      "Epoch [28], last_lr: 0.00065, train_loss: 0.6232, val_loss: 1.5674, val_acc: 0.5959\n",
      "Epoch [29], last_lr: 0.00061, train_loss: 0.5674, val_loss: 1.6506, val_acc: 0.5959\n",
      "Epoch [30], last_lr: 0.00057, train_loss: 0.5239, val_loss: 1.5978, val_acc: 0.5973\n",
      "Epoch [31], last_lr: 0.00052, train_loss: 0.4672, val_loss: 1.5395, val_acc: 0.6294\n",
      "Epoch [32], last_lr: 0.00048, train_loss: 0.4207, val_loss: 1.5350, val_acc: 0.6241\n",
      "Epoch [33], last_lr: 0.00043, train_loss: 0.3796, val_loss: 1.4455, val_acc: 0.6513\n",
      "Epoch [34], last_lr: 0.00039, train_loss: 0.3281, val_loss: 1.4938, val_acc: 0.6435\n",
      "Epoch [35], last_lr: 0.00035, train_loss: 0.2800, val_loss: 1.4642, val_acc: 0.6528\n",
      "Epoch [36], last_lr: 0.00030, train_loss: 0.2383, val_loss: 1.4053, val_acc: 0.6699\n",
      "Epoch [37], last_lr: 0.00026, train_loss: 0.1940, val_loss: 1.3775, val_acc: 0.6784\n",
      "Epoch [38], last_lr: 0.00022, train_loss: 0.1565, val_loss: 1.3207, val_acc: 0.6899\n",
      "Epoch [39], last_lr: 0.00019, train_loss: 0.1241, val_loss: 1.2743, val_acc: 0.6961\n",
      "Epoch [40], last_lr: 0.00015, train_loss: 0.0962, val_loss: 1.2401, val_acc: 0.7082\n",
      "Epoch [41], last_lr: 0.00012, train_loss: 0.0730, val_loss: 1.2252, val_acc: 0.7190\n",
      "Epoch [42], last_lr: 0.00010, train_loss: 0.0541, val_loss: 1.2044, val_acc: 0.7225\n",
      "Epoch [43], last_lr: 0.00007, train_loss: 0.0439, val_loss: 1.1839, val_acc: 0.7226\n",
      "Epoch [44], last_lr: 0.00005, train_loss: 0.0333, val_loss: 1.1769, val_acc: 0.7283\n",
      "Epoch [45], last_lr: 0.00003, train_loss: 0.0272, val_loss: 1.1832, val_acc: 0.7293\n",
      "Epoch [46], last_lr: 0.00002, train_loss: 0.0239, val_loss: 1.1729, val_acc: 0.7321\n",
      "Epoch [47], last_lr: 0.00001, train_loss: 0.0215, val_loss: 1.1692, val_acc: 0.7333\n",
      "Epoch [48], last_lr: 0.00000, train_loss: 0.0203, val_loss: 1.1694, val_acc: 0.7331\n",
      "Epoch [49], last_lr: 0.00000, train_loss: 0.0205, val_loss: 1.1696, val_acc: 0.7330\n",
      "Accuracy score: 0.733100\n"
     ]
    }
   ],
   "source": [
    "for d in d_list:\n",
    "    model = ResNet9(3, 100)\n",
    "    if d==0:\n",
    "        model.classifier = nn.Sequential(nn.MaxPool2d(2), # 1028 x 1 x 1\n",
    "                                nn.Flatten(), # 1028 \n",
    "                                nn.Linear(1028, 100)\n",
    "                                ) # 1028 -> 100\n",
    "    else:\n",
    "        model.classifier = nn.Sequential(nn.MaxPool2d(2), # 1028 x 1 x 1\n",
    "                                    nn.Flatten(), # 1028 \n",
    "                                    nn.Linear(1028, d),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(d, 100),\n",
    "                                    ) # 1028 -> 100\n",
    "\n",
    "    model = to_device(model, device)\n",
    "    history = [evaluate(model, testloader)]\n",
    "    print(history)\n",
    "    history+=fit_one_cycle(50, max_lr, model, trainloader, testloader, \n",
    "                                grad_clip=grad_clip, \n",
    "                                weight_decay=weight_decay, \n",
    "                                opt_func=opt_func)\n",
    "    y_test, y_pred = test_label_predictions(model, device, testloader)\n",
    "    ac=accuracy_score(y_test, y_pred)\n",
    "    print('Accuracy score: %f' % ac)\n",
    "    accuracy_list.append(ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7434,\n",
       " 0.6636,\n",
       " 0.7087,\n",
       " 0.7165,\n",
       " 0.7218,\n",
       " 0.7288,\n",
       " 0.7361,\n",
       " 0.7299,\n",
       " 0.7319,\n",
       " 0.7331]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # x axis values \n",
    "# x = [1,2,3,4,5,6] \n",
    "# # corresponding y axis values \n",
    "# y = [2,4,1,5,2,6] \n",
    "  \n",
    "# plotting the points  \n",
    "plt.plot(d_list, accuracy_list, color='green', linestyle='dashed', linewidth = 3, \n",
    "         marker='o', markerfacecolor='blue', markersize=12) \n",
    "  \n",
    "# setting x and y axis range \n",
    "plt.ylim(1,8) \n",
    "plt.xlim(1,8) \n",
    "  \n",
    "# naming the x axis \n",
    "plt.xlabel('D (number of neurons in the introduced layer)') \n",
    "# naming the y axis \n",
    "plt.ylabel('Accuracy') \n",
    "  \n",
    "# giving a title to my graph \n",
    "plt.title('Accuracy vs D') \n",
    "  \n",
    "# function to show the plot \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7434, 0.6636, 0.7087, 0.7165, 0.7218, 0.7288, 0.7361, 0.7299, 0.7319, 0.7331]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(d_list, accuracy_list, color='green', linestyle='dashed', linewidth = 3, \n",
    "         marker='o', markerfacecolor='blue', markersize=12) \n",
    "  \n",
    "# setting x and y axis range \n",
    "  \n",
    "# naming the x axis \n",
    "plt.xlabel('D (number of neurons in the introduced layer)') \n",
    "# naming the y axis \n",
    "plt.ylabel('Accuracy') \n",
    "  \n",
    "# giving a title to my graph \n",
    "plt.title('Accuracy vs D') \n",
    "  \n",
    "# function to show the plot \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 4.612682342529297, 'val_acc': 0.009999999776482582}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial evaluation\n",
    "history = [evaluate(model, testloader)]\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], last_lr: 0.00007, train_loss: 4.3989, val_loss: 4.2552, val_acc: 0.0811\n",
      "Epoch [1], last_lr: 0.00015, train_loss: 4.1657, val_loss: 4.0262, val_acc: 0.1381\n",
      "Epoch [2], last_lr: 0.00028, train_loss: 3.8679, val_loss: 3.8434, val_acc: 0.1597\n",
      "Epoch [3], last_lr: 0.00044, train_loss: 3.4173, val_loss: 3.3148, val_acc: 0.2367\n",
      "Epoch [4], last_lr: 0.00060, train_loss: 2.9256, val_loss: 2.9982, val_acc: 0.2786\n",
      "Epoch [5], last_lr: 0.00076, train_loss: 2.5708, val_loss: 2.9613, val_acc: 0.2962\n",
      "Epoch [6], last_lr: 0.00089, train_loss: 2.3261, val_loss: 2.8279, val_acc: 0.3090\n",
      "Epoch [7], last_lr: 0.00097, train_loss: 2.1256, val_loss: 2.4450, val_acc: 0.3742\n",
      "Epoch [8], last_lr: 0.00100, train_loss: 1.9623, val_loss: 2.3904, val_acc: 0.3953\n",
      "Epoch [9], last_lr: 0.00099, train_loss: 1.8206, val_loss: 2.6234, val_acc: 0.3569\n",
      "Epoch [10], last_lr: 0.00098, train_loss: 1.7048, val_loss: 2.3221, val_acc: 0.4215\n",
      "Epoch [11], last_lr: 0.00095, train_loss: 1.5919, val_loss: 2.3442, val_acc: 0.4131\n",
      "Epoch [12], last_lr: 0.00091, train_loss: 1.4928, val_loss: 2.2243, val_acc: 0.4378\n",
      "Epoch [13], last_lr: 0.00087, train_loss: 1.4089, val_loss: 1.9792, val_acc: 0.4822\n",
      "Epoch [14], last_lr: 0.00081, train_loss: 1.3191, val_loss: 2.1851, val_acc: 0.4518\n",
      "Epoch [15], last_lr: 0.00075, train_loss: 1.2324, val_loss: 2.5427, val_acc: 0.4184\n",
      "Epoch [16], last_lr: 0.00068, train_loss: 1.1476, val_loss: 2.2144, val_acc: 0.4668\n",
      "Epoch [17], last_lr: 0.00061, train_loss: 1.0520, val_loss: 1.7065, val_acc: 0.5578\n",
      "Epoch [18], last_lr: 0.00054, train_loss: 0.9601, val_loss: 1.8188, val_acc: 0.5354\n",
      "Epoch [19], last_lr: 0.00046, train_loss: 0.8591, val_loss: 1.6464, val_acc: 0.5854\n",
      "Epoch [20], last_lr: 0.00039, train_loss: 0.7646, val_loss: 1.5279, val_acc: 0.6125\n",
      "Epoch [21], last_lr: 0.00032, train_loss: 0.6661, val_loss: 1.5406, val_acc: 0.6143\n",
      "Epoch [22], last_lr: 0.00025, train_loss: 0.5461, val_loss: 1.4783, val_acc: 0.6347\n",
      "Epoch [23], last_lr: 0.00019, train_loss: 0.4456, val_loss: 1.4103, val_acc: 0.6563\n",
      "Epoch [24], last_lr: 0.00013, train_loss: 0.3490, val_loss: 1.3439, val_acc: 0.6690\n",
      "Epoch [25], last_lr: 0.00009, train_loss: 0.2605, val_loss: 1.2963, val_acc: 0.6861\n",
      "Epoch [26], last_lr: 0.00005, train_loss: 0.1981, val_loss: 1.2584, val_acc: 0.6965\n",
      "Epoch [27], last_lr: 0.00002, train_loss: 0.1534, val_loss: 1.2457, val_acc: 0.7043\n",
      "Epoch [28], last_lr: 0.00001, train_loss: 0.1273, val_loss: 1.2498, val_acc: 0.7066\n",
      "Epoch [29], last_lr: 0.00000, train_loss: 0.1155, val_loss: 1.2517, val_acc: 0.7062\n"
     ]
    }
   ],
   "source": [
    "# Fitting the first 1/4 epochs\n",
    "current_time=time.time()\n",
    "history += fit_one_cycle(int(epochs/4), max_lr, model, trainloader, testloader, \n",
    "                             grad_clip=grad_clip, \n",
    "                             weight_decay=weight_decay, \n",
    "                             opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the second 1/4 epochs\n",
    "# history += fit_one_cycle(int(epochs/4), max_lr/10, model, trainloader, testloader, \n",
    "#                              grad_clip=grad_clip, \n",
    "#                              weight_decay=weight_decay, \n",
    "#                              opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              ReLU-3           [-1, 64, 32, 32]               0\n",
      "            Conv2d-4          [-1, 128, 32, 32]          73,856\n",
      "       BatchNorm2d-5          [-1, 128, 32, 32]             256\n",
      "              ReLU-6          [-1, 128, 32, 32]               0\n",
      "         MaxPool2d-7          [-1, 128, 16, 16]               0\n",
      "            Conv2d-8          [-1, 128, 16, 16]         147,584\n",
      "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
      "             ReLU-10          [-1, 128, 16, 16]               0\n",
      "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
      "             ReLU-13          [-1, 128, 16, 16]               0\n",
      "           Conv2d-14          [-1, 256, 16, 16]         295,168\n",
      "      BatchNorm2d-15          [-1, 256, 16, 16]             512\n",
      "             ReLU-16          [-1, 256, 16, 16]               0\n",
      "        MaxPool2d-17            [-1, 256, 8, 8]               0\n",
      "           Conv2d-18            [-1, 512, 8, 8]       1,180,160\n",
      "      BatchNorm2d-19            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-20            [-1, 512, 8, 8]               0\n",
      "        MaxPool2d-21            [-1, 512, 4, 4]               0\n",
      "           Conv2d-22            [-1, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-23            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-24            [-1, 512, 4, 4]               0\n",
      "           Conv2d-25            [-1, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-27            [-1, 512, 4, 4]               0\n",
      "           Conv2d-28           [-1, 1028, 4, 4]       4,738,052\n",
      "      BatchNorm2d-29           [-1, 1028, 4, 4]           2,056\n",
      "             ReLU-30           [-1, 1028, 4, 4]               0\n",
      "        MaxPool2d-31           [-1, 1028, 2, 2]               0\n",
      "           Conv2d-32           [-1, 1028, 2, 2]       9,512,084\n",
      "      BatchNorm2d-33           [-1, 1028, 2, 2]           2,056\n",
      "             ReLU-34           [-1, 1028, 2, 2]               0\n",
      "           Conv2d-35           [-1, 1028, 2, 2]       9,512,084\n",
      "      BatchNorm2d-36           [-1, 1028, 2, 2]           2,056\n",
      "             ReLU-37           [-1, 1028, 2, 2]               0\n",
      "        MaxPool2d-38           [-1, 1028, 1, 1]               0\n",
      "          Flatten-39                 [-1, 1028]               0\n",
      "           Linear-40                   [-1, 20]          20,580\n",
      "             ReLU-41                   [-1, 20]               0\n",
      "           Linear-42                  [-1, 100]           2,100\n",
      "================================================================\n",
      "Total params: 30,361,308\n",
      "Trainable params: 30,361,308\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 9.68\n",
      "Params size (MB): 115.82\n",
      "Estimated Total Size (MB): 125.51\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(summary(model,(3, 32, 32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
