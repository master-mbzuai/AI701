{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.utils import download_url, check_integrity\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as tt\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import *\n",
    "from torchsummary import summary\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import errno\n",
    "import sys\n",
    "if sys.version_info[0] == 2:\n",
    "    import cPickle as pickle\n",
    "else:\n",
    "    import pickle\n",
    "\n",
    "import torch.utils.data as data\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "class CIFAR10(data.Dataset):\n",
    "    \"\"\"`CIFAR10 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where directory\n",
    "            ``cifar-10-batches-py`` exists.\n",
    "        train (bool, optional): If True, creates dataset from training set, otherwise\n",
    "            creates from test set.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "    \"\"\"\n",
    "    base_folder = 'cifar-10-batches-py'\n",
    "    url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "    filename = \"cifar-10-python.tar.gz\"\n",
    "    tgz_md5 = 'c58f30108f718f92721af3b95e74349a'\n",
    "    train_list = [\n",
    "        ['data_batch_1', 'c99cafc152244af753f735de768cd75f'],\n",
    "        ['data_batch_2', 'd4bba439e000b95fd0a9bffe97cbabec'],\n",
    "        ['data_batch_3', '54ebc095f3ab1f0389bbae665268c751'],\n",
    "        ['data_batch_4', '634d18415352ddfa80567beed471001a'],\n",
    "        ['data_batch_5', '482c414d41f54cd18b22e5b47cb7c3cb'],\n",
    "    ]\n",
    "\n",
    "    test_list = [\n",
    "        ['test_batch', '40351d587109b95175f43aff81a1287e'],\n",
    "    ]\n",
    "\n",
    "    meta = {\n",
    "        \"filename\": \"batches.meta\",\n",
    "        \"key\": \"label_names\",\n",
    "        \"md5\": \"5ff9c542aee3614f3951f8cda6e48888\",\n",
    "    }\n",
    "\n",
    "\n",
    "    def __init__(self, root, train=True,\n",
    "                 transform=None, target_transform=None,\n",
    "                 download=False, coarse=False, coarseNumber=None):\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train = train  # training set or test set\n",
    "        self.coarse = coarse\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_integrity():\n",
    "            raise RuntimeError('Dataset not found or corrupted.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "        # now load the picked numpy arrays\n",
    "        if self.train:\n",
    "            self.train_data = []\n",
    "            self.train_labels = []\n",
    "            self.train_coarse_labels = []\n",
    "            for fentry in self.train_list:\n",
    "                f = fentry[0]\n",
    "                file = os.path.join(self.root, self.base_folder, f)\n",
    "                fo = open(file, 'rb')\n",
    "                if sys.version_info[0] == 2:\n",
    "                    entry = pickle.load(fo)\n",
    "                else:\n",
    "                    entry = pickle.load(fo, encoding='latin1')\n",
    "                self.train_data.append(entry['data'])\n",
    "                if 'labels' in entry:\n",
    "                    self.train_labels += entry['labels']\n",
    "                else:\n",
    "                    self.train_labels += entry['fine_labels']\n",
    "                    if self.coarse:\n",
    "                        self.train_coarse_labels += entry['coarse_labels']\n",
    "                fo.close()\n",
    "\n",
    "            self.train_data = np.concatenate(self.train_data)\n",
    "            self.train_data = self.train_data.reshape((len(self.train_data), 3, 32, 32))\n",
    "            self.train_data = self.train_data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "        else:\n",
    "            f = self.test_list[0][0]\n",
    "            file = os.path.join(self.root, self.base_folder, f)\n",
    "            fo = open(file, 'rb')\n",
    "            if sys.version_info[0] == 2:\n",
    "                entry = pickle.load(fo)\n",
    "            else:\n",
    "                entry = pickle.load(fo, encoding='latin1')\n",
    "            self.test_data = entry['data']\n",
    "\n",
    "            if 'labels' in entry:\n",
    "                self.test_labels = entry['labels']\n",
    "            else:\n",
    "                self.test_labels = entry['fine_labels']\n",
    "                if self.coarse:\n",
    "                    self.test_coarse_labels = entry['coarse_labels']\n",
    "            fo.close()\n",
    "            self.test_data = self.test_data.reshape((len(self.test_data), 3, 32, 32))\n",
    "            self.test_data = self.test_data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        if self.train:\n",
    "            img, target = self.train_data[index], self.train_labels[index]\n",
    "            if self.coarse:\n",
    "                coarse_target = self.train_coarse_labels[index]\n",
    "        else:\n",
    "            img, target = self.test_data[index], self.test_labels[index]\n",
    "            if self.coarse:\n",
    "                coarse_target = self.test_coarse_labels[index]\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        if not self.coarse:\n",
    "            return img, target\n",
    "        else:\n",
    "            return img, target, coarse_target\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_data)\n",
    "        else:\n",
    "            return len(self.test_data)\n",
    "\n",
    "    def _check_integrity(self):\n",
    "        root = self.root\n",
    "        for fentry in (self.train_list + self.test_list):\n",
    "            filename, md5 = fentry[0], fentry[1]\n",
    "            fpath = os.path.join(root, self.base_folder, filename)\n",
    "            if not check_integrity(fpath, md5):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def download(self):\n",
    "        import tarfile\n",
    "\n",
    "        if self._check_integrity():\n",
    "            print('Files already downloaded and verified')\n",
    "            return\n",
    "\n",
    "        root = self.root\n",
    "        download_url(self.url, root, self.filename, self.tgz_md5)\n",
    "\n",
    "        # extract file\n",
    "        cwd = os.getcwd()\n",
    "        tar = tarfile.open(os.path.join(root, self.filename), \"r:gz\")\n",
    "        os.chdir(root)\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "        os.chdir(cwd)\n",
    "\n",
    "\n",
    "class CIFAR100(CIFAR10):\n",
    "    \"\"\"`CIFAR100 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
    "    This is a subclass of the `CIFAR10` Dataset.\n",
    "    \"\"\"\n",
    "    base_folder = 'cifar-100-python'\n",
    "    url = \"https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\"\n",
    "    filename = \"cifar-100-python.tar.gz\"\n",
    "    tgz_md5 = 'eb9058c3a382ffc7106e4002c42a8d85'\n",
    "    train_list = [\n",
    "        ['train', '16019d7e3df5f24257cddd939b257f8d'],\n",
    "    ]\n",
    "\n",
    "    test_list = [\n",
    "        ['test', 'f0ef6b0ae62326f3e7ffdfab6717acfc'],\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 400\n",
    "epochs = 120\n",
    "max_lr = 0.001\n",
    "grad_clip = 0.01\n",
    "weight_decay =0.001\n",
    "opt_func = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = torchvision.datasets.CIFAR100('./', train=True, download=True)\n",
    "\n",
    "# # Stick all the images together to form a 1600000 X 32 X 3 array\n",
    "# x = np.concatenate([np.asarray(train_data[i][0]) for i in range(len(train_data))])\n",
    "\n",
    "# # calculate the mean and std along the (0, 1) axes\n",
    "# mean = np.mean(x, axis=(0, 1))/255\n",
    "# std = np.std(x, axis=(0, 1))/255\n",
    "# # the the mean and std\n",
    "# mean=mean.tolist()\n",
    "# std=std.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = tt.Compose([tt.RandomCrop(32, padding=4,padding_mode='reflect'), \n",
    "                         tt.RandomHorizontalFlip(), \n",
    "                         tt.ToTensor(), \n",
    "                         #tt.Normalize(mean,std,inplace=True)\n",
    "                         ]\n",
    "                         )\n",
    "transform_test = tt.Compose([tt.ToTensor(), \n",
    "                             #tt.Normalize(mean,std)\n",
    "                             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = CIFAR100('./data', train=True,\n",
    "                 transform=transform_train,\n",
    "                 download=True, coarse=True, coarseNumber=2)\n",
    "test_data = CIFAR100('./data', train=False,\n",
    "                 transform=transform_test,\n",
    "                 download=True, coarse=True, coarseNumber=2)\n",
    "\n",
    "train_length = train_data.__len__() # Length training dataset\n",
    "train_indices = np.arange(train_length)\n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                        train_data, \n",
    "                        batch_size=batch_size, \n",
    "                        num_workers=2,\n",
    "                        pin_memory=True,\n",
    "                    )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                        test_data, \n",
    "                        batch_size=batch_size*2,\n",
    "                        num_workers=2,\n",
    "                        pin_memory=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset = torchvision.datasets.CIFAR100(\"./\",\n",
    "#                                          train=True,\n",
    "#                                          download=True,\n",
    "#                                          transform=transform_train)\n",
    "# trainloader = torch.utils.data.DataLoader(\n",
    "#     trainset, batch_size, shuffle=True, num_workers=2,pin_memory=True)\n",
    "\n",
    "# testset = torchvision.datasets.CIFAR100(\"./\",\n",
    "#                                         train=False,\n",
    "#                                         download=True,\n",
    "#                                         transform=transform_test)\n",
    "# testloader = torch.utils.data.DataLoader(\n",
    "#     testset, batch_size*2,pin_memory=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()\n",
    "trainloader = DeviceDataLoader(train_loader, device)\n",
    "testloader = DeviceDataLoader(test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet9(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (res1): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (res2): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv5): Sequential(\n",
       "    (0): Conv2d(512, 1028, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(1028, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (res3): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(1028, 1028, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1028, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(1028, 1028, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1028, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier_parent): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=1028, out_features=20, bias=True)\n",
       "  )\n",
       "  (classifier_child): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Flatten(start_dim=1, end_dim=-1)\n",
       "      (2): Linear(in_features=1028, out_features=20, bias=True)\n",
       "    )\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=20, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def __init__(self, fine):\n",
    "        super(ImageClassificationBase, self).__init__()\n",
    "        self.fine = fine\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, fine, coarse = batch \n",
    "        # if self.fine:\n",
    "        #     labels=fine\n",
    "        # else:\n",
    "        #     labels=coarse\n",
    "        out_parent, out_child = self(images)                  # Generate predictions\n",
    "        loss_parent = F.cross_entropy(out_parent, coarse)\n",
    "        loss_child = F.cross_entropy(out_child, fine) # Calculate loss\n",
    "        return loss_parent+1.5*loss_child\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, fine, coarse = batch \n",
    "        # if self.fine:\n",
    "        #     labels=fine\n",
    "        # else:\n",
    "        #     labels=coarse\n",
    "        #out = self(images)                    # Generate predictions\n",
    "        #loss = F.cross_entropy(out, labels)\n",
    "        out_parent, out_child = self(images)                  # Generate predictions\n",
    "        loss_parent = F.cross_entropy(out_parent, coarse)\n",
    "        loss_child = F.cross_entropy(out_child, fine)   # Calculate loss\n",
    "        acc_parent = accuracy(out_parent, coarse)\n",
    "        acc_child = accuracy(out_child, fine)           # Calculate accuracy\n",
    "        return {'val_loss_parent': loss_parent.detach(), 'val_acc_parent': acc_parent, 'val_loss_child':loss_child.detach(), 'val_acc_child': acc_child}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses_parent = [x['val_loss_parent'] for x in outputs]\n",
    "        epoch_loss_parent = torch.stack(batch_losses_parent).mean()   # Combine losses\n",
    "        #\n",
    "        batch_accs_parent = [x['val_acc_parent'] for x in outputs]\n",
    "        epoch_acc_parent = torch.stack(batch_accs_parent).mean()  # Combine accuracies\n",
    "        ###     \n",
    "        batch_losses_child = [x['val_loss_child'] for x in outputs]\n",
    "        epoch_loss_child = torch.stack(batch_losses_child).mean()   # Combine losses\n",
    "        #\n",
    "        batch_accs_child = [x['val_acc_child'] for x in outputs]\n",
    "        epoch_acc_child = torch.stack(batch_accs_child).mean() \n",
    "        return {'val_loss_parent': epoch_loss_parent.item(), 'val_acc_parent': epoch_acc_parent.item(), 'val_loss_child':epoch_loss_child.item(), \n",
    "                'val_acc_child':epoch_acc_child.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss_parent: {:.4f}, val_acc_parent: {:.4f}, val_loss_child: {:.4f}, val_acc_child: {:.4f}\".format(\n",
    "            epoch, result['lrs'][-1], result['train_loss'], result['val_loss_parent'], result['val_acc_parent'], result['val_loss_child'], result['val_acc_child']))\n",
    "        \n",
    "def conv_block(in_channels, out_channels, pool=False):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
    "              nn.BatchNorm2d(out_channels), \n",
    "              nn.ReLU(inplace=True)]\n",
    "    if pool: layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class ResNet9(ImageClassificationBase):\n",
    "    def __init__(self, in_channels, num_classes, fine):\n",
    "        super().__init__(fine)\n",
    "        \n",
    "        self.conv1 = conv_block(in_channels, 64)\n",
    "        self.conv2 = conv_block(64, 128, pool=True) \n",
    "        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128)) \n",
    "        \n",
    "        self.conv3 = conv_block(128, 256, pool=True)\n",
    "        self.conv4 = conv_block(256, 512, pool=True) \n",
    "        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512)) \n",
    "        self.conv5 = conv_block(512, 1028, pool=True) \n",
    "        self.res3 = nn.Sequential(conv_block(1028, 1028), conv_block(1028, 1028))\n",
    "\n",
    "        #-------------------\n",
    "        self.classifier_parent = nn.Sequential(nn.MaxPool2d(2), # 1028 x 1 x 1\n",
    "                                        nn.Flatten(), # 1028 \n",
    "                                        nn.Linear(1028, 20))\n",
    "                                 # 1028 -> 100 \n",
    "\n",
    "        self.classifier_child = nn.Sequential(self.classifier_parent,\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(20, num_classes)\n",
    "                                ) # 1028 -> 100 \n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.conv1(xb)\n",
    "        out = self.conv2(out)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.conv5(out)\n",
    "        out = self.res3(out) + out\n",
    "        parent_out=self.classifier_parent(out)\n",
    "        child_out = self.classifier_child(out)\n",
    "        return parent_out,child_out\n",
    "\n",
    "model100 = to_device(ResNet9(3, 100, True), device)\n",
    "model100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in test_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def fit_one_cycle(epochs, max_lr, model, train_loader, test_loader, \n",
    "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
    "    torch.cuda.empty_cache()\n",
    "    history = []\n",
    "    \n",
    "    # Set up cutom optimizer with weight decay\n",
    "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
    "    # Set up one-cycle learning rate scheduler\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n",
    "                                                steps_per_epoch=len(train_loader))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        lrs = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            if grad_clip: \n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Record & update learning rate\n",
    "            lrs.append(get_lr(optimizer))\n",
    "            sched.step()\n",
    "        \n",
    "        # Validation phase\n",
    "        result = evaluate(model, test_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        result['lrs'] = lrs\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'val_loss_parent': 2.9958324432373047,\n",
       "  'val_acc_parent': 0.05038461834192276,\n",
       "  'val_loss_child': 4.61177921295166,\n",
       "  'val_acc_child': 0.010000000707805157}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial evaluation\n",
    "history = [evaluate(model100, testloader)]\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], last_lr: 0.00007, train_loss: 9.1768, val_loss_parent: 2.0767, val_acc_parent: 0.3675, val_loss_child: 4.5795, val_acc_child: 0.0148\n",
      "Epoch [1], last_lr: 0.00015, train_loss: 8.7596, val_loss_parent: 1.8545, val_acc_parent: 0.4134, val_loss_child: 4.4895, val_acc_child: 0.0304\n",
      "Epoch [2], last_lr: 0.00028, train_loss: 8.3348, val_loss_parent: 1.9024, val_acc_parent: 0.4151, val_loss_child: 4.1549, val_acc_child: 0.0742\n",
      "Epoch [3], last_lr: 0.00044, train_loss: 7.3158, val_loss_parent: 2.0614, val_acc_parent: 0.3988, val_loss_child: 3.5674, val_acc_child: 0.1642\n",
      "Epoch [4], last_lr: 0.00060, train_loss: 6.1643, val_loss_parent: 2.5394, val_acc_parent: 0.3726, val_loss_child: 3.3009, val_acc_child: 0.2140\n",
      "Epoch [5], last_lr: 0.00076, train_loss: 5.4410, val_loss_parent: 2.8475, val_acc_parent: 0.3808, val_loss_child: 3.2799, val_acc_child: 0.2371\n",
      "Epoch [6], last_lr: 0.00089, train_loss: 4.9254, val_loss_parent: 2.0365, val_acc_parent: 0.4755, val_loss_child: 2.7677, val_acc_child: 0.3138\n",
      "Epoch [7], last_lr: 0.00097, train_loss: 4.5060, val_loss_parent: 1.9437, val_acc_parent: 0.4989, val_loss_child: 2.6234, val_acc_child: 0.3389\n",
      "Epoch [8], last_lr: 0.00100, train_loss: 4.1439, val_loss_parent: 2.4194, val_acc_parent: 0.4679, val_loss_child: 2.9148, val_acc_child: 0.3363\n",
      "Epoch [9], last_lr: 0.00099, train_loss: 3.8319, val_loss_parent: 2.6675, val_acc_parent: 0.4430, val_loss_child: 3.2500, val_acc_child: 0.2948\n",
      "Epoch [10], last_lr: 0.00098, train_loss: 3.5358, val_loss_parent: 1.3689, val_acc_parent: 0.6229, val_loss_child: 2.0729, val_acc_child: 0.4553\n",
      "Epoch [11], last_lr: 0.00095, train_loss: 3.2877, val_loss_parent: 1.4475, val_acc_parent: 0.6168, val_loss_child: 2.0108, val_acc_child: 0.4657\n",
      "Epoch [12], last_lr: 0.00091, train_loss: 3.0666, val_loss_parent: 1.4101, val_acc_parent: 0.6233, val_loss_child: 2.0160, val_acc_child: 0.4693\n",
      "Epoch [13], last_lr: 0.00087, train_loss: 2.8524, val_loss_parent: 1.2119, val_acc_parent: 0.6680, val_loss_child: 1.8445, val_acc_child: 0.5099\n",
      "Epoch [14], last_lr: 0.00081, train_loss: 2.6522, val_loss_parent: 1.1464, val_acc_parent: 0.6790, val_loss_child: 1.7661, val_acc_child: 0.5287\n",
      "Epoch [15], last_lr: 0.00075, train_loss: 2.4688, val_loss_parent: 1.3349, val_acc_parent: 0.6599, val_loss_child: 1.9036, val_acc_child: 0.5062\n",
      "Epoch [16], last_lr: 0.00068, train_loss: 2.2732, val_loss_parent: 1.1303, val_acc_parent: 0.7066, val_loss_child: 1.6703, val_acc_child: 0.5641\n",
      "Epoch [17], last_lr: 0.00061, train_loss: 2.0921, val_loss_parent: 1.1717, val_acc_parent: 0.6999, val_loss_child: 1.6579, val_acc_child: 0.5651\n",
      "Epoch [18], last_lr: 0.00054, train_loss: 1.8854, val_loss_parent: 1.1647, val_acc_parent: 0.7106, val_loss_child: 1.6768, val_acc_child: 0.5731\n",
      "Epoch [19], last_lr: 0.00046, train_loss: 1.6552, val_loss_parent: 1.1230, val_acc_parent: 0.7260, val_loss_child: 1.6334, val_acc_child: 0.5843\n",
      "Epoch [20], last_lr: 0.00039, train_loss: 1.4675, val_loss_parent: 1.1050, val_acc_parent: 0.7425, val_loss_child: 1.5659, val_acc_child: 0.6066\n",
      "Epoch [21], last_lr: 0.00032, train_loss: 1.2578, val_loss_parent: 1.0060, val_acc_parent: 0.7548, val_loss_child: 1.4896, val_acc_child: 0.6184\n",
      "Epoch [22], last_lr: 0.00025, train_loss: 1.0719, val_loss_parent: 1.0585, val_acc_parent: 0.7585, val_loss_child: 1.5640, val_acc_child: 0.6152\n",
      "Epoch [23], last_lr: 0.00019, train_loss: 0.8801, val_loss_parent: 0.9552, val_acc_parent: 0.7865, val_loss_child: 1.3885, val_acc_child: 0.6519\n",
      "Epoch [24], last_lr: 0.00013, train_loss: 0.6847, val_loss_parent: 0.9295, val_acc_parent: 0.7975, val_loss_child: 1.3189, val_acc_child: 0.6730\n",
      "Epoch [25], last_lr: 0.00009, train_loss: 0.5374, val_loss_parent: 0.9158, val_acc_parent: 0.8040, val_loss_child: 1.2749, val_acc_child: 0.6889\n",
      "Epoch [26], last_lr: 0.00005, train_loss: 0.4331, val_loss_parent: 0.8857, val_acc_parent: 0.8131, val_loss_child: 1.2437, val_acc_child: 0.6955\n",
      "Epoch [27], last_lr: 0.00002, train_loss: 0.3553, val_loss_parent: 0.8888, val_acc_parent: 0.8139, val_loss_child: 1.2347, val_acc_child: 0.7014\n",
      "Epoch [28], last_lr: 0.00001, train_loss: 0.3097, val_loss_parent: 0.8900, val_acc_parent: 0.8143, val_loss_child: 1.2337, val_acc_child: 0.7013\n",
      "Epoch [29], last_lr: 0.00000, train_loss: 0.2894, val_loss_parent: 0.8924, val_acc_parent: 0.8137, val_loss_child: 1.2353, val_acc_child: 0.7023\n"
     ]
    }
   ],
   "source": [
    "# Fitting the first 1/4 epochs\n",
    "current_time=time.time()\n",
    "history += fit_one_cycle(int(epochs/4), max_lr, model100, trainloader, testloader, \n",
    "                             grad_clip=grad_clip, \n",
    "                             weight_decay=weight_decay, \n",
    "                             opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the second 1/4 epochs\n",
    "# history += fit_one_cycle(int(epochs/4), max_lr/10, model, trainloader, testloader, \n",
    "#                              grad_clip=grad_clip, \n",
    "#                              weight_decay=weight_decay, \n",
    "#                              opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history += fit_one_cycle(int(epochs/8), max_lr/100, model, trainloader, testloader, \n",
    "#                              grad_clip=grad_clip, \n",
    "#                              weight_decay=weight_decay, \n",
    "#                              opt_func=opt_func)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model to h5 file\n",
    "torch.save(model100.state_dict(), 'group_1028_to_parent_Loss_parent_and_child_pretrained_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
