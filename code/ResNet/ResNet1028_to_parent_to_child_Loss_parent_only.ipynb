{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'11': {'15': 0, '19': 1, '21': 2, '31': 3, '38': 4}, '15': {'27': 0, '29': 1, '44': 2, '78': 3, '93': 4}, '4': {'0': 0, '51': 1, '53': 2, '57': 3, '83': 4}, '14': {'2': 0, '11': 1, '35': 2, '46': 3, '98': 4}, '1': {'1': 0, '32': 1, '67': 2, '73': 3, '91': 4}, '5': {'22': 0, '39': 1, '40': 2, '86': 3, '87': 4}, '18': {'8': 0, '13': 1, '48': 2, '58': 3, '90': 4}, '3': {'9': 0, '10': 1, '16': 2, '28': 3, '61': 4}, '10': {'23': 0, '33': 1, '49': 2, '60': 3, '71': 4}, '17': {'47': 0, '52': 1, '56': 2, '59': 3, '96': 4}, '2': {'54': 0, '62': 1, '70': 2, '82': 3, '92': 4}, '9': {'12': 0, '17': 1, '37': 2, '68': 3, '76': 4}, '8': {'3': 0, '42': 1, '43': 2, '88': 3, '97': 4}, '16': {'36': 0, '50': 1, '65': 2, '74': 3, '80': 4}, '6': {'5': 0, '20': 1, '25': 2, '84': 3, '94': 4}, '12': {'34': 0, '63': 1, '64': 2, '66': 3, '75': 4}, '19': {'41': 0, '69': 1, '81': 2, '85': 3, '89': 4}, '7': {'6': 0, '7': 1, '14': 2, '18': 3, '24': 4}, '13': {'26': 0, '45': 1, '77': 2, '79': 3, '99': 4}, '0': {'4': 0, '30': 1, '55': 2, '72': 3, '95': 4}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "f = open('parent_to_child_class_from_0_to_5.json')\n",
    "parent_to_child_class_from_0_to_5 = json.load(f)\n",
    "print(parent_to_child_class_from_0_to_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import errno\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "if sys.version_info[0] == 2:\n",
    "    import cPickle as pickle\n",
    "else:\n",
    "    import pickle\n",
    "\n",
    "import torch.utils.data as data\n",
    "from torchvision.datasets.utils import download_url, check_integrity\n",
    "import torchvision.transforms as tt\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from sklearn.metrics import *\n",
    "from torchsummary import summary\n",
    "\n",
    "class CIFAR10(data.Dataset):\n",
    "    \"\"\"`CIFAR10 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where directory\n",
    "            ``cifar-10-batches-py`` exists.\n",
    "        train (bool, optional): If True, creates dataset from training set, otherwise\n",
    "            creates from test set.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "    \"\"\"\n",
    "    base_folder = 'cifar-10-batches-py'\n",
    "    url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "    filename = \"cifar-10-python.tar.gz\"\n",
    "    tgz_md5 = 'c58f30108f718f92721af3b95e74349a'\n",
    "    train_list = [\n",
    "        ['data_batch_1', 'c99cafc152244af753f735de768cd75f'],\n",
    "        ['data_batch_2', 'd4bba439e000b95fd0a9bffe97cbabec'],\n",
    "        ['data_batch_3', '54ebc095f3ab1f0389bbae665268c751'],\n",
    "        ['data_batch_4', '634d18415352ddfa80567beed471001a'],\n",
    "        ['data_batch_5', '482c414d41f54cd18b22e5b47cb7c3cb'],\n",
    "    ]\n",
    "\n",
    "    test_list = [\n",
    "        ['test_batch', '40351d587109b95175f43aff81a1287e'],\n",
    "    ]\n",
    "\n",
    "    meta = {\n",
    "        \"filename\": \"batches.meta\",\n",
    "        \"key\": \"label_names\",\n",
    "        \"md5\": \"5ff9c542aee3614f3951f8cda6e48888\",\n",
    "    }\n",
    "\n",
    "\n",
    "    def __init__(self, root, train=True,\n",
    "                 transform=None, target_transform=None,\n",
    "                 download=False, coarse=False, coarseNumber=None):\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train = train  # training set or test set\n",
    "        self.coarse = coarse\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_integrity():\n",
    "            raise RuntimeError('Dataset not found or corrupted.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "        # now load the picked numpy arrays\n",
    "        if self.train:\n",
    "            self.train_data = []\n",
    "            self.train_labels = []\n",
    "            self.train_coarse_labels = []\n",
    "            for fentry in self.train_list:\n",
    "                f = fentry[0]\n",
    "                file = os.path.join(self.root, self.base_folder, f)\n",
    "                fo = open(file, 'rb')\n",
    "                if sys.version_info[0] == 2:\n",
    "                    entry = pickle.load(fo)\n",
    "                else:\n",
    "                    entry = pickle.load(fo, encoding='latin1')\n",
    "                self.train_data.append(entry['data'])\n",
    "                if 'labels' in entry:\n",
    "                    self.train_labels += entry['labels']\n",
    "                else:\n",
    "                    self.train_labels += entry['fine_labels']\n",
    "                    if self.coarse:\n",
    "                        self.train_coarse_labels += entry['coarse_labels']\n",
    "                fo.close()\n",
    "            ###\n",
    "            new_train_coarse_labels=[]\n",
    "            new_train_fine_labels=[]\n",
    "            new_train_data=[]\n",
    "            #print(\"before data Train\",np.concatenate(self.train_data))\n",
    "            #print(len(self.train_data))\n",
    "            #print(\"before fine Train\",self.train_labels)\n",
    "            #print(len(self.train_labels))\n",
    "            #print(\"before coarse Train\",self.train_coarse_labels)\n",
    "            #print(len(self.train_coarse_labels))\n",
    "            for data, fine,coarse in zip(self.train_data[0],self.train_labels, self.train_coarse_labels):\n",
    "                if coarse==coarseNumber:\n",
    "                    new_train_data.append(data)\n",
    "                    new_train_fine_labels.append(parent_to_child_class_from_0_to_5[str(coarseNumber)][str(fine)])\n",
    "                    new_train_coarse_labels.append(coarseNumber)\n",
    "            # print(\"now coarse \",new_train_coarse_labels)\n",
    "            # print(\"now fine \",new_train_fine_labels)\n",
    "            # print(len(new_train_coarse_labels))\n",
    "            # print(len(new_train_fine_labels))\n",
    "            # print(\"============\")\n",
    "            # self.train_data=new_train_data\n",
    "            #print(parent_to_child_class_from_0_to_5[str(coarseNumber)])\n",
    "            self.train_data=np.array([np.array(xi) for xi in new_train_data])\n",
    "            self.train_labels=new_train_fine_labels\n",
    "            self.train_coarse_labels=new_train_coarse_labels\n",
    "            #print(self.train_labels)\n",
    "            # print(\" \",self.train_data)\n",
    "            # print(\" \",self.train_labels)\n",
    "            # print(\" \",self.train_coarse_labels)\n",
    "            ###\n",
    "            # print(\"after data Train\",self.train_data)\n",
    "            # print(len(self.train_data))\n",
    "            #print(\"after fine Train\",self.train_labels)\n",
    "            #print(len(self.train_labels))\n",
    "            #print(\"after coarse Train\",self.train_coarse_labels)\n",
    "            #self.train_data = np.concatenate(self.train_data)\n",
    "            self.train_data = self.train_data.reshape((len(new_train_data), 3, 32, 32))\n",
    "            self.train_data = self.train_data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "        else:\n",
    "            f = self.test_list[0][0]\n",
    "            file = os.path.join(self.root, self.base_folder, f)\n",
    "            fo = open(file, 'rb')\n",
    "            if sys.version_info[0] == 2:\n",
    "                entry = pickle.load(fo)\n",
    "            else:\n",
    "                entry = pickle.load(fo, encoding='latin1')\n",
    "            self.test_data = entry['data']\n",
    "\n",
    "            if 'labels' in entry:\n",
    "                self.test_labels = entry['labels']\n",
    "            else:\n",
    "                self.test_labels = entry['fine_labels']\n",
    "                if self.coarse:\n",
    "                    self.test_coarse_labels = entry['coarse_labels']\n",
    "                new_test_coarse_labels=[]\n",
    "                new_test_fine_labels=[]\n",
    "                new_test_data=[]\n",
    "                # print(\"before fine \",entry['fine_labels'])\n",
    "                # print(len(entry['fine_labels']))\n",
    "                # print(\"before coarse \",entry['coarse_labels'])\n",
    "                # print(len(entry['coarse_labels']))\n",
    "                for data, fine,coarse in zip(self.test_data,self.test_labels, self.test_coarse_labels):\n",
    "                    if coarse==coarseNumber:\n",
    "                        new_test_data.append(data)\n",
    "                        new_test_fine_labels.append(parent_to_child_class_from_0_to_5[str(coarseNumber)][str(fine)])\n",
    "                        new_test_coarse_labels.append(coarseNumber)\n",
    "                # print(\"now coarse \",new_test_coarse_labels)\n",
    "                # print(\"now fine \",new_test_fine_labels)\n",
    "                # print(len(new_test_coarse_labels))\n",
    "                # print(len(new_test_fine_labels))\n",
    "                # print(\"============\")\n",
    "                # print(\"now data \",new_test_data)\n",
    "                # print(len(new_test_data))\n",
    "                # print(\"self test data before\",self.test_data)\n",
    "                # print(\"test data type before\", type(self.test_data))\n",
    "                # print(\"shape of test data before \", self.test_data.shape)\n",
    "                self.test_data=np.array([np.array(xi) for xi in new_test_data])\n",
    "                # print(\"test data type after\", type(self.test_data))\n",
    "                # print(\"shape of test data after \", self.test_data.shape)\n",
    "                self.test_labels=new_test_fine_labels\n",
    "                self.test_coarse_labels=new_test_coarse_labels\n",
    "            fo.close()\n",
    "            self.test_data = self.test_data.reshape((len(new_test_data), 3, 32, 32))\n",
    "            self.test_data = self.test_data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        if self.train:\n",
    "            img, target = self.train_data[index], self.train_labels[index]\n",
    "            if self.coarse:\n",
    "                coarse_target = self.train_coarse_labels[index]\n",
    "        else:\n",
    "            img, target = self.test_data[index], self.test_labels[index]\n",
    "            if self.coarse:\n",
    "                coarse_target = self.test_coarse_labels[index]\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        if not self.coarse:\n",
    "            return img, target\n",
    "        else:\n",
    "            return img, target, coarse_target\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_data)\n",
    "        else:\n",
    "            return len(self.test_data)\n",
    "\n",
    "    def _check_integrity(self):\n",
    "        root = self.root\n",
    "        for fentry in (self.train_list + self.test_list):\n",
    "            filename, md5 = fentry[0], fentry[1]\n",
    "            fpath = os.path.join(root, self.base_folder, filename)\n",
    "            if not check_integrity(fpath, md5):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def download(self):\n",
    "        import tarfile\n",
    "\n",
    "        if self._check_integrity():\n",
    "            print('Files already downloaded and verified')\n",
    "            return\n",
    "\n",
    "        root = self.root\n",
    "        download_url(self.url, root, self.filename, self.tgz_md5)\n",
    "\n",
    "        # extract file\n",
    "        cwd = os.getcwd()\n",
    "        tar = tarfile.open(os.path.join(root, self.filename), \"r:gz\")\n",
    "        os.chdir(root)\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "        os.chdir(cwd)\n",
    "\n",
    "\n",
    "class CIFAR100(CIFAR10):\n",
    "    \"\"\"`CIFAR100 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
    "    This is a subclass of the `CIFAR10` Dataset.\n",
    "    \"\"\"\n",
    "    base_folder = 'cifar-100-python'\n",
    "    url = \"https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\"\n",
    "    filename = \"cifar-100-python.tar.gz\"\n",
    "    tgz_md5 = 'eb9058c3a382ffc7106e4002c42a8d85'\n",
    "    train_list = [\n",
    "        ['train', '16019d7e3df5f24257cddd939b257f8d'],\n",
    "    ]\n",
    "\n",
    "    test_list = [\n",
    "        ['test', 'f0ef6b0ae62326f3e7ffdfab6717acfc'],\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = tt.Compose([tt.RandomCrop(32, padding=4,padding_mode='reflect'), \n",
    "                         tt.RandomHorizontalFlip(), \n",
    "                         tt.ToTensor(), \n",
    "                         #tt.Normalize(mean,std,inplace=True) \n",
    "                         ]\n",
    "                         )\n",
    "transform_test = tt.Compose([tt.ToTensor(), \n",
    "                             #tt.Normalize(mean,std)\n",
    "                             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 400\n",
    "epochs = 120\n",
    "max_lr = 0.001\n",
    "grad_clip = 0.01\n",
    "weight_decay =0.001\n",
    "opt_func = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = CIFAR100('./data', train=True,\n",
    "                 transform=transform_train,\n",
    "                 download=True, coarse=True, coarseNumber=2)\n",
    "test_data = CIFAR100('./data', train=False,\n",
    "                 transform=transform_test,\n",
    "                 download=True, coarse=True, coarseNumber=2)\n",
    "\n",
    "train_length = train_data.__len__() # Length training dataset\n",
    "train_indices = np.arange(train_length)\n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                        train_data, \n",
    "                        batch_size=batch_size, \n",
    "                        num_workers=2,\n",
    "                        pin_memory=True,\n",
    "                    )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                        test_data, \n",
    "                        batch_size=batch_size*2,\n",
    "                        num_workers=2,\n",
    "                        pin_memory=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()\n",
    "trainloader = DeviceDataLoader(train_loader, device)\n",
    "testloader = DeviceDataLoader(test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def __init__(self, fine):\n",
    "        super(ImageClassificationBase, self).__init__()\n",
    "        self.fine = fine\n",
    "        #self.parent_to_child_class={}\n",
    "        self.unique_outs=[]\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, fine, coarse = batch\n",
    "        if self.fine:\n",
    "            labels=fine\n",
    "        else:\n",
    "            labels=coarse\n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, fine, coarse = batch \n",
    "\n",
    "        #print(\"coarse \", coarse)\n",
    "        #print(\"fine \", fine)    \n",
    "        if self.fine:\n",
    "            labels=fine\n",
    "        else:\n",
    "            labels=coarse\n",
    "        out = self(images)\n",
    "        #print(\"out shape \",out.shape)\n",
    "        #print(\"out first three\", out[:3,:])  \n",
    "        #print(\"labels shape \",labels.shape)\n",
    "        #print(\"labels first three\", labels[:3])\n",
    "        #labels=labels.cpu().apply_(lambda val: dict.get(val)).to(labels.device)\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))\n",
    "        \n",
    "def conv_block(in_channels, out_channels, pool=False):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
    "              nn.BatchNorm2d(out_channels), \n",
    "              nn.ReLU(inplace=True)]\n",
    "    if pool: layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class ResNet9(ImageClassificationBase):\n",
    "    def __init__(self, in_channels, num_classes, fine):\n",
    "        super().__init__(fine)\n",
    "        \n",
    "        self.conv1 = conv_block(in_channels, 64)\n",
    "        self.conv2 = conv_block(64, 128, pool=True) \n",
    "        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128)) \n",
    "        \n",
    "        self.conv3 = conv_block(128, 256, pool=True)\n",
    "        self.conv4 = conv_block(256, 512, pool=True) \n",
    "        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512)) \n",
    "        self.conv5 = conv_block(512, 1028, pool=True) \n",
    "        self.res3 = nn.Sequential(conv_block(1028, 1028), conv_block(1028, 1028))  \n",
    "        \n",
    "        # self.classifier_parent = nn.Sequential(nn.MaxPool2d(2), # 1028 x 1 x 1\n",
    "        #                                 nn.Flatten(), # 1028 \n",
    "        #                                 nn.Linear(1028, 20))\n",
    "        \n",
    "        # self.classifier_child = self.classifier_parent\n",
    "\n",
    "        self.classifier = nn.Sequential(nn.MaxPool2d(2), # 1028 x 1 x 1\n",
    "                                nn.Flatten(), # 1028 \n",
    "                                nn.Linear(1028, num_classes)\n",
    "                                )\n",
    "\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.conv1(xb)\n",
    "        out = self.conv2(out)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.conv5(out)\n",
    "        out = self.res3(out) + out\n",
    "        out = self.classifier(out)\n",
    "        #out = self.classifier_child(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in test_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def fit_one_cycle(epochs, max_lr, model, train_loader, test_loader, \n",
    "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
    "    torch.cuda.empty_cache()\n",
    "    history = []\n",
    "    \n",
    "    # Set up cutom optimizer with weight decay\n",
    "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
    "    # Set up one-cycle learning rate scheduler\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n",
    "                                                steps_per_epoch=len(train_loader))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        lrs = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            if grad_clip: \n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Record & update learning rate\n",
    "            lrs.append(get_lr(optimizer))\n",
    "            sched.step()\n",
    "        \n",
    "        # Validation phase\n",
    "        result = evaluate(model, test_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        result['lrs'] = lrs\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate testing accuracy, predicted label, confusion matrix, and table for classification report\n",
    "def test_label_predictions(model, device, test_loader, fine):\n",
    "    model.eval()\n",
    "    actuals = []\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        if fine:\n",
    "            for data, target, _ in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                prediction = output.argmax(dim=1, keepdim=True)\n",
    "                print(\"predicted \", prediction, \" actual: \", target)\n",
    "                actuals.extend(target.view_as(prediction))\n",
    "                predictions.extend(prediction)\n",
    "        else:\n",
    "            for data, _, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                prediction = output.argmax(dim=1, keepdim=True)\n",
    "                print(\"predicted \", prediction, \" actual: \", target)\n",
    "                actuals.extend(target.view_as(prediction))\n",
    "                predictions.extend(prediction)\n",
    "\n",
    "    return [i.item() for i in actuals], [i.item() for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model20To100 = ResNet9(3, 20, True)\n",
    "model20To100.load_state_dict(torch.load('group_1028_to_parent_Loss_parent_only_pretrained_model.h5'))\n",
    "for param in model20To100.parameters():\n",
    "    param.requires_grad=False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('conv1.0.weight', Parameter containing:\n",
      "tensor([[[[ 1.3848e-02,  2.7870e-02,  1.6179e-01],\n",
      "          [ 1.4104e-01,  6.5892e-03,  3.5931e-02],\n",
      "          [-2.2531e-02, -1.2339e-01, -9.6927e-02]],\n",
      "\n",
      "         [[-1.1477e-01, -1.4049e-01,  1.1485e-01],\n",
      "          [-2.4349e-03, -8.9735e-03, -1.0072e-01],\n",
      "          [ 1.8900e-02,  1.0296e-01, -1.2280e-01]],\n",
      "\n",
      "         [[-4.4796e-02,  7.7847e-02,  4.3542e-02],\n",
      "          [-5.2279e-02, -1.3026e-01, -8.6491e-02],\n",
      "          [ 1.1891e-01, -7.0256e-03,  8.3161e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0085e-03, -1.1155e-01,  1.1853e-01],\n",
      "          [-2.4626e-03, -8.4874e-02,  7.8723e-02],\n",
      "          [ 9.8813e-02, -1.4438e-01,  5.5212e-02]],\n",
      "\n",
      "         [[-3.3386e-02, -4.3205e-02,  1.6478e-01],\n",
      "          [-5.5575e-02,  7.6668e-02, -8.8138e-02],\n",
      "          [-1.2586e-01,  5.7888e-02, -1.5326e-02]],\n",
      "\n",
      "         [[-6.9401e-02,  4.9565e-02,  1.0866e-01],\n",
      "          [-1.0783e-01, -1.7551e-01,  1.4099e-01],\n",
      "          [ 5.6394e-02,  9.2375e-02, -5.8212e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.6109e-02, -7.9624e-02,  8.0556e-02],\n",
      "          [-9.2821e-03,  3.3786e-02, -9.9689e-02],\n",
      "          [-1.0642e-01, -1.2313e-01, -9.6416e-02]],\n",
      "\n",
      "         [[-9.1560e-02,  2.2315e-02,  4.0199e-02],\n",
      "          [ 7.7503e-02,  1.4189e-01,  6.1784e-02],\n",
      "          [-1.3595e-01,  1.5412e-01,  8.1433e-02]],\n",
      "\n",
      "         [[-1.2514e-01, -6.8350e-02,  1.2212e-01],\n",
      "          [ 1.0875e-01, -3.3868e-02, -4.3849e-02],\n",
      "          [ 6.3362e-02, -1.2190e-02, -9.1000e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 7.9966e-02,  6.3985e-02,  9.0034e-02],\n",
      "          [-1.2643e-01, -1.2906e-01, -6.0795e-02],\n",
      "          [ 6.7128e-02, -1.0911e-02,  3.1460e-02]],\n",
      "\n",
      "         [[ 4.9955e-03, -1.7137e-02, -1.2936e-01],\n",
      "          [-1.2073e-02,  4.2371e-03,  1.2479e-01],\n",
      "          [-3.4482e-02,  1.0547e-01, -4.0765e-02]],\n",
      "\n",
      "         [[-1.0787e-01, -1.4360e-01,  1.4970e-02],\n",
      "          [ 2.2158e-02, -5.6516e-02,  5.8308e-02],\n",
      "          [ 1.4664e-01,  6.6390e-02, -1.1622e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.9730e-02,  3.2146e-02,  6.3167e-02],\n",
      "          [ 7.7474e-02,  9.0175e-02,  8.8843e-02],\n",
      "          [-4.9459e-02, -6.5666e-02, -1.4781e-01]],\n",
      "\n",
      "         [[-4.8604e-02, -8.5027e-02, -1.1642e-01],\n",
      "          [ 2.9207e-02,  1.2975e-01, -4.2643e-02],\n",
      "          [-3.6721e-03, -2.1207e-02, -3.5831e-02]],\n",
      "\n",
      "         [[-1.3313e-01, -5.8278e-02,  8.1024e-02],\n",
      "          [-5.8621e-03,  8.0806e-02, -1.2453e-01],\n",
      "          [ 5.4067e-02,  4.2311e-02,  1.4996e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.2862e-02, -1.4385e-01, -4.1043e-03],\n",
      "          [ 1.5383e-01,  3.3457e-03, -1.2566e-01],\n",
      "          [ 3.7281e-02, -1.1598e-01,  1.9391e-01]],\n",
      "\n",
      "         [[ 2.1503e-02,  7.5907e-03,  1.1825e-01],\n",
      "          [ 1.2895e-04,  1.0171e-01,  1.1330e-01],\n",
      "          [-9.2032e-02, -1.4001e-01, -1.9225e-03]],\n",
      "\n",
      "         [[-5.4311e-02, -3.4955e-02,  8.1213e-02],\n",
      "          [ 7.6864e-02, -4.7638e-02, -4.8719e-02],\n",
      "          [-9.9788e-03, -1.0372e-01,  6.9746e-02]]]]))\n",
      "('conv1.0.bias', Parameter containing:\n",
      "tensor([-1.0411e-06,  1.7911e-07,  1.4282e-07,  4.5427e-07,  3.9970e-07,\n",
      "         2.9408e-07, -2.1738e-07, -1.2702e-07, -4.8886e-07,  3.9991e-06,\n",
      "         5.4496e-07, -2.7249e-06, -5.8805e-07, -1.4566e-06, -3.6921e-07,\n",
      "        -2.4198e-06,  4.4923e-07, -2.4142e-07, -5.2366e-07,  3.4411e-06,\n",
      "         1.4383e-07, -5.8707e-08, -3.4430e-06,  1.5709e-06, -6.0342e-07,\n",
      "        -1.5726e-07, -3.4748e-07, -6.5747e-07, -4.3216e-07,  5.3416e-06,\n",
      "        -6.3201e-07, -1.1133e-06, -2.1084e-06, -6.6962e-07,  1.5313e-06,\n",
      "        -4.1009e-09,  1.9453e-07,  1.1411e-06, -8.2542e-07, -7.6902e-07,\n",
      "        -3.2866e-07, -1.8763e-08, -4.5586e-06,  3.4843e-07, -3.3852e-06,\n",
      "         1.3532e-07,  9.8787e-07, -9.2364e-07,  6.2563e-07,  3.9314e-06,\n",
      "         2.5029e-06,  1.6920e-07,  3.1474e-07,  1.0505e-07, -7.8930e-07,\n",
      "         3.7329e-07,  1.4069e-07, -1.8682e-07, -1.2303e-07, -2.9211e-07,\n",
      "        -1.0115e-06,  3.3473e-07,  1.9497e-07, -3.2959e-06]))\n",
      "('conv1.1.weight', Parameter containing:\n",
      "tensor([0.6234, 0.7548, 0.5708, 0.6344, 0.7465, 0.9445, 0.6160, 0.6145, 0.7289,\n",
      "        0.8221, 0.6840, 0.8101, 0.5929, 0.6156, 0.9841, 0.8584, 0.6082, 0.6552,\n",
      "        0.6930, 0.8627, 0.6779, 0.6527, 0.7352, 0.7370, 0.7582, 0.6083, 0.6123,\n",
      "        0.6088, 0.6522, 0.9049, 0.6114, 0.7194, 0.7634, 0.7278, 0.7318, 0.6681,\n",
      "        0.7908, 0.7237, 0.6850, 0.7315, 0.6396, 0.6372, 0.7674, 0.8208, 0.7293,\n",
      "        0.5775, 0.7780, 0.6171, 0.6308, 0.7340, 0.8495, 0.6627, 0.5797, 0.6091,\n",
      "        0.9215, 0.6488, 0.5811, 0.6466, 0.6813, 0.6684, 0.8447, 0.8278, 0.6269,\n",
      "        0.7067]))\n",
      "('conv1.1.bias', Parameter containing:\n",
      "tensor([-0.1146,  0.0149, -0.0751, -0.0773,  0.0671,  0.3324, -0.0414, -0.0682,\n",
      "         0.0468,  0.2182, -0.0839,  0.1400, -0.1395, -0.1162,  0.2578,  0.3597,\n",
      "        -0.1737, -0.0414,  0.0030,  0.1072,  0.0512, -0.0936,  0.2496,  0.0837,\n",
      "         0.0852, -0.1452, -0.1468, -0.0706, -0.0660,  0.0459, -0.0212,  0.1903,\n",
      "         0.2176,  0.1590,  0.0529,  0.0702,  0.1057,  0.0051, -0.0340,  0.1180,\n",
      "        -0.1511, -0.1389,  0.1590,  0.1392,  0.2262, -0.1207,  0.3349, -0.0684,\n",
      "        -0.0831,  0.1647,  0.2717,  0.0064, -0.1397, -0.0730,  0.3068,  0.0160,\n",
      "        -0.1979, -0.0213,  0.1402, -0.0309,  0.1952,  0.1016, -0.0863,  0.0994]))\n",
      "('conv2.0.weight', Parameter containing:\n",
      "tensor([[[[ 2.2546e-02,  1.8895e-02,  2.4396e-02],\n",
      "          [ 1.6011e-02,  4.1955e-02,  1.1477e-02],\n",
      "          [ 4.7530e-02,  4.4687e-02,  4.0008e-02]],\n",
      "\n",
      "         [[-3.6756e-02, -1.4400e-02, -1.8290e-02],\n",
      "          [-4.1056e-02, -3.4732e-02, -3.1926e-02],\n",
      "          [-5.9162e-02, -5.6434e-02, -3.9677e-02]],\n",
      "\n",
      "         [[ 5.8793e-04, -1.5237e-02,  1.4192e-02],\n",
      "          [ 3.7047e-04, -7.4448e-03, -9.3850e-03],\n",
      "          [ 3.7271e-02, -1.1093e-02, -9.9016e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.4259e-02, -2.3572e-02,  2.6540e-02],\n",
      "          [ 1.1997e-02,  2.7083e-02,  2.4677e-03],\n",
      "          [ 3.5226e-03, -2.1788e-02,  2.6972e-04]],\n",
      "\n",
      "         [[-1.6935e-02, -3.2248e-02, -4.0172e-02],\n",
      "          [-2.0323e-02, -7.9728e-03,  5.2562e-03],\n",
      "          [-1.0361e-02, -2.3298e-02, -2.7428e-02]],\n",
      "\n",
      "         [[ 1.9577e-02, -1.3210e-02,  2.4694e-02],\n",
      "          [-1.0053e-02, -3.0141e-02,  1.9335e-02],\n",
      "          [ 1.5690e-02, -1.4061e-03, -1.3023e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.5114e-02,  4.3238e-03, -7.8556e-04],\n",
      "          [ 2.3240e-02, -5.5041e-03, -7.4371e-03],\n",
      "          [ 3.7490e-04,  1.8170e-02,  1.8130e-02]],\n",
      "\n",
      "         [[-1.2624e-03, -2.9036e-02, -3.4238e-02],\n",
      "          [-2.7119e-02, -4.1361e-03, -2.2984e-03],\n",
      "          [-6.9702e-03, -1.7737e-02, -2.0367e-02]],\n",
      "\n",
      "         [[ 1.3010e-02,  1.6746e-02, -3.6302e-03],\n",
      "          [-1.4996e-02,  3.1364e-02,  2.6664e-03],\n",
      "          [-3.2378e-02,  2.7919e-02,  1.3363e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.5487e-02, -4.1401e-02, -3.0865e-02],\n",
      "          [ 2.0429e-04,  6.2185e-03,  2.4997e-02],\n",
      "          [-6.8503e-03,  2.0633e-02,  1.0571e-02]],\n",
      "\n",
      "         [[ 1.3344e-02, -6.0411e-03, -9.4293e-03],\n",
      "          [ 7.1550e-03, -1.7834e-02, -4.0880e-02],\n",
      "          [-1.7559e-02, -8.6545e-03, -6.8620e-03]],\n",
      "\n",
      "         [[-4.7894e-02,  1.4583e-02, -2.3511e-02],\n",
      "          [-4.2906e-02,  5.2283e-03,  3.3324e-02],\n",
      "          [-1.2887e-02,  8.1011e-03, -3.0841e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9383e-02,  1.3933e-02,  3.5245e-02],\n",
      "          [-1.1103e-02, -3.7673e-02, -1.9994e-03],\n",
      "          [-6.7868e-03, -1.1536e-02, -4.2406e-03]],\n",
      "\n",
      "         [[-3.5465e-02, -5.2708e-02,  2.6671e-02],\n",
      "          [ 1.0581e-02, -7.9288e-03, -2.8610e-03],\n",
      "          [ 7.0658e-03,  5.4717e-03, -1.5652e-02]],\n",
      "\n",
      "         [[ 2.8179e-02,  1.0746e-02,  1.3860e-03],\n",
      "          [ 2.0990e-02,  1.6977e-02,  3.7805e-03],\n",
      "          [-1.0848e-02, -1.4580e-02,  2.6190e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.8100e-03,  3.5714e-02, -1.2429e-02],\n",
      "          [ 3.7727e-02,  5.4000e-02,  2.2914e-02],\n",
      "          [-6.3810e-03, -1.8243e-02, -1.6323e-02]],\n",
      "\n",
      "         [[-5.6101e-03,  1.5257e-02, -5.5399e-03],\n",
      "          [-3.3493e-02,  9.6296e-03, -2.4497e-03],\n",
      "          [-2.5519e-02,  7.4806e-03,  5.1291e-03]],\n",
      "\n",
      "         [[-2.8997e-02, -4.1217e-02, -5.0770e-02],\n",
      "          [ 2.9713e-02,  3.3650e-02,  3.4114e-03],\n",
      "          [ 2.4501e-02,  2.7812e-02,  1.2868e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 3.3095e-02, -2.3345e-02,  8.1938e-04],\n",
      "          [ 2.2937e-02,  3.2082e-02,  1.1641e-02],\n",
      "          [-1.7656e-02, -3.6519e-03,  3.0307e-02]],\n",
      "\n",
      "         [[ 1.6203e-02,  2.9874e-02,  2.2972e-02],\n",
      "          [-2.1885e-02, -2.5510e-02,  2.1267e-02],\n",
      "          [-1.5663e-02, -2.9331e-02, -3.4632e-03]],\n",
      "\n",
      "         [[ 1.9142e-02, -1.1106e-02,  1.1184e-02],\n",
      "          [-4.8432e-03,  4.2104e-02,  9.6187e-03],\n",
      "          [ 1.3277e-02,  5.6726e-03,  2.7735e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.2560e-02,  7.7942e-02,  2.9367e-02],\n",
      "          [ 2.6464e-02, -1.0244e-02, -4.0409e-02],\n",
      "          [-1.9127e-02, -2.8076e-02, -5.6758e-02]],\n",
      "\n",
      "         [[-3.5441e-02, -4.1011e-02, -1.4084e-02],\n",
      "          [ 2.1127e-02,  9.3935e-03,  8.8659e-04],\n",
      "          [ 3.2325e-02,  2.5431e-02,  2.8575e-03]],\n",
      "\n",
      "         [[ 5.8935e-03, -1.2620e-02, -3.9758e-03],\n",
      "          [ 9.9236e-03, -1.9837e-04,  1.7890e-02],\n",
      "          [-2.1032e-03, -2.4922e-02,  1.1823e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.9306e-02,  1.7114e-02,  7.4907e-03],\n",
      "          [ 7.3954e-05, -8.0633e-03, -4.3372e-02],\n",
      "          [-6.1967e-03,  1.7380e-02, -2.7663e-02]],\n",
      "\n",
      "         [[-4.9617e-02,  4.2278e-03,  1.9615e-02],\n",
      "          [-3.7808e-02, -4.0061e-03,  3.8305e-02],\n",
      "          [ 1.1853e-03, -7.3038e-03,  1.5955e-02]],\n",
      "\n",
      "         [[ 2.7339e-02, -1.2337e-02, -1.4519e-02],\n",
      "          [ 2.6867e-02, -2.2741e-03,  1.1550e-02],\n",
      "          [ 1.6024e-02,  2.7858e-03,  3.2819e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.7780e-02,  1.6393e-02,  2.0268e-02],\n",
      "          [-5.8885e-03,  1.5642e-02,  2.5917e-02],\n",
      "          [-3.3098e-02, -3.8290e-02, -5.7146e-02]],\n",
      "\n",
      "         [[-8.4235e-03,  1.8106e-02, -2.1031e-02],\n",
      "          [ 7.2854e-03,  1.7028e-03, -3.4869e-03],\n",
      "          [ 5.9880e-03, -4.3004e-02, -1.4478e-02]],\n",
      "\n",
      "         [[-4.1065e-02,  2.4779e-02,  2.7976e-02],\n",
      "          [-5.2556e-02,  1.9735e-03,  3.1287e-02],\n",
      "          [ 1.6053e-04,  1.8524e-02,  1.6748e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.8930e-02, -2.8238e-02, -1.6062e-03],\n",
      "          [ 6.0670e-03, -2.0820e-03, -2.8651e-02],\n",
      "          [ 1.0283e-02,  2.4140e-02,  3.7099e-02]],\n",
      "\n",
      "         [[ 4.1752e-03,  1.6910e-02,  5.2264e-03],\n",
      "          [-2.4368e-03,  8.3362e-03,  1.7124e-02],\n",
      "          [ 1.9239e-02, -2.1921e-02,  1.8014e-02]],\n",
      "\n",
      "         [[ 2.5429e-02,  1.3804e-03, -1.3860e-04],\n",
      "          [ 8.2099e-03, -2.1621e-02, -7.9677e-03],\n",
      "          [ 1.1361e-02, -4.7857e-03, -1.8661e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.4877e-02, -1.3988e-02, -4.8570e-02],\n",
      "          [ 1.2719e-02, -3.0033e-02, -1.1276e-02],\n",
      "          [-8.1113e-03,  1.8277e-02,  1.5906e-02]],\n",
      "\n",
      "         [[-1.8795e-02,  2.8277e-03,  1.0068e-02],\n",
      "          [-2.8105e-02, -1.2076e-02, -1.3405e-02],\n",
      "          [ 7.0240e-04, -2.2770e-02, -3.8577e-02]],\n",
      "\n",
      "         [[ 1.7019e-02,  1.7499e-02, -2.8065e-02],\n",
      "          [ 2.7196e-02,  4.3981e-02, -2.0199e-02],\n",
      "          [ 4.2224e-02, -1.2594e-03,  6.2496e-03]]]]))\n",
      "('conv2.0.bias', Parameter containing:\n",
      "tensor([-1.6499e-08,  3.3774e-08, -9.3468e-08,  2.0996e-08, -1.9149e-08,\n",
      "         1.3688e-07,  4.3155e-08,  1.1174e-08,  1.6133e-08, -2.1015e-08,\n",
      "         7.5070e-08, -1.4814e-07, -2.4482e-08, -1.6594e-08,  2.5202e-08,\n",
      "         1.0461e-07,  9.2944e-08,  5.4724e-08,  2.6107e-08, -7.7266e-08,\n",
      "        -9.8810e-08,  2.8143e-08, -6.5721e-09, -6.9736e-08,  1.8528e-08,\n",
      "         3.8895e-09, -6.4002e-08,  1.1088e-07, -6.8483e-08, -1.0203e-07,\n",
      "         1.0283e-07,  1.0391e-07,  1.7513e-08,  1.3859e-07, -7.2410e-09,\n",
      "        -2.3434e-08,  1.4159e-08, -6.7254e-08, -4.5731e-08, -1.2282e-07,\n",
      "        -1.1360e-07, -8.7575e-08, -3.6839e-08, -1.3048e-09, -7.9694e-08,\n",
      "        -2.9485e-08,  6.9338e-08, -4.7063e-08,  8.6995e-08,  1.4112e-07,\n",
      "        -1.5240e-07,  2.4311e-07, -3.0640e-08,  7.6742e-10, -2.0688e-08,\n",
      "        -2.6958e-08, -3.6417e-09,  1.0575e-07,  3.8202e-08,  1.6499e-08,\n",
      "         4.1066e-08,  1.4309e-07, -4.9630e-08, -1.8386e-08,  1.3954e-08,\n",
      "        -1.9350e-08, -6.2474e-08,  8.3172e-09, -8.7903e-08, -9.0618e-08,\n",
      "         1.7879e-08,  7.3504e-09,  1.0621e-08, -5.6970e-08,  3.9196e-08,\n",
      "        -5.9749e-09, -8.0334e-08, -1.5494e-08,  1.2876e-08, -2.4839e-08,\n",
      "         2.9117e-08, -1.8259e-07, -3.3771e-08,  6.6529e-09,  1.0568e-07,\n",
      "        -3.1697e-07,  5.6300e-08, -4.9280e-08,  1.1180e-08,  2.1504e-08,\n",
      "        -1.7991e-07,  8.0806e-09,  4.8308e-08,  1.4875e-07, -9.6453e-09,\n",
      "         4.4190e-08, -1.7391e-08, -9.1594e-09, -8.7827e-08, -5.8298e-08,\n",
      "         9.1427e-08, -5.7823e-08, -1.0138e-07,  1.8262e-08,  1.1012e-07,\n",
      "         6.4249e-09,  1.7344e-08,  4.6663e-08,  1.3137e-07,  1.0174e-07,\n",
      "        -6.3887e-08, -3.9846e-08,  1.4663e-07,  1.6024e-08,  7.5800e-08,\n",
      "         1.1947e-07,  7.8542e-08, -8.5927e-08,  3.5642e-08, -6.3433e-08,\n",
      "        -1.0508e-07, -8.5723e-08,  1.7530e-07,  6.1206e-08, -2.1454e-08,\n",
      "         6.0382e-09, -1.1245e-07, -5.4727e-08]))\n",
      "('conv2.1.weight', Parameter containing:\n",
      "tensor([0.5948, 0.5885, 0.6505, 0.5646, 0.5167, 0.5861, 0.6365, 0.5021, 0.7385,\n",
      "        0.6356, 0.6138, 0.5769, 0.6966, 0.6888, 0.4793, 0.6291, 0.5188, 0.6596,\n",
      "        0.6558, 0.5623, 0.5615, 0.5683, 0.5514, 0.5811, 0.5518, 0.6151, 0.6097,\n",
      "        0.5486, 0.6415, 0.6731, 0.5558, 0.5655, 0.5443, 0.5617, 0.5718, 0.6260,\n",
      "        0.5575, 0.5129, 0.4903, 0.5925, 0.5568, 0.4665, 0.6339, 0.5337, 0.6719,\n",
      "        0.5839, 0.6705, 0.6152, 0.6737, 0.6275, 0.6904, 0.6507, 0.6237, 0.5326,\n",
      "        0.6122, 0.7299, 0.7406, 0.5608, 0.6438, 0.5072, 0.5742, 0.6192, 0.6051,\n",
      "        0.6572, 0.5509, 0.5713, 0.5414, 0.6393, 0.6094, 0.5791, 0.5039, 0.5507,\n",
      "        0.5520, 0.5883, 0.5205, 0.5078, 0.5966, 0.5265, 0.5900, 0.6015, 0.6578,\n",
      "        0.6190, 0.4935, 0.5405, 0.6384, 0.7165, 0.5393, 0.6263, 0.6171, 0.5388,\n",
      "        0.6593, 0.5782, 0.6751, 0.5840, 0.6097, 0.5502, 0.4613, 0.5851, 0.6752,\n",
      "        0.5764, 0.6000, 0.5488, 0.7341, 0.6385, 0.5939, 0.6454, 0.5993, 0.5905,\n",
      "        0.4903, 0.5889, 0.6545, 0.4512, 0.6850, 0.6769, 0.5909, 0.8040, 0.5990,\n",
      "        0.5564, 0.4643, 0.5846, 0.6134, 0.6835, 0.5400, 0.5801, 0.4945, 0.5943,\n",
      "        0.5200, 0.6021]))\n",
      "('conv2.1.bias', Parameter containing:\n",
      "tensor([-0.1314, -0.0927, -0.1033, -0.1177, -0.1637, -0.0974, -0.1446, -0.1400,\n",
      "        -0.1832, -0.0963, -0.1372, -0.0957, -0.0881, -0.0828, -0.1245, -0.1322,\n",
      "        -0.0843, -0.0956, -0.1122, -0.0684, -0.0817, -0.1022, -0.0950, -0.1443,\n",
      "        -0.1060, -0.1255, -0.1087, -0.1074, -0.1005, -0.0832, -0.0930, -0.1143,\n",
      "        -0.1193, -0.0978, -0.1030, -0.0694, -0.0856, -0.1634, -0.0812, -0.1376,\n",
      "        -0.0653, -0.1129, -0.1021, -0.1181, -0.1429, -0.0977, -0.1093, -0.0915,\n",
      "        -0.0603, -0.1332, -0.0752, -0.1238, -0.0883, -0.0883, -0.1044, -0.0921,\n",
      "        -0.1088, -0.1038, -0.1090, -0.1387, -0.1649, -0.1328, -0.0716, -0.0753,\n",
      "        -0.0693, -0.1274, -0.0803, -0.1165, -0.1239, -0.1576, -0.1536, -0.1029,\n",
      "        -0.1048, -0.1190, -0.1363, -0.1101, -0.0765, -0.0920, -0.1151, -0.0704,\n",
      "        -0.0517, -0.0709, -0.0801, -0.1280, -0.1313, -0.1106, -0.1212, -0.0692,\n",
      "        -0.1418, -0.0852, -0.1807, -0.1228, -0.1508, -0.1159, -0.1403, -0.0688,\n",
      "        -0.1019, -0.1246, -0.1507, -0.1513, -0.0670, -0.1357, -0.1031, -0.1199,\n",
      "        -0.1512, -0.1364, -0.0967, -0.1418, -0.0927, -0.0667, -0.1042, -0.1318,\n",
      "        -0.0598, -0.1285, -0.0605, -0.1006, -0.0927, -0.0584, -0.1030, -0.1628,\n",
      "        -0.0982, -0.1016, -0.0969, -0.1100, -0.1387, -0.1029, -0.1191, -0.1272]))\n",
      "('res1.0.0.weight', Parameter containing:\n",
      "tensor([[[[ 9.7626e-03, -4.6681e-04,  1.9322e-02],\n",
      "          [-1.1948e-02,  6.8808e-03,  1.4673e-02],\n",
      "          [ 7.6763e-03,  1.3591e-02,  1.2084e-02]],\n",
      "\n",
      "         [[-4.8247e-03,  9.6675e-03,  4.3417e-04],\n",
      "          [-6.3488e-03, -5.6654e-04, -1.2570e-02],\n",
      "          [-1.8458e-02, -7.7863e-03, -5.0200e-03]],\n",
      "\n",
      "         [[ 1.7512e-02, -1.9921e-02, -1.8381e-02],\n",
      "          [ 3.3625e-02, -7.1819e-03, -2.2760e-02],\n",
      "          [ 2.7903e-02,  1.8531e-02,  1.9693e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1963e-02,  3.4816e-03,  1.8819e-02],\n",
      "          [ 1.8688e-02, -3.8392e-05, -1.0000e-02],\n",
      "          [ 1.0381e-02,  9.0482e-03, -8.3377e-03]],\n",
      "\n",
      "         [[ 1.6770e-02,  7.0396e-03,  2.4533e-03],\n",
      "          [ 3.6287e-03, -1.3583e-02, -5.2597e-03],\n",
      "          [ 1.1078e-03,  1.0754e-03,  8.2911e-03]],\n",
      "\n",
      "         [[-1.5715e-03, -3.8924e-02, -2.2102e-02],\n",
      "          [ 8.8709e-03, -3.3565e-02, -6.2843e-03],\n",
      "          [ 9.8114e-03,  1.2385e-02,  2.3840e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.8931e-03,  6.6841e-03, -1.3554e-03],\n",
      "          [ 1.6528e-03, -1.4233e-02,  2.3902e-03],\n",
      "          [-1.5102e-02, -5.6513e-03,  1.0318e-02]],\n",
      "\n",
      "         [[-2.6294e-02, -3.9017e-03,  2.0950e-02],\n",
      "          [-3.1484e-04, -7.2026e-03,  3.6754e-03],\n",
      "          [-8.7470e-03,  1.4004e-02,  2.1299e-02]],\n",
      "\n",
      "         [[-3.7474e-03,  2.7929e-04,  5.7494e-03],\n",
      "          [ 1.5640e-02,  1.6814e-03,  1.0741e-02],\n",
      "          [ 3.6508e-02,  2.4063e-02, -1.0383e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2154e-02,  1.6694e-04,  9.5525e-03],\n",
      "          [-1.6153e-02, -4.9780e-02, -3.3286e-02],\n",
      "          [ 6.7653e-03, -2.3929e-02, -3.6450e-02]],\n",
      "\n",
      "         [[-8.8200e-03, -1.2722e-02, -7.9320e-03],\n",
      "          [-1.0755e-02, -9.2702e-03,  8.4304e-03],\n",
      "          [-1.4093e-02, -1.9367e-02, -5.0011e-03]],\n",
      "\n",
      "         [[ 1.1839e-03, -5.0115e-03,  1.3496e-02],\n",
      "          [-1.1169e-02, -6.6783e-03, -1.2655e-02],\n",
      "          [-2.2188e-03,  4.9335e-04, -1.2213e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.8345e-03,  1.5212e-02, -1.9907e-02],\n",
      "          [ 2.5348e-02, -2.8449e-03, -7.2303e-04],\n",
      "          [ 1.2909e-02,  4.4186e-03, -5.0533e-03]],\n",
      "\n",
      "         [[ 3.6311e-03, -1.5571e-02, -2.8317e-03],\n",
      "          [-2.1826e-04,  1.8858e-03, -1.4681e-02],\n",
      "          [ 1.3342e-02,  8.7702e-04, -1.5681e-02]],\n",
      "\n",
      "         [[ 6.9251e-03,  3.5817e-02, -2.6569e-05],\n",
      "          [ 2.0814e-02,  2.3099e-02,  5.0190e-03],\n",
      "          [ 2.5127e-02,  5.0968e-02,  3.8450e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.6033e-02,  1.6909e-02,  9.0043e-03],\n",
      "          [ 1.2129e-02,  2.0034e-02,  9.8760e-04],\n",
      "          [ 7.1780e-03,  1.1641e-02, -5.8482e-03]],\n",
      "\n",
      "         [[-4.2895e-03, -3.8459e-03, -5.3868e-03],\n",
      "          [-1.2659e-02, -1.2098e-02, -6.4797e-03],\n",
      "          [-1.3223e-02, -2.0720e-02, -1.9875e-02]],\n",
      "\n",
      "         [[-2.3843e-03,  3.1850e-03,  1.9965e-03],\n",
      "          [-1.3750e-02, -5.7704e-03, -1.7991e-02],\n",
      "          [ 1.1738e-02,  9.1645e-03, -2.5690e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-7.5754e-03, -1.5263e-03, -1.8984e-02],\n",
      "          [ 2.8107e-03, -1.3162e-02,  6.9531e-03],\n",
      "          [ 4.4634e-03,  1.5400e-02, -8.6874e-03]],\n",
      "\n",
      "         [[ 1.8954e-02, -6.0491e-03, -3.5410e-03],\n",
      "          [ 1.7777e-02,  3.6948e-03, -1.2764e-02],\n",
      "          [-3.8898e-03, -1.9245e-03,  2.1159e-03]],\n",
      "\n",
      "         [[-1.8444e-03,  1.2885e-02,  7.2849e-03],\n",
      "          [-5.8702e-03,  4.9522e-03, -2.2021e-03],\n",
      "          [-1.0627e-02,  4.7736e-03,  6.0756e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.1924e-03, -6.2079e-03,  2.3248e-02],\n",
      "          [ 8.9427e-03, -1.7287e-02, -1.0065e-02],\n",
      "          [ 4.4779e-03,  9.7971e-03,  2.0792e-02]],\n",
      "\n",
      "         [[ 1.5512e-02, -1.2406e-02, -5.7379e-03],\n",
      "          [-6.3600e-03, -3.1408e-02, -2.9705e-03],\n",
      "          [ 2.4789e-02,  2.0611e-02,  9.2053e-03]],\n",
      "\n",
      "         [[ 1.1733e-02, -1.3470e-02,  4.6171e-03],\n",
      "          [ 2.2772e-02,  3.5636e-04,  4.8822e-03],\n",
      "          [-1.3532e-05,  1.5771e-03,  5.2966e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.0931e-02, -8.9452e-03,  1.1570e-03],\n",
      "          [-1.2438e-02,  3.0357e-04, -1.8483e-02],\n",
      "          [ 5.1315e-04,  7.5098e-03, -4.3110e-03]],\n",
      "\n",
      "         [[-8.3199e-03, -6.1630e-03, -1.1488e-02],\n",
      "          [-8.5006e-03, -9.1505e-03, -1.0306e-02],\n",
      "          [-1.4975e-02,  4.3940e-03,  5.2624e-04]],\n",
      "\n",
      "         [[ 4.9965e-03,  4.4188e-03,  1.4550e-02],\n",
      "          [ 2.6375e-03,  3.3113e-02,  3.6308e-02],\n",
      "          [ 2.6218e-02,  2.2027e-02,  1.5472e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3709e-03, -7.7728e-03,  1.9824e-02],\n",
      "          [-3.0656e-03, -2.9128e-02, -2.6847e-02],\n",
      "          [-2.4781e-03, -2.7245e-02, -1.0374e-03]],\n",
      "\n",
      "         [[-5.8333e-03, -2.5445e-03,  2.6270e-03],\n",
      "          [ 1.1027e-04, -5.2945e-03,  1.0672e-02],\n",
      "          [-1.9714e-02,  1.0378e-02, -7.8234e-03]],\n",
      "\n",
      "         [[-6.5101e-03, -6.1781e-03, -9.4581e-03],\n",
      "          [-6.9575e-03, -2.6333e-02, -2.2490e-02],\n",
      "          [ 3.1834e-05, -1.3538e-02, -1.8255e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1677e-02, -9.1368e-03, -2.1008e-03],\n",
      "          [-1.8651e-02, -9.0340e-03,  1.4513e-03],\n",
      "          [-1.6604e-02,  8.6152e-03,  1.0817e-02]],\n",
      "\n",
      "         [[ 2.1818e-02,  7.0819e-03,  1.6764e-02],\n",
      "          [ 7.6791e-03, -5.4279e-03,  1.2453e-02],\n",
      "          [-8.2493e-03, -1.1669e-02, -1.0747e-02]],\n",
      "\n",
      "         [[-3.0731e-02, -2.6824e-02, -3.6349e-02],\n",
      "          [ 5.0767e-04,  1.6538e-03, -3.5968e-03],\n",
      "          [-4.0992e-02, -2.1220e-02, -2.9571e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6817e-02, -3.2020e-02, -1.2423e-02],\n",
      "          [ 8.2608e-03,  3.9627e-03,  1.6332e-02],\n",
      "          [-8.8508e-03,  1.0782e-02,  1.0505e-02]],\n",
      "\n",
      "         [[ 2.1496e-02, -1.8696e-03,  2.2729e-02],\n",
      "          [ 8.2421e-03, -5.9913e-03,  1.1706e-02],\n",
      "          [-2.1308e-03, -2.9079e-03,  1.6695e-02]],\n",
      "\n",
      "         [[ 3.8255e-04, -1.1149e-02, -1.1838e-02],\n",
      "          [-3.6439e-03,  1.1215e-02,  4.9463e-03],\n",
      "          [ 3.0613e-03, -7.5590e-03, -9.6223e-03]]]]))\n",
      "('res1.0.0.bias', Parameter containing:\n",
      "tensor([-2.1264e-08,  2.4482e-08,  2.7934e-08, -6.5943e-09,  5.0586e-09,\n",
      "         5.4192e-08, -1.7359e-08,  3.9437e-09,  2.0025e-08, -2.6515e-08,\n",
      "         3.1937e-08, -3.7610e-08, -1.2898e-08, -7.9145e-09, -6.7215e-08,\n",
      "        -5.5337e-08,  9.0979e-10, -4.0841e-08, -7.5816e-09,  1.1700e-07,\n",
      "         3.4208e-08,  1.9950e-08, -1.6269e-08,  1.1212e-08,  1.9194e-08,\n",
      "        -1.4997e-07,  1.3803e-08, -7.1015e-08, -2.4491e-08, -3.6298e-08,\n",
      "        -7.0097e-08,  7.9256e-09,  9.9316e-09, -5.5874e-09, -2.1561e-08,\n",
      "         7.2071e-08,  8.0746e-08, -9.3279e-09,  4.0258e-08,  2.4020e-08,\n",
      "        -1.2358e-07,  5.0896e-08, -3.3091e-08,  1.9857e-08,  2.1983e-08,\n",
      "         4.9415e-08,  2.9227e-08,  4.6328e-08,  8.5235e-08,  3.6845e-08,\n",
      "         5.0975e-08, -2.4644e-08, -4.7602e-08, -1.9100e-08,  1.5535e-08,\n",
      "        -1.4915e-08, -3.2174e-08,  1.9493e-08, -4.5928e-09,  2.5114e-08,\n",
      "         7.3574e-09, -8.8953e-08, -3.0517e-08,  8.9472e-09,  3.1187e-08,\n",
      "         3.9188e-09,  4.5349e-08,  3.4729e-08, -1.9041e-08,  2.0541e-08,\n",
      "        -2.7294e-09,  2.0520e-09, -2.0962e-08,  4.0709e-08, -4.6305e-08,\n",
      "        -9.9007e-09, -1.1657e-08,  1.5458e-08, -9.0953e-08, -3.2970e-09,\n",
      "         3.0250e-08, -1.1214e-07, -3.7616e-08,  3.1724e-08,  2.3227e-08,\n",
      "         7.1320e-09, -6.5246e-08, -5.6226e-09, -9.3137e-08, -2.9833e-08,\n",
      "         4.7202e-08,  9.5211e-09,  3.0524e-08,  1.5199e-08,  3.2334e-08,\n",
      "         5.7445e-08,  1.9076e-08, -3.2079e-08,  4.0005e-08, -7.2316e-08,\n",
      "         2.2481e-09, -6.3645e-08, -1.1419e-07,  2.8180e-08, -9.2691e-09,\n",
      "         6.7931e-08,  4.1711e-08,  2.1269e-08,  1.3870e-08, -3.4053e-08,\n",
      "        -4.6868e-08, -1.8069e-09, -6.0634e-09,  1.9907e-08, -3.1936e-08,\n",
      "         9.5715e-09, -2.5162e-08,  1.7000e-08,  2.1387e-07, -3.4478e-08,\n",
      "        -2.8975e-08,  1.8483e-08, -4.6512e-08,  1.4747e-08,  5.0621e-08,\n",
      "        -1.2963e-08,  1.4424e-09, -3.6602e-08]))\n",
      "('res1.0.1.weight', Parameter containing:\n",
      "tensor([0.4742, 0.5367, 0.4468, 0.4780, 0.4752, 0.3927, 0.4039, 0.5117, 0.5892,\n",
      "        0.4735, 0.5350, 0.5337, 0.5593, 0.4995, 0.5076, 0.4663, 0.4404, 0.4777,\n",
      "        0.4664, 0.5191, 0.4535, 0.4662, 0.4673, 0.4924, 0.5219, 0.5138, 0.4866,\n",
      "        0.4676, 0.4465, 0.4338, 0.5470, 0.4096, 0.4178, 0.4796, 0.5460, 0.4637,\n",
      "        0.5097, 0.5077, 0.4697, 0.4657, 0.5041, 0.4158, 0.4486, 0.4762, 0.6085,\n",
      "        0.4929, 0.5654, 0.4586, 0.4688, 0.5623, 0.4668, 0.5240, 0.5273, 0.4630,\n",
      "        0.4076, 0.5284, 0.5293, 0.4503, 0.5354, 0.4808, 0.4997, 0.5554, 0.6066,\n",
      "        0.4514, 0.5026, 0.4049, 0.4957, 0.4569, 0.3557, 0.5364, 0.4672, 0.5331,\n",
      "        0.4116, 0.5306, 0.4437, 0.4539, 0.4124, 0.4045, 0.5073, 0.4433, 0.4531,\n",
      "        0.5135, 0.4465, 0.4736, 0.5360, 0.4916, 0.4156, 0.4184, 0.5334, 0.5483,\n",
      "        0.5201, 0.4858, 0.4788, 0.5415, 0.4994, 0.5059, 0.5020, 0.4240, 0.4421,\n",
      "        0.5249, 0.4575, 0.4484, 0.5287, 0.5323, 0.5286, 0.5076, 0.4468, 0.4326,\n",
      "        0.4722, 0.5478, 0.5193, 0.4313, 0.3994, 0.5579, 0.4712, 0.5356, 0.4077,\n",
      "        0.5360, 0.5154, 0.5102, 0.4578, 0.4330, 0.4588, 0.4864, 0.5034, 0.5182,\n",
      "        0.4482, 0.3916]))\n",
      "('res1.0.1.bias', Parameter containing:\n",
      "tensor([-0.0912, -0.1424, -0.1209, -0.0789, -0.0785, -0.0778, -0.0646, -0.1104,\n",
      "        -0.1128, -0.0838, -0.0767, -0.1230, -0.0863, -0.1061, -0.0431, -0.1242,\n",
      "        -0.1068, -0.1018, -0.1167, -0.1061, -0.1029, -0.1039, -0.0884, -0.1254,\n",
      "        -0.1143, -0.1545, -0.1309, -0.0543, -0.0798, -0.0935, -0.0895, -0.1075,\n",
      "        -0.0797, -0.0653, -0.0849, -0.1192, -0.1331, -0.0697, -0.0601, -0.0826,\n",
      "        -0.1012, -0.0718, -0.0939, -0.0710, -0.0997, -0.0833, -0.1012, -0.0774,\n",
      "        -0.0772, -0.0860, -0.0217, -0.1047, -0.1217, -0.0718, -0.0677, -0.0991,\n",
      "        -0.0671, -0.1043, -0.0977, -0.0708, -0.1189, -0.0982, -0.1262, -0.0894,\n",
      "        -0.0806, -0.0545, -0.1029, -0.0928, -0.0512, -0.0797, -0.0928, -0.0948,\n",
      "        -0.0395, -0.0825, -0.0844, -0.0689, -0.0826, -0.0152, -0.0890, -0.1214,\n",
      "        -0.0887, -0.1259, -0.0929, -0.0921, -0.0754, -0.0723, -0.0657, -0.0547,\n",
      "        -0.0815, -0.1283, -0.1242, -0.1181, -0.1368, -0.0949, -0.0853, -0.1038,\n",
      "        -0.1046, -0.1230, -0.0750, -0.1224, -0.0756, -0.1033, -0.1256, -0.1083,\n",
      "        -0.1160, -0.0961, -0.0871, -0.1041, -0.1107, -0.0834, -0.0990, -0.0787,\n",
      "        -0.0869, -0.0750, -0.0689, -0.0976, -0.0945, -0.1054, -0.1109, -0.1017,\n",
      "        -0.0809, -0.0771, -0.1095, -0.0686, -0.1072, -0.0847, -0.1178, -0.0713]))\n",
      "('res1.1.0.weight', Parameter containing:\n",
      "tensor([[[[ 1.2800e-02,  2.3554e-02,  2.7668e-02],\n",
      "          [ 1.5121e-02,  4.4540e-02,  2.1293e-02],\n",
      "          [ 1.8747e-02,  3.4384e-02,  4.8302e-02]],\n",
      "\n",
      "         [[ 1.6443e-03,  3.8352e-03, -1.0519e-02],\n",
      "          [ 1.1768e-02,  3.5972e-02,  1.8253e-03],\n",
      "          [ 1.5742e-02,  3.0749e-02,  1.0166e-02]],\n",
      "\n",
      "         [[ 2.7811e-03,  2.3744e-03, -1.7938e-02],\n",
      "          [-5.4600e-03,  2.3021e-03, -1.2809e-02],\n",
      "          [-6.6779e-03, -8.8367e-03,  3.5643e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.5687e-04,  2.2376e-02,  2.1617e-03],\n",
      "          [-1.7312e-03,  1.6636e-02,  5.5251e-03],\n",
      "          [-7.0128e-03,  1.6393e-02,  1.8528e-02]],\n",
      "\n",
      "         [[ 8.0678e-03,  2.3291e-02, -1.3637e-02],\n",
      "          [ 2.4210e-02,  3.1648e-02, -1.2870e-02],\n",
      "          [ 2.8680e-02,  2.0560e-02,  7.8178e-03]],\n",
      "\n",
      "         [[-5.8977e-03,  1.1474e-02,  1.1045e-02],\n",
      "          [ 1.7270e-02,  2.2740e-02,  2.0380e-02],\n",
      "          [ 1.2840e-04, -7.2519e-03, -1.6376e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8574e-02, -2.6311e-03, -4.7618e-03],\n",
      "          [-1.6127e-02, -1.2570e-02, -9.5188e-03],\n",
      "          [-1.8255e-02, -9.1276e-03,  3.6464e-03]],\n",
      "\n",
      "         [[ 1.4780e-02,  4.1739e-02,  2.1614e-02],\n",
      "          [-2.0980e-02,  9.3768e-04,  1.7807e-02],\n",
      "          [-5.7106e-03, -1.8990e-02, -1.4057e-02]],\n",
      "\n",
      "         [[ 1.4775e-02,  6.8313e-03,  8.8943e-03],\n",
      "          [ 2.0473e-02, -1.2088e-03, -1.0177e-02],\n",
      "          [ 9.9061e-03, -5.4984e-03, -1.5522e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.2990e-02, -2.4742e-02, -2.2233e-03],\n",
      "          [ 2.7766e-03,  3.2249e-03, -9.6282e-03],\n",
      "          [ 2.2151e-02,  9.2195e-03,  1.1438e-02]],\n",
      "\n",
      "         [[ 1.9346e-02,  2.1455e-02,  2.1446e-02],\n",
      "          [-2.3064e-03,  3.2169e-03,  1.7139e-02],\n",
      "          [-3.2618e-02, -9.6077e-03, -7.5979e-04]],\n",
      "\n",
      "         [[-9.5090e-03,  8.1085e-03, -2.1855e-03],\n",
      "          [-8.2363e-03,  8.1077e-03, -2.1431e-03],\n",
      "          [ 6.0259e-03,  2.8720e-02,  2.4315e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4817e-03,  1.0921e-02,  3.0864e-02],\n",
      "          [-3.4022e-02, -3.2004e-02,  7.6321e-03],\n",
      "          [-1.7607e-02, -2.8896e-02, -7.2747e-04]],\n",
      "\n",
      "         [[-1.3630e-02, -1.8574e-02,  6.5570e-03],\n",
      "          [ 6.8704e-03, -7.2511e-03, -9.5364e-03],\n",
      "          [ 5.2467e-03, -8.1088e-03, -2.1178e-02]],\n",
      "\n",
      "         [[-1.8082e-02, -3.5918e-03, -6.1402e-03],\n",
      "          [-2.8045e-02, -2.2492e-02, -2.6886e-03],\n",
      "          [-8.9176e-03, -3.8850e-05, -1.6799e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.2850e-03,  2.1985e-02,  4.6707e-03],\n",
      "          [ 3.3231e-03, -7.1658e-03,  1.1632e-02],\n",
      "          [-1.6163e-02, -2.1396e-02,  5.8428e-03]],\n",
      "\n",
      "         [[ 1.8189e-02,  3.8330e-03,  3.1450e-02],\n",
      "          [ 1.2185e-02,  4.2336e-03,  4.3742e-03],\n",
      "          [ 2.1303e-02, -5.8053e-03, -5.0740e-03]],\n",
      "\n",
      "         [[-1.7466e-02, -2.9540e-02, -2.0805e-02],\n",
      "          [ 1.8480e-03, -3.4652e-02, -1.8528e-02],\n",
      "          [ 3.6471e-02, -3.9509e-05,  7.5280e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.1602e-03, -1.5615e-02,  1.6220e-02],\n",
      "          [-1.9513e-02, -2.0047e-02, -1.7306e-03],\n",
      "          [-1.4629e-03, -5.5491e-04, -2.7886e-03]],\n",
      "\n",
      "         [[ 1.9304e-02,  2.4266e-02,  3.1655e-02],\n",
      "          [-2.2269e-02, -1.2823e-02,  4.4531e-03],\n",
      "          [-2.4681e-02, -2.7274e-02, -1.9130e-03]],\n",
      "\n",
      "         [[ 8.2065e-03, -8.4882e-03, -6.4432e-03],\n",
      "          [-2.5251e-02, -2.3288e-02, -6.0773e-03],\n",
      "          [-2.3361e-02, -1.5687e-02, -9.5693e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.9662e-02, -2.3581e-02, -4.5599e-02],\n",
      "          [ 1.4156e-02, -1.4254e-02, -2.2969e-02],\n",
      "          [ 2.4843e-02,  9.1915e-03,  7.9150e-03]],\n",
      "\n",
      "         [[ 1.1576e-02, -2.4281e-03,  2.0650e-02],\n",
      "          [ 6.0789e-03, -8.5390e-03,  1.0576e-02],\n",
      "          [ 8.7207e-03,  8.2407e-03,  4.7610e-03]],\n",
      "\n",
      "         [[-2.2995e-02, -9.9028e-03, -3.1697e-03],\n",
      "          [-5.6579e-03, -1.1298e-02, -1.7819e-02],\n",
      "          [-9.7723e-03, -1.2758e-02,  1.6084e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5819e-02,  1.4544e-02, -1.9374e-02],\n",
      "          [ 1.2660e-02,  6.4538e-03, -3.7606e-04],\n",
      "          [ 2.1679e-02,  1.3317e-02,  4.7172e-03]],\n",
      "\n",
      "         [[ 7.1730e-03,  8.5879e-03,  2.4314e-02],\n",
      "          [ 1.1157e-02,  1.8462e-02,  1.0847e-02],\n",
      "          [ 6.2723e-03,  1.4829e-02,  1.6369e-02]],\n",
      "\n",
      "         [[-5.8179e-03,  1.0389e-02, -3.4318e-03],\n",
      "          [ 9.7385e-03, -9.6579e-03,  5.2974e-03],\n",
      "          [-8.9566e-04, -4.0328e-04, -1.7305e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.2175e-02,  1.5515e-02,  1.2809e-02],\n",
      "          [ 1.3366e-02,  6.7399e-03, -1.8300e-03],\n",
      "          [ 2.3926e-03,  5.4625e-03,  2.6979e-02]],\n",
      "\n",
      "         [[-4.1152e-03, -2.5664e-02, -1.4730e-02],\n",
      "          [ 2.2420e-03, -2.0390e-02, -1.3849e-02],\n",
      "          [ 4.9137e-04, -5.8812e-04, -5.0870e-03]],\n",
      "\n",
      "         [[-1.1190e-03, -4.3722e-03, -1.6130e-02],\n",
      "          [ 4.4258e-03, -1.0509e-02, -7.8195e-03],\n",
      "          [-1.8613e-02, -2.7444e-02, -9.4812e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7776e-02, -1.4852e-03,  5.1765e-03],\n",
      "          [ 2.1581e-02,  9.7758e-03, -8.0664e-03],\n",
      "          [ 4.1739e-03,  9.5806e-04, -1.9957e-02]],\n",
      "\n",
      "         [[-1.0494e-02,  5.3867e-03, -9.2015e-03],\n",
      "          [ 1.1916e-04, -1.1084e-03, -6.6788e-03],\n",
      "          [ 6.0469e-03,  1.6331e-02, -7.9527e-03]],\n",
      "\n",
      "         [[ 7.7945e-04, -7.3186e-03, -3.7663e-03],\n",
      "          [ 9.3018e-03, -9.5710e-04,  7.4014e-03],\n",
      "          [-1.8548e-02,  5.4373e-03,  9.7184e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.8307e-04, -1.7488e-02, -4.2857e-02],\n",
      "          [ 3.2467e-02, -1.4151e-03, -1.7459e-02],\n",
      "          [ 8.5983e-03,  1.1822e-02,  3.3801e-03]],\n",
      "\n",
      "         [[-1.8627e-02, -1.2989e-02, -7.6311e-03],\n",
      "          [ 1.2560e-02,  8.0847e-04, -5.6655e-03],\n",
      "          [ 2.2682e-02,  2.5036e-03, -1.6301e-02]],\n",
      "\n",
      "         [[-1.2597e-02, -8.1700e-03, -9.9671e-03],\n",
      "          [-1.0465e-02, -1.5664e-02, -2.4561e-02],\n",
      "          [ 4.4396e-03,  2.4702e-02,  5.3715e-03]]]]))\n",
      "('res1.1.0.bias', Parameter containing:\n",
      "tensor([-1.1895e-08, -2.6828e-08,  9.2283e-08,  1.0010e-07,  2.5699e-08,\n",
      "         8.8450e-09,  6.7446e-09,  1.7507e-08,  2.2607e-08,  9.0458e-08,\n",
      "        -9.9976e-08,  5.6857e-08, -6.3599e-09,  1.0877e-07, -4.4694e-08,\n",
      "         6.2338e-08,  4.6327e-08,  1.9385e-08, -5.6709e-08,  6.9503e-08,\n",
      "         1.1128e-07, -8.3603e-08, -3.6785e-08, -1.0343e-10,  1.1049e-07,\n",
      "        -7.0913e-08,  4.0316e-08,  2.3463e-08,  4.5797e-08, -1.5613e-08,\n",
      "         2.3535e-08, -5.6107e-08,  3.4737e-08, -1.0641e-07,  2.6839e-08,\n",
      "         3.9636e-09, -6.2851e-08,  4.7295e-08, -1.2286e-08, -3.3519e-08,\n",
      "         2.4506e-08,  4.5910e-08, -3.0282e-08,  1.3426e-08, -1.7303e-08,\n",
      "         1.1617e-07,  7.3323e-08, -9.9734e-09, -2.3414e-08,  6.2517e-08,\n",
      "        -3.6852e-08, -4.9611e-08,  5.4596e-08, -1.8225e-08,  5.0309e-08,\n",
      "         5.2452e-08,  5.1051e-08,  3.4919e-09,  9.4127e-10,  2.8465e-08,\n",
      "        -5.4868e-08, -9.8591e-09,  1.4205e-08,  5.0661e-08, -3.2398e-08,\n",
      "         1.7956e-07, -1.0008e-07,  3.6846e-08,  1.3920e-07,  2.2159e-08,\n",
      "        -1.2888e-08,  2.0346e-10, -8.6197e-08, -1.1917e-08,  1.9287e-08,\n",
      "        -6.2019e-08,  6.1619e-08, -1.0543e-07,  1.7753e-07, -3.5360e-08,\n",
      "        -7.6063e-08,  2.9017e-08, -9.9384e-08, -1.9193e-08,  1.8600e-08,\n",
      "        -2.8275e-08,  3.0913e-08, -3.8004e-08, -5.0874e-08,  7.0252e-09,\n",
      "         4.1221e-08, -1.0261e-07,  7.4717e-08, -4.2231e-08, -1.2699e-07,\n",
      "         4.8590e-08, -1.1720e-08,  2.0250e-08, -3.4060e-08, -8.3296e-08,\n",
      "        -9.2968e-08,  2.2425e-08,  6.5343e-08,  7.3157e-08,  3.1663e-08,\n",
      "         1.6694e-09, -4.3078e-08,  7.1713e-08, -2.6377e-08,  1.0587e-07,\n",
      "         1.8186e-08,  9.5811e-08,  7.7301e-09,  5.8041e-08, -1.4830e-08,\n",
      "        -4.9640e-08, -3.6477e-08, -3.6975e-08,  8.5562e-09,  3.8881e-08,\n",
      "        -6.6593e-08,  8.2538e-08,  1.2198e-07,  1.2447e-08, -1.3323e-08,\n",
      "         5.4105e-09,  5.1118e-08, -3.3079e-08]))\n",
      "('res1.1.1.weight', Parameter containing:\n",
      "tensor([0.6527, 0.5013, 0.5277, 0.4945, 0.5313, 0.5066, 0.5192, 0.5783, 0.5484,\n",
      "        0.5709, 0.5599, 0.5688, 0.4666, 0.5253, 0.4788, 0.5055, 0.4451, 0.5130,\n",
      "        0.5519, 0.6166, 0.4705, 0.4900, 0.5095, 0.4876, 0.4834, 0.5121, 0.5503,\n",
      "        0.5094, 0.5550, 0.5609, 0.4520, 0.5641, 0.5929, 0.4635, 0.5665, 0.5675,\n",
      "        0.6442, 0.4713, 0.4509, 0.4476, 0.4872, 0.4995, 0.5846, 0.5280, 0.5455,\n",
      "        0.4900, 0.5735, 0.4264, 0.5965, 0.5673, 0.4811, 0.6029, 0.5261, 0.5418,\n",
      "        0.5787, 0.5419, 0.5663, 0.5036, 0.6201, 0.6155, 0.6051, 0.4938, 0.5769,\n",
      "        0.5530, 0.5156, 0.5306, 0.5133, 0.6421, 0.5533, 0.5922, 0.4861, 0.5138,\n",
      "        0.5412, 0.5151, 0.5156, 0.5203, 0.5526, 0.4543, 0.5086, 0.5980, 0.5469,\n",
      "        0.5659, 0.4872, 0.5689, 0.5796, 0.5323, 0.5451, 0.5469, 0.5283, 0.5204,\n",
      "        0.5838, 0.5282, 0.6059, 0.5238, 0.6163, 0.4816, 0.5422, 0.5793, 0.5502,\n",
      "        0.5769, 0.5904, 0.4662, 0.5721, 0.5161, 0.4891, 0.5955, 0.5704, 0.5703,\n",
      "        0.4393, 0.5102, 0.5962, 0.4838, 0.5338, 0.5779, 0.6284, 0.5661, 0.5428,\n",
      "        0.5330, 0.5068, 0.5027, 0.5644, 0.6092, 0.5500, 0.5866, 0.4695, 0.4738,\n",
      "        0.5211, 0.5921]))\n",
      "('res1.1.1.bias', Parameter containing:\n",
      "tensor([-0.0633, -0.0413, -0.0518, -0.0274, -0.0026, -0.0668, -0.0308, -0.0660,\n",
      "        -0.0694, -0.0583, -0.0563, -0.0399, -0.0702, -0.0020, -0.0564, -0.0494,\n",
      "        -0.0122, -0.0745, -0.0388, -0.0941, -0.0674, -0.0605, -0.0924, -0.0548,\n",
      "        -0.0198, -0.0656, -0.1079, -0.0135, -0.0566, -0.0174, -0.0568, -0.0372,\n",
      "        -0.0588, -0.0471, -0.0575, -0.0681, -0.0958, -0.0337, -0.0069, -0.0525,\n",
      "        -0.0335, -0.0563, -0.0620, -0.0703, -0.0223, -0.0791,  0.0344, -0.0428,\n",
      "        -0.0944, -0.0246, -0.0877, -0.0812, -0.0582, -0.0891, -0.1003, -0.0507,\n",
      "        -0.0592, -0.0213, -0.0948, -0.0447, -0.0343, -0.0179, -0.0631, -0.0383,\n",
      "        -0.0483, -0.0457, -0.0328, -0.1083, -0.1009, -0.0420,  0.0041, -0.0613,\n",
      "        -0.0156, -0.0371, -0.0724, -0.0798, -0.1155, -0.0481, -0.0365, -0.0571,\n",
      "        -0.0740, -0.0896, -0.0090, -0.0579, -0.0570, -0.0019, -0.0441, -0.0715,\n",
      "         0.0124, -0.0789,  0.0133, -0.0222, -0.0949, -0.0341, -0.0448, -0.0498,\n",
      "        -0.0228, -0.0596, -0.0390,  0.0137, -0.0367, -0.0199, -0.0125, -0.0561,\n",
      "        -0.0168, -0.1080, -0.0276, -0.0731, -0.0360, -0.0616, -0.0933, -0.0133,\n",
      "        -0.0206, -0.0647, -0.1284, -0.0587, -0.0951, -0.0654,  0.0040, -0.0236,\n",
      "        -0.0330, -0.0389, -0.0681, -0.0521, -0.0068,  0.0034, -0.0787, -0.0349]))\n",
      "('conv3.0.weight', Parameter containing:\n",
      "tensor([[[[-8.0099e-04, -6.2263e-03, -1.3137e-02],\n",
      "          [ 3.3234e-03, -2.5474e-02, -2.0046e-03],\n",
      "          [-7.4612e-03, -2.9662e-02,  1.7399e-02]],\n",
      "\n",
      "         [[ 8.8095e-03,  1.3782e-02,  2.1668e-02],\n",
      "          [ 2.0151e-02, -1.1075e-03,  2.9101e-02],\n",
      "          [-7.9145e-03,  3.6350e-03,  5.8318e-03]],\n",
      "\n",
      "         [[ 1.1090e-02, -1.7271e-02, -2.1721e-02],\n",
      "          [-8.1065e-03, -1.5594e-02, -9.7553e-03],\n",
      "          [ 4.7066e-04,  5.2812e-03, -2.2812e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0521e-02,  2.6308e-03,  2.6293e-03],\n",
      "          [-7.1551e-03, -3.9423e-04, -4.8941e-03],\n",
      "          [ 9.8949e-03, -7.7800e-03, -7.0216e-03]],\n",
      "\n",
      "         [[-2.0127e-03, -8.5673e-03, -3.4202e-03],\n",
      "          [ 1.0756e-02, -2.7394e-02, -9.8039e-03],\n",
      "          [ 3.1205e-03, -3.3193e-02, -1.3861e-03]],\n",
      "\n",
      "         [[ 3.6069e-03, -2.4813e-02, -1.0356e-02],\n",
      "          [-2.3381e-02, -2.6972e-02,  1.6169e-02],\n",
      "          [-1.4373e-02,  2.0662e-02,  3.0524e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.7361e-03, -5.2941e-03, -3.9050e-03],\n",
      "          [-1.4017e-02, -2.4682e-02, -2.1719e-02],\n",
      "          [ 3.9545e-04, -2.0499e-02, -1.4269e-03]],\n",
      "\n",
      "         [[ 1.2814e-02,  2.5314e-03,  2.9815e-03],\n",
      "          [ 1.5971e-02,  6.5358e-03,  3.2408e-03],\n",
      "          [-5.8162e-03, -1.9581e-02, -6.7547e-04]],\n",
      "\n",
      "         [[-2.2813e-03,  1.8849e-02,  4.1815e-02],\n",
      "          [ 1.3050e-02,  3.1640e-02,  5.5105e-02],\n",
      "          [ 1.3874e-02,  7.2358e-04,  1.0239e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.8771e-03, -1.8125e-02, -2.8958e-02],\n",
      "          [-3.8516e-03,  3.2606e-02,  2.2417e-02],\n",
      "          [ 1.5596e-02,  2.1870e-02, -6.9009e-03]],\n",
      "\n",
      "         [[-8.7420e-03, -4.7348e-04,  1.9174e-02],\n",
      "          [-2.7091e-02, -1.4217e-03,  4.6532e-03],\n",
      "          [-3.4129e-02, -1.5203e-02, -1.6501e-02]],\n",
      "\n",
      "         [[-2.4741e-02, -7.1838e-03, -1.7839e-03],\n",
      "          [-1.4106e-02,  4.7873e-03,  2.0760e-02],\n",
      "          [ 4.9223e-03,  1.6934e-02,  1.2642e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.0534e-02, -2.6024e-02,  9.4253e-03],\n",
      "          [-3.2671e-02, -1.8908e-02, -1.3493e-02],\n",
      "          [-4.3309e-03,  5.1291e-03,  2.0596e-03]],\n",
      "\n",
      "         [[ 1.8124e-02,  2.7621e-02, -5.3121e-06],\n",
      "          [-2.8717e-02, -1.7247e-02,  5.6638e-03],\n",
      "          [ 1.3467e-02, -1.8541e-02, -1.2516e-02]],\n",
      "\n",
      "         [[ 5.4569e-04,  2.6510e-02, -1.8302e-03],\n",
      "          [ 1.8383e-02,  9.6161e-03, -2.7190e-03],\n",
      "          [-1.3632e-02, -2.6918e-02, -9.6887e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.5828e-02, -4.4773e-03,  2.1768e-03],\n",
      "          [-1.7328e-02, -1.6688e-02,  2.3242e-02],\n",
      "          [-2.9071e-02, -1.7317e-02,  2.7644e-02]],\n",
      "\n",
      "         [[ 2.4305e-02,  2.8109e-03, -1.8322e-02],\n",
      "          [-5.7289e-03,  1.7059e-02,  4.5323e-03],\n",
      "          [ 6.3229e-03,  1.8653e-02,  2.4043e-02]],\n",
      "\n",
      "         [[ 8.6663e-03,  2.1636e-02,  3.0518e-02],\n",
      "          [ 1.5181e-02,  2.9801e-02,  4.6581e-02],\n",
      "          [ 1.1933e-02,  2.3420e-03, -4.4131e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-6.7244e-03, -3.7080e-03, -6.0008e-03],\n",
      "          [-1.5125e-02,  6.2470e-03, -7.8357e-04],\n",
      "          [ 1.5290e-02,  1.8127e-03,  1.6465e-03]],\n",
      "\n",
      "         [[-9.5686e-03,  3.0182e-02, -1.0515e-02],\n",
      "          [ 5.3885e-03,  2.7184e-02, -1.0268e-02],\n",
      "          [-3.0222e-03,  1.6935e-02, -1.9556e-02]],\n",
      "\n",
      "         [[-2.7577e-02, -1.7732e-02, -2.3188e-03],\n",
      "          [-3.6870e-02,  9.7191e-03, -1.0391e-02],\n",
      "          [-3.0852e-02, -4.3526e-03, -3.3703e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.5101e-03,  2.1316e-02, -4.6497e-03],\n",
      "          [ 3.9447e-03,  1.5689e-02, -1.7326e-02],\n",
      "          [ 6.4651e-03,  6.5524e-03, -1.0604e-02]],\n",
      "\n",
      "         [[ 3.2386e-03, -1.4634e-02,  1.7096e-02],\n",
      "          [-1.7638e-02, -3.0980e-03, -1.0514e-03],\n",
      "          [ 6.5993e-03,  1.1907e-03,  1.6050e-02]],\n",
      "\n",
      "         [[-7.0007e-03,  1.2749e-02,  1.3830e-02],\n",
      "          [-1.6346e-02,  1.7912e-02,  4.8387e-03],\n",
      "          [-5.5711e-03,  1.7296e-02, -5.2060e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.8164e-02, -3.8650e-02, -1.9274e-02],\n",
      "          [-2.3819e-02, -2.4482e-02, -1.2791e-02],\n",
      "          [ 1.1474e-02,  8.6142e-04,  4.5700e-03]],\n",
      "\n",
      "         [[-3.1493e-03,  3.7119e-03,  7.2595e-03],\n",
      "          [ 1.4208e-02,  1.4175e-02,  1.6638e-02],\n",
      "          [ 5.1840e-03,  3.7814e-02,  3.2142e-02]],\n",
      "\n",
      "         [[-3.0885e-02, -2.8302e-03,  2.6074e-02],\n",
      "          [-1.5416e-02, -3.9531e-02, -6.1855e-03],\n",
      "          [ 2.2918e-03, -2.9651e-02, -2.5263e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.4231e-02, -6.9148e-03,  3.5797e-02],\n",
      "          [-1.7138e-02, -4.7711e-02, -1.2998e-02],\n",
      "          [ 5.3931e-02, -2.0840e-02, -2.4841e-02]],\n",
      "\n",
      "         [[-1.4961e-02,  6.4616e-03, -1.3404e-02],\n",
      "          [ 4.4377e-03,  5.3202e-04, -7.5927e-03],\n",
      "          [ 1.3059e-02, -1.2794e-04, -2.0060e-02]],\n",
      "\n",
      "         [[ 3.4710e-03, -9.1386e-03, -1.3837e-02],\n",
      "          [-2.9431e-03, -4.4111e-03, -5.1662e-03],\n",
      "          [ 9.2341e-04,  1.8713e-02,  1.5812e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1875e-02, -6.8738e-03,  9.5854e-03],\n",
      "          [-2.5225e-02, -4.4107e-03,  7.8672e-03],\n",
      "          [-1.8123e-02, -1.5221e-02,  7.6288e-04]],\n",
      "\n",
      "         [[-1.5627e-02, -1.7734e-02,  2.8834e-03],\n",
      "          [-2.6406e-02, -1.6026e-02, -1.1876e-03],\n",
      "          [-1.5267e-02, -2.4439e-02, -2.3931e-03]],\n",
      "\n",
      "         [[-9.0843e-03,  5.4399e-04,  8.3069e-03],\n",
      "          [-2.7197e-02,  9.6213e-03,  4.7396e-04],\n",
      "          [ 1.5655e-03,  3.9714e-03,  2.0512e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8630e-02,  5.4240e-03, -5.8914e-03],\n",
      "          [-1.2537e-04, -1.1712e-02, -5.0658e-03],\n",
      "          [-1.3175e-02, -2.2703e-02, -6.1631e-03]],\n",
      "\n",
      "         [[ 6.5187e-03, -8.9495e-03, -2.3077e-02],\n",
      "          [-8.0610e-03,  1.5077e-02, -5.4956e-03],\n",
      "          [-2.1213e-02, -1.0948e-02,  6.2889e-03]],\n",
      "\n",
      "         [[-1.9935e-02, -8.8326e-03,  2.2160e-02],\n",
      "          [ 3.3579e-03,  2.4304e-02,  3.7830e-02],\n",
      "          [-1.1273e-02,  2.6560e-02,  1.8517e-02]]]]))\n",
      "('conv3.0.bias', Parameter containing:\n",
      "tensor([ 2.2761e-08,  2.5767e-09,  1.9704e-08,  2.8415e-08,  3.3265e-08,\n",
      "        -5.2353e-08, -6.0645e-08,  1.0976e-08,  8.7052e-09, -2.1169e-08,\n",
      "         3.2960e-08, -1.9493e-08, -4.4321e-08,  7.6983e-09,  3.3685e-09,\n",
      "        -1.9663e-08, -1.3868e-08, -1.0222e-07,  3.6350e-08,  7.1076e-09,\n",
      "         2.2690e-08,  1.6221e-08, -2.7806e-08, -4.8839e-09,  3.9790e-08,\n",
      "         3.4404e-09, -3.8004e-08, -8.6446e-08,  1.1683e-09,  5.0559e-08,\n",
      "        -4.7919e-08, -5.3174e-09, -2.6505e-08, -1.0185e-08, -4.1431e-08,\n",
      "         4.5575e-08,  6.3155e-09,  1.6761e-08, -4.0530e-08,  2.9414e-09,\n",
      "        -3.5398e-08,  1.6134e-09, -5.9181e-09,  6.0292e-09,  2.9112e-08,\n",
      "        -6.3748e-08,  3.5032e-09, -3.7345e-08, -2.3452e-08,  1.1533e-08,\n",
      "         1.1923e-08, -2.1236e-09, -2.3539e-08, -3.2951e-08, -1.3526e-07,\n",
      "         1.3496e-07, -5.9977e-08, -8.5463e-09,  2.0558e-08,  5.6065e-08,\n",
      "        -2.8147e-08,  1.6042e-08, -2.1808e-09, -4.6527e-08, -4.4563e-08,\n",
      "         4.6751e-08, -4.5071e-08, -1.1517e-08, -1.7299e-08, -1.5686e-09,\n",
      "        -1.1866e-08,  2.8565e-08,  2.9568e-08, -5.9167e-08, -4.0449e-08,\n",
      "        -5.1323e-08,  1.6061e-08,  2.5983e-08,  1.8721e-08, -5.9815e-09,\n",
      "         4.2293e-08, -2.8352e-08,  7.2405e-09,  4.0443e-08,  1.9324e-08,\n",
      "        -2.2077e-08, -2.9703e-08,  1.0727e-07, -2.1025e-08,  8.0697e-08,\n",
      "        -2.3678e-08,  2.5922e-08, -3.1294e-08, -3.7537e-08,  1.4581e-08,\n",
      "         1.3391e-08, -1.8130e-08,  5.4183e-08,  1.1883e-08,  6.8127e-09,\n",
      "        -2.0237e-08, -1.8253e-09,  2.7211e-08, -2.7707e-08, -4.3648e-08,\n",
      "        -1.7455e-08, -1.5696e-08, -2.2194e-08, -7.9438e-09,  2.7613e-08,\n",
      "         2.0383e-08,  5.0878e-09, -5.9513e-08,  4.1883e-08,  9.4798e-09,\n",
      "        -1.7030e-08, -8.4657e-09,  2.2633e-08,  4.1043e-09,  7.6308e-10,\n",
      "        -3.7129e-08, -6.3597e-09,  3.6388e-08, -7.1376e-08, -2.7701e-09,\n",
      "         2.3663e-08,  2.6588e-08, -4.5294e-09,  1.3143e-08,  1.1737e-08,\n",
      "         4.4022e-09,  7.8195e-08, -3.7450e-09,  1.1786e-08,  1.4317e-08,\n",
      "        -3.4127e-09, -5.4064e-09, -3.9401e-08,  1.7072e-08, -2.2795e-08,\n",
      "         1.1809e-08, -4.9574e-08, -2.2000e-09, -1.9063e-08,  2.5926e-08,\n",
      "         3.4459e-08,  1.1076e-08, -1.2667e-08,  1.0754e-08, -3.6994e-08,\n",
      "        -3.2058e-09, -8.8498e-09,  2.7891e-08,  4.8885e-08,  5.8079e-08,\n",
      "        -4.6073e-08,  1.2369e-08, -1.9493e-08,  1.1179e-08,  2.0604e-08,\n",
      "         1.4379e-08, -2.4858e-08, -3.6692e-08, -1.5584e-08,  1.3309e-09,\n",
      "         3.4109e-08, -2.0090e-08, -4.5245e-08, -1.5764e-09,  6.2886e-09,\n",
      "         6.3589e-09, -3.4168e-08,  1.6253e-08, -6.6821e-09, -2.7339e-09,\n",
      "         1.7576e-08,  5.9098e-08, -1.5089e-08,  8.9530e-09, -6.8817e-09,\n",
      "        -2.5071e-09,  1.1201e-08,  6.6403e-08,  1.1286e-08, -5.5625e-09,\n",
      "        -7.2106e-08, -6.1220e-09,  1.1788e-08,  9.7867e-09,  2.5987e-08,\n",
      "        -3.7822e-09,  3.3281e-08, -6.6438e-08,  1.7751e-08,  2.2791e-08,\n",
      "         8.7164e-10, -4.6632e-08, -6.8150e-08,  2.0345e-08, -5.5982e-08,\n",
      "        -9.4518e-08,  5.7650e-08, -6.3784e-08,  1.0814e-08,  4.4878e-09,\n",
      "         4.3871e-08, -7.0972e-08,  3.7913e-08,  2.1156e-08,  5.6076e-08,\n",
      "        -4.1674e-08,  1.3676e-08,  2.9788e-08,  4.7142e-08,  2.3451e-08,\n",
      "        -7.8085e-09,  3.6209e-08,  5.2170e-08,  8.6045e-09, -6.8130e-09,\n",
      "        -1.1291e-08,  1.9176e-08, -2.0833e-08, -1.4595e-08,  2.7993e-08,\n",
      "         2.2270e-09,  5.1559e-08,  1.4438e-08,  2.7429e-08, -1.8080e-08,\n",
      "         5.7773e-08,  5.8057e-09, -3.5936e-08,  4.5329e-08, -3.4194e-09,\n",
      "        -2.9296e-08, -7.9571e-09, -6.4274e-09,  9.5909e-08,  1.1609e-08,\n",
      "        -4.5282e-08, -1.7218e-08, -4.1391e-10, -2.5798e-08, -1.0372e-08,\n",
      "        -4.9959e-09, -4.4050e-10,  1.2135e-08, -5.1289e-08, -1.0184e-08,\n",
      "        -3.8342e-09, -2.7809e-09, -3.3101e-08, -1.2508e-08,  3.2033e-08,\n",
      "        -2.0533e-09]))\n",
      "('conv3.1.weight', Parameter containing:\n",
      "tensor([0.4974, 0.4139, 0.5183, 0.4058, 0.3333, 0.4169, 0.4250, 0.4434, 0.4103,\n",
      "        0.3659, 0.4171, 0.4913, 0.4238, 0.4744, 0.3630, 0.5181, 0.4802, 0.5443,\n",
      "        0.3780, 0.4743, 0.4517, 0.3912, 0.4377, 0.4032, 0.4132, 0.4311, 0.3776,\n",
      "        0.5376, 0.4212, 0.3355, 0.4124, 0.4993, 0.5332, 0.5861, 0.2713, 0.4818,\n",
      "        0.5641, 0.4045, 0.4376, 0.5077, 0.4563, 0.3905, 0.5374, 0.4804, 0.4782,\n",
      "        0.5284, 0.4707, 0.4309, 0.4198, 0.5211, 0.4725, 0.5571, 0.4175, 0.4858,\n",
      "        0.4416, 0.5372, 0.5560, 0.3980, 0.3489, 0.4928, 0.4114, 0.4293, 0.4791,\n",
      "        0.4217, 0.4279, 0.4799, 0.2814, 0.4881, 0.2773, 0.5759, 0.3613, 0.4840,\n",
      "        0.4578, 0.4330, 0.4676, 0.4344, 0.4535, 0.4413, 0.4822, 0.4614, 0.4010,\n",
      "        0.5350, 0.4105, 0.4746, 0.3733, 0.4625, 0.4504, 0.4634, 0.4821, 0.4122,\n",
      "        0.4404, 0.3499, 0.4838, 0.4726, 0.4969, 0.4167, 0.4551, 0.4470, 0.4282,\n",
      "        0.4267, 0.4848, 0.4562, 0.3840, 0.4325, 0.3557, 0.4932, 0.3699, 0.4160,\n",
      "        0.5004, 0.3990, 0.4536, 0.4331, 0.5154, 0.5147, 0.4176, 0.5589, 0.4425,\n",
      "        0.4922, 0.3941, 0.4751, 0.4347, 0.3497, 0.4503, 0.4303, 0.4556, 0.4395,\n",
      "        0.4017, 0.3938, 0.4296, 0.4900, 0.4116, 0.4217, 0.3559, 0.3953, 0.3828,\n",
      "        0.4534, 0.5239, 0.4599, 0.4191, 0.4792, 0.3820, 0.4462, 0.3337, 0.5223,\n",
      "        0.3616, 0.4185, 0.4562, 0.4822, 0.4039, 0.4061, 0.4763, 0.4071, 0.4668,\n",
      "        0.4220, 0.4628, 0.4549, 0.4468, 0.4519, 0.3929, 0.4233, 0.4165, 0.4147,\n",
      "        0.4832, 0.4515, 0.4829, 0.4026, 0.4897, 0.4652, 0.4057, 0.3852, 0.3891,\n",
      "        0.5052, 0.4012, 0.4163, 0.3889, 0.4384, 0.4670, 0.4519, 0.4735, 0.3649,\n",
      "        0.5058, 0.4491, 0.4351, 0.3802, 0.4027, 0.5114, 0.4345, 0.4467, 0.3813,\n",
      "        0.4491, 0.3651, 0.4272, 0.4169, 0.3930, 0.4560, 0.4410, 0.4502, 0.4770,\n",
      "        0.3924, 0.5596, 0.5047, 0.4473, 0.5150, 0.4515, 0.4435, 0.5455, 0.3995,\n",
      "        0.4296, 0.4046, 0.4313, 0.4858, 0.4851, 0.5027, 0.4473, 0.4426, 0.4671,\n",
      "        0.4618, 0.5672, 0.3918, 0.3950, 0.4030, 0.4875, 0.3858, 0.4806, 0.3953,\n",
      "        0.4550, 0.5113, 0.3532, 0.5121, 0.3586, 0.3760, 0.4514, 0.4919, 0.4541,\n",
      "        0.4561, 0.4239, 0.4269, 0.4594, 0.4798, 0.5186, 0.4400, 0.3819, 0.3766,\n",
      "        0.4506, 0.4597, 0.4697, 0.3749, 0.5052, 0.4509, 0.4663, 0.4459, 0.4844,\n",
      "        0.4960, 0.4568, 0.4083, 0.4564]))\n",
      "('conv3.1.bias', Parameter containing:\n",
      "tensor([-0.1955, -0.1919, -0.2821, -0.1793, -0.1739, -0.1848, -0.2462, -0.2075,\n",
      "        -0.2029, -0.1684, -0.1626, -0.1788, -0.1821, -0.2167, -0.1796, -0.1954,\n",
      "        -0.2413, -0.2785, -0.1699, -0.1918, -0.2027, -0.1584, -0.2049, -0.1854,\n",
      "        -0.2074, -0.2119, -0.1738, -0.2248, -0.2255, -0.1548, -0.1600, -0.2634,\n",
      "        -0.2563, -0.2254, -0.1090, -0.2731, -0.2348, -0.1674, -0.1820, -0.2184,\n",
      "        -0.1969, -0.1856, -0.2228, -0.2367, -0.1444, -0.1917, -0.2222, -0.1839,\n",
      "        -0.1690, -0.1730, -0.1948, -0.2393, -0.1896, -0.2283, -0.2298, -0.2237,\n",
      "        -0.2463, -0.1392, -0.1512, -0.2272, -0.1685, -0.1831, -0.1898, -0.1492,\n",
      "        -0.1679, -0.2382, -0.1295, -0.2229, -0.1194, -0.2559, -0.1483, -0.2426,\n",
      "        -0.1838, -0.2170, -0.1898, -0.2154, -0.2000, -0.2012, -0.2342, -0.1906,\n",
      "        -0.1416, -0.2366, -0.1259, -0.2624, -0.1798, -0.2255, -0.2096, -0.1937,\n",
      "        -0.2032, -0.1738, -0.2066, -0.1242, -0.2060, -0.1961, -0.2517, -0.1748,\n",
      "        -0.2245, -0.2112, -0.1255, -0.1513, -0.2318, -0.2183, -0.2276, -0.2198,\n",
      "        -0.1609, -0.2012, -0.1710, -0.1989, -0.2657, -0.1971, -0.1538, -0.2051,\n",
      "        -0.2234, -0.2329, -0.1899, -0.2595, -0.1486, -0.2350, -0.1719, -0.2554,\n",
      "        -0.2186, -0.1576, -0.2058, -0.1800, -0.2148, -0.1901, -0.1657, -0.2205,\n",
      "        -0.1734, -0.2165, -0.1887, -0.1652, -0.1447, -0.2113, -0.1632, -0.2071,\n",
      "        -0.2776, -0.2201, -0.1797, -0.2410, -0.1915, -0.2154, -0.1508, -0.2382,\n",
      "        -0.1755, -0.1681, -0.1865, -0.2218, -0.1860, -0.1877, -0.2504, -0.1606,\n",
      "        -0.2043, -0.2138, -0.2020, -0.2068, -0.2269, -0.1980, -0.1960, -0.1888,\n",
      "        -0.1418, -0.1235, -0.1806, -0.2521, -0.2841, -0.1619, -0.1963, -0.1687,\n",
      "        -0.1866, -0.1358, -0.1430, -0.2127, -0.1863, -0.1697, -0.1669, -0.2364,\n",
      "        -0.1960, -0.2027, -0.1647, -0.2022, -0.2096, -0.2235, -0.2116, -0.1635,\n",
      "        -0.1912, -0.1684, -0.1888, -0.2028, -0.1866, -0.2320, -0.1768, -0.2086,\n",
      "        -0.2106, -0.1874, -0.2407, -0.1899, -0.2201, -0.1738, -0.1861, -0.2024,\n",
      "        -0.2328, -0.1842, -0.2280, -0.2205, -0.1786, -0.2605, -0.1594, -0.1766,\n",
      "        -0.1750, -0.2069, -0.1719, -0.1942, -0.1847, -0.2088, -0.2134, -0.1788,\n",
      "        -0.2039, -0.2526, -0.1913, -0.1758, -0.1676, -0.2244, -0.2111, -0.2089,\n",
      "        -0.1512, -0.1797, -0.1880, -0.1437, -0.2260, -0.1346, -0.1611, -0.1698,\n",
      "        -0.2110, -0.1977, -0.1882, -0.1937, -0.1605, -0.1995, -0.2069, -0.2116,\n",
      "        -0.1793, -0.1658, -0.1861, -0.2136, -0.1905, -0.2216, -0.1460, -0.2107,\n",
      "        -0.2403, -0.2186, -0.1845, -0.1889, -0.2346, -0.1729, -0.1950, -0.2271]))\n",
      "('conv4.0.weight', Parameter containing:\n",
      "tensor([[[[ 2.4861e-02,  1.1793e-02,  1.5076e-02],\n",
      "          [ 9.7671e-03, -3.3431e-04, -6.6171e-03],\n",
      "          [-1.4147e-02,  5.9160e-03,  9.6286e-03]],\n",
      "\n",
      "         [[ 1.1161e-02,  4.6907e-03, -1.0713e-03],\n",
      "          [-4.8948e-03, -1.2305e-02, -1.0432e-02],\n",
      "          [ 4.1116e-03, -1.0628e-03, -4.1800e-03]],\n",
      "\n",
      "         [[-7.8836e-03,  2.4486e-04,  2.6069e-03],\n",
      "          [-1.3675e-02, -1.9661e-02, -1.2952e-02],\n",
      "          [-8.9031e-03, -1.6515e-02,  6.0611e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0064e-03,  7.0172e-03, -3.1430e-03],\n",
      "          [ 1.3991e-02,  1.0010e-02,  3.7431e-05],\n",
      "          [ 4.5602e-03,  1.0220e-02, -3.2722e-04]],\n",
      "\n",
      "         [[-1.3652e-02, -1.4239e-03,  3.1740e-03],\n",
      "          [-4.4941e-03, -6.3968e-03, -5.0365e-03],\n",
      "          [-9.9572e-03,  4.2614e-03,  6.7958e-03]],\n",
      "\n",
      "         [[ 2.4107e-03, -3.8982e-04,  1.0862e-02],\n",
      "          [ 4.5882e-03,  6.0639e-03,  1.2504e-02],\n",
      "          [ 2.0204e-03, -6.3748e-03, -5.6669e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 8.6831e-03,  5.3624e-03, -2.8066e-02],\n",
      "          [-5.0153e-03, -1.4213e-02, -2.0029e-02],\n",
      "          [-7.4794e-03, -1.3322e-02, -2.4993e-02]],\n",
      "\n",
      "         [[-1.9007e-02, -1.2137e-02,  1.7971e-03],\n",
      "          [ 8.2608e-03,  1.0421e-02,  1.4191e-02],\n",
      "          [-1.5044e-02, -2.7831e-02,  6.8427e-03]],\n",
      "\n",
      "         [[-7.7398e-03, -1.1759e-02, -2.1740e-02],\n",
      "          [ 5.1955e-03, -2.2445e-02, -2.1289e-02],\n",
      "          [ 8.1885e-03, -6.3880e-03, -5.6688e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3806e-03, -1.9465e-03, -3.3034e-03],\n",
      "          [-5.7589e-03,  1.8834e-03,  1.5694e-03],\n",
      "          [-1.8499e-03,  2.1027e-02,  1.5336e-02]],\n",
      "\n",
      "         [[-4.8469e-03,  1.6196e-02,  1.9349e-03],\n",
      "          [ 1.2625e-02,  2.3013e-02,  6.4696e-03],\n",
      "          [ 7.9894e-03,  1.3740e-02, -8.7157e-03]],\n",
      "\n",
      "         [[ 7.1306e-03, -2.5768e-03,  3.5526e-03],\n",
      "          [ 1.1692e-02,  1.4927e-02, -2.0826e-03],\n",
      "          [ 1.2132e-02,  2.2943e-02, -8.2205e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3500e-02,  1.3411e-02,  4.8436e-03],\n",
      "          [ 1.2569e-02, -1.1665e-02, -1.6092e-02],\n",
      "          [ 5.3350e-03, -5.8337e-04,  1.5063e-03]],\n",
      "\n",
      "         [[ 1.3104e-03,  4.5253e-03,  1.0368e-03],\n",
      "          [-1.9344e-02, -1.6396e-02, -7.7446e-03],\n",
      "          [-1.4633e-02, -1.7487e-02,  1.8909e-03]],\n",
      "\n",
      "         [[-1.2510e-02, -6.8863e-04, -2.5848e-03],\n",
      "          [ 1.1836e-02,  1.1058e-02,  9.6737e-03],\n",
      "          [ 5.7894e-03,  1.5335e-02,  2.2266e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2302e-02, -9.5467e-03,  5.0404e-03],\n",
      "          [ 1.2027e-02, -1.0744e-02, -2.2569e-03],\n",
      "          [-1.1292e-03, -1.1508e-02,  2.2980e-04]],\n",
      "\n",
      "         [[ 1.5683e-02,  1.4100e-02, -3.5267e-03],\n",
      "          [ 2.7257e-02,  1.3305e-02, -2.0703e-03],\n",
      "          [ 6.7376e-03,  9.8493e-03, -6.8005e-05]],\n",
      "\n",
      "         [[-1.7563e-03,  5.0630e-03,  9.3214e-03],\n",
      "          [-4.6620e-03, -2.3049e-02, -1.3463e-02],\n",
      "          [ 8.8442e-03, -4.5558e-03,  1.2734e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-5.8943e-03, -1.5236e-02, -1.9782e-02],\n",
      "          [ 2.1048e-02, -5.7069e-03, -2.0152e-02],\n",
      "          [ 2.6348e-02, -1.1298e-02, -9.3499e-03]],\n",
      "\n",
      "         [[ 7.2632e-03,  1.4061e-02, -2.7575e-03],\n",
      "          [ 4.4943e-03, -6.4584e-03, -4.2280e-03],\n",
      "          [-7.0604e-03, -1.4633e-02, -1.5320e-02]],\n",
      "\n",
      "         [[ 1.8516e-03, -2.6164e-04, -9.0958e-03],\n",
      "          [ 1.4053e-02,  8.2386e-05, -2.7069e-04],\n",
      "          [-6.4294e-04,  6.2083e-03, -1.2920e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.8499e-03,  2.9185e-03, -1.8402e-03],\n",
      "          [ 1.8496e-04,  1.0129e-02,  2.8477e-05],\n",
      "          [-6.9695e-03,  1.3285e-02,  8.1404e-03]],\n",
      "\n",
      "         [[-4.2313e-03, -9.2967e-03,  1.7699e-04],\n",
      "          [ 7.2371e-03, -1.0532e-02, -1.8358e-02],\n",
      "          [-4.6717e-04, -9.4178e-03, -1.7785e-02]],\n",
      "\n",
      "         [[-4.8009e-03,  7.2992e-03,  9.3497e-03],\n",
      "          [-9.4392e-03, -4.7637e-03, -5.5376e-04],\n",
      "          [-1.4222e-02, -9.5850e-03, -1.3329e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.3158e-03,  6.6196e-03, -1.0124e-02],\n",
      "          [ 3.7360e-03,  1.5365e-02, -8.6659e-03],\n",
      "          [-5.7680e-03, -1.5129e-02,  2.7960e-05]],\n",
      "\n",
      "         [[ 8.4149e-04,  1.4043e-02,  8.8420e-03],\n",
      "          [ 9.4769e-03,  6.9300e-03,  1.7081e-02],\n",
      "          [-1.4680e-02, -1.3163e-02,  2.1837e-03]],\n",
      "\n",
      "         [[-2.1009e-03, -8.5657e-04, -1.0263e-02],\n",
      "          [-1.2334e-02,  7.8019e-03, -2.3268e-03],\n",
      "          [-7.5328e-03,  2.1846e-02, -4.5836e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.8998e-02, -3.0671e-02, -6.0433e-03],\n",
      "          [-1.0622e-02, -8.3438e-03, -5.0727e-05],\n",
      "          [-1.6800e-02, -6.8509e-03, -1.0718e-02]],\n",
      "\n",
      "         [[-1.2997e-03,  4.6203e-03,  1.2915e-02],\n",
      "          [ 1.6014e-02,  2.5613e-02,  2.7166e-02],\n",
      "          [ 2.2038e-02,  3.2434e-02,  1.0760e-02]],\n",
      "\n",
      "         [[-1.4352e-02,  1.3305e-02,  9.1562e-03],\n",
      "          [-9.5476e-03, -9.8047e-03,  8.9707e-03],\n",
      "          [-1.7694e-02, -1.4782e-02, -4.0589e-03]]],\n",
      "\n",
      "\n",
      "        [[[-5.6778e-03,  9.7163e-03,  4.4493e-03],\n",
      "          [-1.2020e-02,  3.4821e-03,  5.1667e-03],\n",
      "          [ 1.8690e-04,  2.6021e-02,  2.5494e-02]],\n",
      "\n",
      "         [[-2.0794e-03, -2.3599e-02, -2.1283e-02],\n",
      "          [-2.1670e-02,  5.4842e-04,  4.5568e-03],\n",
      "          [-1.8511e-03,  1.4409e-02,  1.7410e-02]],\n",
      "\n",
      "         [[ 2.7645e-03, -9.4273e-03,  1.1215e-02],\n",
      "          [ 2.3431e-02,  1.3121e-02, -2.8681e-02],\n",
      "          [ 3.2965e-03,  1.2519e-03,  7.6019e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.4590e-03,  1.7403e-02,  3.1779e-03],\n",
      "          [-3.4568e-03,  2.4429e-02,  9.2183e-03],\n",
      "          [ 7.7093e-03,  1.8476e-02,  8.6873e-03]],\n",
      "\n",
      "         [[-5.0082e-03, -1.2894e-02,  7.8492e-04],\n",
      "          [-1.6222e-02, -2.3736e-02, -2.3297e-02],\n",
      "          [-5.2150e-03, -1.1082e-02, -2.1827e-02]],\n",
      "\n",
      "         [[-3.4180e-03, -4.5151e-03, -1.0735e-02],\n",
      "          [-1.7781e-03,  1.1005e-02, -5.1527e-04],\n",
      "          [-6.9192e-03, -1.6654e-02, -2.7378e-03]]]]))\n",
      "('conv4.0.bias', Parameter containing:\n",
      "tensor([-1.4194e-08, -4.3628e-08,  5.3922e-09,  8.4014e-09, -2.4689e-08,\n",
      "         1.1376e-08, -1.4599e-08, -2.7029e-08,  2.7756e-08, -3.7769e-08,\n",
      "         1.7395e-08,  8.4641e-08,  2.8332e-08, -4.2482e-09,  3.5835e-08,\n",
      "        -1.1052e-09,  8.6207e-09, -4.6676e-08, -2.1818e-08, -8.5572e-09,\n",
      "        -1.2817e-08,  1.7156e-09, -3.6454e-08,  3.0702e-08,  3.3494e-08,\n",
      "        -1.2650e-08,  2.4891e-08, -3.1980e-08, -3.6812e-08,  3.3888e-08,\n",
      "        -2.1128e-08,  8.4157e-09,  2.2938e-08, -4.4852e-08,  1.7767e-08,\n",
      "         8.9113e-09,  7.3606e-09, -2.7604e-09, -7.1573e-09,  1.0446e-07,\n",
      "         4.8020e-09, -5.3403e-09,  1.0997e-09,  2.0560e-08,  3.6462e-09,\n",
      "        -3.0518e-09, -8.9106e-09,  2.6146e-08, -3.1131e-08,  3.8829e-09,\n",
      "         2.7100e-08, -1.6819e-09,  3.1532e-08,  1.6423e-08, -1.3618e-08,\n",
      "        -6.4325e-09,  1.5318e-08, -4.1758e-08, -1.8946e-08, -3.2896e-08,\n",
      "         8.8439e-08, -1.4683e-08, -5.3958e-08,  2.3813e-09, -3.4733e-09,\n",
      "         1.7941e-08, -1.7663e-08, -3.9540e-08, -4.9334e-08, -5.3978e-09,\n",
      "         1.5538e-08, -1.2224e-08, -5.1700e-09, -2.8205e-08,  1.9466e-09,\n",
      "         4.4342e-09,  1.1402e-08, -1.3527e-08, -2.0904e-08, -1.1292e-08,\n",
      "        -6.2963e-08,  1.5850e-08, -1.4148e-08, -6.8039e-10,  3.6695e-08,\n",
      "         6.1891e-08,  2.4196e-08, -2.9487e-08,  1.4642e-08, -2.3306e-08,\n",
      "         1.2318e-08, -5.4648e-09,  5.8084e-09, -1.6398e-08,  7.1834e-09,\n",
      "         1.0049e-08, -7.5374e-09, -1.5115e-08,  1.8464e-08, -1.6120e-08,\n",
      "         3.4112e-08,  2.4222e-09,  1.7913e-08,  5.4663e-08, -3.6077e-08,\n",
      "        -1.6548e-08, -4.5871e-08, -1.9888e-08,  1.8659e-08, -3.6795e-08,\n",
      "         1.1061e-08,  5.7517e-09, -2.7940e-09,  5.3921e-08,  1.1900e-08,\n",
      "        -1.5298e-08,  1.6175e-08,  4.4966e-08,  4.5636e-08, -2.5518e-08,\n",
      "        -3.5025e-08, -6.2472e-08, -1.1324e-08,  4.1637e-08,  5.7218e-08,\n",
      "        -1.5052e-08, -2.1597e-08,  2.7799e-08,  5.4093e-09, -4.1833e-08,\n",
      "        -1.3449e-09, -3.5971e-08,  5.6156e-10, -1.0723e-08, -2.2277e-08,\n",
      "         2.5627e-08, -2.7989e-08, -1.1661e-08,  2.6564e-09,  9.0950e-09,\n",
      "         4.8999e-09, -1.2031e-08, -4.1057e-08,  1.1379e-09, -2.7186e-08,\n",
      "         8.3543e-09, -5.1403e-09, -1.5500e-08, -5.6101e-09, -2.3982e-08,\n",
      "        -1.1985e-08,  2.7210e-08,  1.5542e-08, -1.2262e-08,  1.9946e-08,\n",
      "         7.3476e-09, -2.2023e-08,  4.4291e-08,  2.3346e-08, -2.6816e-08,\n",
      "        -1.1317e-08,  1.8544e-08,  7.0880e-09,  1.9009e-09,  8.8870e-08,\n",
      "        -8.9967e-09, -2.8598e-08,  7.4378e-09, -1.1196e-08, -5.4240e-08,\n",
      "        -1.0494e-08, -1.4438e-08,  1.9292e-08, -1.4125e-08,  8.9894e-09,\n",
      "         2.3339e-09,  2.4576e-08, -3.4188e-08,  1.5572e-08,  2.8766e-08,\n",
      "        -2.0960e-08,  3.2868e-08,  1.8920e-08,  3.3067e-09,  2.1435e-09,\n",
      "         4.0963e-08, -6.5129e-09, -1.0706e-08, -2.9853e-08,  2.3192e-08,\n",
      "         2.5336e-08, -3.8423e-08,  4.4010e-10, -1.4514e-08,  5.1680e-08,\n",
      "        -1.5230e-08,  1.9051e-08,  1.0275e-08, -1.3714e-08,  1.0320e-08,\n",
      "        -7.8448e-08, -1.2016e-08,  6.1138e-08, -4.3713e-08, -1.4244e-08,\n",
      "        -5.4521e-08, -2.4195e-08, -4.8365e-08,  9.9252e-09, -3.2118e-09,\n",
      "        -2.5281e-08, -4.0311e-09, -2.1490e-08, -7.1633e-08, -1.0084e-07,\n",
      "         3.9851e-08, -1.1440e-08, -1.5077e-08,  3.9139e-08,  4.0108e-08,\n",
      "         2.6007e-08, -6.8164e-09, -1.2854e-08, -5.3923e-08, -1.1299e-07,\n",
      "        -1.4638e-08, -1.5300e-09,  5.2875e-08,  2.7407e-09,  2.6224e-09,\n",
      "        -5.2663e-08,  4.7025e-09, -2.6268e-08,  4.7521e-08,  7.9476e-09,\n",
      "        -3.6153e-08,  3.5325e-09, -1.3652e-08, -4.8239e-08, -2.7632e-08,\n",
      "         2.4713e-08, -1.1394e-08, -3.2771e-08,  1.0673e-08,  2.5573e-08,\n",
      "         4.1783e-10,  3.0486e-08,  4.2728e-09, -2.1041e-08, -2.0225e-08,\n",
      "        -4.3310e-08, -2.7796e-09, -3.5053e-10, -1.0250e-09,  8.7083e-09,\n",
      "        -6.5036e-09,  5.0138e-08, -1.4182e-09,  6.7992e-09, -9.4958e-09,\n",
      "        -2.7077e-08, -9.1684e-09,  1.3046e-08,  2.7576e-08, -7.6736e-08,\n",
      "        -2.8480e-08, -1.7037e-08,  1.2904e-08, -1.6945e-08,  5.9378e-08,\n",
      "         3.9994e-08,  1.3479e-08,  2.9240e-08, -2.1092e-08,  2.7534e-08,\n",
      "         2.5390e-08, -2.9445e-08,  3.5641e-08,  3.1215e-08, -5.5620e-08,\n",
      "         6.4676e-08, -8.5626e-09,  9.4855e-09, -4.1867e-08,  8.1367e-08,\n",
      "         5.7275e-09,  1.5409e-08, -3.3849e-08, -5.0080e-09, -2.8739e-10,\n",
      "         1.1848e-07,  1.6737e-08, -2.7307e-08, -2.2145e-08, -5.8182e-08,\n",
      "         4.0535e-08,  1.6023e-08,  3.5054e-08, -9.9679e-08,  6.1821e-08,\n",
      "        -2.2990e-08, -2.0531e-08, -3.4525e-08, -2.6845e-08, -5.4871e-08,\n",
      "        -4.7989e-08, -2.2276e-08, -7.1980e-09,  4.4299e-08,  1.3632e-08,\n",
      "        -2.7018e-08,  2.7968e-08, -2.8189e-09, -2.6500e-08,  1.7985e-08,\n",
      "         7.4658e-08, -2.8288e-08,  3.4994e-09, -3.4040e-08,  1.1612e-08,\n",
      "         3.3547e-08,  3.3358e-08, -3.6610e-08,  6.4484e-08, -4.1571e-08,\n",
      "        -1.5942e-08,  8.3670e-09,  2.7164e-08,  3.3138e-08,  9.6158e-08,\n",
      "        -1.2908e-08,  5.0654e-08,  1.5808e-08, -1.9630e-08,  1.6411e-09,\n",
      "         1.1686e-08,  3.9711e-09,  9.9376e-09, -1.3080e-08, -2.4599e-08,\n",
      "         2.0227e-08, -2.6306e-09, -2.2175e-08, -1.9640e-08,  2.1921e-08,\n",
      "         6.5286e-09,  4.3063e-08,  1.3330e-08,  1.8872e-08,  3.4501e-10,\n",
      "        -2.3329e-08, -1.0558e-08,  1.3877e-08,  1.3014e-08, -2.7089e-08,\n",
      "         3.2970e-08,  4.7329e-08,  2.4860e-08,  3.0037e-08, -3.3224e-08,\n",
      "        -3.0459e-08, -4.8124e-08, -3.4719e-08, -5.6214e-08,  2.4827e-08,\n",
      "         1.6094e-09,  5.0727e-09,  2.4442e-08, -3.3828e-08,  3.4760e-08,\n",
      "        -9.8576e-08, -1.8703e-08,  2.9522e-08, -3.7960e-09, -1.7358e-08,\n",
      "         5.9610e-10, -5.7007e-08, -1.6612e-08,  1.9504e-08, -8.8518e-08,\n",
      "        -1.1074e-08,  1.2142e-08, -3.5628e-08, -6.5260e-08, -2.6236e-08,\n",
      "         6.7576e-09, -2.9521e-09, -3.0125e-09, -1.6518e-08,  3.6842e-08,\n",
      "         1.7903e-08,  1.6011e-08, -4.0708e-08,  1.6163e-08,  2.7031e-08,\n",
      "         4.4521e-08, -4.8140e-09, -2.7359e-08,  5.8546e-09, -2.8929e-09,\n",
      "         1.9669e-08, -1.0485e-08,  1.8616e-08, -1.5763e-08, -2.6068e-08,\n",
      "        -4.3674e-08,  4.2927e-08, -3.7997e-08, -1.3191e-08,  2.7589e-08,\n",
      "        -1.9828e-08,  2.2156e-08, -4.0049e-08,  2.4741e-08, -4.7155e-10,\n",
      "        -6.7753e-09, -9.0284e-08, -2.2890e-08, -2.0095e-08,  1.9175e-08,\n",
      "        -1.5798e-08, -4.7264e-08,  6.3774e-08,  2.0119e-08, -1.7929e-08,\n",
      "         5.6420e-08, -2.4213e-09,  2.5359e-08,  9.5746e-09,  2.8846e-09,\n",
      "        -3.7136e-08,  6.1649e-09, -4.4234e-08, -3.7246e-08, -5.4385e-08,\n",
      "         3.6589e-09, -6.6697e-09, -9.4340e-09,  3.2698e-09, -1.6851e-08,\n",
      "         3.0763e-08, -8.2708e-08, -2.0846e-08, -8.5432e-09, -5.4947e-08,\n",
      "        -1.4049e-08,  2.4879e-08, -3.5713e-08, -1.8469e-08, -1.6820e-08,\n",
      "         2.3014e-08,  1.7707e-08, -9.7267e-10,  2.3462e-08,  3.9169e-09,\n",
      "         1.5402e-08, -7.5040e-09, -5.6515e-09,  9.4789e-09,  5.3641e-08,\n",
      "         4.4761e-09,  4.0947e-08,  4.7599e-08,  6.5395e-09,  2.1045e-08,\n",
      "         2.3925e-08,  2.1349e-08, -9.2039e-09, -1.9552e-08, -6.5847e-09,\n",
      "        -5.2370e-08, -1.9822e-08,  3.7000e-08, -7.0723e-08, -1.4307e-08,\n",
      "         1.3807e-08,  2.9444e-08,  1.0219e-07, -2.9772e-08, -3.4226e-08,\n",
      "         8.4362e-09,  1.8273e-08,  9.4138e-09,  1.6554e-08,  8.8680e-09,\n",
      "         7.6600e-09,  1.9764e-08,  2.7202e-08, -1.9347e-08,  3.4550e-08,\n",
      "        -1.4861e-08, -2.5655e-09, -3.5014e-08, -9.0430e-09, -1.3205e-08,\n",
      "        -6.0302e-08,  8.4671e-10,  6.8236e-08, -1.6324e-08,  2.0338e-08,\n",
      "        -2.2333e-08, -4.4583e-09, -4.0109e-08, -1.0615e-08, -7.1673e-08,\n",
      "         8.0561e-09,  2.0353e-09, -6.4651e-09,  1.7773e-08, -2.9848e-08,\n",
      "        -1.5293e-08, -4.9708e-08]))\n",
      "('conv4.1.weight', Parameter containing:\n",
      "tensor([0.3315, 0.3215, 0.2608, 0.2998, 0.2951, 0.2622, 0.2649, 0.3675, 0.3231,\n",
      "        0.3073, 0.3015, 0.4105, 0.2971, 0.2966, 0.2998, 0.2805, 0.2744, 0.2884,\n",
      "        0.2660, 0.2846, 0.2832, 0.2631, 0.2690, 0.2714, 0.2768, 0.2682, 0.3368,\n",
      "        0.3013, 0.3657, 0.3375, 0.2547, 0.2413, 0.3446, 0.3466, 0.3065, 0.3260,\n",
      "        0.2887, 0.1904, 0.2244, 0.4596, 0.2657, 0.2502, 0.4195, 0.3378, 0.3032,\n",
      "        0.2598, 0.3116, 0.2959, 0.3022, 0.2471, 0.3166, 0.2484, 0.2757, 0.3240,\n",
      "        0.2580, 0.2944, 0.3275, 0.3413, 0.2309, 0.3283, 0.3661, 0.3106, 0.3286,\n",
      "        0.2817, 0.2544, 0.3033, 0.4670, 0.2302, 0.3572, 0.2541, 0.3253, 0.2545,\n",
      "        0.3383, 0.3068, 0.2318, 0.2782, 0.2594, 0.3575, 0.3010, 0.3085, 0.3074,\n",
      "        0.3396, 0.3866, 0.3259, 0.3366, 0.3395, 0.2914, 0.2851, 0.3102, 0.2727,\n",
      "        0.3384, 0.3019, 0.2493, 0.3197, 0.3015, 0.2939, 0.2807, 0.2515, 0.3051,\n",
      "        0.2897, 0.3308, 0.2239, 0.3921, 0.3512, 0.3079, 0.3642, 0.2817, 0.2523,\n",
      "        0.2752, 0.2874, 0.4298, 0.2639, 0.2811, 0.3511, 0.3148, 0.1960, 0.3010,\n",
      "        0.3079, 0.2473, 0.2470, 0.3211, 0.2902, 0.2715, 0.3252, 0.3213, 0.2953,\n",
      "        0.3271, 0.2338, 0.2559, 0.3018, 0.2927, 0.3230, 0.3207, 0.2842, 0.2673,\n",
      "        0.3605, 0.3343, 0.2543, 0.2813, 0.2753, 0.3198, 0.2989, 0.3151, 0.2433,\n",
      "        0.2360, 0.3459, 0.2517, 0.2835, 0.3053, 0.3000, 0.3558, 0.3203, 0.1894,\n",
      "        0.2659, 0.2285, 0.2553, 0.2994, 0.2732, 0.2571, 0.3659, 0.2933, 0.2839,\n",
      "        0.2918, 0.3096, 0.3103, 0.4406, 0.3223, 0.2974, 0.3296, 0.3165, 0.3466,\n",
      "        0.3428, 0.3061, 0.2770, 0.2809, 0.3221, 0.3300, 0.3707, 0.2793, 0.2493,\n",
      "        0.3003, 0.3293, 0.1694, 0.3694, 0.2915, 0.3152, 0.3061, 0.3068, 0.2104,\n",
      "        0.2814, 0.2703, 0.2703, 0.2932, 0.3744, 0.2796, 0.2997, 0.2761, 0.2240,\n",
      "        0.2713, 0.2434, 0.2501, 0.2749, 0.2414, 0.2861, 0.1939, 0.2655, 0.2410,\n",
      "        0.3395, 0.2549, 0.2786, 0.3093, 0.2685, 0.3130, 0.3364, 0.3597, 0.2307,\n",
      "        0.2923, 0.2811, 0.4015, 0.2596, 0.2695, 0.2769, 0.2272, 0.2376, 0.2684,\n",
      "        0.2965, 0.2641, 0.3425, 0.3215, 0.3610, 0.2582, 0.3180, 0.2859, 0.3434,\n",
      "        0.3237, 0.3856, 0.2170, 0.2648, 0.3241, 0.1889, 0.3331, 0.3039, 0.3149,\n",
      "        0.3513, 0.2814, 0.2844, 0.3272, 0.2623, 0.2985, 0.2716, 0.2969, 0.3129,\n",
      "        0.3369, 0.2803, 0.3291, 0.3114, 0.3336, 0.3981, 0.3036, 0.2852, 0.2477,\n",
      "        0.2924, 0.2823, 0.3183, 0.2040, 0.3019, 0.2352, 0.2527, 0.3488, 0.3312,\n",
      "        0.3659, 0.2997, 0.3213, 0.2428, 0.2819, 0.3492, 0.2701, 0.3922, 0.2741,\n",
      "        0.3002, 0.3706, 0.3002, 0.2814, 0.4056, 0.2760, 0.2341, 0.2930, 0.2969,\n",
      "        0.2733, 0.2986, 0.3244, 0.3232, 0.2790, 0.3101, 0.2977, 0.2983, 0.2616,\n",
      "        0.2817, 0.3522, 0.3044, 0.4063, 0.2844, 0.2544, 0.3363, 0.2908, 0.3503,\n",
      "        0.2717, 0.3469, 0.2984, 0.2456, 0.3444, 0.3470, 0.2863, 0.2796, 0.2034,\n",
      "        0.2339, 0.3017, 0.2908, 0.2596, 0.3004, 0.2860, 0.3294, 0.2577, 0.3485,\n",
      "        0.3517, 0.2369, 0.2520, 0.3449, 0.2843, 0.3656, 0.2497, 0.3052, 0.2603,\n",
      "        0.2802, 0.3107, 0.4591, 0.3117, 0.3084, 0.2241, 0.3566, 0.2911, 0.3461,\n",
      "        0.3382, 0.3741, 0.2723, 0.2266, 0.3431, 0.2550, 0.2561, 0.2648, 0.3497,\n",
      "        0.3549, 0.3042, 0.2252, 0.2583, 0.2747, 0.3487, 0.2645, 0.3571, 0.2894,\n",
      "        0.2727, 0.2097, 0.2641, 0.3176, 0.3218, 0.2826, 0.2656, 0.3693, 0.1979,\n",
      "        0.2583, 0.3601, 0.2774, 0.3265, 0.2997, 0.3011, 0.2674, 0.3152, 0.3319,\n",
      "        0.2592, 0.3274, 0.2603, 0.3533, 0.3453, 0.3054, 0.3885, 0.1655, 0.2531,\n",
      "        0.2561, 0.2966, 0.3846, 0.2675, 0.2661, 0.2631, 0.2764, 0.2974, 0.2827,\n",
      "        0.2374, 0.2774, 0.2839, 0.2801, 0.3148, 0.3255, 0.3431, 0.2546, 0.3035,\n",
      "        0.3132, 0.2702, 0.3054, 0.1923, 0.3356, 0.3009, 0.2996, 0.3226, 0.3140,\n",
      "        0.3058, 0.3370, 0.4096, 0.3009, 0.2524, 0.3081, 0.3380, 0.2893, 0.3112,\n",
      "        0.3267, 0.2897, 0.3345, 0.1854, 0.2833, 0.3197, 0.3302, 0.4144, 0.2408,\n",
      "        0.3233, 0.3164, 0.3175, 0.3074, 0.2848, 0.3864, 0.2690, 0.2743, 0.2860,\n",
      "        0.3984, 0.2469, 0.2341, 0.2485, 0.2988, 0.2495, 0.2683, 0.3349, 0.2883,\n",
      "        0.2120, 0.3268, 0.2446, 0.3408, 0.3386, 0.3098, 0.2478, 0.2278, 0.2829,\n",
      "        0.4032, 0.2750, 0.2800, 0.2697, 0.3027, 0.2880, 0.3113, 0.3391, 0.2747,\n",
      "        0.2778, 0.3941, 0.3057, 0.2540, 0.3450, 0.3412, 0.2451, 0.2591, 0.3089,\n",
      "        0.2935, 0.2805, 0.3182, 0.3382, 0.3353, 0.2772, 0.3169, 0.3075, 0.3234,\n",
      "        0.2499, 0.2536, 0.3489, 0.3097, 0.2663, 0.2746, 0.2655, 0.2761, 0.2454,\n",
      "        0.2695, 0.3393, 0.3010, 0.3290, 0.3115, 0.2578, 0.3133, 0.2541, 0.2591,\n",
      "        0.3252, 0.2798, 0.2766, 0.4027, 0.2952, 0.2839, 0.3565, 0.3071]))\n",
      "('conv4.1.bias', Parameter containing:\n",
      "tensor([-0.2515, -0.2760, -0.2204, -0.2687, -0.2589, -0.2659, -0.2244, -0.3698,\n",
      "        -0.2837, -0.2801, -0.2505, -0.3257, -0.2837, -0.2943, -0.2978, -0.2681,\n",
      "        -0.2565, -0.2471, -0.2707, -0.2330, -0.2581, -0.2437, -0.2580, -0.2437,\n",
      "        -0.2502, -0.2485, -0.2873, -0.2687, -0.3031, -0.2911, -0.2225, -0.2242,\n",
      "        -0.3276, -0.3272, -0.2483, -0.2758, -0.2589, -0.1761, -0.1849, -0.3862,\n",
      "        -0.2494, -0.2251, -0.3305, -0.2901, -0.2786, -0.2426, -0.2664, -0.2652,\n",
      "        -0.2609, -0.2197, -0.2639, -0.2187, -0.2294, -0.2876, -0.2319, -0.2514,\n",
      "        -0.2785, -0.3459, -0.1759, -0.2891, -0.3341, -0.2761, -0.2779, -0.2350,\n",
      "        -0.2114, -0.2892, -0.3819, -0.2095, -0.3237, -0.2245, -0.3060, -0.2254,\n",
      "        -0.3151, -0.2645, -0.2286, -0.2617, -0.2291, -0.2561, -0.2850, -0.2766,\n",
      "        -0.2859, -0.3523, -0.3031, -0.3137, -0.3230, -0.2607, -0.2589, -0.2727,\n",
      "        -0.2587, -0.2294, -0.2758, -0.2727, -0.2328, -0.2482, -0.3100, -0.3072,\n",
      "        -0.2588, -0.2625, -0.2413, -0.2407, -0.2827, -0.2162, -0.3608, -0.2774,\n",
      "        -0.2550, -0.3112, -0.1938, -0.2286, -0.2587, -0.2434, -0.3315, -0.2285,\n",
      "        -0.2566, -0.3348, -0.3000, -0.1515, -0.2658, -0.2829, -0.2122, -0.1964,\n",
      "        -0.2863, -0.2898, -0.2296, -0.2915, -0.2618, -0.2627, -0.2930, -0.1853,\n",
      "        -0.2230, -0.2356, -0.2718, -0.2288, -0.2580, -0.2633, -0.2269, -0.3316,\n",
      "        -0.2909, -0.2362, -0.2481, -0.2414, -0.2998, -0.2584, -0.2589, -0.2370,\n",
      "        -0.1854, -0.2719, -0.2422, -0.2551, -0.2498, -0.2556, -0.2819, -0.2688,\n",
      "        -0.1830, -0.2374, -0.2053, -0.2240, -0.2804, -0.2306, -0.2530, -0.3630,\n",
      "        -0.2580, -0.2260, -0.2536, -0.2866, -0.2491, -0.3456, -0.2625, -0.2596,\n",
      "        -0.2695, -0.2651, -0.2309, -0.2889, -0.2686, -0.2318, -0.2418, -0.2680,\n",
      "        -0.2986, -0.2982, -0.2586, -0.2097, -0.2595, -0.3385, -0.1652, -0.3192,\n",
      "        -0.2679, -0.2738, -0.2586, -0.2463, -0.1792, -0.2724, -0.2396, -0.2758,\n",
      "        -0.2325, -0.3391, -0.2516, -0.2748, -0.2423, -0.2082, -0.2282, -0.2180,\n",
      "        -0.2288, -0.2665, -0.2275, -0.2051, -0.2203, -0.2605, -0.2242, -0.2995,\n",
      "        -0.2427, -0.2322, -0.2408, -0.2435, -0.2561, -0.3148, -0.3044, -0.1985,\n",
      "        -0.3042, -0.2625, -0.2882, -0.2383, -0.2385, -0.2098, -0.2043, -0.2372,\n",
      "        -0.2199, -0.2802, -0.2423, -0.3003, -0.2780, -0.3032, -0.2617, -0.2877,\n",
      "        -0.2647, -0.2800, -0.2830, -0.3491, -0.2361, -0.2371, -0.2775, -0.1798,\n",
      "        -0.2759, -0.2687, -0.2765, -0.2961, -0.2452, -0.2900, -0.2883, -0.1973,\n",
      "        -0.2599, -0.2006, -0.2719, -0.2811, -0.2655, -0.2502, -0.2721, -0.2672,\n",
      "        -0.2694, -0.3776, -0.3011, -0.2283, -0.2070, -0.2456, -0.2270, -0.2882,\n",
      "        -0.2034, -0.2568, -0.2373, -0.2174, -0.2765, -0.2614, -0.3288, -0.2468,\n",
      "        -0.2792, -0.2134, -0.2341, -0.3143, -0.2384, -0.3439, -0.2412, -0.3065,\n",
      "        -0.3539, -0.2520, -0.2353, -0.3082, -0.2330, -0.2367, -0.2569, -0.2156,\n",
      "        -0.2526, -0.2450, -0.2836, -0.2898, -0.2271, -0.2690, -0.2474, -0.2366,\n",
      "        -0.2523, -0.2316, -0.3270, -0.2804, -0.2428, -0.2012, -0.2339, -0.3235,\n",
      "        -0.2790, -0.3785, -0.2675, -0.2639, -0.2805, -0.2158, -0.2429, -0.2141,\n",
      "        -0.2810, -0.2590, -0.2001, -0.2343, -0.2969, -0.2793, -0.2278, -0.2519,\n",
      "        -0.2296, -0.2773, -0.2501, -0.3229, -0.2830, -0.1995, -0.2602, -0.2857,\n",
      "        -0.2199, -0.2417, -0.2440, -0.2726, -0.2418, -0.2799, -0.2572, -0.3308,\n",
      "        -0.2308, -0.2605, -0.1670, -0.3247, -0.2326, -0.3635, -0.3142, -0.3131,\n",
      "        -0.2406, -0.2289, -0.2910, -0.2162, -0.2279, -0.2623, -0.2089, -0.2691,\n",
      "        -0.2410, -0.2227, -0.2365, -0.2370, -0.2966, -0.2307, -0.3287, -0.2312,\n",
      "        -0.2816, -0.1856, -0.2288, -0.2887, -0.2961, -0.2430, -0.2406, -0.2901,\n",
      "        -0.1855, -0.2357, -0.3064, -0.2528, -0.2751, -0.2668, -0.3053, -0.2448,\n",
      "        -0.2565, -0.2821, -0.2041, -0.2913, -0.2516, -0.2985, -0.2873, -0.2744,\n",
      "        -0.3409, -0.1403, -0.2570, -0.2442, -0.2881, -0.3232, -0.2461, -0.2235,\n",
      "        -0.2627, -0.2645, -0.3219, -0.2333, -0.2269, -0.2195, -0.1962, -0.2414,\n",
      "        -0.2791, -0.2876, -0.2850, -0.2365, -0.2553, -0.2426, -0.2461, -0.2952,\n",
      "        -0.1776, -0.2975, -0.2603, -0.2652, -0.3037, -0.3088, -0.2792, -0.2772,\n",
      "        -0.2957, -0.2625, -0.2416, -0.2873, -0.2869, -0.2593, -0.2719, -0.3105,\n",
      "        -0.2444, -0.3031, -0.1876, -0.2626, -0.2462, -0.2365, -0.3144, -0.2276,\n",
      "        -0.2988, -0.2973, -0.2880, -0.2875, -0.2500, -0.3081, -0.2709, -0.2445,\n",
      "        -0.2787, -0.3373, -0.2385, -0.2035, -0.2273, -0.2594, -0.2258, -0.2417,\n",
      "        -0.2934, -0.2548, -0.1925, -0.2591, -0.2331, -0.3128, -0.3151, -0.2769,\n",
      "        -0.2378, -0.2200, -0.3128, -0.3192, -0.2268, -0.2590, -0.2596, -0.2329,\n",
      "        -0.2615, -0.2809, -0.2625, -0.2337, -0.2418, -0.3223, -0.2888, -0.2412,\n",
      "        -0.3416, -0.3096, -0.1878, -0.2344, -0.2443, -0.2384, -0.2580, -0.2852,\n",
      "        -0.2988, -0.3070, -0.2388, -0.2995, -0.2926, -0.3203, -0.2504, -0.2186,\n",
      "        -0.2898, -0.2721, -0.2395, -0.2600, -0.2149, -0.2390, -0.2336, -0.2336,\n",
      "        -0.2308, -0.2683, -0.2645, -0.2998, -0.2016, -0.2570, -0.2132, -0.2144,\n",
      "        -0.2924, -0.2422, -0.2328, -0.3997, -0.2385, -0.2244, -0.2691, -0.2995]))\n",
      "('res2.0.0.weight', Parameter containing:\n",
      "tensor([[[[ 1.8929e-03,  7.7266e-03, -2.4239e-03],\n",
      "          [ 8.7535e-03,  1.1395e-02, -1.3138e-02],\n",
      "          [-4.9699e-03, -2.0369e-03, -9.9439e-03]],\n",
      "\n",
      "         [[-5.8024e-03, -1.2085e-02, -7.2388e-03],\n",
      "          [-4.0678e-03, -5.1261e-03, -3.8779e-04],\n",
      "          [-4.3280e-03, -5.2883e-03,  2.9540e-03]],\n",
      "\n",
      "         [[ 3.2106e-03,  4.2188e-03,  8.8488e-04],\n",
      "          [ 2.8778e-04,  4.4343e-03,  1.7602e-03],\n",
      "          [-5.2959e-03, -9.9920e-03, -5.3882e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.9804e-03,  4.3491e-03, -2.5823e-03],\n",
      "          [-8.7218e-03,  2.3855e-03, -6.6959e-03],\n",
      "          [-1.3054e-02, -4.1475e-03, -9.3822e-04]],\n",
      "\n",
      "         [[ 3.3202e-03,  1.0643e-02,  1.9219e-03],\n",
      "          [-3.7628e-03, -2.7363e-04,  3.3237e-03],\n",
      "          [ 8.3123e-03,  8.6027e-03,  5.6689e-03]],\n",
      "\n",
      "         [[-4.4267e-03, -3.9923e-03, -3.2680e-04],\n",
      "          [ 2.5981e-03,  9.7653e-04,  9.8860e-03],\n",
      "          [ 8.3420e-05,  3.8245e-03,  1.0383e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.3372e-03,  2.7807e-03, -6.6417e-03],\n",
      "          [ 7.9840e-03,  8.9939e-03,  1.0727e-02],\n",
      "          [ 8.0456e-03,  5.3478e-03,  5.2954e-03]],\n",
      "\n",
      "         [[ 2.8826e-03,  2.8042e-03,  1.4738e-02],\n",
      "          [-1.7875e-03,  3.7715e-03,  8.7366e-03],\n",
      "          [-1.2492e-02, -1.0990e-02, -2.2884e-03]],\n",
      "\n",
      "         [[ 1.4255e-02,  1.3553e-02,  3.1033e-03],\n",
      "          [ 9.8202e-03,  1.0806e-02,  5.5628e-03],\n",
      "          [ 8.2088e-04, -7.7872e-03, -5.9997e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.3845e-03, -8.1260e-03, -1.0283e-02],\n",
      "          [-1.5256e-02, -1.6294e-02, -5.9190e-03],\n",
      "          [-7.6576e-03, -1.7625e-02, -8.4729e-04]],\n",
      "\n",
      "         [[ 2.2195e-02,  2.8328e-02,  2.5443e-02],\n",
      "          [ 8.2674e-03,  1.6514e-02,  1.1292e-02],\n",
      "          [-1.2273e-02, -1.0450e-02, -1.7976e-03]],\n",
      "\n",
      "         [[ 5.3505e-03,  7.6773e-03,  6.0287e-03],\n",
      "          [ 1.7598e-02,  1.9172e-02,  1.0169e-02],\n",
      "          [ 8.8432e-03,  2.4817e-03, -8.8889e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.4797e-02, -9.7753e-03, -1.1793e-02],\n",
      "          [ 1.5179e-03, -3.8074e-03, -1.4951e-03],\n",
      "          [ 9.3977e-03, -3.3162e-03,  3.3644e-03]],\n",
      "\n",
      "         [[-3.1083e-03,  9.0101e-03,  1.9480e-03],\n",
      "          [ 9.0131e-03,  1.6918e-02, -8.1378e-03],\n",
      "          [ 1.0978e-02,  1.9088e-02, -1.1267e-02]],\n",
      "\n",
      "         [[-3.9289e-03, -6.7523e-03, -1.9312e-03],\n",
      "          [ 3.7364e-03,  2.4371e-03,  8.0790e-03],\n",
      "          [-8.2956e-03,  1.6897e-04,  3.4356e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.8566e-04, -4.3455e-03,  2.5296e-03],\n",
      "          [ 1.6512e-02,  1.6898e-03,  4.1979e-03],\n",
      "          [ 1.2061e-02, -5.5424e-03,  5.5795e-03]],\n",
      "\n",
      "         [[ 1.4032e-02,  8.9488e-04,  1.9592e-03],\n",
      "          [ 1.1027e-02,  8.0338e-03, -1.1148e-02],\n",
      "          [-1.1810e-02, -5.7007e-03, -1.4238e-02]],\n",
      "\n",
      "         [[ 4.8417e-03, -2.2118e-03,  1.6255e-02],\n",
      "          [ 1.8446e-04, -1.9539e-03, -4.2957e-03],\n",
      "          [-4.0219e-03,  5.0662e-03, -1.1242e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-5.1185e-03,  4.3494e-04,  4.6107e-04],\n",
      "          [ 6.3175e-03,  2.4634e-04,  7.2538e-03],\n",
      "          [ 7.4788e-03,  4.9776e-03,  6.4000e-03]],\n",
      "\n",
      "         [[-1.7833e-02, -1.4118e-02,  9.9086e-04],\n",
      "          [-1.1320e-02, -7.7565e-03, -6.3943e-03],\n",
      "          [-2.0048e-03, -6.3100e-03,  3.8490e-03]],\n",
      "\n",
      "         [[ 6.5002e-05, -3.2606e-03, -1.1359e-03],\n",
      "          [-1.2878e-02, -1.5183e-02, -7.5956e-03],\n",
      "          [-1.0169e-02, -1.1831e-02, -8.3722e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.7482e-03, -2.8309e-03,  8.8030e-04],\n",
      "          [-2.2630e-03, -2.2368e-03, -1.9725e-03],\n",
      "          [ 1.6598e-03,  1.9309e-03,  4.7770e-03]],\n",
      "\n",
      "         [[-4.5196e-03, -8.7861e-03, -2.7485e-03],\n",
      "          [-9.5736e-03, -9.5570e-03, -8.2276e-04],\n",
      "          [-6.6068e-03, -2.3241e-03,  3.1630e-03]],\n",
      "\n",
      "         [[-6.3373e-04,  8.2150e-03,  4.5170e-03],\n",
      "          [-2.0057e-03,  3.4840e-03, -1.4382e-03],\n",
      "          [-5.5307e-04,  1.8303e-03, -2.5883e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8653e-03, -5.0937e-03, -5.5179e-03],\n",
      "          [ 8.7455e-04, -5.2481e-03, -4.3097e-03],\n",
      "          [-5.8794e-03, -7.5828e-03,  3.0680e-03]],\n",
      "\n",
      "         [[ 3.5572e-04, -2.3701e-03, -4.7662e-03],\n",
      "          [ 2.4266e-03, -1.1189e-03, -5.2192e-03],\n",
      "          [ 1.8542e-03, -3.4857e-03, -1.3895e-03]],\n",
      "\n",
      "         [[ 8.5991e-03,  1.0986e-02,  2.1754e-03],\n",
      "          [ 4.0674e-03,  8.1481e-03,  1.6515e-03],\n",
      "          [-1.7547e-04,  3.9894e-03,  1.1259e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4205e-02,  1.2750e-02,  7.6709e-03],\n",
      "          [ 2.1020e-04, -2.0152e-03, -2.1032e-03],\n",
      "          [-1.2407e-02, -1.6062e-02, -6.6348e-03]],\n",
      "\n",
      "         [[-1.6106e-02, -9.5083e-03,  4.0880e-03],\n",
      "          [-6.6608e-03, -7.5409e-03,  5.4262e-03],\n",
      "          [-8.4516e-03, -9.5487e-03,  4.7263e-03]],\n",
      "\n",
      "         [[ 7.1016e-03, -5.2487e-03,  6.5953e-04],\n",
      "          [ 1.7820e-04,  1.1602e-03,  5.2440e-03],\n",
      "          [-1.1190e-04,  9.2016e-03,  8.7307e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.6896e-04, -3.7478e-03, -1.2303e-03],\n",
      "          [-5.0435e-03, -1.2088e-03, -2.9512e-03],\n",
      "          [-2.9317e-03, -7.5162e-03, -3.1308e-03]],\n",
      "\n",
      "         [[-3.6833e-03, -2.1825e-03, -3.3641e-03],\n",
      "          [ 7.2100e-04,  3.5429e-03, -6.9629e-03],\n",
      "          [-3.7339e-03, -5.0767e-03, -2.2924e-03]],\n",
      "\n",
      "         [[ 3.3856e-03,  4.7671e-03, -4.0022e-03],\n",
      "          [-3.7253e-03,  3.2372e-04, -4.6792e-04],\n",
      "          [-2.3296e-03, -3.0354e-03, -3.3318e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.3688e-05,  4.3093e-03,  5.0529e-03],\n",
      "          [ 2.9458e-03,  2.0181e-04,  1.1122e-02],\n",
      "          [ 8.2011e-03,  3.8706e-03,  2.6369e-03]],\n",
      "\n",
      "         [[-2.0021e-03, -4.7951e-03, -5.3646e-03],\n",
      "          [-6.2000e-03,  1.3003e-03, -2.4694e-03],\n",
      "          [ 2.5153e-05, -5.9380e-03,  1.1687e-03]],\n",
      "\n",
      "         [[-5.2095e-03,  4.9429e-03,  5.8910e-03],\n",
      "          [-4.7356e-03,  1.3015e-02,  5.7475e-03],\n",
      "          [-6.4509e-03, -3.0544e-04, -7.1060e-03]]]]))\n",
      "('res2.0.0.bias', Parameter containing:\n",
      "tensor([-2.7370e-08, -1.3522e-08,  5.1729e-09, -1.9364e-08, -3.4172e-08,\n",
      "        -4.7216e-08,  1.6197e-08,  8.2030e-09,  1.0724e-09,  5.8057e-09,\n",
      "        -6.3089e-08, -1.9808e-07,  2.6188e-09, -4.5975e-08,  4.0652e-08,\n",
      "        -5.0140e-08, -3.9302e-08, -8.5765e-09, -6.4797e-08, -3.9564e-08,\n",
      "        -7.6148e-08,  2.1259e-08,  7.9762e-08, -3.8960e-08, -2.8524e-08,\n",
      "        -3.1753e-08, -3.7317e-08, -2.6553e-08, -5.3030e-08, -2.6623e-08,\n",
      "         4.0596e-08,  5.2017e-09,  1.4083e-07,  2.9707e-08, -3.2786e-08,\n",
      "         1.3737e-08,  8.9447e-08,  1.1316e-08,  3.0953e-09,  5.1267e-08,\n",
      "        -6.1212e-09, -5.4781e-08, -3.8645e-08,  1.1658e-08, -3.3903e-08,\n",
      "        -3.2279e-08,  1.6760e-08, -2.5422e-09, -1.3562e-08,  6.5051e-08,\n",
      "         4.8335e-08,  2.6050e-09, -3.9676e-08, -1.7255e-07, -7.3515e-08,\n",
      "         8.3557e-09,  5.2283e-08, -5.6480e-08, -3.5720e-08, -1.6243e-08,\n",
      "         4.8907e-08, -5.7080e-08,  1.7230e-08, -5.8857e-09,  4.9074e-08,\n",
      "         9.6547e-08,  3.1049e-08, -5.9042e-08,  4.0178e-10, -2.2993e-08,\n",
      "        -2.0743e-08,  6.0658e-08, -1.9759e-08, -3.7770e-10, -3.1997e-08,\n",
      "        -3.1854e-08,  1.3998e-07,  8.1605e-09, -4.5061e-08,  1.9851e-08,\n",
      "         3.5152e-08, -1.0524e-08,  2.5657e-08, -4.5845e-09,  1.0187e-09,\n",
      "        -1.9455e-08,  3.6117e-08, -2.6428e-08, -1.2423e-08,  2.1541e-09,\n",
      "         1.9861e-08, -1.2267e-07,  2.0286e-08,  3.3160e-09,  2.1536e-08,\n",
      "        -1.6326e-08, -5.3988e-08, -4.4327e-09, -6.4732e-08,  3.0573e-08,\n",
      "        -6.0711e-09, -7.0545e-08, -1.5263e-07,  1.4144e-08,  1.0789e-08,\n",
      "        -1.4815e-08,  2.7794e-08,  3.4756e-08,  4.7102e-08, -1.5880e-07,\n",
      "         4.9002e-08, -2.5486e-09, -1.3308e-07,  9.4602e-08,  1.1144e-08,\n",
      "         2.2979e-08,  4.3982e-08,  4.2593e-09,  6.4279e-08,  7.3234e-08,\n",
      "        -5.8137e-08,  1.2034e-08,  3.0477e-08,  8.7583e-09, -7.6947e-08,\n",
      "         5.5687e-08,  1.6273e-08,  4.8491e-09,  3.4741e-08,  1.2065e-08,\n",
      "        -6.0396e-08, -8.1451e-09, -3.4364e-08,  1.6898e-09, -1.4924e-08,\n",
      "         1.6390e-08,  4.0562e-08,  2.9976e-08,  2.6156e-08,  2.1509e-08,\n",
      "         5.6921e-08, -4.4135e-09, -7.6338e-09, -1.2987e-08,  2.2038e-09,\n",
      "        -3.4417e-08, -5.1730e-08, -2.4822e-08, -2.6580e-08, -9.4971e-08,\n",
      "         2.0399e-08,  6.6424e-08,  1.2444e-07, -2.2675e-09,  8.0027e-09,\n",
      "        -3.2331e-09,  2.0880e-08, -1.2058e-07, -1.1926e-07, -4.6388e-08,\n",
      "        -6.7037e-08, -1.1298e-07,  5.8900e-08, -2.2504e-09, -1.7716e-08,\n",
      "        -5.3847e-08, -1.9288e-08, -3.1661e-09,  1.1412e-07,  6.3781e-08,\n",
      "         6.6145e-09,  7.4596e-09, -6.5180e-08,  1.4984e-07,  2.2313e-08,\n",
      "         9.0660e-09,  1.9391e-08,  2.2482e-08,  1.7638e-08,  1.5101e-08,\n",
      "        -1.3166e-08, -2.2226e-08,  2.5208e-08,  9.4400e-08,  1.2876e-08,\n",
      "         1.2887e-08, -9.4045e-08, -2.4284e-08, -2.6247e-08,  1.0360e-07,\n",
      "        -1.2113e-07,  2.4273e-09,  9.2588e-09,  1.3220e-08,  1.0426e-08,\n",
      "        -6.3580e-08, -2.6568e-08, -8.0356e-09,  4.7411e-08,  3.2354e-08,\n",
      "         1.4481e-08,  4.6508e-08, -1.7678e-08, -2.2177e-08,  7.2542e-09,\n",
      "         6.3129e-08,  1.4070e-09,  8.6850e-09, -8.4125e-09, -1.2766e-08,\n",
      "        -7.0246e-09,  5.4901e-08,  4.3909e-08,  1.0795e-09,  4.7857e-08,\n",
      "         2.8764e-08,  3.0506e-08, -5.2829e-08,  5.3376e-08,  5.8732e-08,\n",
      "        -2.3542e-08,  1.2924e-08,  9.5823e-09,  3.4863e-08,  3.0706e-08,\n",
      "         4.0768e-08, -3.2266e-09, -5.0960e-08,  4.2626e-09,  1.0690e-07,\n",
      "         8.4097e-08,  3.0438e-09,  4.5072e-08, -4.5981e-08,  4.1842e-08,\n",
      "        -7.0848e-09, -1.7480e-08, -2.7255e-08,  3.5126e-08,  1.4891e-08,\n",
      "        -2.3882e-08,  2.3965e-08, -1.3497e-08, -1.4896e-08,  2.3054e-08,\n",
      "        -5.9358e-09,  2.2300e-08,  1.8907e-08, -1.1540e-07,  1.0441e-07,\n",
      "         8.9817e-09, -1.9447e-08, -3.1771e-08, -6.3838e-08, -1.1569e-08,\n",
      "        -3.8966e-08, -6.0277e-08,  1.0994e-07,  5.7081e-08,  5.8859e-08,\n",
      "        -4.8154e-08, -7.5518e-08,  1.7803e-08,  8.1442e-08,  1.3696e-07,\n",
      "         7.3519e-08,  3.9832e-08, -4.5948e-08,  3.5325e-08,  2.6475e-08,\n",
      "         6.7763e-08, -3.1406e-09,  2.4685e-08,  1.6453e-08,  1.4418e-08,\n",
      "         2.3548e-08,  3.0986e-08, -1.3089e-08, -3.5915e-08, -5.2768e-09,\n",
      "         6.7853e-08, -2.6451e-08, -3.9458e-08,  1.8325e-08,  3.5120e-08,\n",
      "         1.2122e-07, -3.5674e-10,  3.7691e-09,  2.5327e-08,  2.1182e-08,\n",
      "         4.9297e-11, -1.3646e-08,  4.2947e-08, -9.3008e-08, -3.9122e-08,\n",
      "         2.9224e-08, -1.8444e-08,  5.2982e-08, -1.3823e-07,  1.5562e-08,\n",
      "         5.2751e-08,  4.6562e-09, -1.0570e-08,  8.0111e-09, -2.0435e-08,\n",
      "         2.6607e-09,  5.5021e-08, -2.4396e-08, -5.5703e-09, -1.6372e-08,\n",
      "         7.5165e-11, -2.6081e-08, -2.0174e-08, -6.2362e-08,  3.4939e-09,\n",
      "         4.9217e-08,  4.9855e-09, -2.1966e-08,  3.4783e-08,  3.1133e-08,\n",
      "         1.5983e-08,  1.0531e-07,  5.1263e-08, -1.5040e-10,  2.9774e-08,\n",
      "        -4.6885e-08, -2.9282e-08,  1.9365e-08, -1.6497e-08, -1.2533e-08,\n",
      "         3.0270e-08, -3.6793e-08,  2.4821e-10,  1.4350e-08,  6.5950e-08,\n",
      "         2.7870e-08,  2.0871e-08, -4.8722e-08, -1.1436e-08,  4.5345e-08,\n",
      "        -1.2664e-08,  5.4407e-08, -3.1026e-09,  2.7927e-08,  3.9267e-08,\n",
      "         8.1031e-08,  2.0503e-09, -4.4344e-08,  3.6904e-08,  1.0483e-07,\n",
      "        -3.0584e-08,  3.2137e-07, -8.9795e-08, -3.1258e-08,  1.5897e-08,\n",
      "        -2.8217e-08, -7.9934e-08, -6.2762e-08, -1.1650e-09, -2.2842e-08,\n",
      "        -2.1721e-08,  2.5834e-08, -1.3073e-07, -6.6831e-09,  7.7877e-08,\n",
      "        -5.6869e-08, -9.9633e-09, -2.0871e-08, -9.1432e-09,  1.2391e-08,\n",
      "         8.0410e-09,  9.7383e-09, -5.3946e-08, -8.5539e-08,  4.7984e-08,\n",
      "        -9.9006e-09,  2.2304e-08,  6.9542e-08,  1.6182e-08,  2.3567e-09,\n",
      "        -4.1751e-08, -1.4036e-08, -1.2472e-07,  1.9643e-09,  4.1270e-08,\n",
      "         1.2203e-08, -1.7664e-08, -1.9860e-08,  2.6407e-08, -5.8342e-08,\n",
      "        -4.9574e-08, -6.7611e-08, -3.8208e-08,  2.5126e-08,  3.0861e-08,\n",
      "         3.5379e-08,  1.7685e-08,  3.8043e-09,  3.9625e-08,  3.7728e-08,\n",
      "         6.6166e-09,  1.3202e-08, -2.7260e-08,  7.9801e-09, -2.2856e-08,\n",
      "         3.9681e-09, -1.1192e-07,  3.0674e-08,  6.6839e-09,  6.3927e-09,\n",
      "         3.1936e-08,  8.4204e-08, -1.6522e-07,  6.4699e-09, -1.8815e-08,\n",
      "         1.3970e-08,  5.3079e-09,  6.2471e-08,  4.6876e-08,  3.1802e-08,\n",
      "        -3.4216e-08, -4.3157e-08, -5.9262e-08,  2.2183e-08, -5.6928e-08,\n",
      "        -2.2447e-07, -3.9786e-08, -1.6485e-08,  3.2567e-08,  2.7561e-08,\n",
      "        -2.9424e-08, -6.9800e-08, -2.9305e-08, -1.5170e-08,  3.9761e-09,\n",
      "         2.9096e-08, -1.3788e-09, -5.9338e-08,  6.1845e-09, -3.4147e-09,\n",
      "         4.4725e-08,  6.8825e-08,  2.3639e-08, -9.2585e-08,  1.2294e-08,\n",
      "        -7.7939e-09, -8.1373e-10, -1.7181e-08, -7.7051e-09,  2.5107e-08,\n",
      "        -1.6188e-08,  8.3581e-08, -2.9578e-09,  2.2381e-08,  3.4931e-08,\n",
      "         3.3795e-08,  4.9113e-08, -3.7775e-08,  7.1072e-09,  1.6746e-08,\n",
      "        -2.7856e-08, -6.2330e-08,  6.8556e-08,  1.5039e-09,  3.4009e-08,\n",
      "         2.6185e-08, -1.0378e-09,  3.9847e-08, -6.7503e-08,  3.4737e-08,\n",
      "         1.7194e-08, -2.0321e-08, -2.8547e-08, -3.0633e-08,  2.7561e-08,\n",
      "        -2.2184e-08, -2.8005e-09, -7.1146e-08, -8.1824e-09, -1.9287e-09,\n",
      "         3.0327e-08, -2.1458e-08,  1.8444e-09, -4.6159e-08, -6.8679e-08,\n",
      "        -3.0892e-08,  1.0533e-08,  3.9337e-08, -1.6096e-08, -3.2555e-08,\n",
      "         3.7110e-08, -3.9203e-09, -4.6816e-08, -1.3577e-08, -5.9499e-09,\n",
      "        -2.5261e-08, -1.1169e-08, -1.4087e-08, -3.1765e-08, -3.4680e-08,\n",
      "        -2.7328e-08, -5.2368e-09,  3.7291e-08, -9.4321e-09,  2.6021e-08,\n",
      "         8.3851e-09, -1.2466e-08,  9.2952e-09,  5.5442e-08, -8.7124e-08,\n",
      "        -7.4729e-08,  1.2156e-08]))\n",
      "('res2.0.1.weight', Parameter containing:\n",
      "tensor([0.2222, 0.2818, 0.2563, 0.1141, 0.3513, 0.1485, 0.1144, 0.2062, 0.1499,\n",
      "        0.1276, 0.2897, 0.2487, 0.2414, 0.2244, 0.2053, 0.2822, 0.2793, 0.2826,\n",
      "        0.2294, 0.2325, 0.2917, 0.2348, 0.1783, 0.1939, 0.2044, 0.2097, 0.2406,\n",
      "        0.2232, 0.3407, 0.2063, 0.3937, 0.2553, 0.2685, 0.2473, 0.3099, 0.1994,\n",
      "        0.2183, 0.2008, 0.2864, 0.3210, 0.2706, 0.2368, 0.2279, 0.1336, 0.1974,\n",
      "        0.2251, 0.1928, 0.2099, 0.2351, 0.2402, 0.2597, 0.2815, 0.1615, 0.3191,\n",
      "        0.2690, 0.2921, 0.2784, 0.2358, 0.2432, 0.2139, 0.2283, 0.2059, 0.2130,\n",
      "        0.1802, 0.1338, 0.1705, 0.2348, 0.1934, 0.1726, 0.1937, 0.3402, 0.2246,\n",
      "        0.2732, 0.2427, 0.2082, 0.2767, 0.3936, 0.2687, 0.3330, 0.2141, 0.2796,\n",
      "        0.2292, 0.3184, 0.1604, 0.1403, 0.1639, 0.1542, 0.3115, 0.2531, 0.1870,\n",
      "        0.2488, 0.3086, 0.2199, 0.3221, 0.1675, 0.2524, 0.2526, 0.3664, 0.2444,\n",
      "        0.2502, 0.1658, 0.2329, 0.4305, 0.2713, 0.2298, 0.2204, 0.2163, 0.1396,\n",
      "        0.2063, 0.3495, 0.3815, 0.1115, 0.2410, 0.1824, 0.1288, 0.2429, 0.2114,\n",
      "        0.1835, 0.2813, 0.2354, 0.2858, 0.3150, 0.1658, 0.1802, 0.2326, 0.1973,\n",
      "        0.2249, 0.1626, 0.2265, 0.2263, 0.3208, 0.2814, 0.2245, 0.2984, 0.2194,\n",
      "        0.2406, 0.2578, 0.2536, 0.2986, 0.3323, 0.2653, 0.1797, 0.1798, 0.2546,\n",
      "        0.2612, 0.1807, 0.2659, 0.2244, 0.1346, 0.2784, 0.1559, 0.2324, 0.2972,\n",
      "        0.1057, 0.1422, 0.1974, 0.2248, 0.2504, 0.2714, 0.2813, 0.1998, 0.3853,\n",
      "        0.2243, 0.2095, 0.1436, 0.3650, 0.1860, 0.1315, 0.3069, 0.1939, 0.2765,\n",
      "        0.1938, 0.2769, 0.3090, 0.1073, 0.1348, 0.3456, 0.2525, 0.2360, 0.2982,\n",
      "        0.2844, 0.2678, 0.1989, 0.2840, 0.1495, 0.2250, 0.3533, 0.2210, 0.3464,\n",
      "        0.4189, 0.3468, 0.1382, 0.0959, 0.2264, 0.1568, 0.2322, 0.1545, 0.1518,\n",
      "        0.2085, 0.2469, 0.1814, 0.1978, 0.2560, 0.1797, 0.1922, 0.1137, 0.2280,\n",
      "        0.1488, 0.2357, 0.3054, 0.1918, 0.3127, 0.2992, 0.1491, 0.3437, 0.2070,\n",
      "        0.1924, 0.2490, 0.2525, 0.2387, 0.2375, 0.1710, 0.2227, 0.1391, 0.3121,\n",
      "        0.1535, 0.3076, 0.3212, 0.2720, 0.2753, 0.3863, 0.2434, 0.2092, 0.2620,\n",
      "        0.2529, 0.2079, 0.1131, 0.1464, 0.1845, 0.2049, 0.1489, 0.3353, 0.1651,\n",
      "        0.3165, 0.2612, 0.1635, 0.2093, 0.2296, 0.1510, 0.2784, 0.2811, 0.2314,\n",
      "        0.3874, 0.2691, 0.3261, 0.2247, 0.2723, 0.2518, 0.3015, 0.2574, 0.2451,\n",
      "        0.2701, 0.2683, 0.3151, 0.3222, 0.3056, 0.2391, 0.2071, 0.2080, 0.1737,\n",
      "        0.2702, 0.2451, 0.2140, 0.2386, 0.1341, 0.2044, 0.1375, 0.2811, 0.1794,\n",
      "        0.0907, 0.2367, 0.2435, 0.2915, 0.2138, 0.2336, 0.3651, 0.1625, 0.1614,\n",
      "        0.2088, 0.2045, 0.1808, 0.1730, 0.3194, 0.3403, 0.2733, 0.1656, 0.3057,\n",
      "        0.1804, 0.2567, 0.1684, 0.3045, 0.3091, 0.2462, 0.1654, 0.2539, 0.2427,\n",
      "        0.2556, 0.2622, 0.2949, 0.2886, 0.1448, 0.2077, 0.1842, 0.3038, 0.2033,\n",
      "        0.2286, 0.2123, 0.1691, 0.2219, 0.2470, 0.1681, 0.2544, 0.2393, 0.1608,\n",
      "        0.2495, 0.2003, 0.1801, 0.1662, 0.3190, 0.0775, 0.2485, 0.2864, 0.2197,\n",
      "        0.2250, 0.2408, 0.1641, 0.2984, 0.2232, 0.1363, 0.1989, 0.2603, 0.1750,\n",
      "        0.1666, 0.3846, 0.2077, 0.2176, 0.2034, 0.2348, 0.3009, 0.2389, 0.3782,\n",
      "        0.2614, 0.2605, 0.1357, 0.2647, 0.2390, 0.2242, 0.2887, 0.1992, 0.3242,\n",
      "        0.1347, 0.3603, 0.3200, 0.2685, 0.4026, 0.3205, 0.1747, 0.1817, 0.2628,\n",
      "        0.2473, 0.1349, 0.2456, 0.1957, 0.2564, 0.2456, 0.1640, 0.4574, 0.2733,\n",
      "        0.1891, 0.1522, 0.2324, 0.1345, 0.2544, 0.1875, 0.2130, 0.3350, 0.1298,\n",
      "        0.2577, 0.2113, 0.3096, 0.3188, 0.2657, 0.2379, 0.2031, 0.3065, 0.2284,\n",
      "        0.0944, 0.2285, 0.2277, 0.2083, 0.3188, 0.1446, 0.2504, 0.1135, 0.2194,\n",
      "        0.2403, 0.3780, 0.2408, 0.3615, 0.1210, 0.1738, 0.2512, 0.3437, 0.1352,\n",
      "        0.1618, 0.2021, 0.1645, 0.2833, 0.2182, 0.2684, 0.2189, 0.2555, 0.1768,\n",
      "        0.2299, 0.3473, 0.2324, 0.1678, 0.1822, 0.1896, 0.2122, 0.2016, 0.3498,\n",
      "        0.2678, 0.2261, 0.2782, 0.1583, 0.1502, 0.2164, 0.3625, 0.1926, 0.3494,\n",
      "        0.2045, 0.3356, 0.3240, 0.1878, 0.1782, 0.2677, 0.1509, 0.1935, 0.3428,\n",
      "        0.2284, 0.2300, 0.2048, 0.2416, 0.4703, 0.3188, 0.2432, 0.1977, 0.2541,\n",
      "        0.1547, 0.2169, 0.3074, 0.1450, 0.1977, 0.2225, 0.2489, 0.3105, 0.2375,\n",
      "        0.2576, 0.3343, 0.2810, 0.2091, 0.2467, 0.2955, 0.2352, 0.1286, 0.1916,\n",
      "        0.3555, 0.1688, 0.1791, 0.1371, 0.1815, 0.1987, 0.1388, 0.2138, 0.3765,\n",
      "        0.1774, 0.3396, 0.2336, 0.2564, 0.1827, 0.1327, 0.2427, 0.1583, 0.2921,\n",
      "        0.1943, 0.2005, 0.1759, 0.2267, 0.2568, 0.2744, 0.2821, 0.1603, 0.2733,\n",
      "        0.2199, 0.1413, 0.2600, 0.1641, 0.3287, 0.2454, 0.1773, 0.1604]))\n",
      "('res2.0.1.bias', Parameter containing:\n",
      "tensor([-0.1624, -0.1841, -0.1594, -0.0855, -0.2137, -0.1177, -0.0845, -0.1571,\n",
      "        -0.0776, -0.0994, -0.1923, -0.1651, -0.1533, -0.1457, -0.1421, -0.1878,\n",
      "        -0.2075, -0.1866, -0.1426, -0.1495, -0.1688, -0.1322, -0.1473, -0.1268,\n",
      "        -0.1607, -0.1567, -0.1794, -0.1695, -0.1466, -0.1302, -0.2337, -0.1749,\n",
      "        -0.1578, -0.1557, -0.2208, -0.1281, -0.1652, -0.1299, -0.1845, -0.2035,\n",
      "        -0.1631, -0.1600, -0.1737, -0.1084, -0.1275, -0.1468, -0.1226, -0.1359,\n",
      "        -0.1707, -0.1601, -0.1990, -0.1929, -0.1229, -0.2254, -0.1706, -0.2015,\n",
      "        -0.1952, -0.1588, -0.1584, -0.1517, -0.1688, -0.1377, -0.1431, -0.1243,\n",
      "        -0.0686, -0.1376, -0.1747, -0.1377, -0.1048, -0.1243, -0.2143, -0.1469,\n",
      "        -0.1661, -0.1809, -0.1434, -0.1718, -0.1917, -0.1550, -0.1946, -0.1607,\n",
      "        -0.1836, -0.1555, -0.1954, -0.1207, -0.1028, -0.1021, -0.1126, -0.2150,\n",
      "        -0.1633, -0.1685, -0.1888, -0.2107, -0.1609, -0.2156, -0.1189, -0.1679,\n",
      "        -0.1623, -0.1857, -0.1871, -0.1856, -0.1104, -0.1670, -0.2806, -0.2106,\n",
      "        -0.1678, -0.1684, -0.1297, -0.1073, -0.1446, -0.1932, -0.2290, -0.0844,\n",
      "        -0.1844, -0.1370, -0.0860, -0.1897, -0.1493, -0.1494, -0.1485, -0.1635,\n",
      "        -0.1699, -0.2363, -0.1181, -0.1243, -0.1459, -0.1475, -0.1441, -0.1124,\n",
      "        -0.1721, -0.1179, -0.2153, -0.1744, -0.1580, -0.2033, -0.1490, -0.1712,\n",
      "        -0.2065, -0.1477, -0.1770, -0.2015, -0.1646, -0.1046, -0.1602, -0.2004,\n",
      "        -0.1978, -0.1346, -0.1802, -0.1553, -0.1056, -0.1945, -0.1112, -0.1663,\n",
      "        -0.2109, -0.0766, -0.1208, -0.1300, -0.1818, -0.1714, -0.1819, -0.2018,\n",
      "        -0.1600, -0.2316, -0.1666, -0.1430, -0.0741, -0.2321, -0.1440, -0.0959,\n",
      "        -0.2195, -0.1054, -0.1714, -0.1341, -0.1839, -0.2260, -0.0731, -0.1138,\n",
      "        -0.2020, -0.1408, -0.1483, -0.1953, -0.1857, -0.1648, -0.1570, -0.2052,\n",
      "        -0.1151, -0.1482, -0.2470, -0.1472, -0.1915, -0.2773, -0.2141, -0.0974,\n",
      "        -0.0937, -0.1705, -0.1296, -0.1546, -0.1201, -0.1023, -0.1743, -0.1625,\n",
      "        -0.1015, -0.1421, -0.1723, -0.1262, -0.1455, -0.0667, -0.1128, -0.0985,\n",
      "        -0.1851, -0.1777, -0.1402, -0.1608, -0.2111, -0.1195, -0.2045, -0.1437,\n",
      "        -0.1369, -0.1426, -0.1767, -0.1884, -0.1710, -0.1647, -0.1393, -0.0854,\n",
      "        -0.1659, -0.0878, -0.1890, -0.1869, -0.1871, -0.2082, -0.2010, -0.1380,\n",
      "        -0.1672, -0.2070, -0.1649, -0.1549, -0.0920, -0.1245, -0.1345, -0.1276,\n",
      "        -0.0914, -0.2156, -0.1048, -0.1572, -0.1919, -0.1028, -0.1585, -0.1709,\n",
      "        -0.1043, -0.2163, -0.2169, -0.1320, -0.2317, -0.2072, -0.2125, -0.1725,\n",
      "        -0.1642, -0.1774, -0.1948, -0.1846, -0.1543, -0.1611, -0.2120, -0.2384,\n",
      "        -0.1712, -0.1710, -0.1360, -0.1544, -0.1581, -0.1336, -0.1616, -0.1379,\n",
      "        -0.1550, -0.1528, -0.0779, -0.1216, -0.1219, -0.1570, -0.1088, -0.0852,\n",
      "        -0.1739, -0.1676, -0.2224, -0.1643, -0.1883, -0.2287, -0.1220, -0.1200,\n",
      "        -0.1650, -0.1553, -0.1389, -0.1145, -0.2114, -0.2357, -0.1880, -0.1310,\n",
      "        -0.1877, -0.1427, -0.1736, -0.1481, -0.2147, -0.1839, -0.1422, -0.0981,\n",
      "        -0.1663, -0.1619, -0.1928, -0.2036, -0.2170, -0.1878, -0.1126, -0.1951,\n",
      "        -0.1291, -0.1856, -0.1249, -0.1961, -0.1499, -0.1120, -0.1709, -0.1590,\n",
      "        -0.1357, -0.1540, -0.1314, -0.1281, -0.1872, -0.1463, -0.1257, -0.1389,\n",
      "        -0.2135, -0.0818, -0.1704, -0.1743, -0.1498, -0.1468, -0.1830, -0.1347,\n",
      "        -0.1853, -0.1355, -0.0835, -0.1338, -0.1627, -0.1424, -0.1229, -0.2333,\n",
      "        -0.1351, -0.1636, -0.1539, -0.1394, -0.2261, -0.1530, -0.2461, -0.1608,\n",
      "        -0.1933, -0.1127, -0.1555, -0.2051, -0.1569, -0.2026, -0.1267, -0.2160,\n",
      "        -0.0977, -0.2294, -0.2256, -0.1946, -0.2851, -0.1991, -0.1087, -0.1329,\n",
      "        -0.1875, -0.1314, -0.0644, -0.1874, -0.1568, -0.1909, -0.1569, -0.1377,\n",
      "        -0.2909, -0.1672, -0.1524, -0.1181, -0.1752, -0.1020, -0.1678, -0.1395,\n",
      "        -0.1311, -0.2164, -0.1072, -0.1773, -0.1592, -0.1987, -0.1888, -0.1514,\n",
      "        -0.1502, -0.1236, -0.1998, -0.1206, -0.0731, -0.1221, -0.1592, -0.1051,\n",
      "        -0.2021, -0.1061, -0.1634, -0.0738, -0.1609, -0.1502, -0.2476, -0.1797,\n",
      "        -0.1970, -0.0876, -0.1253, -0.1857, -0.1868, -0.1054, -0.1031, -0.1424,\n",
      "        -0.1240, -0.1647, -0.1304, -0.2134, -0.1448, -0.1813, -0.1172, -0.1731,\n",
      "        -0.2566, -0.1408, -0.1235, -0.1146, -0.1661, -0.1340, -0.1316, -0.2136,\n",
      "        -0.1674, -0.1819, -0.1889, -0.1121, -0.1282, -0.1663, -0.2466, -0.1468,\n",
      "        -0.2428, -0.1151, -0.2400, -0.2076, -0.1497, -0.1268, -0.1663, -0.1091,\n",
      "        -0.1327, -0.2241, -0.1572, -0.1728, -0.1246, -0.1463, -0.2563, -0.2156,\n",
      "        -0.1934, -0.1312, -0.1892, -0.1045, -0.1495, -0.2178, -0.0759, -0.1272,\n",
      "        -0.1563, -0.1554, -0.2092, -0.2016, -0.1579, -0.2331, -0.2141, -0.1546,\n",
      "        -0.1666, -0.1722, -0.1629, -0.0931, -0.1469, -0.1948, -0.1340, -0.1228,\n",
      "        -0.1151, -0.1104, -0.1392, -0.1075, -0.1402, -0.2249, -0.1397, -0.1858,\n",
      "        -0.1657, -0.1825, -0.1380, -0.0807, -0.1754, -0.1072, -0.2179, -0.1412,\n",
      "        -0.1179, -0.1453, -0.1753, -0.1687, -0.1915, -0.1782, -0.1185, -0.2026,\n",
      "        -0.1492, -0.1141, -0.1989, -0.1174, -0.1644, -0.1826, -0.1324, -0.1230]))\n",
      "('res2.1.0.weight', Parameter containing:\n",
      "tensor([[[[ 1.0141e-02,  1.2342e-02,  5.2055e-03],\n",
      "          [ 3.9248e-03,  3.7861e-03,  4.4910e-03],\n",
      "          [-5.4532e-03, -1.9792e-03, -1.1067e-03]],\n",
      "\n",
      "         [[ 1.0855e-02,  5.2103e-03, -2.4169e-03],\n",
      "          [ 8.4601e-03,  7.4443e-03,  2.1938e-03],\n",
      "          [-1.2143e-02, -1.2602e-02, -1.6096e-02]],\n",
      "\n",
      "         [[-3.4872e-04,  1.5392e-02,  1.9160e-02],\n",
      "          [-5.0011e-03,  1.5068e-03,  9.0785e-03],\n",
      "          [ 1.4728e-03, -6.1776e-03,  3.6857e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.0030e-03, -7.3326e-03, -2.9796e-03],\n",
      "          [ 3.0738e-03,  1.4273e-03, -1.0101e-03],\n",
      "          [-2.0662e-04, -1.6680e-03, -2.8307e-03]],\n",
      "\n",
      "         [[ 2.8876e-03, -6.8121e-03, -5.0892e-03],\n",
      "          [-2.0057e-03,  1.1384e-03, -3.1169e-03],\n",
      "          [-4.2382e-03,  1.9011e-03,  4.2216e-03]],\n",
      "\n",
      "         [[ 8.2089e-03,  9.2456e-03,  7.4766e-03],\n",
      "          [ 4.0272e-03,  7.1011e-03,  4.7096e-03],\n",
      "          [ 3.6860e-03,  3.9025e-03,  2.7478e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4378e-03,  5.7002e-03, -8.2420e-03],\n",
      "          [-1.3143e-04,  4.8314e-03,  1.9075e-03],\n",
      "          [-6.8985e-03, -4.7659e-03,  1.7829e-03]],\n",
      "\n",
      "         [[-3.1979e-03, -4.8824e-03, -4.6036e-03],\n",
      "          [-7.9377e-03, -1.0406e-02, -1.2867e-02],\n",
      "          [-8.7144e-03, -1.2782e-02, -1.1998e-02]],\n",
      "\n",
      "         [[ 3.8022e-03,  2.4246e-05,  7.5237e-03],\n",
      "          [-7.3174e-03, -9.2281e-03,  4.7930e-03],\n",
      "          [-3.2051e-03, -3.4423e-03,  3.2163e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.4243e-03, -4.9452e-03, -6.0023e-03],\n",
      "          [-3.5746e-03, -2.2070e-03, -1.7643e-04],\n",
      "          [ 3.5943e-03,  6.4175e-03,  6.4987e-03]],\n",
      "\n",
      "         [[ 4.8346e-04,  3.4606e-03, -2.1579e-03],\n",
      "          [-7.6002e-03, -2.6581e-03,  1.1480e-04],\n",
      "          [-3.6764e-03, -2.7796e-03, -3.0033e-04]],\n",
      "\n",
      "         [[ 6.1636e-03,  1.4248e-03,  6.8536e-04],\n",
      "          [ 3.3325e-04, -4.9406e-03, -2.4375e-03],\n",
      "          [ 9.3645e-04,  2.3394e-03,  2.1197e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.7939e-04,  9.8109e-04, -1.6152e-03],\n",
      "          [-2.6991e-03, -5.6464e-03, -7.3788e-03],\n",
      "          [ 2.9556e-03,  3.6096e-03,  3.1170e-03]],\n",
      "\n",
      "         [[ 1.0094e-02,  9.2215e-03,  7.5396e-03],\n",
      "          [-1.7255e-03,  2.5745e-03,  2.6371e-03],\n",
      "          [ 5.9042e-04,  9.4882e-03,  3.0714e-03]],\n",
      "\n",
      "         [[-4.3905e-03,  1.4122e-03,  4.1204e-03],\n",
      "          [ 3.6968e-03, -2.1128e-04, -6.5180e-03],\n",
      "          [-2.3976e-03, -4.3653e-03, -7.4441e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3151e-03,  4.3453e-03,  6.6061e-03],\n",
      "          [ 3.1656e-03,  5.0171e-03,  1.2131e-03],\n",
      "          [-6.9661e-03, -9.6902e-03, -1.0395e-02]],\n",
      "\n",
      "         [[-2.5253e-04, -3.6228e-03,  2.0937e-03],\n",
      "          [-3.6043e-03,  8.2395e-05,  6.6537e-03],\n",
      "          [-1.0539e-03,  5.1688e-03,  2.2298e-03]],\n",
      "\n",
      "         [[-5.4648e-03, -6.6609e-03, -3.4752e-03],\n",
      "          [-4.8037e-03,  3.8723e-04,  4.3892e-03],\n",
      "          [-8.4865e-04, -2.2615e-03,  3.8225e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 7.8592e-03,  8.7442e-03,  9.4733e-03],\n",
      "          [ 5.1622e-03, -3.3215e-03,  5.3769e-03],\n",
      "          [ 3.2982e-03, -2.6258e-03,  1.5856e-03]],\n",
      "\n",
      "         [[-4.1076e-03, -1.9027e-02, -1.9950e-02],\n",
      "          [ 1.6751e-03, -1.0422e-02, -1.3782e-02],\n",
      "          [ 5.6191e-03,  1.1399e-04, -3.3236e-04]],\n",
      "\n",
      "         [[ 1.5337e-02,  1.3463e-02,  5.0928e-03],\n",
      "          [ 8.5634e-03,  1.3031e-02,  7.2790e-03],\n",
      "          [ 3.9484e-03,  9.9561e-03,  5.5211e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.7412e-03,  3.8998e-03,  1.0301e-03],\n",
      "          [-5.7500e-03, -1.6678e-03, -7.2128e-04],\n",
      "          [-9.9488e-03, -7.5447e-03, -8.7137e-03]],\n",
      "\n",
      "         [[-6.0559e-03, -3.9574e-03,  3.3747e-03],\n",
      "          [-2.8501e-03, -6.2397e-03,  4.6836e-03],\n",
      "          [ 9.9160e-04, -8.0864e-04,  4.0795e-03]],\n",
      "\n",
      "         [[ 9.3185e-03,  1.4643e-02,  7.3133e-03],\n",
      "          [ 4.7311e-04,  7.4576e-03,  2.3918e-03],\n",
      "          [-1.0107e-02, -5.4110e-03, -3.9514e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 7.7957e-03,  9.3904e-03,  4.4972e-03],\n",
      "          [-3.3724e-04,  2.0610e-03,  3.6033e-03],\n",
      "          [-1.1473e-03, -6.0546e-03, -1.4291e-03]],\n",
      "\n",
      "         [[ 6.1232e-03,  8.6321e-03,  1.5720e-03],\n",
      "          [-2.7791e-03, -3.8802e-03, -5.0715e-03],\n",
      "          [-1.7202e-03, -6.2671e-03, -7.5582e-03]],\n",
      "\n",
      "         [[-2.5448e-03, -2.0461e-03, -8.4814e-03],\n",
      "          [-3.6435e-03, -9.0062e-03,  1.1608e-03],\n",
      "          [ 1.3605e-03, -1.5183e-03,  6.9553e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.0508e-03,  8.6851e-03,  1.5786e-03],\n",
      "          [-3.1213e-03,  4.3703e-03,  1.8724e-03],\n",
      "          [ 4.0464e-03,  9.7380e-03,  4.4105e-03]],\n",
      "\n",
      "         [[ 4.1391e-03,  4.9730e-03,  1.0804e-02],\n",
      "          [-3.1608e-03, -1.2819e-02, -1.6980e-03],\n",
      "          [-2.7152e-03, -7.1120e-03,  2.3370e-03]],\n",
      "\n",
      "         [[ 1.4885e-02,  1.2620e-02,  8.9990e-03],\n",
      "          [ 4.4202e-04,  1.6398e-03, -3.6558e-03],\n",
      "          [ 2.8373e-03, -9.8705e-04, -4.1800e-04]]],\n",
      "\n",
      "\n",
      "        [[[-6.2742e-03, -5.0981e-03, -1.1707e-02],\n",
      "          [-8.3681e-05,  1.1039e-02,  7.6436e-03],\n",
      "          [-5.2116e-03,  7.9796e-04,  1.3837e-03]],\n",
      "\n",
      "         [[ 6.6776e-03,  6.0352e-03,  6.6913e-03],\n",
      "          [ 1.0440e-02,  1.7649e-02,  1.6770e-02],\n",
      "          [ 4.3504e-03,  1.0345e-02,  6.6692e-03]],\n",
      "\n",
      "         [[-7.0519e-03, -1.5611e-02, -1.5979e-03],\n",
      "          [ 2.0170e-03,  1.3144e-02, -2.3433e-03],\n",
      "          [-2.7295e-03,  2.3095e-03, -2.0816e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.5698e-03, -7.0056e-03, -5.5126e-03],\n",
      "          [-7.3202e-03, -9.8713e-03, -2.0669e-03],\n",
      "          [-4.7309e-03, -1.8936e-03, -7.2119e-04]],\n",
      "\n",
      "         [[ 1.4487e-03,  1.6361e-03, -5.3776e-03],\n",
      "          [ 6.2507e-03,  4.9895e-04, -1.5253e-03],\n",
      "          [ 8.7618e-03, -1.9392e-03, -1.1499e-03]],\n",
      "\n",
      "         [[ 2.7369e-03, -8.5281e-04, -2.6692e-03],\n",
      "          [-6.6583e-03,  8.9404e-04,  3.4013e-03],\n",
      "          [-1.6733e-03,  3.6433e-03,  9.4952e-03]]]]))\n",
      "('res2.1.0.bias', Parameter containing:\n",
      "tensor([ 6.9669e-08,  4.5976e-08, -1.8851e-08,  5.4964e-08, -1.7535e-08,\n",
      "        -6.0516e-08,  6.4596e-08,  1.5881e-07,  8.0375e-08, -1.1889e-08,\n",
      "         4.9810e-08,  1.5826e-09,  2.7425e-08,  1.2925e-08, -6.7609e-08,\n",
      "        -1.8910e-08, -8.6442e-08, -6.6286e-10,  2.1460e-08,  9.3322e-08,\n",
      "         1.9605e-08,  8.0165e-08, -7.6042e-08,  4.3768e-08, -9.6545e-08,\n",
      "         2.2965e-08, -1.4393e-07, -8.4069e-08,  6.6860e-08, -8.0378e-08,\n",
      "         3.8856e-08, -1.4443e-08,  2.9070e-08, -9.1263e-08, -2.4865e-08,\n",
      "         6.7145e-08, -2.9487e-08, -3.1862e-08,  1.9780e-08, -1.1722e-08,\n",
      "        -5.2278e-09,  4.8477e-08,  1.4072e-08,  1.1920e-07,  3.3214e-09,\n",
      "         7.4772e-09,  6.7122e-08, -2.5152e-08, -4.4856e-09, -1.4920e-08,\n",
      "         1.9638e-08,  2.1874e-08,  4.3738e-10, -6.2515e-08,  4.5164e-08,\n",
      "         2.1207e-08,  1.4509e-08, -1.6662e-07, -2.2711e-09, -1.1116e-09,\n",
      "         6.0115e-08,  2.2697e-08, -1.7910e-07, -4.3892e-09, -8.2656e-09,\n",
      "         1.6040e-08, -8.5340e-08, -2.3589e-08,  1.6522e-07,  2.9852e-09,\n",
      "         5.6219e-08, -5.2716e-08,  1.4510e-08,  2.0617e-07,  5.1413e-08,\n",
      "         2.1470e-09,  6.9999e-09,  4.1676e-08,  9.0782e-09, -7.9513e-09,\n",
      "         3.6422e-08,  4.2472e-08, -5.7468e-08,  2.4384e-08,  6.2268e-09,\n",
      "        -3.6156e-08, -1.1356e-08, -5.8666e-08, -2.9546e-10,  5.8505e-08,\n",
      "        -8.5157e-09, -1.6507e-08, -2.1752e-08,  6.0790e-08,  2.2277e-08,\n",
      "         1.0472e-07, -4.2734e-09,  7.6431e-09,  8.8993e-09,  1.4698e-08,\n",
      "        -9.8184e-09,  2.8875e-08, -1.6837e-07,  4.9561e-09,  7.8527e-08,\n",
      "         1.7439e-08,  3.7170e-08, -1.6633e-08, -1.6019e-08,  5.2400e-08,\n",
      "         2.8257e-08,  7.9607e-09,  2.5388e-08,  3.8727e-08,  3.1421e-08,\n",
      "        -6.9726e-08,  4.2525e-08,  9.0753e-08,  2.9565e-08, -8.3928e-08,\n",
      "        -2.7695e-08, -2.4724e-08, -6.4699e-08, -3.8473e-08,  1.6579e-08,\n",
      "        -3.7988e-08,  1.9619e-08,  3.0763e-08,  9.2956e-09, -9.6832e-08,\n",
      "        -7.9099e-09,  6.5482e-09, -7.9163e-10, -2.5042e-08, -2.9860e-08,\n",
      "         3.6858e-08, -2.9171e-08,  3.4358e-09, -1.1472e-08,  8.3486e-09,\n",
      "         2.6063e-08, -4.3099e-08,  6.9801e-08,  5.7942e-09,  3.5017e-08,\n",
      "        -2.9633e-08,  3.0757e-08, -3.2441e-08, -5.0158e-09, -7.3535e-09,\n",
      "        -2.7351e-08,  6.3050e-08,  1.4034e-08, -4.8694e-08,  1.7912e-09,\n",
      "         1.7852e-09,  2.1651e-09, -6.0676e-10,  8.6096e-09,  3.0942e-08,\n",
      "        -9.4669e-09, -2.8522e-08,  4.8127e-08,  3.5171e-09,  1.5570e-08,\n",
      "        -2.0848e-08,  1.9828e-09, -2.6168e-09, -3.6890e-08,  7.0422e-10,\n",
      "        -7.4151e-08,  6.3825e-09, -4.2498e-08,  3.8704e-08,  5.1533e-08,\n",
      "         9.2222e-08,  4.7377e-08, -2.2040e-08, -5.8881e-09, -3.6754e-08,\n",
      "         3.0090e-08, -8.4780e-09,  2.6462e-08, -3.7418e-07,  8.3368e-09,\n",
      "         6.2456e-09, -1.5065e-08, -4.6225e-08, -1.0928e-08, -3.0849e-08,\n",
      "         4.1408e-08, -6.7175e-08, -7.9609e-09, -1.0951e-07,  3.0814e-08,\n",
      "        -6.2826e-08,  5.2217e-08,  7.8228e-09, -2.1995e-08, -7.9988e-09,\n",
      "         2.3235e-08,  3.4227e-08, -2.0776e-08, -1.0988e-08, -5.0840e-09,\n",
      "         1.5587e-07, -4.1042e-08,  3.6475e-08,  2.3274e-08, -7.0633e-08,\n",
      "         1.7998e-08, -1.1024e-09,  4.2014e-08, -6.0520e-09, -4.8232e-08,\n",
      "        -4.3298e-08,  3.2828e-08,  8.5247e-08,  1.1261e-07,  9.8421e-08,\n",
      "        -2.5313e-08, -1.1347e-07,  4.7889e-10,  5.0340e-08, -3.4941e-08,\n",
      "        -1.0848e-08, -9.8786e-08, -1.5186e-09, -2.4550e-08, -4.1993e-09,\n",
      "        -4.3301e-08,  4.6851e-08, -2.5844e-08, -3.8699e-08, -5.6798e-09,\n",
      "         4.3754e-08,  3.0728e-08,  7.2191e-08, -1.9450e-08,  3.4063e-08,\n",
      "         3.4033e-08,  5.4746e-08, -2.4785e-08, -2.3476e-08,  3.6333e-08,\n",
      "         1.6104e-08,  4.4074e-08, -1.3575e-08, -3.7904e-08,  2.4524e-08,\n",
      "        -4.8200e-10, -7.3590e-09, -2.2338e-08,  2.0409e-09, -1.6363e-08,\n",
      "        -2.5199e-08,  4.3809e-08, -2.4361e-08,  2.2867e-08, -1.2362e-08,\n",
      "        -3.7137e-08,  1.5847e-08, -5.9863e-08,  4.0085e-08,  2.1532e-08,\n",
      "        -6.2331e-09,  2.8136e-08,  5.6785e-08,  8.4170e-08, -1.0039e-08,\n",
      "         8.7675e-08,  1.9158e-08,  1.9418e-08,  4.2079e-08,  3.2822e-08,\n",
      "        -4.3480e-09, -1.3229e-08, -9.9851e-08,  2.4441e-08,  1.2247e-08,\n",
      "        -4.1946e-08,  1.7652e-08,  1.0304e-08, -8.0941e-09, -4.9003e-08,\n",
      "        -2.3341e-08, -4.9470e-08,  1.0347e-07, -7.7534e-09, -1.0781e-08,\n",
      "         4.5394e-08,  9.4506e-08, -6.0213e-09,  3.5134e-09, -2.6977e-08,\n",
      "        -6.3935e-10,  3.0087e-08,  7.3046e-08,  4.0742e-09, -8.8590e-08,\n",
      "        -8.2049e-08,  1.9166e-08,  2.9711e-08,  2.8701e-08, -6.2501e-08,\n",
      "        -4.7742e-08, -7.6754e-09,  1.2580e-08, -6.8882e-10,  5.2381e-08,\n",
      "         1.1834e-08,  9.5838e-09,  4.7015e-08, -2.3610e-08,  1.5478e-08,\n",
      "         1.4885e-08, -2.9931e-08, -4.8055e-08, -1.2930e-08,  7.0385e-08,\n",
      "        -6.1538e-09,  9.1236e-08,  2.4793e-08, -3.4828e-08,  1.3023e-08,\n",
      "        -8.4297e-10, -4.4853e-08,  1.7163e-08, -4.9148e-08, -4.5288e-08,\n",
      "        -7.5708e-09,  4.0606e-09,  1.9858e-08, -3.9666e-08, -4.5825e-09,\n",
      "        -2.0089e-07, -2.5915e-08, -8.0137e-08, -1.0268e-08, -2.1227e-08,\n",
      "         5.7779e-08, -2.7639e-08,  2.5741e-08,  1.5515e-07, -4.0432e-09,\n",
      "        -1.1913e-08, -5.7903e-08,  1.2022e-08, -1.3254e-08, -8.6169e-08,\n",
      "        -2.4460e-08,  2.7761e-08, -3.5330e-08, -1.3058e-08, -4.7486e-08,\n",
      "         4.9404e-08,  2.1022e-08,  4.8532e-09, -1.8623e-08,  3.2538e-08,\n",
      "         2.9122e-10, -4.0600e-08, -1.7766e-07, -1.1838e-07,  6.2955e-08,\n",
      "        -2.9328e-08,  4.5832e-08,  4.8677e-09,  2.6494e-08,  1.5030e-08,\n",
      "         2.8304e-08,  7.4821e-08,  9.0045e-08,  4.2761e-08,  4.6502e-08,\n",
      "        -2.6650e-08,  1.7648e-09, -4.7783e-08,  6.5344e-09,  8.3454e-08,\n",
      "         9.2198e-08, -3.8635e-08,  6.6949e-08, -1.2820e-09,  2.3294e-07,\n",
      "        -1.5897e-08,  2.7437e-08,  2.9001e-08, -1.4488e-08, -4.8328e-08,\n",
      "         7.6666e-08,  1.8015e-08, -2.2100e-08,  1.0984e-07, -9.5264e-08,\n",
      "         3.9955e-08,  2.0496e-08, -4.3444e-09,  2.0378e-08,  9.2012e-08,\n",
      "        -7.8170e-09,  5.2866e-08,  1.2143e-08,  1.4827e-08,  5.4159e-08,\n",
      "        -1.9722e-08,  7.1751e-08, -4.4326e-08,  1.2033e-08,  3.9568e-09,\n",
      "         5.2758e-09,  2.7699e-08,  4.4799e-08,  8.7334e-08,  7.3361e-08,\n",
      "        -9.4745e-09,  3.9337e-08, -2.2394e-08,  2.8726e-08,  1.6388e-08,\n",
      "         2.2159e-08, -1.8612e-08,  7.2728e-09,  3.2968e-10, -1.2791e-08,\n",
      "        -6.1177e-08,  2.9465e-08, -5.2631e-08,  1.7766e-07, -2.5688e-08,\n",
      "        -8.6293e-08, -2.7200e-08,  4.6231e-08,  3.4603e-08,  2.7406e-08,\n",
      "         3.7492e-08,  2.5191e-08, -7.0998e-08, -3.1536e-08, -1.4207e-08,\n",
      "         8.9010e-08, -1.9225e-08, -1.8151e-08,  1.0599e-08,  6.9240e-08,\n",
      "         6.3559e-09,  5.3986e-08,  5.8083e-08,  9.4954e-09,  1.6605e-08,\n",
      "        -1.2730e-08, -1.2194e-07,  4.2730e-08,  5.8494e-08, -6.7904e-08,\n",
      "         1.2030e-08,  4.1152e-08,  7.4648e-08, -6.0023e-08, -1.0895e-07,\n",
      "        -3.4363e-08, -2.0160e-08,  1.3391e-08,  3.2553e-08,  3.5597e-08,\n",
      "        -1.1086e-07, -3.7479e-09, -4.3151e-09,  5.9260e-10,  9.4838e-08,\n",
      "        -2.9498e-08, -5.8073e-08,  4.0532e-08, -1.0861e-07,  7.7257e-08,\n",
      "         6.8952e-09, -6.5846e-08,  4.1323e-08,  2.2379e-08,  5.7732e-08,\n",
      "        -4.4815e-08, -4.3340e-08, -6.9133e-08,  1.2835e-08,  2.0567e-08,\n",
      "         1.5852e-08, -6.5081e-08,  4.3598e-08,  2.7976e-08, -3.4411e-08,\n",
      "         2.8567e-08, -2.6391e-08, -1.9538e-08, -9.0144e-09, -3.7004e-08,\n",
      "         2.1995e-08, -7.2281e-08,  4.8704e-08, -7.5969e-08,  5.8296e-08,\n",
      "         2.0244e-08, -2.6440e-08,  2.4716e-08,  1.8333e-08,  1.3834e-07,\n",
      "        -8.2998e-10, -1.3789e-08,  8.3978e-09,  5.6123e-08,  5.2761e-08,\n",
      "        -6.0037e-09, -8.6575e-09]))\n",
      "('res2.1.1.weight', Parameter containing:\n",
      "tensor([0.2935, 0.2329, 0.2055, 0.2633, 0.2734, 0.2931, 0.2365, 0.3007, 0.4227,\n",
      "        0.2477, 0.2588, 0.3182, 0.2259, 0.2300, 0.2939, 0.1922, 0.2463, 0.1780,\n",
      "        0.2011, 0.2901, 0.2662, 0.3037, 0.2569, 0.2221, 0.3623, 0.2205, 0.3305,\n",
      "        0.2846, 0.1758, 0.2843, 0.2457, 0.1946, 0.2975, 0.3102, 0.2703, 0.2706,\n",
      "        0.2863, 0.1765, 0.1775, 0.3069, 0.2556, 0.2610, 0.3970, 0.3254, 0.2408,\n",
      "        0.1868, 0.2328, 0.2262, 0.2499, 0.2364, 0.2158, 0.2817, 0.2264, 0.2791,\n",
      "        0.2534, 0.1981, 0.2465, 0.3769, 0.2289, 0.2786, 0.2537, 0.2336, 0.2817,\n",
      "        0.3283, 0.1985, 0.2058, 0.3215, 0.2686, 0.3708, 0.3453, 0.1957, 0.2632,\n",
      "        0.2196, 0.2852, 0.2021, 0.2074, 0.1946, 0.2385, 0.2290, 0.2953, 0.2655,\n",
      "        0.2834, 0.3535, 0.2745, 0.2580, 0.2126, 0.3383, 0.4199, 0.2702, 0.1909,\n",
      "        0.2075, 0.2143, 0.1676, 0.2505, 0.2671, 0.3792, 0.3259, 0.1944, 0.2498,\n",
      "        0.1804, 0.2021, 0.2443, 0.2562, 0.1543, 0.3005, 0.3321, 0.2326, 0.2042,\n",
      "        0.2279, 0.2742, 0.3837, 0.1750, 0.2363, 0.3627, 0.2702, 0.1924, 0.2735,\n",
      "        0.2897, 0.1942, 0.2124, 0.2725, 0.3092, 0.2535, 0.2183, 0.3161, 0.2444,\n",
      "        0.2362, 0.1523, 0.2561, 0.3722, 0.3004, 0.2679, 0.2432, 0.3064, 0.2525,\n",
      "        0.2857, 0.2465, 0.2602, 0.3193, 0.2048, 0.2690, 0.3280, 0.2549, 0.2130,\n",
      "        0.1630, 0.3016, 0.1824, 0.2273, 0.2171, 0.2170, 0.2732, 0.2021, 0.1909,\n",
      "        0.2271, 0.1939, 0.1735, 0.1633, 0.3404, 0.2462, 0.3989, 0.2261, 0.2399,\n",
      "        0.2057, 0.2836, 0.2346, 0.3675, 0.2203, 0.1340, 0.2054, 0.3862, 0.3838,\n",
      "        0.3237, 0.1933, 0.2365, 0.1964, 0.2850, 0.2057, 0.3394, 0.2386, 0.1923,\n",
      "        0.2297, 0.3291, 0.1702, 0.4172, 0.2574, 0.2121, 0.1735, 0.2269, 0.1818,\n",
      "        0.2302, 0.1915, 0.2545, 0.2429, 0.3522, 0.3041, 0.2821, 0.2151, 0.2127,\n",
      "        0.2343, 0.1886, 0.2660, 0.1555, 0.1685, 0.2009, 0.2351, 0.2519, 0.3309,\n",
      "        0.3815, 0.1988, 0.3708, 0.2883, 0.1955, 0.2461, 0.3564, 0.2811, 0.2797,\n",
      "        0.2718, 0.2737, 0.3707, 0.2364, 0.2225, 0.2754, 0.1790, 0.2468, 0.2155,\n",
      "        0.2736, 0.2793, 0.2634, 0.2489, 0.3285, 0.2440, 0.2892, 0.2400, 0.2479,\n",
      "        0.3083, 0.2877, 0.2505, 0.2104, 0.2012, 0.2101, 0.3327, 0.2225, 0.3018,\n",
      "        0.2949, 0.2840, 0.2573, 0.3245, 0.3068, 0.2643, 0.2804, 0.2408, 0.2293,\n",
      "        0.2971, 0.1870, 0.3041, 0.2501, 0.4463, 0.3662, 0.2368, 0.2130, 0.3079,\n",
      "        0.2590, 0.3997, 0.2439, 0.1705, 0.3843, 0.1444, 0.2646, 0.2615, 0.3104,\n",
      "        0.3304, 0.2937, 0.2716, 0.3058, 0.1813, 0.3329, 0.2055, 0.2989, 0.2668,\n",
      "        0.3289, 0.1737, 0.2871, 0.2323, 0.2619, 0.2618, 0.2014, 0.2742, 0.2736,\n",
      "        0.2340, 0.2068, 0.3519, 0.2904, 0.2063, 0.2204, 0.2194, 0.2149, 0.1530,\n",
      "        0.3050, 0.2004, 0.4618, 0.4307, 0.1726, 0.2218, 0.2189, 0.2038, 0.2502,\n",
      "        0.1806, 0.3006, 0.2352, 0.2755, 0.2758, 0.3288, 0.2369, 0.2141, 0.2443,\n",
      "        0.1652, 0.2146, 0.1842, 0.2400, 0.3217, 0.2410, 0.2207, 0.2928, 0.2396,\n",
      "        0.2385, 0.2006, 0.3376, 0.3008, 0.1931, 0.3009, 0.1786, 0.2347, 0.2301,\n",
      "        0.2109, 0.3052, 0.4267, 0.2969, 0.2233, 0.2049, 0.2014, 0.3318, 0.3680,\n",
      "        0.2834, 0.3075, 0.1712, 0.2541, 0.3354, 0.2560, 0.1685, 0.2334, 0.3134,\n",
      "        0.2195, 0.2868, 0.3030, 0.3234, 0.2650, 0.3068, 0.2143, 0.2701, 0.2571,\n",
      "        0.1387, 0.2091, 0.3533, 0.3205, 0.2045, 0.3200, 0.2336, 0.2105, 0.2024,\n",
      "        0.2271, 0.3260, 0.2804, 0.2524, 0.2490, 0.2321, 0.2741, 0.2740, 0.2436,\n",
      "        0.2175, 0.2504, 0.2929, 0.2834, 0.3012, 0.2536, 0.3027, 0.2049, 0.2201,\n",
      "        0.2149, 0.2368, 0.2817, 0.2620, 0.2998, 0.3385, 0.2946, 0.3051, 0.2638,\n",
      "        0.1924, 0.2396, 0.2049, 0.2126, 0.1489, 0.2973, 0.2684, 0.1941, 0.2412,\n",
      "        0.3735, 0.2570, 0.3057, 0.1805, 0.2169, 0.1807, 0.2469, 0.2057, 0.2886,\n",
      "        0.3237, 0.2031, 0.4049, 0.2618, 0.2357, 0.3167, 0.3157, 0.2711, 0.2403,\n",
      "        0.2276, 0.1870, 0.3513, 0.1990, 0.2579, 0.2951, 0.3371, 0.4058, 0.1672,\n",
      "        0.2745, 0.2408, 0.3043, 0.2385, 0.2802, 0.2548, 0.1794, 0.2632, 0.1829,\n",
      "        0.2555, 0.2052, 0.2151, 0.2387, 0.2996, 0.3138, 0.3301, 0.2400, 0.1760,\n",
      "        0.1847, 0.3511, 0.2750, 0.2979, 0.2170, 0.1620, 0.1896, 0.1982, 0.2450,\n",
      "        0.3109, 0.2192, 0.1979, 0.2452, 0.3096, 0.2854, 0.3235, 0.3586, 0.2556,\n",
      "        0.1974, 0.3938, 0.2569, 0.2805, 0.2512, 0.2964, 0.1936, 0.1941, 0.2061,\n",
      "        0.3068, 0.1776, 0.2789, 0.3150, 0.2435, 0.3187, 0.3445, 0.2325, 0.2815,\n",
      "        0.2035, 0.2176, 0.2436, 0.2386, 0.2565, 0.1671, 0.2911, 0.2044, 0.2095,\n",
      "        0.3097, 0.3638, 0.2916, 0.3230, 0.2948, 0.2165, 0.2452, 0.2081, 0.2958,\n",
      "        0.3349, 0.2812, 0.1988, 0.4062, 0.2538, 0.3272, 0.3135, 0.2706]))\n",
      "('res2.1.1.bias', Parameter containing:\n",
      "tensor([-0.1448, -0.0918, -0.1249, -0.1413, -0.1489, -0.1514, -0.0877, -0.1715,\n",
      "        -0.2026, -0.1081, -0.1304, -0.1461, -0.1093, -0.1019, -0.1794, -0.1049,\n",
      "        -0.1081, -0.1221, -0.0816, -0.1800, -0.0883, -0.1487, -0.1853, -0.1094,\n",
      "        -0.2130, -0.1348, -0.1698, -0.1374, -0.0739, -0.1234, -0.1142, -0.1136,\n",
      "        -0.1287, -0.1802, -0.1686, -0.1639, -0.1358, -0.0806, -0.1103, -0.1265,\n",
      "        -0.1609, -0.1157, -0.2067, -0.1868, -0.1285, -0.0932, -0.1047, -0.1114,\n",
      "        -0.1333, -0.1315, -0.1185, -0.1342, -0.1195, -0.1636, -0.1352, -0.0909,\n",
      "        -0.1376, -0.2115, -0.1046, -0.1433, -0.1188, -0.1299, -0.1700, -0.1933,\n",
      "        -0.1053, -0.1062, -0.1982, -0.1445, -0.1980, -0.1633, -0.0858, -0.1272,\n",
      "        -0.1291, -0.1915, -0.1066, -0.0966, -0.0872, -0.1322, -0.1301, -0.1856,\n",
      "        -0.1212, -0.1323, -0.1711, -0.1488, -0.1336, -0.0984, -0.1494, -0.1927,\n",
      "        -0.1554, -0.1040, -0.1243, -0.0957, -0.1052, -0.1263, -0.1112, -0.1976,\n",
      "        -0.1532, -0.1064, -0.1083, -0.0857, -0.0873, -0.1180, -0.1406, -0.0865,\n",
      "        -0.2033, -0.1496, -0.1505, -0.1096, -0.1145, -0.1694, -0.1672, -0.0905,\n",
      "        -0.1388, -0.1686, -0.1683, -0.0871, -0.1414, -0.1288, -0.0792, -0.1262,\n",
      "        -0.1654, -0.1537, -0.1427, -0.0788, -0.1623, -0.1465, -0.1181, -0.0782,\n",
      "        -0.1441, -0.1836, -0.1598, -0.1228, -0.1089, -0.1575, -0.1315, -0.1357,\n",
      "        -0.1520, -0.1524, -0.1669, -0.1245, -0.1674, -0.1478, -0.1297, -0.1353,\n",
      "        -0.0809, -0.1845, -0.0764, -0.1269, -0.1175, -0.1311, -0.1369, -0.0941,\n",
      "        -0.1052, -0.1174, -0.1081, -0.0745, -0.0715, -0.1477, -0.1139, -0.1711,\n",
      "        -0.1097, -0.1267, -0.1291, -0.1653, -0.1310, -0.1722, -0.1243, -0.0844,\n",
      "        -0.1363, -0.2027, -0.2012, -0.1582, -0.0981, -0.1235, -0.1221, -0.1609,\n",
      "        -0.1158, -0.1612, -0.1286, -0.0898, -0.1256, -0.1570, -0.0965, -0.2053,\n",
      "        -0.1395, -0.0996, -0.0866, -0.1056, -0.0983, -0.0993, -0.1138, -0.1203,\n",
      "        -0.1171, -0.1882, -0.1771, -0.1221, -0.0996, -0.0896, -0.1348, -0.0982,\n",
      "        -0.1743, -0.0795, -0.0849, -0.1226, -0.1034, -0.1281, -0.1746, -0.1906,\n",
      "        -0.0757, -0.1972, -0.1424, -0.0835, -0.1332, -0.1874, -0.1217, -0.1208,\n",
      "        -0.1589, -0.1323, -0.2033, -0.1321, -0.1187, -0.1383, -0.0871, -0.1227,\n",
      "        -0.1375, -0.1452, -0.1405, -0.1539, -0.1332, -0.1524, -0.1457, -0.1465,\n",
      "        -0.1433, -0.1469, -0.1544, -0.1281, -0.1508, -0.1219, -0.0957, -0.1267,\n",
      "        -0.1676, -0.1436, -0.1717, -0.1325, -0.1514, -0.1314, -0.1513, -0.1894,\n",
      "        -0.1226, -0.1240, -0.1681, -0.1124, -0.1799, -0.0911, -0.1429, -0.1468,\n",
      "        -0.2051, -0.1721, -0.1022, -0.0788, -0.1717, -0.1354, -0.1795, -0.1368,\n",
      "        -0.0890, -0.1892, -0.0727, -0.1504, -0.1039, -0.1638, -0.2023, -0.1541,\n",
      "        -0.1312, -0.1803, -0.0659, -0.1686, -0.1137, -0.1143, -0.1085, -0.1988,\n",
      "        -0.1102, -0.1730, -0.1317, -0.1546, -0.1513, -0.0997, -0.1529, -0.1394,\n",
      "        -0.1234, -0.1063, -0.1692, -0.1389, -0.1058, -0.1118, -0.1021, -0.0899,\n",
      "        -0.0917, -0.1463, -0.1164, -0.2324, -0.2134, -0.1034, -0.1263, -0.1282,\n",
      "        -0.0856, -0.1390, -0.0966, -0.1669, -0.0975, -0.1387, -0.1724, -0.1683,\n",
      "        -0.1150, -0.1225, -0.1493, -0.0947, -0.1126, -0.0882, -0.1364, -0.1765,\n",
      "        -0.1408, -0.1094, -0.1632, -0.1344, -0.1185, -0.1083, -0.1825, -0.1599,\n",
      "        -0.1328, -0.1294, -0.1074, -0.1159, -0.1198, -0.1051, -0.1433, -0.1817,\n",
      "        -0.1424, -0.1151, -0.1171, -0.1166, -0.1300, -0.1046, -0.1333, -0.1294,\n",
      "        -0.0912, -0.1496, -0.1747, -0.1487, -0.0804, -0.1138, -0.1577, -0.1321,\n",
      "        -0.1400, -0.1626, -0.1686, -0.1125, -0.1378, -0.1282, -0.1637, -0.1355,\n",
      "        -0.0727, -0.1045, -0.1758, -0.1590, -0.1371, -0.1458, -0.1293, -0.1122,\n",
      "        -0.1261, -0.1395, -0.1586, -0.1479, -0.1211, -0.1082, -0.0859, -0.1147,\n",
      "        -0.1255, -0.1652, -0.1179, -0.1180, -0.1484, -0.1747, -0.1536, -0.1372,\n",
      "        -0.1807, -0.0873, -0.1325, -0.1043, -0.1164, -0.1453, -0.1558, -0.1454,\n",
      "        -0.1735, -0.1693, -0.1420, -0.1341, -0.1015, -0.1170, -0.1041, -0.1267,\n",
      "        -0.0699, -0.1397, -0.1615, -0.1002, -0.1189, -0.2303, -0.1312, -0.1726,\n",
      "        -0.1144, -0.1084, -0.1013, -0.1264, -0.1199, -0.1432, -0.1866, -0.1005,\n",
      "        -0.1922, -0.1424, -0.1198, -0.1903, -0.1707, -0.1589, -0.1063, -0.1154,\n",
      "        -0.0913, -0.1734, -0.1112, -0.1396, -0.1587, -0.1659, -0.1814, -0.1078,\n",
      "        -0.1478, -0.1142, -0.1622, -0.1065, -0.1442, -0.1567, -0.0951, -0.1481,\n",
      "        -0.0849, -0.1649, -0.1080, -0.1106, -0.1322, -0.1816, -0.1579, -0.1812,\n",
      "        -0.1167, -0.0925, -0.1014, -0.2102, -0.1273, -0.1769, -0.1185, -0.1148,\n",
      "        -0.0975, -0.1053, -0.1630, -0.1778, -0.1295, -0.0816, -0.1182, -0.1699,\n",
      "        -0.1727, -0.1374, -0.1385, -0.1520, -0.1138, -0.2016, -0.1185, -0.1425,\n",
      "        -0.1445, -0.1868, -0.0796, -0.1018, -0.1147, -0.1582, -0.0969, -0.1356,\n",
      "        -0.1500, -0.1534, -0.1714, -0.1591, -0.1094, -0.1566, -0.0972, -0.1194,\n",
      "        -0.1430, -0.1558, -0.1544, -0.0755, -0.1525, -0.1137, -0.0988, -0.1814,\n",
      "        -0.1965, -0.1610, -0.1459, -0.1576, -0.1189, -0.1180, -0.1094, -0.1656,\n",
      "        -0.1689, -0.1615, -0.0991, -0.1570, -0.1360, -0.1935, -0.1931, -0.1683]))\n",
      "('conv5.0.weight', Parameter containing:\n",
      "tensor([[[[-3.8524e-03, -6.2252e-03, -8.8265e-04],\n",
      "          [ 8.5434e-03,  9.9263e-03,  5.7827e-03],\n",
      "          [ 3.2411e-03,  2.0089e-03,  6.5785e-03]],\n",
      "\n",
      "         [[-2.1955e-03,  1.3251e-03,  3.4417e-03],\n",
      "          [-4.4862e-04, -6.3268e-03,  6.1954e-04],\n",
      "          [-1.9799e-03, -1.6389e-03, -2.6395e-04]],\n",
      "\n",
      "         [[ 2.4868e-03,  6.8817e-04,  2.6075e-04],\n",
      "          [ 5.6359e-03,  4.1376e-04,  1.8891e-03],\n",
      "          [-1.6696e-04, -5.4681e-04,  1.4339e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4117e-03, -4.4684e-03, -1.4889e-03],\n",
      "          [ 1.3599e-04,  6.8266e-04,  3.0665e-03],\n",
      "          [ 6.9500e-05, -3.7607e-03, -1.6945e-03]],\n",
      "\n",
      "         [[-3.0303e-03, -5.6593e-03, -2.8111e-03],\n",
      "          [ 7.7618e-04,  2.1498e-03,  7.6669e-04],\n",
      "          [ 5.5223e-03,  4.5693e-03,  2.6791e-03]],\n",
      "\n",
      "         [[-3.8297e-03,  1.8445e-04,  3.9855e-03],\n",
      "          [-3.0621e-03, -1.9904e-03,  2.0431e-03],\n",
      "          [-3.5251e-03, -8.3384e-04,  1.2709e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.0176e-03, -1.3152e-02, -5.5092e-03],\n",
      "          [-7.3934e-03, -4.6228e-03, -4.9711e-03],\n",
      "          [ 6.9178e-03, -2.4559e-04,  2.1831e-03]],\n",
      "\n",
      "         [[ 2.0593e-03, -3.2179e-03, -1.3486e-02],\n",
      "          [-5.0349e-03,  8.8703e-03, -8.7283e-04],\n",
      "          [-1.3051e-03,  6.7390e-03,  7.0331e-03]],\n",
      "\n",
      "         [[-2.0384e-03, -6.5648e-03,  7.5508e-04],\n",
      "          [ 5.1504e-03, -1.1486e-03,  5.3290e-03],\n",
      "          [-1.3966e-03,  2.6239e-04,  3.2797e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.1093e-03,  1.7319e-04, -3.7053e-04],\n",
      "          [-8.9436e-04,  6.6959e-03, -8.2871e-03],\n",
      "          [-2.4822e-03, -1.5417e-03, -6.7665e-03]],\n",
      "\n",
      "         [[ 1.1231e-03, -2.9456e-04, -6.3208e-03],\n",
      "          [-2.7638e-03, -7.2017e-03, -4.5600e-03],\n",
      "          [ 3.9853e-03, -8.4106e-03, -8.5043e-03]],\n",
      "\n",
      "         [[-5.8662e-03, -1.0036e-02, -2.3248e-03],\n",
      "          [-2.6369e-06, -5.9626e-03, -9.8573e-04],\n",
      "          [ 4.9377e-03,  5.6693e-03,  7.6390e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 8.9679e-04, -2.9985e-03,  2.2377e-03],\n",
      "          [ 4.8262e-03,  3.0115e-03, -1.4086e-03],\n",
      "          [-6.5818e-03,  3.6569e-03,  1.1361e-03]],\n",
      "\n",
      "         [[-8.6762e-03, -8.2741e-04, -1.7014e-04],\n",
      "          [-9.1199e-03, -5.7498e-03,  3.8589e-03],\n",
      "          [ 3.4206e-03,  3.0504e-03,  7.1591e-03]],\n",
      "\n",
      "         [[-1.2663e-04,  4.2787e-04, -7.8413e-04],\n",
      "          [-9.7983e-03, -6.4876e-03,  4.3123e-04],\n",
      "          [ 1.4847e-03,  6.3938e-03,  7.4330e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.9166e-04,  1.2418e-03, -3.0963e-04],\n",
      "          [-3.8749e-03, -4.1075e-03, -1.7834e-03],\n",
      "          [-8.0848e-03, -1.3763e-02, -6.3472e-03]],\n",
      "\n",
      "         [[-1.3755e-03,  3.0228e-03,  4.9326e-03],\n",
      "          [-1.1578e-02, -2.4404e-03,  7.4041e-03],\n",
      "          [-3.9231e-03, -5.3330e-03,  7.6282e-03]],\n",
      "\n",
      "         [[-3.3378e-03, -4.9006e-03, -1.8332e-03],\n",
      "          [-3.0744e-03,  1.8720e-03,  3.7010e-04],\n",
      "          [ 9.6807e-03, -6.9080e-03, -3.8543e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-6.2114e-03, -1.5435e-02, -4.5301e-03],\n",
      "          [-3.5276e-03, -1.4310e-03,  4.7260e-03],\n",
      "          [ 9.7430e-03,  1.9331e-03,  2.0284e-03]],\n",
      "\n",
      "         [[ 3.3465e-03,  1.6907e-02,  7.0325e-03],\n",
      "          [-5.4354e-03,  1.1680e-02,  4.3562e-03],\n",
      "          [-8.3773e-03,  7.8255e-06, -2.1033e-03]],\n",
      "\n",
      "         [[ 7.7986e-03,  3.4882e-03, -1.4252e-03],\n",
      "          [ 1.3612e-02,  1.0061e-02, -1.8947e-03],\n",
      "          [ 7.6080e-03,  3.3543e-03, -3.1993e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.0083e-03,  6.7952e-03, -3.3489e-03],\n",
      "          [-4.4164e-03,  3.8675e-03, -6.5049e-03],\n",
      "          [ 1.5634e-03,  2.4666e-03,  1.9823e-03]],\n",
      "\n",
      "         [[ 1.4998e-02,  3.5941e-03,  8.6734e-03],\n",
      "          [ 1.1760e-02,  1.1709e-03,  4.9162e-03],\n",
      "          [-2.9410e-03, -1.6858e-03,  4.0817e-03]],\n",
      "\n",
      "         [[ 1.7037e-02, -1.0123e-03, -1.5910e-03],\n",
      "          [ 5.1025e-03, -9.4470e-04, -1.4716e-03],\n",
      "          [ 1.5979e-03,  1.8595e-03, -2.5235e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7546e-04,  3.5511e-03, -2.7262e-03],\n",
      "          [ 6.1317e-03,  6.6761e-03,  9.5339e-03],\n",
      "          [ 1.4943e-03,  8.0828e-03,  2.8789e-03]],\n",
      "\n",
      "         [[-1.8861e-03,  1.7432e-03,  1.7884e-04],\n",
      "          [-6.9141e-04, -1.5009e-03, -5.8734e-03],\n",
      "          [ 1.2190e-02,  2.2701e-03,  1.0842e-03]],\n",
      "\n",
      "         [[ 1.5975e-03,  5.9465e-04, -4.4719e-03],\n",
      "          [-9.0622e-05, -1.8257e-03,  9.1131e-03],\n",
      "          [ 4.4309e-03, -2.3902e-03,  4.3857e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.6354e-03,  2.0699e-03,  7.7872e-05],\n",
      "          [ 1.1018e-03,  5.9365e-03,  5.1431e-03],\n",
      "          [-3.0549e-03, -2.1154e-04, -3.8662e-03]],\n",
      "\n",
      "         [[ 6.4674e-03,  7.3490e-03,  6.9471e-03],\n",
      "          [ 3.4918e-03, -1.3035e-03,  1.1215e-03],\n",
      "          [-4.8475e-03, -1.0551e-02, -6.2279e-03]],\n",
      "\n",
      "         [[-5.9107e-03, -6.1939e-03, -3.3529e-03],\n",
      "          [-9.7488e-03, -8.2751e-03, -4.8121e-03],\n",
      "          [-6.0439e-03, -9.8632e-03, -3.1188e-03]]],\n",
      "\n",
      "\n",
      "        [[[-5.7826e-03, -2.4236e-03, -3.6694e-03],\n",
      "          [ 1.7620e-03,  1.7504e-03, -3.2026e-04],\n",
      "          [ 1.3477e-03,  1.6943e-03,  2.6682e-03]],\n",
      "\n",
      "         [[ 2.8945e-03,  3.8480e-03,  1.1388e-04],\n",
      "          [ 2.2976e-03,  3.4553e-03,  4.3708e-04],\n",
      "          [-1.4019e-03, -1.1127e-03,  4.1364e-03]],\n",
      "\n",
      "         [[-4.8968e-04,  1.4361e-03,  4.0308e-03],\n",
      "          [ 1.7918e-04,  1.3838e-03,  4.5328e-03],\n",
      "          [ 1.1628e-03,  1.2781e-03,  4.2297e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.4923e-04,  9.4629e-03,  7.5464e-03],\n",
      "          [-6.2293e-03,  4.2275e-03,  4.3417e-03],\n",
      "          [-2.6161e-03,  9.1439e-06,  2.3145e-03]],\n",
      "\n",
      "         [[ 4.8857e-03, -3.4641e-05,  1.4729e-03],\n",
      "          [ 3.7855e-03,  1.6671e-03, -3.7515e-03],\n",
      "          [ 2.6659e-03, -6.8872e-03,  3.4392e-04]],\n",
      "\n",
      "         [[-4.8030e-03,  2.9875e-03,  2.1071e-03],\n",
      "          [-1.9915e-03,  7.1594e-03,  4.5243e-03],\n",
      "          [ 2.6139e-03,  3.5273e-03, -1.5774e-03]]]]))\n",
      "('conv5.0.bias', Parameter containing:\n",
      "tensor([ 2.1364e-09,  7.8043e-09,  1.0062e-08,  ..., -1.3529e-08,\n",
      "         8.0345e-09,  1.1195e-08]))\n",
      "('conv5.1.weight', Parameter containing:\n",
      "tensor([0.3188, 0.5270, 0.4642,  ..., 0.4508, 0.4451, 0.3415]))\n",
      "('conv5.1.bias', Parameter containing:\n",
      "tensor([-0.0061, -0.0025, -0.0186,  ..., -0.0254, -0.0183, -0.0172]))\n",
      "('res3.0.0.weight', Parameter containing:\n",
      "tensor([[[[-5.9729e-05, -4.5664e-05, -8.3626e-05],\n",
      "          [-4.9596e-05, -7.8107e-04, -4.4778e-04],\n",
      "          [ 9.0415e-05, -4.6149e-05, -1.0110e-04]],\n",
      "\n",
      "         [[-2.6496e-04, -1.7818e-04, -2.2986e-05],\n",
      "          [ 5.0669e-06,  2.3961e-04, -2.4794e-04],\n",
      "          [ 8.0314e-05,  2.7631e-04, -1.1770e-04]],\n",
      "\n",
      "         [[ 1.1947e-05,  1.5018e-05, -1.6758e-04],\n",
      "          [-5.6188e-05, -3.9264e-04, -3.0247e-04],\n",
      "          [ 5.7479e-05,  1.5179e-04, -9.8856e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.5170e-04,  1.4745e-05, -1.4764e-04],\n",
      "          [-2.8406e-04, -7.8190e-05,  6.7081e-05],\n",
      "          [ 2.1129e-04,  7.7298e-04,  5.6032e-04]],\n",
      "\n",
      "         [[-4.3755e-04, -4.0919e-05, -7.8318e-05],\n",
      "          [-2.9688e-05,  2.5102e-04,  3.2522e-04],\n",
      "          [ 1.9397e-04, -2.1825e-04, -1.0929e-04]],\n",
      "\n",
      "         [[-1.8548e-04, -4.3803e-05,  5.7507e-05],\n",
      "          [-2.0179e-04,  1.9536e-04,  2.4787e-04],\n",
      "          [ 6.1894e-05,  1.3331e-04,  8.2061e-05]]],\n",
      "\n",
      "\n",
      "        [[[-1.6016e-05, -3.6525e-04, -9.2739e-05],\n",
      "          [ 1.4505e-04, -1.1554e-04,  5.5936e-06],\n",
      "          [ 5.1067e-05, -6.5444e-05, -1.0899e-04]],\n",
      "\n",
      "         [[-1.7264e-04,  8.7483e-05, -1.4446e-04],\n",
      "          [ 2.8653e-04,  8.2651e-04,  5.5595e-05],\n",
      "          [ 1.4796e-04, -6.3963e-05, -1.2277e-04]],\n",
      "\n",
      "         [[ 2.2839e-04,  5.7649e-04,  5.4353e-04],\n",
      "          [ 2.2653e-04,  7.3189e-05, -1.2517e-04],\n",
      "          [ 3.4899e-05, -1.1376e-04, -1.4783e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2330e-04,  1.6496e-04, -2.1122e-04],\n",
      "          [ 1.9576e-04,  2.0529e-04, -4.9951e-04],\n",
      "          [ 2.1435e-04, -9.4182e-05, -7.5423e-05]],\n",
      "\n",
      "         [[-1.8907e-04,  2.2085e-04,  1.2332e-04],\n",
      "          [-5.3361e-05,  1.2297e-04,  1.8753e-04],\n",
      "          [ 2.0953e-05, -2.8182e-04, -1.2661e-04]],\n",
      "\n",
      "         [[-8.2589e-05,  4.9444e-05, -1.3826e-05],\n",
      "          [-1.5393e-04,  1.1368e-04,  1.5165e-04],\n",
      "          [ 4.0408e-05,  6.8949e-05, -1.8495e-04]]],\n",
      "\n",
      "\n",
      "        [[[-2.8438e-04, -7.5491e-04, -3.8777e-04],\n",
      "          [-2.7738e-04, -3.8574e-04, -1.1619e-04],\n",
      "          [-1.4873e-04, -1.3088e-04,  4.2040e-05]],\n",
      "\n",
      "         [[-4.0903e-04, -5.2405e-04, -6.5537e-04],\n",
      "          [-1.5557e-04, -1.2120e-03, -8.0121e-04],\n",
      "          [-8.1547e-05, -5.6275e-04, -3.2774e-04]],\n",
      "\n",
      "         [[-2.5148e-04, -1.1264e-03, -8.3317e-04],\n",
      "          [-1.8425e-04, -1.5189e-03, -1.5355e-03],\n",
      "          [-7.9097e-05, -5.7224e-04, -1.9307e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.6557e-05,  4.9848e-05, -3.4201e-04],\n",
      "          [ 1.1355e-05,  2.3012e-04,  1.3911e-03],\n",
      "          [ 5.0664e-05,  2.4252e-04,  5.8096e-04]],\n",
      "\n",
      "         [[-1.8950e-04, -7.2633e-04, -9.5547e-05],\n",
      "          [-6.1773e-04, -5.2296e-04, -4.8929e-04],\n",
      "          [-3.2675e-04, -1.2837e-04,  1.7910e-05]],\n",
      "\n",
      "         [[ 1.1830e-04,  4.8162e-04, -1.2546e-04],\n",
      "          [ 1.9402e-04,  6.6874e-04, -5.1962e-04],\n",
      "          [ 7.3828e-05, -1.3738e-04, -5.1616e-04]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.9614e-04, -2.2561e-04,  1.9065e-04],\n",
      "          [-8.1134e-05, -8.7182e-05,  2.6769e-04],\n",
      "          [-4.9267e-05,  4.2938e-06,  2.0844e-04]],\n",
      "\n",
      "         [[-2.5047e-04,  1.6287e-04, -1.2556e-05],\n",
      "          [ 2.4639e-04,  1.2450e-04,  3.0067e-04],\n",
      "          [ 2.9422e-04,  4.9716e-05,  3.1993e-04]],\n",
      "\n",
      "         [[-2.4934e-04, -5.3812e-04,  2.2436e-04],\n",
      "          [-7.6354e-05, -1.0698e-04,  9.8046e-05],\n",
      "          [-1.1525e-04, -6.0266e-05,  2.5115e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3233e-04, -1.9866e-04,  1.1834e-04],\n",
      "          [-1.0044e-04, -2.7906e-04,  2.8965e-04],\n",
      "          [ 1.7785e-04,  1.7902e-04, -1.7015e-04]],\n",
      "\n",
      "         [[-3.0237e-04,  2.6422e-04,  2.5505e-04],\n",
      "          [ 6.2197e-05,  2.1122e-04,  3.7277e-04],\n",
      "          [-2.5477e-05, -5.0643e-05, -6.7722e-05]],\n",
      "\n",
      "         [[-1.1456e-04,  2.5272e-04,  3.2040e-04],\n",
      "          [-2.0815e-06,  3.3931e-04,  2.2876e-04],\n",
      "          [ 4.4789e-05, -8.3537e-05, -1.2942e-04]]],\n",
      "\n",
      "\n",
      "        [[[-9.1157e-05, -3.0153e-04, -2.9623e-04],\n",
      "          [-8.3987e-05, -3.2982e-04, -1.3514e-04],\n",
      "          [ 4.0729e-05, -3.3630e-05,  5.8581e-05]],\n",
      "\n",
      "         [[ 3.1079e-04,  7.3783e-05, -1.6674e-04],\n",
      "          [ 6.4545e-04, -1.3613e-04, -3.6547e-04],\n",
      "          [ 4.5277e-04,  4.4585e-04, -1.1293e-04]],\n",
      "\n",
      "         [[-8.7222e-05, -2.9588e-04, -3.0937e-04],\n",
      "          [-1.6372e-04, -3.6150e-04,  1.8115e-04],\n",
      "          [-6.6550e-05, -3.1891e-04, -1.6820e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.0311e-05, -5.2023e-05, -1.7772e-04],\n",
      "          [ 9.7736e-07, -2.0263e-04, -8.9043e-05],\n",
      "          [ 9.2987e-05,  4.9200e-04,  4.0848e-04]],\n",
      "\n",
      "         [[ 1.6536e-04,  9.3120e-05, -1.6251e-04],\n",
      "          [ 1.5062e-04,  7.0627e-04,  5.0121e-04],\n",
      "          [-2.5179e-04,  1.1435e-04,  1.7284e-04]],\n",
      "\n",
      "         [[ 1.6242e-04, -6.3091e-05, -2.1404e-04],\n",
      "          [ 3.7854e-04,  6.3739e-04, -3.8928e-05],\n",
      "          [ 2.3957e-04,  6.4126e-04,  2.9635e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.5413e-04, -1.8209e-04, -1.6071e-04],\n",
      "          [ 6.5090e-05,  2.4345e-05, -9.2490e-05],\n",
      "          [ 1.0268e-04,  1.2129e-04,  7.2461e-05]],\n",
      "\n",
      "         [[ 1.9797e-04, -4.1851e-04, -1.5951e-04],\n",
      "          [ 1.7818e-04, -6.7321e-04, -1.1816e-04],\n",
      "          [ 1.5596e-04,  8.8405e-05, -3.8652e-05]],\n",
      "\n",
      "         [[-4.7678e-04, -5.0403e-04, -4.6404e-04],\n",
      "          [-1.1913e-04, -8.4340e-05, -4.6540e-05],\n",
      "          [-1.4980e-04,  1.2652e-05,  8.1658e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.2763e-04,  1.1681e-04, -1.1061e-04],\n",
      "          [ 1.2313e-04,  1.6517e-04, -6.7212e-05],\n",
      "          [ 3.6002e-04,  1.8058e-04,  2.0012e-05]],\n",
      "\n",
      "         [[ 1.6622e-05, -1.1532e-04, -2.0112e-05],\n",
      "          [-2.5064e-04, -2.0097e-04, -8.1731e-05],\n",
      "          [-4.0320e-05,  1.2639e-04, -2.2575e-07]],\n",
      "\n",
      "         [[ 1.1423e-04, -2.0380e-04, -1.0600e-04],\n",
      "          [ 1.0763e-04, -1.5299e-04, -1.3504e-04],\n",
      "          [-8.8612e-06, -2.6076e-04,  1.2389e-05]]]]))\n",
      "('res3.0.0.bias', Parameter containing:\n",
      "tensor([-6.0925e-10,  1.1931e-10, -2.5503e-09,  ...,  2.1900e-10,\n",
      "        -4.4686e-10, -5.2896e-11]))\n",
      "('res3.0.1.weight', Parameter containing:\n",
      "tensor([0.0353, 0.0382, 0.0511,  ..., 0.0308, 0.0401, 0.0344]))\n",
      "('res3.0.1.bias', Parameter containing:\n",
      "tensor([-0.0158, -0.0181, -0.0068,  ..., -0.0214, -0.0183, -0.0181]))\n",
      "('res3.1.0.weight', Parameter containing:\n",
      "tensor([[[[ 2.3927e-04,  7.4528e-04, -2.8592e-04],\n",
      "          [-6.0309e-04, -2.2870e-04, -1.8821e-04],\n",
      "          [-1.0115e-04, -2.9427e-05, -3.4600e-05]],\n",
      "\n",
      "         [[ 2.2920e-04,  1.5243e-04, -5.7730e-05],\n",
      "          [ 3.6469e-04, -7.4940e-05, -2.9286e-04],\n",
      "          [-9.4222e-05,  9.0737e-06, -1.3969e-05]],\n",
      "\n",
      "         [[-2.4448e-04,  4.0029e-04, -9.5713e-05],\n",
      "          [-5.1589e-04, -5.9792e-05, -3.6550e-04],\n",
      "          [ 2.4899e-04, -3.0828e-04, -3.0714e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.9401e-04, -5.2622e-05,  4.7075e-04],\n",
      "          [ 2.4986e-04, -4.2623e-04,  3.5503e-04],\n",
      "          [ 9.7154e-05, -2.6097e-04,  1.0441e-05]],\n",
      "\n",
      "         [[-2.7300e-04,  2.8041e-04,  2.6053e-04],\n",
      "          [-3.2102e-04, -2.8824e-04, -1.1054e-04],\n",
      "          [-4.8374e-06, -1.3670e-04, -3.8646e-05]],\n",
      "\n",
      "         [[ 6.2308e-05,  1.7471e-04, -1.8061e-04],\n",
      "          [-3.8895e-04,  2.1507e-04,  3.6645e-04],\n",
      "          [ 1.3754e-05, -1.1308e-04, -1.2919e-04]]],\n",
      "\n",
      "\n",
      "        [[[-4.8072e-04, -1.6896e-04,  1.1261e-04],\n",
      "          [-9.9931e-05,  6.0518e-05,  2.3882e-04],\n",
      "          [-8.1267e-06,  2.1413e-04, -9.1477e-05]],\n",
      "\n",
      "         [[ 2.0091e-04, -6.3290e-04,  1.9234e-04],\n",
      "          [-1.0996e-04, -1.3215e-03,  1.1897e-03],\n",
      "          [ 2.4637e-04, -9.5937e-04,  1.0467e-03]],\n",
      "\n",
      "         [[-6.2862e-04,  8.9510e-04, -1.4716e-05],\n",
      "          [-1.0704e-03, -1.4184e-03, -5.5591e-04],\n",
      "          [-1.6070e-04,  3.6750e-05,  5.9862e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.6625e-05, -7.0492e-06,  5.7980e-04],\n",
      "          [-5.9586e-05,  1.2596e-04, -2.7410e-04],\n",
      "          [-1.8265e-04,  3.5743e-04, -6.0761e-04]],\n",
      "\n",
      "         [[-3.3877e-05, -1.1194e-04, -2.8135e-05],\n",
      "          [-1.7210e-04,  4.2010e-04,  8.1511e-05],\n",
      "          [ 8.1748e-06, -4.3466e-05,  4.3649e-05]],\n",
      "\n",
      "         [[ 2.5654e-06, -5.6251e-05,  5.1486e-04],\n",
      "          [-7.4287e-05,  1.5547e-04, -4.7528e-04],\n",
      "          [-7.9446e-05,  6.7823e-05, -2.9267e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0028e-04,  2.3078e-04,  2.2112e-04],\n",
      "          [ 9.3522e-04,  4.3636e-04,  4.7878e-04],\n",
      "          [-1.4211e-05, -1.6474e-04, -1.8964e-05]],\n",
      "\n",
      "         [[ 1.2558e-04,  9.7014e-05,  5.2140e-05],\n",
      "          [ 8.6310e-04,  8.7991e-04,  6.3398e-04],\n",
      "          [ 8.2371e-04,  7.3000e-04,  2.0895e-04]],\n",
      "\n",
      "         [[ 3.1022e-05, -2.4172e-04, -4.0860e-05],\n",
      "          [-3.9633e-05, -3.8361e-04,  3.1625e-04],\n",
      "          [-4.3709e-04, -3.0164e-04, -1.6416e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0308e-04,  3.1927e-04,  9.5646e-05],\n",
      "          [ 3.6631e-04,  7.6635e-04,  5.6676e-04],\n",
      "          [-7.6300e-05,  3.3757e-04,  8.5905e-05]],\n",
      "\n",
      "         [[ 4.3219e-04,  5.9688e-04, -4.6901e-07],\n",
      "          [ 4.6612e-04,  6.4922e-04,  7.4215e-04],\n",
      "          [-8.8898e-06,  1.8625e-04,  1.5710e-04]],\n",
      "\n",
      "         [[ 4.4616e-06,  1.0152e-04, -1.1841e-04],\n",
      "          [-9.0588e-06,  3.9885e-04,  7.1072e-04],\n",
      "          [ 9.2136e-05,  5.5480e-04,  5.1958e-05]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.2181e-03, -1.6080e-04,  2.0534e-04],\n",
      "          [-2.3103e-04, -8.4839e-04, -1.0084e-04],\n",
      "          [ 7.9405e-05,  1.8685e-04,  1.6466e-05]],\n",
      "\n",
      "         [[-1.5393e-04, -6.3243e-04, -5.6058e-05],\n",
      "          [-4.3554e-04, -7.6212e-04,  1.5631e-04],\n",
      "          [-4.7900e-04, -3.4056e-04, -2.4525e-04]],\n",
      "\n",
      "         [[ 5.4213e-04, -3.2704e-05,  3.7743e-05],\n",
      "          [ 3.0200e-03,  6.4476e-04, -2.1072e-04],\n",
      "          [ 9.4276e-04, -1.6094e-03, -3.9229e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.0639e-04,  1.7843e-04,  3.7495e-04],\n",
      "          [ 8.7486e-04, -1.0782e-03, -2.3170e-04],\n",
      "          [-3.0329e-04, -4.4799e-04, -2.5150e-04]],\n",
      "\n",
      "         [[ 5.3958e-04, -3.1984e-04, -4.8649e-04],\n",
      "          [ 1.4291e-04, -1.0795e-03, -1.3944e-04],\n",
      "          [-1.0075e-05, -2.0520e-04,  4.2494e-05]],\n",
      "\n",
      "         [[-1.9613e-05, -2.1118e-04, -3.1673e-04],\n",
      "          [-1.7437e-04, -1.5659e-04, -7.7786e-04],\n",
      "          [ 1.0386e-05, -2.2615e-04, -1.9954e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0004e-04,  4.7484e-04,  2.5033e-04],\n",
      "          [ 1.7612e-04,  1.6421e-04, -7.6671e-05],\n",
      "          [ 3.6156e-05,  1.7928e-05,  3.9700e-04]],\n",
      "\n",
      "         [[ 7.3340e-05,  1.9103e-04,  1.0379e-04],\n",
      "          [ 2.0387e-04,  1.1024e-03,  5.1908e-04],\n",
      "          [ 1.1595e-05, -3.4053e-05, -6.5964e-04]],\n",
      "\n",
      "         [[-1.7869e-04, -1.1663e-04,  3.0308e-04],\n",
      "          [-7.2060e-04, -1.0438e-03,  3.1687e-05],\n",
      "          [-1.0298e-04, -1.6864e-04, -6.0022e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.8444e-04,  2.7060e-04,  5.3925e-04],\n",
      "          [ 5.1823e-04,  9.5249e-05,  5.7226e-04],\n",
      "          [ 3.4059e-04,  4.9958e-04, -8.1223e-05]],\n",
      "\n",
      "         [[ 4.1396e-04,  4.5562e-04,  6.2071e-04],\n",
      "          [ 2.0432e-04,  1.3194e-03,  7.9778e-04],\n",
      "          [ 6.6998e-06, -7.6630e-06, -8.7842e-05]],\n",
      "\n",
      "         [[ 4.6476e-06, -1.5406e-04,  3.0836e-04],\n",
      "          [ 8.5029e-05,  9.7344e-06,  4.6856e-04],\n",
      "          [ 1.9738e-05, -6.9606e-05, -3.5529e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3051e-04,  3.1136e-04, -1.2799e-04],\n",
      "          [ 1.8539e-04,  5.5007e-04,  3.9360e-05],\n",
      "          [-2.7996e-05,  1.1198e-05,  3.9973e-06]],\n",
      "\n",
      "         [[-1.7505e-06,  1.1648e-04, -3.4987e-05],\n",
      "          [ 3.0753e-04,  1.1873e-04, -3.4809e-04],\n",
      "          [ 5.2590e-04,  1.5464e-04, -3.3456e-04]],\n",
      "\n",
      "         [[ 8.3356e-05,  6.3744e-04,  5.9791e-04],\n",
      "          [ 2.8735e-04,  1.0009e-03,  8.8442e-04],\n",
      "          [-2.4149e-04,  2.5917e-04,  5.3925e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.5945e-05,  2.6861e-05, -2.4404e-04],\n",
      "          [-2.7840e-04,  1.3051e-04,  4.5759e-04],\n",
      "          [ 5.6888e-05,  1.5068e-04,  2.8126e-05]],\n",
      "\n",
      "         [[ 4.3805e-05,  4.3989e-04,  3.8374e-04],\n",
      "          [ 2.6760e-04,  4.5211e-04,  3.4147e-04],\n",
      "          [-3.1447e-06,  1.0965e-05, -7.0176e-05]],\n",
      "\n",
      "         [[ 1.0060e-05, -7.6114e-05, -7.5782e-05],\n",
      "          [-7.4110e-06,  2.9193e-04,  3.8172e-04],\n",
      "          [ 1.3054e-06,  1.0982e-04,  3.0477e-05]]]]))\n",
      "('res3.1.0.bias', Parameter containing:\n",
      "tensor([-1.9533e-08,  8.1121e-08, -2.3021e-08,  ..., -3.8754e-08,\n",
      "         7.9893e-09,  2.7417e-09]))\n",
      "('res3.1.1.weight', Parameter containing:\n",
      "tensor([0.2360, 0.2902, 0.3164,  ..., 0.3320, 0.3145, 0.2659]))\n",
      "('res3.1.1.bias', Parameter containing:\n",
      "tensor([-0.0062, -0.0059, -0.0114,  ..., -0.0195, -0.0107, -0.0110]))\n",
      "('classifier.2.weight', Parameter containing:\n",
      "tensor([[ 0.0200, -0.0110, -0.0124,  ..., -0.0258, -0.0354,  0.0168],\n",
      "        [ 0.0093, -0.0529,  0.0246,  ...,  0.0577, -0.0070,  0.0033],\n",
      "        [-0.0197,  0.0680, -0.0294,  ...,  0.0133,  0.0172,  0.0331],\n",
      "        ...,\n",
      "        [ 0.0218,  0.0692, -0.0108,  ...,  0.0053, -0.0075,  0.0254],\n",
      "        [ 0.0022,  0.0207,  0.0491,  ...,  0.0720,  0.0261, -0.0085],\n",
      "        [ 0.0722,  0.0334,  0.0537,  ..., -0.0166,  0.0488,  0.0007]]))\n",
      "('classifier.2.bias', Parameter containing:\n",
      "tensor([ 0.0479, -0.0028,  0.0398,  0.0062,  0.0287,  0.0191,  0.0354,  0.0323,\n",
      "         0.0306,  0.0422,  0.0499,  0.0177,  0.0429,  0.0073,  0.0396,  0.0391,\n",
      "         0.0480,  0.0242,  0.0266, -0.0088]))\n"
     ]
    }
   ],
   "source": [
    "for param in model20To100.named_parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet9(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (res1): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (res2): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv5): Sequential(\n",
       "    (0): Conv2d(512, 1028, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(1028, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (res3): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(1028, 1028, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1028, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(1028, 1028, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1028, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Flatten(start_dim=1, end_dim=-1)\n",
       "      (2): Linear(in_features=1028, out_features=20, bias=True)\n",
       "    )\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=20, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model20To100.classifier= nn.Sequential(model20To100.classifier,\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(20, 5),\n",
    "                                        )\n",
    "                                        \n",
    "model20To100=to_device(model20To100, device)\n",
    "model20To100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 9.623312950134277, 'val_acc': 0.20000000298023224}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial evaluation\n",
    "history = [evaluate(model20To100, testloader)]\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], last_lr: 0.00004, train_loss: 1.5951, val_loss: 1.6545, val_acc: 0.3280\n",
      "Epoch [1], last_lr: 0.00005, train_loss: 1.6057, val_loss: 1.6520, val_acc: 0.3300\n",
      "Epoch [2], last_lr: 0.00005, train_loss: 1.6016, val_loss: 1.6523, val_acc: 0.3320\n",
      "Epoch [3], last_lr: 0.00007, train_loss: 1.6034, val_loss: 1.6522, val_acc: 0.3300\n",
      "Epoch [4], last_lr: 0.00008, train_loss: 1.6132, val_loss: 1.6489, val_acc: 0.3340\n",
      "Epoch [5], last_lr: 0.00010, train_loss: 1.5890, val_loss: 1.6483, val_acc: 0.3340\n",
      "Epoch [6], last_lr: 0.00012, train_loss: 1.5986, val_loss: 1.6469, val_acc: 0.3340\n",
      "Epoch [7], last_lr: 0.00015, train_loss: 1.5946, val_loss: 1.6449, val_acc: 0.3380\n",
      "Epoch [8], last_lr: 0.00018, train_loss: 1.5891, val_loss: 1.6433, val_acc: 0.3400\n",
      "Epoch [9], last_lr: 0.00021, train_loss: 1.5852, val_loss: 1.6409, val_acc: 0.3340\n",
      "Epoch [10], last_lr: 0.00024, train_loss: 1.5863, val_loss: 1.6380, val_acc: 0.3360\n",
      "Epoch [11], last_lr: 0.00028, train_loss: 1.5683, val_loss: 1.6345, val_acc: 0.3460\n",
      "Epoch [12], last_lr: 0.00031, train_loss: 1.5720, val_loss: 1.6295, val_acc: 0.3500\n",
      "Epoch [13], last_lr: 0.00035, train_loss: 1.5812, val_loss: 1.6256, val_acc: 0.3460\n",
      "Epoch [14], last_lr: 0.00039, train_loss: 1.5724, val_loss: 1.6188, val_acc: 0.3500\n",
      "Epoch [15], last_lr: 0.00043, train_loss: 1.5647, val_loss: 1.6137, val_acc: 0.3520\n",
      "Epoch [16], last_lr: 0.00048, train_loss: 1.5640, val_loss: 1.6071, val_acc: 0.3520\n",
      "Epoch [17], last_lr: 0.00052, train_loss: 1.5533, val_loss: 1.6019, val_acc: 0.3540\n",
      "Epoch [18], last_lr: 0.00056, train_loss: 1.5422, val_loss: 1.5965, val_acc: 0.3540\n",
      "Epoch [19], last_lr: 0.00060, train_loss: 1.5481, val_loss: 1.5885, val_acc: 0.3600\n",
      "Epoch [20], last_lr: 0.00064, train_loss: 1.5347, val_loss: 1.5826, val_acc: 0.3680\n",
      "Epoch [21], last_lr: 0.00068, train_loss: 1.5405, val_loss: 1.5770, val_acc: 0.3560\n",
      "Epoch [22], last_lr: 0.00072, train_loss: 1.5202, val_loss: 1.5690, val_acc: 0.3640\n",
      "Epoch [23], last_lr: 0.00076, train_loss: 1.5097, val_loss: 1.5622, val_acc: 0.3620\n",
      "Epoch [24], last_lr: 0.00079, train_loss: 1.5183, val_loss: 1.5548, val_acc: 0.3660\n",
      "Epoch [25], last_lr: 0.00083, train_loss: 1.5065, val_loss: 1.5470, val_acc: 0.3760\n",
      "Epoch [26], last_lr: 0.00086, train_loss: 1.5031, val_loss: 1.5426, val_acc: 0.3720\n",
      "Epoch [27], last_lr: 0.00089, train_loss: 1.4875, val_loss: 1.5395, val_acc: 0.3780\n",
      "Epoch [28], last_lr: 0.00091, train_loss: 1.4912, val_loss: 1.5275, val_acc: 0.3820\n",
      "Epoch [29], last_lr: 0.00094, train_loss: 1.4961, val_loss: 1.5215, val_acc: 0.3820\n",
      "Epoch [30], last_lr: 0.00095, train_loss: 1.4770, val_loss: 1.5160, val_acc: 0.3760\n",
      "Epoch [31], last_lr: 0.00097, train_loss: 1.4576, val_loss: 1.5086, val_acc: 0.3960\n",
      "Epoch [32], last_lr: 0.00098, train_loss: 1.4582, val_loss: 1.5022, val_acc: 0.3900\n",
      "Epoch [33], last_lr: 0.00099, train_loss: 1.4613, val_loss: 1.5023, val_acc: 0.3900\n",
      "Epoch [34], last_lr: 0.00100, train_loss: 1.4491, val_loss: 1.4946, val_acc: 0.3920\n",
      "Epoch [35], last_lr: 0.00100, train_loss: 1.4575, val_loss: 1.4888, val_acc: 0.3960\n",
      "Epoch [36], last_lr: 0.00100, train_loss: 1.4466, val_loss: 1.4871, val_acc: 0.3940\n",
      "Epoch [37], last_lr: 0.00100, train_loss: 1.4495, val_loss: 1.4817, val_acc: 0.4020\n",
      "Epoch [38], last_lr: 0.00100, train_loss: 1.4430, val_loss: 1.4757, val_acc: 0.3960\n",
      "Epoch [39], last_lr: 0.00099, train_loss: 1.4477, val_loss: 1.4699, val_acc: 0.4000\n",
      "Epoch [40], last_lr: 0.00099, train_loss: 1.4275, val_loss: 1.4653, val_acc: 0.3880\n",
      "Epoch [41], last_lr: 0.00099, train_loss: 1.4384, val_loss: 1.4641, val_acc: 0.4060\n",
      "Epoch [42], last_lr: 0.00098, train_loss: 1.4219, val_loss: 1.4577, val_acc: 0.3960\n",
      "Epoch [43], last_lr: 0.00098, train_loss: 1.4123, val_loss: 1.4493, val_acc: 0.3960\n",
      "Epoch [44], last_lr: 0.00097, train_loss: 1.4132, val_loss: 1.4520, val_acc: 0.3980\n",
      "Epoch [45], last_lr: 0.00097, train_loss: 1.4256, val_loss: 1.4455, val_acc: 0.4040\n",
      "Epoch [46], last_lr: 0.00096, train_loss: 1.4086, val_loss: 1.4379, val_acc: 0.4060\n",
      "Epoch [47], last_lr: 0.00095, train_loss: 1.4026, val_loss: 1.4361, val_acc: 0.4040\n",
      "Epoch [48], last_lr: 0.00094, train_loss: 1.4055, val_loss: 1.4377, val_acc: 0.4020\n",
      "Epoch [49], last_lr: 0.00093, train_loss: 1.3954, val_loss: 1.4299, val_acc: 0.4020\n",
      "Epoch [50], last_lr: 0.00092, train_loss: 1.4100, val_loss: 1.4319, val_acc: 0.4100\n",
      "Epoch [51], last_lr: 0.00091, train_loss: 1.4033, val_loss: 1.4274, val_acc: 0.4020\n",
      "Epoch [52], last_lr: 0.00090, train_loss: 1.3974, val_loss: 1.4254, val_acc: 0.4120\n",
      "Epoch [53], last_lr: 0.00089, train_loss: 1.3866, val_loss: 1.4228, val_acc: 0.4000\n",
      "Epoch [54], last_lr: 0.00088, train_loss: 1.4018, val_loss: 1.4180, val_acc: 0.4120\n",
      "Epoch [55], last_lr: 0.00087, train_loss: 1.3918, val_loss: 1.4160, val_acc: 0.4120\n",
      "Epoch [56], last_lr: 0.00085, train_loss: 1.3640, val_loss: 1.4133, val_acc: 0.4100\n",
      "Epoch [57], last_lr: 0.00084, train_loss: 1.3812, val_loss: 1.4108, val_acc: 0.4200\n",
      "Epoch [58], last_lr: 0.00083, train_loss: 1.3800, val_loss: 1.4080, val_acc: 0.4180\n",
      "Epoch [59], last_lr: 0.00081, train_loss: 1.3708, val_loss: 1.4118, val_acc: 0.4180\n",
      "Epoch [60], last_lr: 0.00080, train_loss: 1.3865, val_loss: 1.4013, val_acc: 0.4180\n",
      "Epoch [61], last_lr: 0.00078, train_loss: 1.3803, val_loss: 1.4016, val_acc: 0.4060\n",
      "Epoch [62], last_lr: 0.00077, train_loss: 1.3786, val_loss: 1.4006, val_acc: 0.4120\n",
      "Epoch [63], last_lr: 0.00075, train_loss: 1.3672, val_loss: 1.3966, val_acc: 0.4220\n",
      "Epoch [64], last_lr: 0.00073, train_loss: 1.3700, val_loss: 1.3980, val_acc: 0.4180\n",
      "Epoch [65], last_lr: 0.00072, train_loss: 1.3733, val_loss: 1.3938, val_acc: 0.4340\n",
      "Epoch [66], last_lr: 0.00070, train_loss: 1.3683, val_loss: 1.3971, val_acc: 0.4160\n",
      "Epoch [67], last_lr: 0.00068, train_loss: 1.3694, val_loss: 1.3894, val_acc: 0.4300\n",
      "Epoch [68], last_lr: 0.00067, train_loss: 1.3687, val_loss: 1.3902, val_acc: 0.4160\n",
      "Epoch [69], last_lr: 0.00065, train_loss: 1.3707, val_loss: 1.3845, val_acc: 0.4280\n",
      "Epoch [70], last_lr: 0.00063, train_loss: 1.3675, val_loss: 1.3860, val_acc: 0.4160\n",
      "Epoch [71], last_lr: 0.00061, train_loss: 1.3696, val_loss: 1.3803, val_acc: 0.4240\n",
      "Epoch [72], last_lr: 0.00059, train_loss: 1.3610, val_loss: 1.3812, val_acc: 0.4180\n",
      "Epoch [73], last_lr: 0.00057, train_loss: 1.3587, val_loss: 1.3785, val_acc: 0.4300\n",
      "Epoch [74], last_lr: 0.00056, train_loss: 1.3520, val_loss: 1.3792, val_acc: 0.4220\n",
      "Epoch [75], last_lr: 0.00054, train_loss: 1.3554, val_loss: 1.3751, val_acc: 0.4320\n",
      "Epoch [76], last_lr: 0.00052, train_loss: 1.3530, val_loss: 1.3765, val_acc: 0.4320\n",
      "Epoch [77], last_lr: 0.00050, train_loss: 1.3434, val_loss: 1.3754, val_acc: 0.4300\n",
      "Epoch [78], last_lr: 0.00048, train_loss: 1.3646, val_loss: 1.3734, val_acc: 0.4300\n",
      "Epoch [79], last_lr: 0.00046, train_loss: 1.3437, val_loss: 1.3717, val_acc: 0.4360\n",
      "Epoch [80], last_lr: 0.00044, train_loss: 1.3593, val_loss: 1.3721, val_acc: 0.4260\n",
      "Epoch [81], last_lr: 0.00043, train_loss: 1.3540, val_loss: 1.3710, val_acc: 0.4360\n",
      "Epoch [82], last_lr: 0.00041, train_loss: 1.3512, val_loss: 1.3698, val_acc: 0.4460\n",
      "Epoch [83], last_lr: 0.00039, train_loss: 1.3468, val_loss: 1.3698, val_acc: 0.4360\n",
      "Epoch [84], last_lr: 0.00037, train_loss: 1.3599, val_loss: 1.3684, val_acc: 0.4380\n",
      "Epoch [85], last_lr: 0.00035, train_loss: 1.3635, val_loss: 1.3678, val_acc: 0.4360\n",
      "Epoch [86], last_lr: 0.00033, train_loss: 1.3536, val_loss: 1.3666, val_acc: 0.4380\n",
      "Epoch [87], last_lr: 0.00032, train_loss: 1.3375, val_loss: 1.3656, val_acc: 0.4420\n",
      "Epoch [88], last_lr: 0.00030, train_loss: 1.3505, val_loss: 1.3656, val_acc: 0.4400\n",
      "Epoch [89], last_lr: 0.00028, train_loss: 1.3441, val_loss: 1.3649, val_acc: 0.4460\n",
      "Epoch [90], last_lr: 0.00027, train_loss: 1.3532, val_loss: 1.3645, val_acc: 0.4420\n",
      "Epoch [91], last_lr: 0.00025, train_loss: 1.3587, val_loss: 1.3644, val_acc: 0.4380\n",
      "Epoch [92], last_lr: 0.00023, train_loss: 1.3585, val_loss: 1.3631, val_acc: 0.4440\n",
      "Epoch [93], last_lr: 0.00022, train_loss: 1.3408, val_loss: 1.3625, val_acc: 0.4440\n",
      "Epoch [94], last_lr: 0.00020, train_loss: 1.3546, val_loss: 1.3619, val_acc: 0.4440\n",
      "Epoch [95], last_lr: 0.00019, train_loss: 1.3406, val_loss: 1.3616, val_acc: 0.4440\n",
      "Epoch [96], last_lr: 0.00017, train_loss: 1.3532, val_loss: 1.3614, val_acc: 0.4380\n",
      "Epoch [97], last_lr: 0.00016, train_loss: 1.3463, val_loss: 1.3619, val_acc: 0.4460\n",
      "Epoch [98], last_lr: 0.00015, train_loss: 1.3479, val_loss: 1.3618, val_acc: 0.4500\n",
      "Epoch [99], last_lr: 0.00013, train_loss: 1.3343, val_loss: 1.3617, val_acc: 0.4480\n",
      "Epoch [100], last_lr: 0.00012, train_loss: 1.3497, val_loss: 1.3609, val_acc: 0.4440\n",
      "Epoch [101], last_lr: 0.00011, train_loss: 1.3504, val_loss: 1.3601, val_acc: 0.4420\n",
      "Epoch [102], last_lr: 0.00010, train_loss: 1.3455, val_loss: 1.3606, val_acc: 0.4460\n",
      "Epoch [103], last_lr: 0.00009, train_loss: 1.3424, val_loss: 1.3605, val_acc: 0.4500\n",
      "Epoch [104], last_lr: 0.00008, train_loss: 1.3479, val_loss: 1.3602, val_acc: 0.4440\n",
      "Epoch [105], last_lr: 0.00007, train_loss: 1.3346, val_loss: 1.3595, val_acc: 0.4480\n",
      "Epoch [106], last_lr: 0.00006, train_loss: 1.3388, val_loss: 1.3588, val_acc: 0.4440\n",
      "Epoch [107], last_lr: 0.00005, train_loss: 1.3434, val_loss: 1.3595, val_acc: 0.4420\n",
      "Epoch [108], last_lr: 0.00004, train_loss: 1.3356, val_loss: 1.3593, val_acc: 0.4440\n",
      "Epoch [109], last_lr: 0.00003, train_loss: 1.3447, val_loss: 1.3592, val_acc: 0.4440\n",
      "Epoch [110], last_lr: 0.00003, train_loss: 1.3334, val_loss: 1.3595, val_acc: 0.4460\n",
      "Epoch [111], last_lr: 0.00002, train_loss: 1.3345, val_loss: 1.3598, val_acc: 0.4440\n",
      "Epoch [112], last_lr: 0.00002, train_loss: 1.3493, val_loss: 1.3598, val_acc: 0.4480\n",
      "Epoch [113], last_lr: 0.00001, train_loss: 1.3436, val_loss: 1.3597, val_acc: 0.4420\n",
      "Epoch [114], last_lr: 0.00001, train_loss: 1.3392, val_loss: 1.3594, val_acc: 0.4460\n",
      "Epoch [115], last_lr: 0.00001, train_loss: 1.3426, val_loss: 1.3597, val_acc: 0.4420\n",
      "Epoch [116], last_lr: 0.00000, train_loss: 1.3467, val_loss: 1.3595, val_acc: 0.4440\n",
      "Epoch [117], last_lr: 0.00000, train_loss: 1.3459, val_loss: 1.3592, val_acc: 0.4420\n",
      "Epoch [118], last_lr: 0.00000, train_loss: 1.3352, val_loss: 1.3594, val_acc: 0.4400\n",
      "Epoch [119], last_lr: 0.00000, train_loss: 1.3368, val_loss: 1.3590, val_acc: 0.4420\n"
     ]
    }
   ],
   "source": [
    "# Fitting the first 1/4 epochs\n",
    "#current_time=time.time()\n",
    "history += fit_one_cycle(int(epochs), max_lr, model20To100, trainloader, testloader, \n",
    "                             grad_clip=grad_clip, \n",
    "                             weight_decay=weight_decay, \n",
    "                             opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fitting the second 1/4 epochs\n",
    "# history += fit_one_cycle(int(epochs/4), max_lr/10, model20To100, trainloader, testloader, \n",
    "#                              grad_clip=grad_clip, \n",
    "#                              weight_decay=weight_decay, \n",
    "#                              opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[369  22   0   0   1   5   1   2   7   4   2  10  19  11   4  19  23   0\n",
      "    1   0]\n",
      " [ 28 384   5   4   6   7   1   4   1   1   3   4   2   3   6  23  13   0\n",
      "    3   2]\n",
      " [  0   3 463   1   8   3   0  13   0   1   1   0   0   3   1   2   0   0\n",
      "    1   0]\n",
      " [  0   5   1 416   7  28   3   1   1   4   0   2   4   9   7   5   0   1\n",
      "    1   5]\n",
      " [  2   2  17   7 430   6   1   4   1   2   2   5   2   8   0   4   5   0\n",
      "    0   2]\n",
      " [  2   1   1  27   5 403  17   5   0   4   2   0   1   2  10   4   4   1\n",
      "    6   5]\n",
      " [  2   0   1  14   1  18 431   3   1   3   2   0   0   2   4   5   2   0\n",
      "    6   5]\n",
      " [  3   4  10   2   2   2   0 420   3   1   0   1   6  23   4  14   3   0\n",
      "    0   2]\n",
      " [ 27   0   0   1   3   1   2   1 384   0   1  20  23   4   2  13  16   0\n",
      "    2   0]\n",
      " [  1   0   0   1   1   5   3   0   0 449   9   2   0   2   0   1   0   3\n",
      "    8  15]\n",
      " [  2   4   3   0   2   1   2   6   4   9 436   2   3   1   0   2   1  16\n",
      "    1   5]\n",
      " [ 15   1   0   1   4   3   0   1  14   2   2 401   9   4   6  14  19   2\n",
      "    1   1]\n",
      " [ 17   3   2   1   1   0   2   8  20   1   0   9 381   9   1  13  27   0\n",
      "    1   4]\n",
      " [  2   8   5   7   5   7   2  27   3   0   1   6   4 380   3  29   6   1\n",
      "    1   3]\n",
      " [  2   4   3   2   6   4   3   3   0   0   0   8   0   4 453   3   3   0\n",
      "    1   1]\n",
      " [ 27  23   2   3   1   1   1  15   6   2   2  11   7  34   2 347  11   1\n",
      "    1   3]\n",
      " [ 29   4   3   3   4   0   2  11  14   0   1  14  22   8   2  13 367   0\n",
      "    1   2]\n",
      " [  1   2   0   0   2   2   0   1   1   6  12   0   2   3   0   2   1 464\n",
      "    1   0]\n",
      " [  0   1   0   4   0   6   1   1   0   7   0   0   1   2   1   1   0   0\n",
      "  448  27]\n",
      " [  3   0   0   4   2   7   6   4   0  18   2   1   1   1   0   3   0   2\n",
      "   41 405]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.74      0.72       500\n",
      "           1       0.82      0.77      0.79       500\n",
      "           2       0.90      0.93      0.91       500\n",
      "           3       0.84      0.83      0.83       500\n",
      "           4       0.88      0.86      0.87       500\n",
      "           5       0.79      0.81      0.80       500\n",
      "           6       0.90      0.86      0.88       500\n",
      "           7       0.79      0.84      0.82       500\n",
      "           8       0.83      0.77      0.80       500\n",
      "           9       0.87      0.90      0.89       500\n",
      "          10       0.91      0.87      0.89       500\n",
      "          11       0.81      0.80      0.81       500\n",
      "          12       0.78      0.76      0.77       500\n",
      "          13       0.74      0.76      0.75       500\n",
      "          14       0.90      0.91      0.90       500\n",
      "          15       0.67      0.69      0.68       500\n",
      "          16       0.73      0.73      0.73       500\n",
      "          17       0.95      0.93      0.94       500\n",
      "          18       0.85      0.90      0.87       500\n",
      "          19       0.83      0.81      0.82       500\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.82      0.82      0.82     10000\n",
      "weighted avg       0.82      0.82      0.82     10000\n",
      "\n",
      "F1 score: 0.823346\n",
      "Recall score: 0.823100\n",
      "Accuracy score: 0.823100\n"
     ]
    }
   ],
   "source": [
    "y_test, y_pred = test_label_predictions(model20To100, device, testloader)\n",
    "cm=confusion_matrix(y_test, y_pred)\n",
    "cr=classification_report(y_test, y_pred)\n",
    "fs=f1_score(y_test,y_pred,average='weighted')\n",
    "rs=recall_score(y_test, y_pred,average='weighted')\n",
    "accuracy=accuracy_score(y_test, y_pred)\n",
    "print('Confusion matrix:')\n",
    "print(cm)\n",
    "print(cr)\n",
    "print('F1 score: %f' % fs)\n",
    "print('Recall score: %f' % rs)\n",
    "print('Accuracy score: %f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              ReLU-3           [-1, 64, 32, 32]               0\n",
      "            Conv2d-4          [-1, 128, 32, 32]          73,856\n",
      "       BatchNorm2d-5          [-1, 128, 32, 32]             256\n",
      "              ReLU-6          [-1, 128, 32, 32]               0\n",
      "         MaxPool2d-7          [-1, 128, 16, 16]               0\n",
      "            Conv2d-8          [-1, 128, 16, 16]         147,584\n",
      "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
      "             ReLU-10          [-1, 128, 16, 16]               0\n",
      "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
      "             ReLU-13          [-1, 128, 16, 16]               0\n",
      "           Conv2d-14          [-1, 256, 16, 16]         295,168\n",
      "      BatchNorm2d-15          [-1, 256, 16, 16]             512\n",
      "             ReLU-16          [-1, 256, 16, 16]               0\n",
      "        MaxPool2d-17            [-1, 256, 8, 8]               0\n",
      "           Conv2d-18            [-1, 512, 8, 8]       1,180,160\n",
      "      BatchNorm2d-19            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-20            [-1, 512, 8, 8]               0\n",
      "        MaxPool2d-21            [-1, 512, 4, 4]               0\n",
      "           Conv2d-22            [-1, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-23            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-24            [-1, 512, 4, 4]               0\n",
      "           Conv2d-25            [-1, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-27            [-1, 512, 4, 4]               0\n",
      "           Conv2d-28           [-1, 1028, 4, 4]       4,738,052\n",
      "      BatchNorm2d-29           [-1, 1028, 4, 4]           2,056\n",
      "             ReLU-30           [-1, 1028, 4, 4]               0\n",
      "        MaxPool2d-31           [-1, 1028, 2, 2]               0\n",
      "           Conv2d-32           [-1, 1028, 2, 2]       9,512,084\n",
      "      BatchNorm2d-33           [-1, 1028, 2, 2]           2,056\n",
      "             ReLU-34           [-1, 1028, 2, 2]               0\n",
      "           Conv2d-35           [-1, 1028, 2, 2]       9,512,084\n",
      "      BatchNorm2d-36           [-1, 1028, 2, 2]           2,056\n",
      "             ReLU-37           [-1, 1028, 2, 2]               0\n",
      "        MaxPool2d-38           [-1, 1028, 1, 1]               0\n",
      "          Flatten-39                 [-1, 1028]               0\n",
      "           Linear-40                   [-1, 20]          20,580\n",
      "================================================================\n",
      "Total params: 30,359,208\n",
      "Trainable params: 30,359,208\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 9.67\n",
      "Params size (MB): 115.81\n",
      "Estimated Total Size (MB): 125.50\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(summary(model20To100,(3, 32, 32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parent to children Network is more complicated now (20 to 10 to 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model20To100 = ResNet9(3, 20, True)\n",
    "model20To100.load_state_dict(torch.load('group_1028_to_parent_Loss_parent_only_pretrained_model.h5'))\n",
    "for param in model20To100.parameters():\n",
    "    param.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model20To100.classifier= nn.Sequential(model20To100.classifier,\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(20, 10),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(10, 5),\n",
    "                                        )\n",
    "                                        \n",
    "model20To100=to_device(model20To100, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 3.027127265930176, 'val_acc': 0.1979999989271164}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial evaluation\n",
    "history = [evaluate(model20To100, testloader)]\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], last_lr: 0.00004, train_loss: 1.3138, val_loss: 1.3121, val_acc: 0.4640\n",
      "Epoch [1], last_lr: 0.00005, train_loss: 1.3205, val_loss: 1.3121, val_acc: 0.4640\n",
      "Epoch [2], last_lr: 0.00005, train_loss: 1.3114, val_loss: 1.3120, val_acc: 0.4620\n",
      "Epoch [3], last_lr: 0.00007, train_loss: 1.3214, val_loss: 1.3122, val_acc: 0.4640\n",
      "Epoch [4], last_lr: 0.00008, train_loss: 1.3093, val_loss: 1.3122, val_acc: 0.4640\n",
      "Epoch [5], last_lr: 0.00010, train_loss: 1.3202, val_loss: 1.3128, val_acc: 0.4640\n",
      "Epoch [6], last_lr: 0.00012, train_loss: 1.3181, val_loss: 1.3125, val_acc: 0.4640\n",
      "Epoch [7], last_lr: 0.00015, train_loss: 1.3174, val_loss: 1.3116, val_acc: 0.4640\n",
      "Epoch [8], last_lr: 0.00018, train_loss: 1.3195, val_loss: 1.3120, val_acc: 0.4620\n",
      "Epoch [9], last_lr: 0.00021, train_loss: 1.3114, val_loss: 1.3126, val_acc: 0.4580\n",
      "Epoch [10], last_lr: 0.00024, train_loss: 1.3221, val_loss: 1.3123, val_acc: 0.4580\n",
      "Epoch [11], last_lr: 0.00028, train_loss: 1.3178, val_loss: 1.3130, val_acc: 0.4600\n",
      "Epoch [12], last_lr: 0.00031, train_loss: 1.3205, val_loss: 1.3129, val_acc: 0.4580\n",
      "Epoch [13], last_lr: 0.00035, train_loss: 1.3169, val_loss: 1.3123, val_acc: 0.4600\n",
      "Epoch [14], last_lr: 0.00039, train_loss: 1.3281, val_loss: 1.3125, val_acc: 0.4580\n",
      "Epoch [15], last_lr: 0.00043, train_loss: 1.3237, val_loss: 1.3121, val_acc: 0.4640\n",
      "Epoch [16], last_lr: 0.00048, train_loss: 1.3171, val_loss: 1.3127, val_acc: 0.4620\n",
      "Epoch [17], last_lr: 0.00052, train_loss: 1.3209, val_loss: 1.3111, val_acc: 0.4680\n",
      "Epoch [18], last_lr: 0.00056, train_loss: 1.3179, val_loss: 1.3125, val_acc: 0.4560\n",
      "Epoch [19], last_lr: 0.00060, train_loss: 1.3184, val_loss: 1.3115, val_acc: 0.4540\n",
      "Epoch [20], last_lr: 0.00064, train_loss: 1.3250, val_loss: 1.3118, val_acc: 0.4580\n",
      "Epoch [21], last_lr: 0.00068, train_loss: 1.3173, val_loss: 1.3133, val_acc: 0.4640\n",
      "Epoch [22], last_lr: 0.00072, train_loss: 1.3307, val_loss: 1.3116, val_acc: 0.4620\n",
      "Epoch [23], last_lr: 0.00076, train_loss: 1.3205, val_loss: 1.3124, val_acc: 0.4460\n",
      "Epoch [24], last_lr: 0.00079, train_loss: 1.3222, val_loss: 1.3116, val_acc: 0.4620\n",
      "Epoch [25], last_lr: 0.00083, train_loss: 1.3155, val_loss: 1.3127, val_acc: 0.4520\n",
      "Epoch [26], last_lr: 0.00086, train_loss: 1.3220, val_loss: 1.3132, val_acc: 0.4680\n",
      "Epoch [27], last_lr: 0.00089, train_loss: 1.3216, val_loss: 1.3116, val_acc: 0.4560\n",
      "Epoch [28], last_lr: 0.00091, train_loss: 1.3156, val_loss: 1.3118, val_acc: 0.4600\n",
      "Epoch [29], last_lr: 0.00094, train_loss: 1.3160, val_loss: 1.3124, val_acc: 0.4560\n",
      "Epoch [30], last_lr: 0.00095, train_loss: 1.3081, val_loss: 1.3119, val_acc: 0.4640\n",
      "Epoch [31], last_lr: 0.00097, train_loss: 1.3197, val_loss: 1.3151, val_acc: 0.4560\n",
      "Epoch [32], last_lr: 0.00098, train_loss: 1.3095, val_loss: 1.3110, val_acc: 0.4580\n",
      "Epoch [33], last_lr: 0.00099, train_loss: 1.3236, val_loss: 1.3121, val_acc: 0.4660\n",
      "Epoch [34], last_lr: 0.00100, train_loss: 1.3185, val_loss: 1.3107, val_acc: 0.4620\n",
      "Epoch [35], last_lr: 0.00100, train_loss: 1.3198, val_loss: 1.3128, val_acc: 0.4540\n",
      "Epoch [36], last_lr: 0.00100, train_loss: 1.3199, val_loss: 1.3093, val_acc: 0.4620\n",
      "Epoch [37], last_lr: 0.00100, train_loss: 1.3212, val_loss: 1.3125, val_acc: 0.4560\n",
      "Epoch [38], last_lr: 0.00100, train_loss: 1.3241, val_loss: 1.3125, val_acc: 0.4600\n",
      "Epoch [39], last_lr: 0.00099, train_loss: 1.3145, val_loss: 1.3130, val_acc: 0.4580\n",
      "Epoch [40], last_lr: 0.00099, train_loss: 1.3234, val_loss: 1.3111, val_acc: 0.4560\n",
      "Epoch [41], last_lr: 0.00099, train_loss: 1.3157, val_loss: 1.3129, val_acc: 0.4480\n",
      "Epoch [42], last_lr: 0.00098, train_loss: 1.3277, val_loss: 1.3113, val_acc: 0.4560\n",
      "Epoch [43], last_lr: 0.00098, train_loss: 1.3147, val_loss: 1.3127, val_acc: 0.4560\n",
      "Epoch [44], last_lr: 0.00097, train_loss: 1.3177, val_loss: 1.3114, val_acc: 0.4520\n",
      "Epoch [45], last_lr: 0.00097, train_loss: 1.3103, val_loss: 1.3110, val_acc: 0.4540\n",
      "Epoch [46], last_lr: 0.00096, train_loss: 1.3134, val_loss: 1.3101, val_acc: 0.4520\n",
      "Epoch [47], last_lr: 0.00095, train_loss: 1.3099, val_loss: 1.3112, val_acc: 0.4580\n",
      "Epoch [48], last_lr: 0.00094, train_loss: 1.3139, val_loss: 1.3109, val_acc: 0.4560\n",
      "Epoch [49], last_lr: 0.00093, train_loss: 1.3196, val_loss: 1.3109, val_acc: 0.4520\n",
      "Epoch [50], last_lr: 0.00092, train_loss: 1.3081, val_loss: 1.3138, val_acc: 0.4500\n",
      "Epoch [51], last_lr: 0.00091, train_loss: 1.3138, val_loss: 1.3091, val_acc: 0.4520\n",
      "Epoch [52], last_lr: 0.00090, train_loss: 1.3100, val_loss: 1.3101, val_acc: 0.4500\n",
      "Epoch [53], last_lr: 0.00089, train_loss: 1.3040, val_loss: 1.3153, val_acc: 0.4540\n",
      "Epoch [54], last_lr: 0.00088, train_loss: 1.3235, val_loss: 1.3129, val_acc: 0.4500\n",
      "Epoch [55], last_lr: 0.00087, train_loss: 1.3218, val_loss: 1.3126, val_acc: 0.4560\n",
      "Epoch [56], last_lr: 0.00085, train_loss: 1.3185, val_loss: 1.3137, val_acc: 0.4600\n",
      "Epoch [57], last_lr: 0.00084, train_loss: 1.3089, val_loss: 1.3143, val_acc: 0.4600\n",
      "Epoch [58], last_lr: 0.00083, train_loss: 1.3168, val_loss: 1.3129, val_acc: 0.4640\n",
      "Epoch [59], last_lr: 0.00081, train_loss: 1.3171, val_loss: 1.3129, val_acc: 0.4560\n",
      "Epoch [60], last_lr: 0.00080, train_loss: 1.3092, val_loss: 1.3136, val_acc: 0.4580\n",
      "Epoch [61], last_lr: 0.00078, train_loss: 1.3212, val_loss: 1.3100, val_acc: 0.4640\n",
      "Epoch [62], last_lr: 0.00077, train_loss: 1.3004, val_loss: 1.3122, val_acc: 0.4580\n",
      "Epoch [63], last_lr: 0.00075, train_loss: 1.3021, val_loss: 1.3101, val_acc: 0.4640\n",
      "Epoch [64], last_lr: 0.00073, train_loss: 1.3166, val_loss: 1.3096, val_acc: 0.4600\n",
      "Epoch [65], last_lr: 0.00072, train_loss: 1.3106, val_loss: 1.3116, val_acc: 0.4600\n",
      "Epoch [66], last_lr: 0.00070, train_loss: 1.3088, val_loss: 1.3106, val_acc: 0.4640\n",
      "Epoch [67], last_lr: 0.00068, train_loss: 1.3144, val_loss: 1.3100, val_acc: 0.4580\n",
      "Epoch [68], last_lr: 0.00067, train_loss: 1.3104, val_loss: 1.3102, val_acc: 0.4600\n",
      "Epoch [69], last_lr: 0.00065, train_loss: 1.3089, val_loss: 1.3112, val_acc: 0.4660\n",
      "Epoch [70], last_lr: 0.00063, train_loss: 1.3096, val_loss: 1.3117, val_acc: 0.4600\n",
      "Epoch [71], last_lr: 0.00061, train_loss: 1.3200, val_loss: 1.3086, val_acc: 0.4660\n",
      "Epoch [72], last_lr: 0.00059, train_loss: 1.3178, val_loss: 1.3112, val_acc: 0.4580\n",
      "Epoch [73], last_lr: 0.00057, train_loss: 1.3154, val_loss: 1.3078, val_acc: 0.4640\n",
      "Epoch [74], last_lr: 0.00056, train_loss: 1.3108, val_loss: 1.3107, val_acc: 0.4640\n",
      "Epoch [75], last_lr: 0.00054, train_loss: 1.3157, val_loss: 1.3073, val_acc: 0.4620\n",
      "Epoch [76], last_lr: 0.00052, train_loss: 1.3015, val_loss: 1.3122, val_acc: 0.4620\n",
      "Epoch [77], last_lr: 0.00050, train_loss: 1.3123, val_loss: 1.3065, val_acc: 0.4640\n",
      "Epoch [78], last_lr: 0.00048, train_loss: 1.3088, val_loss: 1.3081, val_acc: 0.4560\n",
      "Epoch [79], last_lr: 0.00046, train_loss: 1.3038, val_loss: 1.3071, val_acc: 0.4620\n",
      "Epoch [80], last_lr: 0.00044, train_loss: 1.3087, val_loss: 1.3075, val_acc: 0.4620\n",
      "Epoch [81], last_lr: 0.00043, train_loss: 1.3177, val_loss: 1.3090, val_acc: 0.4520\n",
      "Epoch [82], last_lr: 0.00041, train_loss: 1.3124, val_loss: 1.3078, val_acc: 0.4600\n",
      "Epoch [83], last_lr: 0.00039, train_loss: 1.3125, val_loss: 1.3082, val_acc: 0.4600\n",
      "Epoch [84], last_lr: 0.00037, train_loss: 1.3187, val_loss: 1.3083, val_acc: 0.4580\n",
      "Epoch [85], last_lr: 0.00035, train_loss: 1.3143, val_loss: 1.3069, val_acc: 0.4620\n",
      "Epoch [86], last_lr: 0.00033, train_loss: 1.3150, val_loss: 1.3078, val_acc: 0.4600\n",
      "Epoch [87], last_lr: 0.00032, train_loss: 1.3116, val_loss: 1.3082, val_acc: 0.4600\n",
      "Epoch [88], last_lr: 0.00030, train_loss: 1.3127, val_loss: 1.3067, val_acc: 0.4620\n",
      "Epoch [89], last_lr: 0.00028, train_loss: 1.3113, val_loss: 1.3074, val_acc: 0.4560\n",
      "Epoch [90], last_lr: 0.00027, train_loss: 1.3064, val_loss: 1.3090, val_acc: 0.4580\n",
      "Epoch [91], last_lr: 0.00025, train_loss: 1.3073, val_loss: 1.3084, val_acc: 0.4600\n",
      "Epoch [92], last_lr: 0.00023, train_loss: 1.3209, val_loss: 1.3079, val_acc: 0.4640\n",
      "Epoch [93], last_lr: 0.00022, train_loss: 1.3161, val_loss: 1.3087, val_acc: 0.4560\n",
      "Epoch [94], last_lr: 0.00020, train_loss: 1.3103, val_loss: 1.3084, val_acc: 0.4620\n",
      "Epoch [95], last_lr: 0.00019, train_loss: 1.3066, val_loss: 1.3083, val_acc: 0.4640\n",
      "Epoch [96], last_lr: 0.00017, train_loss: 1.3169, val_loss: 1.3097, val_acc: 0.4580\n",
      "Epoch [97], last_lr: 0.00016, train_loss: 1.3112, val_loss: 1.3099, val_acc: 0.4600\n",
      "Epoch [98], last_lr: 0.00015, train_loss: 1.3165, val_loss: 1.3091, val_acc: 0.4600\n",
      "Epoch [99], last_lr: 0.00013, train_loss: 1.2965, val_loss: 1.3088, val_acc: 0.4620\n",
      "Epoch [100], last_lr: 0.00012, train_loss: 1.3065, val_loss: 1.3091, val_acc: 0.4540\n",
      "Epoch [101], last_lr: 0.00011, train_loss: 1.3070, val_loss: 1.3089, val_acc: 0.4540\n",
      "Epoch [102], last_lr: 0.00010, train_loss: 1.3138, val_loss: 1.3085, val_acc: 0.4580\n",
      "Epoch [103], last_lr: 0.00009, train_loss: 1.3086, val_loss: 1.3090, val_acc: 0.4640\n",
      "Epoch [104], last_lr: 0.00008, train_loss: 1.3134, val_loss: 1.3093, val_acc: 0.4620\n",
      "Epoch [105], last_lr: 0.00007, train_loss: 1.3079, val_loss: 1.3089, val_acc: 0.4560\n",
      "Epoch [106], last_lr: 0.00006, train_loss: 1.3092, val_loss: 1.3086, val_acc: 0.4560\n",
      "Epoch [107], last_lr: 0.00005, train_loss: 1.3130, val_loss: 1.3085, val_acc: 0.4520\n",
      "Epoch [108], last_lr: 0.00004, train_loss: 1.3152, val_loss: 1.3080, val_acc: 0.4540\n",
      "Epoch [109], last_lr: 0.00003, train_loss: 1.3071, val_loss: 1.3081, val_acc: 0.4520\n",
      "Epoch [110], last_lr: 0.00003, train_loss: 1.3130, val_loss: 1.3087, val_acc: 0.4560\n",
      "Epoch [111], last_lr: 0.00002, train_loss: 1.3089, val_loss: 1.3086, val_acc: 0.4540\n",
      "Epoch [112], last_lr: 0.00002, train_loss: 1.3066, val_loss: 1.3093, val_acc: 0.4540\n",
      "Epoch [113], last_lr: 0.00001, train_loss: 1.3009, val_loss: 1.3089, val_acc: 0.4540\n",
      "Epoch [114], last_lr: 0.00001, train_loss: 1.3051, val_loss: 1.3085, val_acc: 0.4540\n",
      "Epoch [115], last_lr: 0.00001, train_loss: 1.3005, val_loss: 1.3083, val_acc: 0.4540\n",
      "Epoch [116], last_lr: 0.00000, train_loss: 1.3142, val_loss: 1.3087, val_acc: 0.4540\n",
      "Epoch [117], last_lr: 0.00000, train_loss: 1.3112, val_loss: 1.3088, val_acc: 0.4560\n",
      "Epoch [118], last_lr: 0.00000, train_loss: 1.3079, val_loss: 1.3085, val_acc: 0.4560\n",
      "Epoch [119], last_lr: 0.00000, train_loss: 1.3140, val_loss: 1.3087, val_acc: 0.4540\n"
     ]
    }
   ],
   "source": [
    "# Fitting the first 1/4 epochs\n",
    "#current_time=time.time()\n",
    "history += fit_one_cycle(int(epochs), max_lr, model20To100, trainloader, testloader, \n",
    "                             grad_clip=grad_clip, \n",
    "                             weight_decay=weight_decay, \n",
    "                             opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
