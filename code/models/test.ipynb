{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/sebastiancavada/Documents/scsv/semester-1/ai/ai-project-2023/code/models/test.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sebastiancavada/Documents/scsv/semester-1/ai/ai-project-2023/code/models/test.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m n_layers \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mceil(torch\u001b[39m.\u001b[39mlog2(torch\u001b[39m.\u001b[39mtensor(n_classes)))\u001b[39m.\u001b[39mint()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sebastiancavada/Documents/scsv/semester-1/ai/ai-project-2023/code/models/test.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m choices \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(n_layers \u001b[39m*\u001b[39m batch_size, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mbool, device\u001b[39m=\u001b[39mdevice)\u001b[39m.\u001b[39mreshape(batch_size, n_layers)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sebastiancavada/Documents/scsv/semester-1/ai/ai-project-2023/code/models/test.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m modifier_bias \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mParameter(torch\u001b[39m.\u001b[39mrandn(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39moutput, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput))\u001b[39m.\u001b[39mto(device)        \n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "# prepare the tensor\n",
    "# tensor of 64 x 344 as input\n",
    "\n",
    "n_classes = 4\n",
    "batch_size = 4\n",
    "\n",
    "embeddings = torch.arange(batch_size*344).reshape(batch_size, 344)\n",
    "n_layers = torch.ceil(torch.log2(torch.tensor(n_classes))).int().item()\n",
    "choices = torch.zeros(n_layers * batch_size, dtype=torch.bool, device=device).reshape(batch_size, n_layers)\n",
    "\n",
    "modifier_bias = nn.Parameter(torch.randn(344, )).to(device)        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(_):\n",
    "    return torch.rand(batch_size * 2).reshape(batch_size, 2)\n",
    "\n",
    "def get_int_parameters(i, softmax_index):\n",
    "    print(softmax_index)\n",
    "    return (2 * i) + softmax_index\n",
    "\n",
    "def DiffSoftmax(logits, tau=1.0, hard=False, dim=-1):\n",
    "    y_soft = (logits / tau).softmax(dim)\n",
    "    if hard:\n",
    "        # Straight through.\n",
    "        index = y_soft.max(dim, keepdim=True)[1]\n",
    "        y_hard = torch.zeros_like(logits, memory_format=torch.legacy_contiguous_format).scatter_(dim, index, 1.0)\n",
    "        ret = y_hard - y_soft.detach() + y_soft\n",
    "    else:\n",
    "        # Reparametrization trick.\n",
    "        ret = y_soft\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False],\n",
      "        [False, False],\n",
      "        [False, False],\n",
      "        [False, False]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# prepare the tensor\n",
    "# tensor of 64 x 344 as input\n",
    "\n",
    "n_classes = 4\n",
    "batch_size = 4\n",
    "\n",
    "embeddings = torch.arange(batch_size*344).reshape(batch_size, 344)\n",
    "n_layers = torch.ceil(torch.log2(torch.tensor(n_classes))).int().item()\n",
    "choices = torch.zeros(n_layers * batch_size, dtype=torch.bool, device=device).reshape(batch_size, n_layers)\n",
    "\n",
    "print(choices)\n",
    "\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3169, 0.2540],\n",
      "        [0.9820, 0.0544],\n",
      "        [0.2194, 0.3662],\n",
      "        [0.5643, 0.0096]])\n",
      "tensor([[False, False],\n",
      "        [ True, False],\n",
      "        [False,  True],\n",
      "        [ True, False]], device='mps:0')\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "tensor([[2.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [2.]])\n"
     ]
    }
   ],
   "source": [
    "x = classifier(embeddings)\n",
    "print(x)\n",
    "softmax = DiffSoftmax(x, tau=1.0, hard=True, dim=-1)\n",
    "choices[:, i:i+1] = softmax[:, i:i+1]\n",
    "print(choices)\n",
    "shift_index = get_int_parameters(i, softmax[:, i:i+1])\n",
    "print(shift_index)\n",
    "#x = x + self.modifier_bias[shift_index]\n",
    "\n",
    "i +=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/sebastiancavada/Documents/scsv/semester-1/ai/ai-project-2023/code/models/test.ipynb Cell 7\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sebastiancavada/Documents/scsv/semester-1/ai/ai-project-2023/code/models/test.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# recurrent classifier that we need to learn\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sebastiancavada/Documents/scsv/semester-1/ai/ai-project-2023/code/models/test.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# first step is to learn the first part of the classifier\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sebastiancavada/Documents/scsv/semester-1/ai/ai-project-2023/code/models/test.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# what if instead that is also a learnable parameters over the different runs of the classifier\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sebastiancavada/Documents/scsv/semester-1/ai/ai-project-2023/code/models/test.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m n_layers \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mceil(torch\u001b[39m.\u001b[39mlog2(torch\u001b[39m.\u001b[39mtensor(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39minput)))\u001b[39m.\u001b[39mint()\u001b[39m.\u001b[39mitem() \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sebastiancavada/Documents/scsv/semester-1/ai/ai-project-2023/code/models/test.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# emtpty tensor of size n_layers, batch_size of datatype torch.bool\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sebastiancavada/Documents/scsv/semester-1/ai/ai-project-2023/code/models/test.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_layers):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "# recurrent classifier that we need to learn\n",
    "# first step is to learn the first part of the classifier\n",
    "# what if instead that is also a learnable parameters over the different runs of the classifier\n",
    "\n",
    "n_layers = torch.ceil(torch.log2(torch.tensor(self.input))).int().item() -1\n",
    "# emtpty tensor of size n_layers, batch_size of datatype torch.bool\n",
    "\n",
    "for i in range(n_layers):\n",
    "    x = self.modules[\"classifier\"](x)\n",
    "    softmax = self.DiffSoftmax(x, tau=1.0, hard=False, dim=-1)\n",
    "    choices[i][:] = torch.bernoulli(softmax[:,1])\n",
    "    shift_index = self.get_int_parameters(i, softmax)\n",
    "    x = x + self.modifier_bias[shift_index]\n",
    "    \n",
    "return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai701",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
