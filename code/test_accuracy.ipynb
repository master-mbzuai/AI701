{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from micromind import MicroMind, Metric\n",
    "from micromind.networks import PhiNet\n",
    "from micromind.utils.parse import parse_arguments\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    )\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(\n",
    "    root=\"data/cifar-100\", train=True, download=True, transform=transform\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size, shuffle=False, num_workers=1\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(\n",
    "        root=\"data/cifar-100\", train=False, download=True, transform=transform\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size, shuffle=False, num_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Running on the GPU\")\n",
    "elif torch.backends.mps.is_available: \n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Running on the MPS\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassification(MicroMind):\n",
    "\n",
    "    # test 1 with n as input vector size and m classes custom d\n",
    "    # n has to be calculated from the output of the neural network of the feature extractor\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.modules[\"feature_extractor\"] = PhiNet(\n",
    "            (3, 32, 32), include_top=True, num_classes=100, alpha=2\n",
    "        )        \n",
    "                \n",
    "        self.modules[\"feature_extractor\"].load_state_dict(torch.load(\"./pretrained/test.ckpt\", map_location=device)[\"classifier\"])\n",
    "\n",
    "    def forward(self, batch):\n",
    "        return self.modules[\"feature_extractor\"](batch[0])\n",
    "\n",
    "    def compute_loss(self, pred, batch):\n",
    "        return nn.CrossEntropyLoss()(pred, batch[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def parse_test():\n",
    "    parser = argparse.ArgumentParser(description=\"General configuration for micromind.\")\n",
    "\n",
    "    parser.add_argument(\"--lr\", type=float, default=0.001, help=\"Learning rate.\")\n",
    "    parser.add_argument(\n",
    "        \"--optimizer\",\n",
    "        dest=\"opt\",\n",
    "        default=\"adam\",\n",
    "        choices=[\"adam\", \"sgd\"],\n",
    "        help=\"Optimizer name.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--experiment_name\", default=\"exp\", help=\"Name of the experiment.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output_folder\", default=\"results\", help=\"Output folder path.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--debug\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Run in debug mode to check train and validation steps.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--d', \n",
    "        type=int\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args(\"\")\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is used ONLY if you are not using argparse to get the hparams\n",
    "hparams = parse_test()\n",
    "\n",
    "m = ImageClassification(hparams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(pred, batch):\n",
    "        # print(pred.argmax(1))\n",
    "        # print(batch[1])\n",
    "        equals = pred.argmax(1) == batch[1]        \n",
    "        tmp = (pred.argmax(1) == batch[1]).float()\n",
    "        return tmp\n",
    "\n",
    "\n",
    "acc = Metric(name=\"accuracy\", fn=compute_accuracy)\n",
    "\n",
    "m.train(\n",
    "    epochs=3,\n",
    "    datasets={\"train\": trainloader, \"val\": trainloader, \"test\": testloader},\n",
    "    metrics=[acc],\n",
    "    debug=hparams.debug,\n",
    ")\n",
    "\n",
    "m.test(\n",
    "    datasets={\"test\": testloader},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1328)\n",
      "true tensor(17) tot 128\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(trainloader))\n",
    "\n",
    "classes = trainloader.dataset.classes\n",
    "\n",
    "m.modules[\"feature_extractor\"].eval()\n",
    "res = m.modules[\"feature_extractor\"](train_features)\n",
    "\n",
    "pred = torch.argmax(res, dim=1)\n",
    "\n",
    "equal = pred.to('cpu') == train_labels\n",
    "\n",
    "# print(pred)\n",
    "# print(train_labels)\n",
    "# print(equal)\n",
    "\n",
    "accuracy = sum(equal)/len(equal)\n",
    "\n",
    "# figure = plt.figure(figsize=(16, 16))\n",
    "# cols, rows = 6, 6\n",
    "# for i in range(1, cols * rows + 1):   \n",
    "#     figure.add_subplot(rows, cols, i)    \n",
    "#     plt.title(\"GT \" + classes[train_labels[i]] + \" - P \" + classes[pred[i]] )\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.imshow(train_features[i].T)\n",
    "# plt.show()\n",
    "\n",
    "print(accuracy)\n",
    "print(\"true\", sum(equal), \"tot\", len(equal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9297)\n",
      "true tensor(119) tot 128\n"
     ]
    }
   ],
   "source": [
    "test_features, test_labels = next(iter(testloader))\n",
    "\n",
    "res_t = m.modules[\"feature_extractor\"](test_features)\n",
    "\n",
    "classes = testloader.dataset.classes\n",
    "\n",
    "pred_t = torch.argmax(res_t, dim=1)\n",
    "\n",
    "equal_t = pred_t.to('cpu') == test_labels\n",
    "\n",
    "# print(pred_t)\n",
    "# print(test_labels)\n",
    "# print(equal_t)\n",
    "\n",
    "accuracy = sum(equal_t)/len(equal_t)\n",
    "\n",
    "# figure = plt.figure(figsize=(16, 16))\n",
    "# cols, rows = 6, 6\n",
    "# for i in range(1, cols * rows + 1):   \n",
    "#     figure.add_subplot(rows, cols, i)    \n",
    "#     plt.title(\"GT \" + classes[test_labels[i]] + \" - P \" + classes[pred_t[i]] )\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.imshow(test_features[i].T)\n",
    "# plt.show()\n",
    "\n",
    "print(accuracy)\n",
    "print(\"true\", sum(equal_t), \"tot\", len(equal_t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai701",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
